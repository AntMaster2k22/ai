text,label
"Performance art
Performance art is an artwork or art exhibition created through actions executed by the artist or other participants. It may be witnessed live or through documentation, spontaneously developed or written, and is traditionally presented to a public in a fine art context in an interdisciplinary mode.[1] Also known as artistic action, it has been developed through the years as a genre of its own in which art is presented live. It had an important and fundamental role in 20th century avant-garde art.[2][3]
It involves five basic elements: time, space, body, presence of the artist, and the relation between the artist and the public. The actions, generally developed in art galleries and museums, can take place in any kind of setting or space, and during any time period.[4] Its goal is to generate a reaction, sometimes with the support of improvisation and a sense of aesthetics. The themes are commonly linked to life experiences of the artist themselves, the need for denunciation or social criticism and with a spirit of transformation.[5]
The term ""performance art"" and ""performance"" became widely used in the 1970s, even though the history of performance in visual arts dates back to futurist productions and cabarets from the 1910s.[6][1] Art critic and performance artist John Perreault credits Marjorie Strider with the invention of the term in 1969.[7] The main pioneers of performance art include Carolee Schneemann,[8] Marina Abramović,[9] Ana Mendieta,[10] Chris Burd",art_culture
"Street art
Street art is visual art created in public locations for public visibility. It has been associated with the terms ""independent art"", ""post-graffiti"", ""neo-graffiti"" and guerrilla art.[2]
Street art has evolved from the early forms of defiant graffiti into a more commercial form of art, as one of the main differences now lies with the messaging. Street art is often meant to provoke thought rather than rejection among the general audience through making its purpose more evident than that of graffiti. The issue of permission has also come at the heart of street art, as graffiti is usually done illegally, whereas street art can nowadays be the product of an agreement or even sometimes a commission. However, it remains different from traditional art exposed in public spaces by its explicit use of said space in the conception phase.
Background
[edit]Street art is a form of artwork that is displayed in public on surrounding buildings, on streets, trains and other publicly viewed surfaces. Many instances come in the form of guerrilla art, which is intended to make a personal statement about the society that the artist lives within. The work has moved from the beginnings of graffiti and vandalism to new modes where artists work to bring messages, or just beauty, to an audience.[3]
Some artists may use ""smart vandalism"" as a way to raise awareness of social and political issues,[4] whereas other artists use urban space as an opportunity to display personal artwork. Artists m",art_culture
"Art Deco
Art Deco, short for the French Arts décoratifs (lit. 'Decorative Arts'),[1] is a style of visual arts, architecture, and product design that first appeared in Paris in the 1910s just before World War I[2] and flourished in the United States, Mexico[3] and Europe during the 1920s to early 1930s, through styling and design of the exterior and interior of anything from large structures to small objects, including clothing, fashion, and jewelry. Art Deco has influenced buildings from skyscrapers to cinemas, bridges, ocean liners, trains, cars, trucks, buses, furniture, and everyday objects, including radios and vacuum cleaners.[4]
The name Art Deco came into use after the 1925 Exposition internationale des arts décoratifs et industriels modernes (International Exhibition of Modern Decorative and Industrial Arts) held in Paris.[5] It has its origin in the bold geometric forms of the Vienna Secession and Cubism. From the outset, Art Deco was influenced by the bright colors of Fauvism and the Ballets Russes, and the exoticized styles of art from China, Japan, India, Persia, ancient Egypt, and Maya. In its time, Art Deco was tagged with other names such as style moderne, Moderne, modernistic, or style contemporain, and it was not recognized as a distinct and homogeneous style.[6]
During its heyday, Art Deco represented luxury, glamour, exuberance, and faith in social and technological progress. The movement featured rare and expensive materials such as ebony and ivory, and e",art_culture
"Contemporary dance
Contemporary dance[1] is a genre of dance performance that developed during the mid-twentieth century and has since grown to become one of the dominant genres for formally trained dancers throughout the world, with particularly strong popularity in the U.S. and Europe. Although originally informed by and borrowing from classical, modern, and jazz styles, it has come to incorporate elements from many styles of dance.[2] According to the New Grove Musical Dictionary, contemporary dance evolved from the foundations of modern and postmodern dance, emphasizing innovation and a break from traditional forms.[3] Due to its technical similarities, it is often perceived to be closely related to modern dance, ballet, and other classical concert dance styles. It is characterized by a blend of styles that often integrate elements of ballet, modern dance, and cultural or social dance forms.[3]
In terms of technique, contemporary dance tends to combine the strong but controlled legwork of ballet with modern dance that stresses on torso. It also employs contract-release, floor work, fall and recovery, and improvisation characteristics of modern dance.[4] Unpredictable changes in rhythm, speed, and direction are often used as well. In the 1980s, the approach to contemporary dance became more intentional and academically focused, often described as “interdisciplinary” and “collaborative.” This period marked a shift from spontaneous and experimental methods to choreographies ",art_culture
"Impressionism
Impressionism was a 19th-century art movement characterized by visible brush strokes, open composition, emphasis on accurate depiction of light in its changing qualities (often accentuating the effects of the passage of time), ordinary subject matter, unusual visual angles, and inclusion of movement as a crucial element of human perception and experience. Impressionism originated with a group of Paris-based artists whose independent exhibitions brought them to prominence during the 1870s and 1880s.
The Impressionists faced harsh opposition from the conventional art community in France. The name of the style derives from the title of a Claude Monet work, Impression, soleil levant (Impression, Sunrise), which provoked the critic Louis Leroy to coin the term in a satirical 1874 review of the First Impressionist Exhibition published in the Parisian newspaper Le Charivari.[1] The development of Impressionism in the visual arts was soon followed by analogous styles in other media that became known as Impressionist music and Impressionist literature.
Overview
[edit]Radicals in their time, the early Impressionists violated the rules of academic painting. They constructed their pictures from freely brushed colours that took precedence over lines and contours, following the example of painters such as Eugène Delacroix and J. M. W. Turner. They also painted realistic scenes of everyday life in natural settings, often outdoors, attempting to capture a moment as experienced.",art_culture
"Surrealism
Surrealism is an art and cultural movement that developed in Europe in the aftermath of World War I in which artists aimed to allow the unconscious mind to express itself, often resulting in the depiction of illogical or dreamlike scenes and ideas.[1] Its intention was, according to leader André Breton, to ""resolve the previously contradictory conditions of dream and reality into an absolute reality, a super-reality"", or surreality.[2][3][4] It produced works of painting, writing, photography, theatre, filmmaking, music, comedy and other media as well.
Works of Surrealism feature the element of surprise, unexpected juxtapositions and non sequitur. However, many Surrealist artists and writers regard their work as an expression of the philosophical movement first and foremost (for instance, of the ""pure psychic automatism"" Breton speaks of in the first Surrealist Manifesto), with the works themselves being secondary, i.e., artifacts of surrealist experimentation.[5] Leader Breton was explicit in his assertion that Surrealism was, above all, a revolutionary movement. At the time, the movement was associated with political causes such as communism and anarchism. It was influenced by the Dada movement of the 1910s.[6]
The term ""Surrealism"" originated with Guillaume Apollinaire in 1917.[7][8] However, the Surrealist movement was not officially established until after October 1924, when the Surrealist Manifesto published by Breton succeeded in claiming the term for his gr",art_culture
"Cubism
Cubism is an early-20th-century avant-garde art movement which began in Paris. It revolutionized painting and the visual arts, and sparked artistic innovations in music, ballet, literature, and architecture.
Cubist subjects are analyzed, broken up, and reassembled in an abstract form. Instead of depicting objects from a single perspective, the artist depicts the subject from multiple perspectives to represent the subject in a greater context.[1] Cubism has been considered the most influential art movement of the 20th century.[2][3] The term cubism is broadly associated with a variety of artworks produced in Paris (Montmartre and Montparnasse) or near Paris (Puteaux) during the 1910s and throughout the 1920s.
The movement was pioneered in partnership by Pablo Picasso and Georges Braque, and joined by Jean Metzinger, Albert Gleizes, Robert Delaunay, Henri Le Fauconnier, Juan Gris, and Fernand Léger.[4] One primary influence that led to Cubism was the representation of three-dimensional form in the late works of Paul Cézanne.[2] A retrospective of Cézanne's paintings was held at the Salon d'Automne of 1904, current works were displayed at the 1905 and 1906 Salon d'Automne, followed by two commemorative retrospectives after his death in 1907.[5]
In France, offshoots of Cubism developed, including Orphism, abstract art and later Purism.[6][7] The impact of Cubism was far-reaching and wide-ranging in the arts and in popular culture. Cubism introduced collage as a modern art ",art_culture
"Abstract expressionism
Abstract expressionism in the United States emerged as a distinct art movement in the aftermath of World War II and gained mainstream acceptance in the 1950s, a shift from the American social realism of the 1930s influenced by the Great Depression and Mexican muralists.[1][2] The term was first applied to American art in 1946 by the art critic Robert Coates. Key figures in the New York School, which was the center of this movement, included such artists as Arshile Gorky, Jackson Pollock, Franz Kline, Mark Rothko, Norman Lewis, Willem de Kooning, Adolph Gottlieb, Clyfford Still, Robert Motherwell, Theodoros Stamos, and Lee Krasner among others.
The movement was not limited to painting but included influential collagists and sculptors, such as David Smith, Louise Nevelson, and others. Abstract expressionism was notably influenced by the spontaneous and subconscious creation methods of Surrealist artists like André Masson and Max Ernst. Artists associated with the movement combined the emotional intensity of German Expressionism with the radical visual vocabularies of European avant-garde schools like Futurism, the Bauhaus, and Synthetic Cubism.
Abstract expressionism was seen as rebellious and idiosyncratic, encompassing various artistic styles. It was the first specifically American movement to achieve international influence and put New York City at the center of the Western art world, a role formerly filled by Paris. Contemporary art critics played a s",art_culture
"Pop art
Pop art is an art movement that emerged in the United Kingdom and the United States during the mid- to late 1950s.[1][2] The movement presented a challenge to traditions of fine art by including imagery from popular and mass culture, such as advertising, comic books and mundane mass-produced objects. One of its aims is to use images of popular culture in art, emphasizing the banal or kitschy elements of any culture, most often through the use of irony.[3] It is also associated with the artists' use of mechanical means of reproduction or rendering techniques. In pop art, material is sometimes visually removed from its known context, isolated, or combined with unrelated material.[2][3]
Amongst the first artists that shaped the pop art movement were Eduardo Paolozzi and Richard Hamilton in Britain, and Larry Rivers, Ray Johnson, Robert Rauschenberg and Jasper Johns among others in the United States. Pop art is widely interpreted as a reaction to the then-dominant ideas of abstract expressionism, as well as an expansion of those ideas.[4] Due to its utilization of found objects and images, it is similar to Dada. Pop art and minimalism are considered to be art movements that precede postmodern art, or are some of the earliest examples of postmodern art themselves.[5]
Pop art often takes imagery that is currently in use in advertising. Product labeling and logos figure prominently in the imagery chosen by pop artists, seen in the labels of Campbell's Soup Cans, by Andy Warh",art_culture
"Minimalism
In visual arts, music, and other media, minimalism is an art movement that began in the post-war era in western art. The movement is interpreted as a reaction to abstract expressionism and modernism; it anticipated contemporary post-minimal art practices, which extend or reflect on minimalism's original objectives.[1] Minimalism's key objectives were to strip away conventional characterizations of art by bringing the importance of the object or the experience a viewer has for the object with minimal mediation from the artist.[2] Prominent artists associated with minimalism include Donald Judd, Agnes Martin, Dan Flavin, Carl Andre, Robert Morris, Anne Truitt, and Frank Stella.[3]
Minimalism in music features methods such as repetition and gradual variation, such as the works of La Monte Young, Terry Riley, Steve Reich, Philip Glass, Julius Eastman, and John Adams. The term is sometimes used to describe the plays and novels of Samuel Beckett, the films of Robert Bresson, the stories of Raymond Carver, and the automobile designs of Colin Chapman.
In recent years, minimalism has come to refer to anything or anyone that is spare or stripped to its essentials.[4]
Visual arts and literalist art
[edit]Minimalism in visual art, sometimes called ""minimal art"", ""literalist art"",[5] and ""ABC Art"",[6] refers to a specific movement of artists that emerged in New York in the early 1960s in response to abstract expressionism.[7] Examples of artists working in painting that are ass",art_culture
"Conceptual art
Conceptual art, also referred to as conceptualism, is art in which the concept(s) or idea(s) involved in the work are prioritized equally to or more than traditional aesthetic, technical, and material concerns. Some works of conceptual art may be constructed by anyone simply by following a set of written instructions.[1] This method was fundamental to American artist Sol LeWitt's definition of conceptual art, one of the first to appear in print:
In conceptual art the idea or concept is the most important aspect of the work. When an artist uses a conceptual form of art, it means that all of the planning and decisions are made beforehand and the execution is a perfunctory affair. The idea becomes a machine that makes the art.[2]
Tony Godfrey, author of Conceptual Art (Art & Ideas) (1998), asserts that conceptual art questions the nature of art,[3] a notion that Joseph Kosuth elevated to a definition of art itself in his seminal, early manifesto of conceptual art, Art after Philosophy (1969). The notion that art should examine its own nature was already a potent aspect of the influential art critic Clement Greenberg's vision of Modern art during the 1950s. With the emergence of an exclusively language-based art in the 1960s, however, conceptual artists such as Art & Language, Joseph Kosuth (who became the American editor of Art-Language), and Lawrence Weiner began a far more radical interrogation of art than was previously possible (see below). One of the first an",art_culture
"Graffiti
Graffiti (singular graffiti, or graffito only in graffiti archeology) is writing or drawings made on a wall or other surface, usually without permission and within public view.[1][2] Graffiti ranges from simple written ""monikers"" to elaborate wall paintings, and has existed since ancient times, with examples dating back to ancient Egypt, ancient Greece, and the Roman Empire.[3]
Modern graffiti is a controversial subject. In most countries, marking or painting property without permission is considered vandalism.[4] Modern graffiti began in the New York City subway system and Philadelphia in the early 1970s and later spread to the rest of the United States and throughout the world.[5]
Etymology
""Graffiti"" (usually both singular and plural) and the rare singular form ""graffito"" are from the Italian word graffiato (""scratched"").[6][1][2] In ancient times graffiti were carved on walls with a sharp object, although sometimes chalk or coal were used. The word originates from Greek γράφειν—graphein—meaning ""to write"".[7]
History
Prehistoric
Most petroglyphs and geoglyphs date between 40,000 and 10,000 years old, the oldest being cave paintings in Australia.[8] Paintings in the Chauvet Cave were made 35,000 years ago, but little is known about who made them or why.[8] Early artists created stencil graffiti of their hands with paint blown through a tube. These stencils may have functioned similarly to a modern-day tag.[8]
Ancient
The oldest written graffiti was found in Ancien",art_culture
"Video art
Video art is an art form which relies on using video technology as a visual and audio medium. Video art emerged during the late 1960s as new consumer video technology such as video tape recorders became available outside corporate broadcasting. Video art can take many forms: recordings that are broadcast; installations viewed in galleries or museums; works either streamed online, or distributed as video tapes, or on DVDs; and performances which may incorporate one or more television sets, video monitors, and projections, displaying live or recorded images and sounds.[1]
Video art is named for the original analog video tape, which was the most commonly used recording technology in much of the form's history into the 1990s. With the advent of digital recording equipment, many artists began to explore digital technology as a new way of expression. Video art does not necessarily rely on the conventions that define theatrical cinema. It may not use actors, may contain no dialogue, and may have no discernible narrative or plot. Video art also differs from cinema subcategories such as avant garde cinema, short films, and experimental film.
Early history
[edit]Nam June Paik, a Korean-American artist who studied in Germany, is widely regarded as a pioneer in video art.[2][3] In March 1963 Paik showed at the Galerie Parnass in Wuppertal the Exposition of Music – Electronic Television.[4][5] In May 1963 Wolf Vostell showed the installation 6 TV Dé-coll/age at the Smolin Galler",art_culture
"Sound art
Sound art is an artistic activity in which sound is utilized as a primary time-based medium or material.[1] Like many genres of contemporary art, sound art may be interdisciplinary in nature, or be used in hybrid forms.[2] According to Brandon LaBelle, sound art as a practice ""harnesses, describes, analyzes, performs, and interrogates the condition of sound and the process by which it operates.""[3]
In Western art, early examples include the Futurist Luigi Russolo's Intonarumori noise intoners (1913), and subsequent experiments by dadaists, surrealists, the Situationist International, and in Fluxus events and other Happenings. Because of the diversity of sound art, there is often debate about whether sound art falls within the domains of visual art or experimental music, or both.[4] Other artistic lineages from which sound art emerges are conceptual art, minimalism, site-specific art, sound poetry, electro-acoustic music, spoken word, avant-garde poetry, sound scenography,[5] and experimental theatre.[6]
Origin of term
[edit]According to Bernhard Gál's research, the first published use of the term was found in Something Else Press on the cover of their 1974 Yearbook.[7] The first use as the title of an exhibition at a major museum was 1979's Sound Art at the Museum of Modern Art in New York (MoMA), featuring Maggi Payne, Connie Beckley, and Julia Heyward.[8] The curator, Barbara London defined sound art as, ""more closely allied to art than to music, and are usually p",art_culture
"Land art
Land art, variously known as Earth art, environmental art, and Earthworks, is an art movement that emerged in the 1960s and 1970s,[1] largely associated with Great Britain and the United States[2][3][4] but that also includes examples from many other countries. As a trend, ""land art"" expanded the boundaries of traditional art making in the materials used and the siting of the works. The materials used are often the materials of the Earth, including the soil, rocks, vegetation, and water found on-site, and the sites are often distant from population centers. Though sometimes fairly inaccessible, photo documentation is commonly brought back to the urban art gallery.[3][5][6]
Concerns of the art movement center around rejection of the commercialization of art-making and enthusiasm with an emergent ecological movement. The beginning of the movement coincided with the popularity of the rejection of urban living and its counterpart, and an enthusiasm for that which is rural. Included in these inclinations were spiritual yearnings concerning the planet Earth as home to humanity.[7][8]
Form
[edit]The art form gained traction in the 1960s and 1970s as land art was not something that could easily be turned into a commodity, unlike the ""mass produced cultural debris"" of the time.[2] During this period, proponents of land art rejected the museum or gallery as the setting of artistic activity and developed monumental landscape projects which were beyond the reach of traditional t",art_culture
"Installation art
Installation art is an artistic genre of three-dimensional works that are often site-specific and designed to transform the perception of a space. Generally, the term is applied to interior spaces, whereas exterior interventions are often called public art, land art or art intervention; however, the boundaries between these terms overlap.
History
[edit]Installation art can be either temporary or permanent. Installation artworks have been constructed in exhibition spaces such as museums and galleries, as well as public and private spaces. The genre incorporates a broad range of everyday and natural materials, which are often chosen for their ""evocative"" qualities, as well as new media such as video, sound, performance, immersive virtual reality and the internet. Many installations are site-specific in that they are designed to exist only in the space for which they were created, appealing to qualities evident in a three-dimensional immersive medium. Artistic collectives such as the Exhibition Lab at New York's American Museum of Natural History created environments to showcase the natural world in as realistic a medium as possible. Likewise, Walt Disney Imagineering employed a similar philosophy when designing the multiple immersive spaces for Disneyland in 1955. Since its acceptance as a separate discipline, a number of institutions focusing on Installation art were created. These included the Mattress Factory, Pittsburgh, the Museum of Installation in London",art_culture
"Kinetic art
Kinetic art is art from any medium that contains movement perceivable by the viewer or that depends on motion for its effects. Canvas paintings that extend the viewer's perspective of the artwork and incorporate multidimensional movement are the earliest examples of kinetic art.[1] More pertinently speaking, kinetic art is a term that today most often refers to three-dimensional sculptures and figures such as mobiles that move naturally or are machine operated (see e.g. videos on this page of works of George Rickey and Uli Aschenborn). The moving parts are generally powered by wind, a motor[2] or the observer. Kinetic art encompasses a wide variety of overlapping techniques and styles.
There is also a portion of kinetic art that includes virtual movement, or rather movement perceived from only certain angles or sections of the work. This term also clashes frequently with the term ""apparent movement"", which many people use when referring to an artwork whose movement is created by motors, machines, or electrically powered systems. Both apparent and virtual movement are styles of kinetic art that only recently have been argued as styles of op art.[3] The amount of overlap between kinetic and op art is not significant enough for artists and art historians to consider merging the two styles under one umbrella term, but there are distinctions that have yet to be made.
""Kinetic art"" as a moniker developed from a number of sources. Kinetic art has its origins in the late ",art_culture
"Fluxus
Fluxus was an international, interdisciplinary community of artists, composers, designers, and poets during the 1960s and 1970s who engaged in experimental art performances which emphasized the artistic process over the finished product.[1][2] Fluxus is known for experimental contributions to different artistic media and disciplines and for generating new art forms. These art forms include intermedia, a term coined by Fluxus artist Dick Higgins;[3][4][5][6] conceptual art, first developed by Henry Flynt,[7][8] an artist contentiously associated with Fluxus; and video art, first pioneered by Nam June Paik and Wolf Vostell.[9][10][11] Dutch gallerist and art critic Harry Ruhé describes Fluxus as ""the most radical and experimental art movement of the sixties"".[12][13]
They produced performance ""events"", which included enactments of scores, ""Neo-Dada"" noise music, and time-based works, as well as concrete poetry, visual art, urban planning, architecture, design, literature, and publishing. Many Fluxus artists share anti-commercial and anti-art sensibilities. Fluxus is sometimes described as ""intermedia"". The ideas and practices of composer John Cage heavily influenced Fluxus, especially his notions that one should embark on an artwork without a conception of its end, and his understanding of the work as a site of interaction between artist and audience. The process of creating was privileged over the finished product.[14] Another notable influence were the readymades of Ma",art_culture
"Neo-expressionism
Neo-expressionism is a style of late modernist or early-postmodern painting and sculpture that emerged in the late 1970s. Neo-expressionists were sometimes called Transavantgarde, Junge Wilde or Neue Wilden ('The new wild ones'; 'New Fauves' would better meet the meaning of the term). It is characterized by intense subjectivity and rough handling of materials.[1]
Neo-expressionism developed as a reaction against conceptual art and minimal art of the 1970s. Neo-expressionists returned to portraying recognizable objects, such as the human body (although sometimes in an abstract manner), in a rough and violently emotional way, often using vivid colors.[2] It was overtly inspired by German Expressionist painters, such as Emil Nolde, Max Beckmann, George Grosz, Ernst Ludwig Kirchner, James Ensor and Edvard Munch. It is also related to American lyrical abstraction painting of the 1960s and 1970s, the Hairy Who movement in Chicago, the Bay Area Figurative School of the 1950s and 1960s, the continuation of abstract expressionism, precedents in Pop Painting,[3] and New Image Painting: a vague late 1970s term applied to painters who employed a strident figurative style with cartoon-like imagery and abrasive handling owing something to neo-expressionism. The New Image Painting term was given currency by a 1978 exhibition entitled New Image Painting held at the Whitney Museum.[4]
Critical reception
[edit]Neo-expressionism dominated the art market until the mid-1980s.[5]",art_culture
"Digital sculpting
Digital sculpting, also known as sculpt modeling or 3D sculpting, is the use of software that offers tools to push, pull, smooth, grab, pinch or otherwise manipulate a digital object as if it were made of a real-life substance such as clay.
Sculpting technology
[edit]The geometry used in digital sculpting programs to represent the model can vary; each offers different benefits and limitations. The majority of digital sculpting tools on the market use mesh-based geometry, in which an object is represented by an interconnected surface mesh of polygons that can be pushed and pulled around. This is somewhat similar to the physical process of beating copper plates to sculpt a scene in relief. Other digital sculpting tools use voxel-based geometry, in which the volume of the object is the basic element. Material can be added and removed, much like sculpting in clay. Still other tools make use of more than one basic geometry representation.
A benefit of mesh-based programs is that they support sculpting at multiple resolutions on a single model. Areas of the model that are finely detailed can have very small polygons while other areas can have larger polygons. In many mesh-based programs, the mesh can be edited at different levels of detail, and the changes at one level will propagate to higher and lower levels of model detail. A limitation of mesh-based sculpting is the fixed topology of the mesh; the specific arrangement of the polygons can limit the ways in whic",Technology & Computing 
"Generative art
Generative art is post-conceptual art that has been created (in whole or in part) with the use of an autonomous system. An autonomous system in this context is generally one that is non-human and can independently determine features of an artwork that would otherwise require decisions made directly by the artist. In some cases the human creator may claim that the generative system represents their own artistic idea, and in others that the system takes on the role of the creator.
""Generative art"" often refers to algorithmic art (algorithmically determined computer generated artwork) and synthetic media (general term for any algorithmically generated media), but artists can also make generative art using systems of chemistry, biology, mechanics and robotics, smart materials, manual randomization, mathematics, data mapping, symmetry, and tiling.
Generative algorithms, algorithms programmed to produce artistic works through predefined rules, stochastic methods, or procedural logic, often yielding dynamic, unique, and contextually adaptable outputs—are central to many of these practices.
History
[edit]The use of the word ""generative"" in the discussion of art has developed over time. The use of ""Artificial DNA"" defines a generative approach to art focused on the construction of a system able to generate unpredictable events, all with a recognizable common character. The use of autonomous systems, required by some contemporary definitions, focuses a generative approac",art_culture
"Bioart
Bioart is an art practice where artists work with biology, live tissues, bacteria, living organisms, and life processes. Using scientific processes and practices such as biology and life science practices, microscopy, and biotechnology (including technologies such as genetic engineering, tissue culture, and cloning) the artworks are produced in laboratories, galleries, or artists' studios. The scope of bioart is a range considered by some artists to be strictly limited to ""living forms"", while other artists include art that uses the imagery of contemporary medicine and biological research, or require that it address a controversy or blind spot posed by the very character of the life sciences.[1]
Bioart originated at the end of the 20th century and beginning of the 21st century. Although bioartists work with living matter, there is some debate as to the stages at which matter can be considered to be alive or living. Creating living beings and practicing in the life sciences brings about ethical, social, and aesthetic inquiry.[2] With his essay “Biotechnology and Art” from 1981, Peter Weibel introduced the term bioart, and defined an art movement that uses biological systems as a means of artistic expression.[3]
The creation of living beings and the study of the biological sciences bring with them ethical, social and aesthetic questions. Within Bio Art there is a debate about whether any form of artistic engagement with the biosciences and their social consequences (e.g.",art_culture
"Mural
A mural is any piece of graphic artwork that is painted or applied directly to a wall, ceiling or other permanent substrate. Mural techniques include fresco, mosaic, graffiti and marouflage.
Word mural in art
[edit]The word mural is a Spanish adjective that is used to refer to what is attached to a wall. The term mural later became a noun. In art, the word began to be used at the beginning of the 20th century.
In 1906, Dr. Atl issued a manifesto calling for the development of a monumental public art movement in Mexico; he named it in Spanish pintura mural (English: wall painting).[1]
In ancient Roman times, a mural crown was given to the fighter who was first to scale the wall of a besieged town.[2] ""Mural"" comes from the Latin muralis, meaning ""wall painting"". This word is related to murus, meaning ""wall"".
History
[edit]Antique art
[edit]Murals of sorts date to Upper Paleolithic times such as the cave paintings in the Lubang Jeriji Saléh cave in Borneo (40,000–52,000 BP), Chauvet Cave in Ardèche department of southern France (around 32,000 BP). Many ancient murals have been found within ancient Egyptian tombs (around 3150 BC),[3] the Minoan palaces (Middle period III of the Neopalatial period, 1700–1600 BC), the Oxtotitlán cave and Juxtlahuaca in Mexico (around 1200–900 BC) and in Pompeii (around 100 BC – AD 79).
During the Middle Ages murals were usually executed on dry plaster (secco). The huge collection of Kerala mural painting dating from the 14th century are exam",art_culture
"Animation
Animation is a filmmaking technique whereby still images are manipulated to create moving images. In traditional animation, images are drawn or painted by hand on transparent celluloid sheets to be photographed and exhibited on film. Animation has been recognized as an artistic medium, specifically within the entertainment industry. Many animations are either traditional animations or computer animations made with computer-generated imagery (CGI). Stop motion animation, in particular claymation, has continued to exist alongside these other forms.
Animation is contrasted with live action, although the two do not exist in isolation. Many moviemakers have produced films that are a hybrid of the two. As CGI increasingly approximates photographic imagery, filmmakers can easily composite 3D animations into their film rather than using practical effects for showy visual effects (VFX).
General overview
[edit]Computer animation can be very detailed 3D animation, while 2D computer animation (which may have the look of traditional animation) can be used for stylistic reasons, low bandwidth, or faster real-time renderings. Other common animation methods apply a stop motion technique to two- and three-dimensional objects like paper cutouts, puppets, or clay figures.
An animated cartoon, or simply a cartoon, is an animated film, usually short, that features an exaggerated visual style. This style is often inspired by comic strips, gag cartoons, and other non-animated art forms. C",art_culture
"Mixed media
In visual art, mixed media describes artwork in which more than one medium or material has been employed.[1][2] Assemblages, collages, and sculpture are three common examples of art using different media. Materials used to create mixed media art include, but are not limited to, paint, cloth, paper, wood and found objects.[citation needed]
Mixed media art is distinguished from multimedia art which combines visual art with non-visual elements, such as recorded sound, literature, drama, dance, motion graphics, music, or interactivity.[3][4]
History of mixed media
[edit]The first modern artwork to be considered mixed media is Pablo Picasso's 1912 collage Still Life with Chair Caning,[citation needed] which used paper, cloth, paint and rope to create a pseudo-3D effect. The influence of movements like Cubism and Dada contributed to the mixed media's growth in popularity throughout the 20th century with artists like Henri Matisse, Joseph Cornell, Jean Dubuffet, and Ellsworth Kelly adopting it. This led to further innovations like installations in the late 20th century.[5] Mixed media continues to be a popular form for artists, with different forms like wet media and markings[further explanation needed] being explored.[6]
Types of mixed media art
[edit]Mixed media art can be differentiated into distinct types,[7] some of which are:
Collage: This is an art form which involves combining different materials like ribbons, newspaper clippings, photographs etc. to create a new",art_culture
"Textile arts
Textile arts are arts and crafts that use plant, animal, or synthetic fibers to construct practical or decorative objects.
Textiles have been a fundamental part of human life since the beginning of civilization.[1][2] The methods and materials used to make them have expanded enormously, while the functions of textiles have remained the same, there are many functions for textiles. Whether it be clothing or something decorative for the house/shelter. The history of textile arts is also the history of international trade. Tyrian purple dye was an important trade good in the ancient Mediterranean. The Silk Road brought Chinese silk to India, Africa, and Europe, and, conversely, Sogdian silk to China. Tastes for imported luxury fabrics led to sumptuary laws during the Middle Ages and Renaissance. The Industrial Revolution was shaped largely by innovation in textiles technology: the cotton gin, the spinning jenny, and the power loom mechanized production and led to the Luddite rebellion.
Concepts
[edit]The word textile is from Latin texere which means ""to weave"", ""to braid"" or ""to construct"".[1] The simplest textile art is felting, in which animal fibers are matted together using heat and moisture. Most textile arts begin with twisting or spinning and plying fibers to make yarn (called thread when it is very fine and rope when it is very heavy). The yarn is then knotted, looped, braided, or woven to make flexible fabric or cloth, and cloth can be used to make clothing ",art_culture
"Fiber art
Fiber art (fibre art in British spelling) refers to fine art whose material consists of natural or synthetic fiber and other components, such as fabric or yarn. It focuses on the materials and on the manual labor on the part of the artist as part of the works' significance, and prioritizes aesthetic value over utility.
History
[edit]The term fiber art came into use by curators and arts historians to describe the work of the artist-craftsman following World War II. Those years saw a sharp increase in the design and production of ""art fabric"". In the 1950s, as the contributions of craft artists became more recognized—not just in fiber but in clay and other media—an increasing number of weavers began binding fibers into nonfunctional forms as works of art.[1]
The 1960s and 70s brought an international revolution in fiber art.[2] Beyond weaving, fiber structures were created through knotting, twining, plaiting, coiling, pleating, lashing, interlacing, and even braiding.[3] Artists in the United States and Europe explored the qualities of fabric to develop works that could be hung or free standing, ""two or three dimensional, flat or volumetric, many stories high or miniature, nonobjective or figurative, and representational or fantasy.""[1] In the UK the founding of The 62 Group of Textile Artists coincided with a growth in interest in using textile media in a fine art context. The women's movement of the same era was important in contributing to the rise of fiber art bec",art_culture
"Scenography
Scenography is the practice of crafting stage environments or atmospheres.[1] In the contemporary English usage, scenography can be defined as the combination of technological and material stagecrafts to represent, enact, and produce a sense of place in performance.
While inclusive of the techniques of scenic design and set design, scenography is a holistic approach to the study and practice of all aspects of design in performance. It also includes the design of lighting, sound, and costumes.
Etymology and cultural interpretations
[edit]The term scenography is of Greek origin (skēnē, meaning 'stage or scene building'; grapho, meaning 'to describe') originally detailed within Aristotle's Poetics as 'skenographia'. Nevertheless, within continental Europe, the term has been closely aligned with the professional practice of scénographie and is synonymous with the English-language term 'theatre design'. More recently, the term has been used in museography with regards to the curation of museum exhibits.[2]
History
[edit]In what is not the first use of the term, Antonio Caimi, in 1862, describes a category of artists practising pittura scenica e l'architettura teatrale, inspired by the artist Ferdinando Galli-Bibiena, who was also known as a painter of quadratura, or architectural painting (usually trompe-l'œil depictions of architecture on ceilings or walls). Caimi also calls this Arte scenografica, and notes that it required ingenious engineering to create movable set",art_culture
"Theatre director
A theatre director or stage director is a professional in the theatre field who oversees and orchestrates the mounting of a theatre production such as a play, opera, dance, drama, musical theatre performance, etc. by unifying various endeavors and aspects of production. The director's function is to ensure the quality and completeness of theatre production and to lead the members of the creative team into realizing their artistic vision for it. The director thereby collaborates with a team of creative individuals and other staff to coordinate research and work on all the aspects of the production which includes the Technical and the Performance aspects. The technical aspects include: stagecraft, costume design, theatrical properties (props), lighting design, set design, and sound design for the production. The performance aspects include: acting, dance, orchestra, chants, and stage combat.
If the production is a new piece of writing or a (new) translation of a play, the director may also work with the playwright or a translator. In contemporary theatre, after the playwright, the director is generally the principle visionary, making decisions on the artistic conception and interpretation of the play and its staging. Different directors occupy different places of authority and responsibility, depending on the structure and philosophy of individual theatre companies. Directors use a wide variety of techniques, philosophies, and levels of collaboration.[1][2]
The",art_culture
"Screenwriting
Screenwriting or scriptwriting is the art and craft of writing scripts for mass media such as feature films, television productions or video games. It is often a freelance profession.
Screenwriters are responsible for researching the story, developing the narrative, writing the script, screenplay, dialogues and delivering it, in the required format, to development executives. Screenwriters therefore have great influence over the creative direction and emotional impact of the screenplay and, arguably, of the finished film.
Screenwriters either pitch original ideas to producers, in the hope that they will be optioned or sold; or are commissioned by a producer to create a screenplay from a concept, true story, existing screen work or literary work, such as a novel, poem, play, comic book, or short story.
Types
[edit]The act of screenwriting takes many forms across the entertainment industry. Often, multiple writers work on the same script at different stages of development with different tasks. Over the course of a successful career, a screenwriter might be hired to write in a wide variety of roles.
Some of the most common forms of screenwriting jobs include:
Spec script writing
[edit]Spec scripts are feature film or television show scripts written without the commission of, but is on speculation of sale to a film studio, production company, or TV network. The content is usually invented solely by the screenwriter, however spec screenplays can also be based on esta",art_culture
"Literary criticism
A genre of arts criticism, literary criticism or literary studies is the study, evaluation, and interpretation of literature. Modern literary criticism is often influenced by literary theory, which is the philosophical analysis of literature's goals and methods. Although the two activities are closely related, literary critics are not always, and have not always been, theorists.
Whether or not literary criticism should be considered a separate field of inquiry from literary theory is a matter of some controversy. For example, The Johns Hopkins Guide to Literary Theory and Criticism[1] draws no distinction between literary theory and literary criticism, and almost always uses the terms together to describe the same concept. Some critics consider literary criticism a practical application of literary theory, because criticism always deals directly with particular literary works, while theory may be more general or abstract.[2]
Literary criticism is often published in essay or book form. Academic literary critics teach in literature departments and publish in academic journals, and more popular critics publish their reviews in broadly circulating periodicals such as The Times Literary Supplement, The New York Times Book Review, The New York Review of Books, the London Review of Books, the Dublin Review of Books, The Nation, Bookforum, and The New Yorker.
History
[edit]Classical and medieval criticism
[edit]Literary criticism is thought to have existed as far b",art_culture
"Free verse
Free verse is an open form of poetry which does not use a prescribed or regular meter or rhyme[1] and tends to follow the rhythm of natural or irregular speech. Free verse encompasses a large range of poetic form, and the distinction between free verse and other forms (such as prose) is often ambiguous.[2][3]
History
[edit]Though individual examples of English free verse poetry surfaced before the 20th-century (parts of John Milton's Samson Agonistes or the majority of Walt Whitman's poetry, for example),[2] free verse is generally considered an early 20th century innovation of the late 19th-century French vers libre.[2][4]
T. E. Hulme and F. S. Flint first introduced the form to the London-based Poets' Club in 1909.[5] This later became the heart of the Imagist movement[6] through Flint's advocacy of the genre.[7] Imagism, in the wake of French Symbolism (i.e. vers libre of French Symbolist poets[8]) was the wellspring out of which the main current of Modernism in English flowed.[9] T. S. Eliot later identified this as ""the point de repere usually taken as the starting point of modern poetry,""[10] as hundreds of poets were led to adopt vers libre as their medium.[11]
Definition
[edit]It is said that verse is free ""when it is not primarily obtained by the metered line.""[12] Free verse does not ""proceed by a strict set of rules … is not a literary type, and does not conform to a formal structure,"" but it is not considered to be completely free. In 1948, Charles Alle",art_culture
"Prose poetry
Prose poetry is poetry written in prose form instead of verse form while otherwise deferring to poetic devices to make meaning.
Characteristics
[edit]Prose poetry is written as prose, without the line breaks associated with poetry. However, it makes use of poetic devices such as fragmentation, compression, repetition, rhyme,[1] metaphor, and figures of speech.[2] Prose can still express the lyricism and emotion of poetry, and can also explore many different themes. There are subgenres within the prose genre, and these include styles like deadpan narrative, surreal narrative, factoid, and postcard. Prose offers a lot of creative freedom to writers, and does not contain as many rules as some poetic styles do. Many writers have different opinions on the form of this genre because it is so open, which makes it harder to objectively define. The prose genre has been used and explored by writers like Walt Whitman, Franz Kafka, Naomi Shihab Nye, and Anne Carson. Almost every form of art can be categorized under either the prose or poetry genre. Poetry covers forms like song lyrics, different poetry forms, and dialogue that contains poetic characteristics like iambic pentameter. On the other hand, prose includes novels, short stories, novellas, and scripts.
History
[edit]Although the Bible is written in prose, it maintains poetic features such as rhythms and lyricism. [3]
In 17th-century Japan, Matsuo Bashō originated haibun, a form of prose poetry combining haiku with pr",art_culture
"Narrative poetry
Narrative poetry is a form of poetry that tells a story, often using the voices of both a narrator and characters; the entire story is usually written in metered verse. Narrative poems do not need to rhyme. The poems that make up this genre may be short or long, and the story it relates to may be complex. It is normally dramatic, with various characters.[1] Narrative poems include all epic poetry, and the various types of ""lay"",[2] most ballads, and some idylls, as well as many poems not falling into a distinct type.
Some narrative poetry takes the form of a novel in verse. An example of this is The Ring and the Book by Robert Browning. In terms of narrative poetry, romance is a narrative poem that tells a story of chivalry. Examples include the Romance of the Rose or Tennyson's Idylls of the King. Although those examples use medieval and Arthurian materials, romances may also tell stories from classical mythology. Sometimes, these short narratives are collected into interrelated groups, as with Chaucer's The Canterbury Tales. So sagas include both incidental poetry and the biographies of poets.
Oral tradition
[edit]The oral tradition is the predecessor of essentially all other modern forms of communication. For thousands of years, cultures passed on their history through oral tradition from generation to generation. Historically, much of poetry has its source in an oral tradition: in more recent times the Scots and English ballads, the tales of Robin Hood po",art_culture
"Metaphysical poets
The term Metaphysical poets was coined by the critic Samuel Johnson to describe a loose group of 17th-century English poets whose work was characterised by the inventive use of conceits, and by a greater emphasis on the spoken rather than lyrical quality of their verse. These poets were not formally affiliated and few were highly regarded until 20th century attention established their importance.
Given the lack of coherence as a movement, and the diversity of style among poets, it has been suggested that calling them Baroque poets after their era might be more useful. Once the Metaphysical style was established, however, it was occasionally adopted by other and especially younger poets to fit appropriate circumstances.
Origin of the name
[edit]In the chapter on Abraham Cowley in his Lives of the Most Eminent English Poets (1779–81), Samuel Johnson refers to the beginning of the 17th century in which there ""appeared a race of writers that may be termed the metaphysical poets"". This does not necessarily imply that he intended ""metaphysical"" to be used in its true sense, in that he was probably referring to a witticism of John Dryden, who said of John Donne:
He affects the metaphysics, not only in his satires, but in his amorous verses, where nature only should reign; and perplexes the minds of the fair sex with nice speculations of philosophy, when he should engage their hearts, and entertain them with the softnesses of love. In this...Mr. Cowley has copied h",art_culture
"Beat Generation
The Beat Generation was a literary subculture movement started by a group of authors whose work explored and influenced American culture and politics in the post-World War II era.[1] The bulk of their work was published and popularized by members of the Silent Generation in the 1950s, better known as Beatniks. The central elements of Beat culture are the rejection of standard narrative values, making a spiritual quest, the exploration of American and Eastern religions, the rejection of economic materialism, explicit portrayals of the human condition, experimentation with psychedelic drugs, and sexual liberation and exploration.[2][3]
Allen Ginsberg's Howl (1956), William S. Burroughs' Naked Lunch (1959), and Jack Kerouac's On the Road (1957) are among the best-known examples of Beat literature.[4] Both Howl and Naked Lunch were the focus of obscenity trials that ultimately helped to liberalize publishing in the United States.[5][6] The members of the Beat Generation developed a reputation as new bohemian hedonists, who celebrated non-conformity and spontaneous creativity.
The core group of Beat Generation authors—Herbert Huncke, Ginsberg, Burroughs, Lucien Carr, and Kerouac—met in 1944 in and around the Columbia University campus in New York City. Later, in the mid-1950s, the central figures, except Burroughs and Carr, ended up together in San Francisco, where they met and became friends of figures associated with the San Francisco Renaissance.
In the 1950s, a",art_culture
"Romantic poetry
Romantic poetry is the poetry of the Romantic era, an artistic, literary, musical and intellectual movement that originated in Europe towards the end of the 18th century. It involved a reaction against prevailing Neoclassical ideas of the 18th century,[1] and lasted approximately from 1800 to 1850.[2][3] Romantic poets rebelled against the style of poetry from the eighteenth century which was based around epics, odes, satires, elegies, epistles and songs.
English
[edit]In early-19th-century England, the poet William Wordsworth defined his and Samuel Taylor Coleridge's innovative poetry in his new Preface to the second edition (1800) of Lyrical Ballads:
I have said before that poetry is the spontaneous overflow of powerful feelings: it takes its origin in emotion recollected in tranquility: the emotion is contemplated till, by a species of reaction, the tranquility gradually disappears, and an emotion, kindred to that which was before the subject of contemplation, is gradually produced, and does itself actually exist in the mind.[4]
The poems of Lyrical Ballads intentionally re-imagined the way poetry should sound: ""By fitting to metrical arrangement a selection of the real language of men,"" Wordsworth and his English contemporaries, such as Coleridge, John Keats, Percy Shelley, Lord Byron and William Blake, wrote poetry that was meant to boil up from serious, contemplative reflection over the interaction of humans with their environment. Although many stress t",art_culture
"Modernist poetry
Modernist poetry refers to poetry written between 1890 and 1950 in the tradition of modernist literature, but the dates of the term depend upon a number of factors, including the nation of origin, the particular school in quest of the critic setting the dates.[1][2] The critic/poet C. H. Sisson observed in his essay Poetry and Sincerity that ""Modernity has been going on for a long time. Not within living memory has there ever been a day when young writers were not coming up, in a threat of iconoclasm.""[3]
Background
[edit]It is usually said to have begun with the French Symbolist movement and it artificially ends with the Second World War, the beginning and ending of the modernist period are of course arbitrary. Poets like W. B. Yeats (1865–1939) and Rainer Maria Rilke (1875–1926) started in a post-Romantic, Symbolist vein and modernised their poetic idiom after being affected by political and literary developments.
Schools
[edit]Acmeist poetry was a Russian modernist poetic school, which emerged c. 1911 and to symbols preferred direct expression through exact images. Figures involved with Acmeism include Nikolay Gumilev, Osip Mandelstam, Mikhail Kuzmin, Anna Akhmatova, and Georgiy Ivanov.[4][5]
The Imagism, Anglo-American school from the 1914 proved radical and important, marking a new point of departure for poetry.[6][7] Some consider that it began in the works of H.D., Hardy and Pound, Eliot and Yeats, Williams and Stevens.[8]
Around World War II, a new ge",art_culture
"Magical realism
Magical realism, magic realism, or marvelous realism is a style or genre of fiction and art that presents a realistic view of the world while incorporating magical elements, often blurring the lines between speculation and reality.[1] Magical realism is the most commonly used of the three terms and refers to literature in particular, with magical or supernatural phenomena presented in an otherwise real-world or mundane setting, and is commonly found in novels and dramatic performances.[2]: 1–5 In his article ""Magical Realism in Spanish American Literature"", Luis Leal explains the difference between magic literature and magical realism, stating that, ""Magical realism is not magic literature either. Its aim, unlike that of magic, is to express emotions, not to evoke them.""[3] Despite including certain magic elements, it is generally considered to be a different genre from fantasy because magical realism uses a substantial amount of realistic detail and employs magical elements to make a point about reality, while fantasy stories are often separated from reality.[4][5][6] The two are also distinguished in that magic realism is closer to literary fiction than to fantasy, which is instead a type of genre fiction.[7] Magical realism is often seen as an amalgamation of real and magical elements that produces a more inclusive writing form than either literary realism or fantasy.[5]
Description
[edit]The term magic realism is broadly descriptive rather than critically ",art_culture
"Gothic fiction
Gothic fiction, sometimes referred to as Gothic horror (primarily in the 20th century), is a literary aesthetic of fear and haunting. The name of the genre is derived from the Renaissance era use of the word ""gothic"", as a pejorative to mean medieval and barbaric, which itself originated from Gothic architecture and in turn the Goths.[1]
The first work to be labelled as Gothic was Horace Walpole's 1764 novel The Castle of Otranto, later subtitled A Gothic Story. Subsequent 18th-century contributors included Clara Reeve, Ann Radcliffe, William Thomas Beckford, and Matthew Lewis. The Gothic influence continued into the early 19th century, with Romantic works by poets, like Samuel Taylor Coleridge and Lord Byron. Novelists such as Mary Shelley, Charles Maturin, Walter Scott and E. T. A. Hoffmann frequently drew upon gothic motifs in their works as well.
Gothic aesthetics continued to be used throughout the early Victorian period in novels by Charles Dickens, Brontë sisters, as well as works by the American writers, Edgar Allan Poe and Nathaniel Hawthorne. Later, Gothic fiction evolved through well-known works like Dracula by Bram Stoker, The Beetle by Richard Marsh, Strange Case of Dr Jekyll and Mr Hyde by Robert Louis Stevenson, and The Picture of Dorian Gray by Oscar Wilde. In the 20th-century, Gothic fiction remained influential with contributors including Daphne du Maurier, Stephen King, V. C. Andrews, Shirley Jackson, Anne Rice, and Toni Morrison.
Characteris",art_culture
"Cyberpunk
Cyberpunk is a subgenre of science fiction set in a dystopian future, is characterized by its focus on a combination of ""low-life and high tech"".[1] It features a range of futuristic technological and scientific achievements, including artificial intelligence and cyberware, which are juxtaposed with societal collapse, dystopia or decay.[2] A significant portion of cyberpunk can be traced back to the New Wave science fiction movement of the 1960s and 1970s. During this period, prominent writers such as Philip K. Dick, Michael Moorcock, Roger Zelazny, John Brunner, J. G. Ballard, Philip José Farmer and Harlan Ellison explored the impact of technology, drug culture, and the sexual revolution. These authors diverged from the utopian inclinations prevalent in earlier science fiction.
Comics exploring cyberpunk themes began appearing as early as Judge Dredd, first published in 1977.[3] Released in 1984, William Gibson's influential debut novel Neuromancer helped solidify cyberpunk as a genre, drawing influence from punk subculture and early hacker culture. Frank Miller's Ronin is an example of a cyberpunk graphic novel. Other influential cyberpunk writers included Bruce Sterling and Rudy Rucker. The Japanese cyberpunk subgenre began in 1982 with the debut of Katsuhiro Otomo's manga series Akira, with its 1988 anime film adaptation (also directed by Otomo) later popularizing the subgenre.
Early films in the genre include Ridley Scott's 1982 film Blade Runner, one of severa",art_culture
"Detective fiction
Detective fiction is a subgenre of crime fiction and mystery fiction in which an investigator or a detective—whether professional, amateur or retired—investigates a crime, often murder. The detective genre began around the same time as speculative fiction and other genre fiction in the mid-nineteenth century and has remained extremely popular, particularly in novels.[1] Some of the most famous heroes of detective fiction include C. Auguste Dupin, Sherlock Holmes, Kogoro Akechi, Miss Marple and Hercule Poirot. Juvenile stories featuring The Hardy Boys, Nancy Drew, and The Boxcar Children have also remained in print for several decades.
History
[edit]Ancient
[edit]Some scholars, such as R. H. Pfeiffer, have suggested that certain ancient and religious texts bear similarities to what would later be called detective fiction. In the Old Testament story of Susanna and the Elders (the Protestant Bible locates this story within the apocrypha), the account told by two witnesses broke down when Daniel cross-examines them. In response, author Julian Symons has argued that ""those who search for fragments of detection in the Bible and Herodotus are looking only for puzzles"" and that these puzzles are not detective stories.[2]
Early Arabic
[edit]One Thousand and One Nights contains several of the earliest detective stories, anticipating modern detective fiction.[3] The oldest known example of a detective story was ""The Three Apples"", one of the tales narrated by Scheheraz",art_culture
"Political satire
Political satire is a type of satire that specializes in gaining entertainment from politics. Political satire can also act as a tool for advancing political arguments in conditions where political speech and dissent are banned.
Political satire is usually distinguished from political protest or political dissent, as it does not necessarily carry an agenda nor seek to influence the political process. While occasionally it may, it more commonly aims simply to provide entertainment. By its very nature, it rarely offers a constructive view in itself; when it is used as part of protest or dissent, it tends to simply establish the error of matters rather than provide solutions.[1] Because of the exaggerated[2] manner of these parodies, satirical news shows can more effectively sway their audiences to believe specific ideas by overemphasizing the flaws of the critiqued subject.[3] This can be very harmful to the reputation of public figures or organizations since the satire frames them in a comical way.[4]
Origins and genres
[edit]Satire can be traced back throughout history; wherever organized government, or social categories have existed, so has satire.[5]
The oldest example that has survived until today is Aristophanes. In his time, satire targeted top politicians, like Cleon,[6] and religion, at the time headed by Zeus. ""Satire and derision progressively attacked even the fundamental and most sacred facts of faith,"" leading to an increased doubt towards religio",history
"Social realism
Social realism is work produced by painters, printmakers, photographers, writers, filmmakers and some musicians that aims to draw attention to the real socio-political conditions of the working class as a means to critique the power structures behind these conditions. While the movement's characteristics vary from nation to nation, it almost always uses a form of descriptive or critical realism.[1]
The term is sometimes more narrowly used for an art movement that flourished in the interwar period as a reaction to the hardships and problems suffered by common people after the Great Crash. In order to make their art more accessible to a wider audience, artists turned to realist portrayals of anonymous workers as well as celebrities as heroic symbols of strength in the face of adversity. The goal of the artists in doing so was political as they wished to expose the deteriorating conditions of the poor and working classes and hold the existing governmental and social systems accountable.[2]
Social realism should not be confused with socialist realism, the official Soviet art form that was institutionalized by Joseph Stalin in 1934 and was later adopted by allied Communist parties worldwide. It is also different from realism as it not only presents conditions of the poor, but does so by conveying the tensions between two opposing forces, such as between farmers and their feudal lord.[1] However, sometimes the terms social realism and socialist realism are used inter",art_culture
"Documentary film
A documentary film (often described simply as a documentary) is a nonfiction motion picture intended to ""document reality, primarily for instruction, education or maintaining a historical record"".[1] The American author and media analyst Bill Nichols has characterized the documentary in terms of ""a filmmaking practice, a cinematic tradition, and mode of audience reception [that remains] a practice without clear boundaries"".[2]
Research into information gathering, as a behavior, and the sharing of knowledge, as a concept, has noted how documentary movies were preceded by the notable practice of documentary photography. This has involved the use of singular photographs to detail the complex attributes of historical events and continues to a certain degree to this day, with an example being the conflict-related photography achieved by popular figures such as Mathew Brady during the American Civil War. Documentary movies evolved from the creation of singular images in order to convey particular types of information in depth, using film as a medium.
Early documentary films, originally called ""actuality films"", briefly lasted for one minute or less in most cases. While faithfully depicting true events, these releases possessed no narrative structure per se and were of limited interest. Over time, documentaries have evolved to become longer in length and to include more categories of information. Some examples are explicitly educational, while others serve as observ",art_culture
"Experimental film
Experimental film or avant-garde cinema is a mode of filmmaking that does not apply standard cinematic conventions, instead adopting non-narrative forms or alternatives to traditional narratives or methods of working.[1] Many experimental films, particularly early ones, relate to arts in other disciplines: painting, dance, literature and poetry,[2] or arise from research and development of new technical resources.[3]
While some experimental films have been distributed through mainstream channels or even made within commercial studios, the vast majority have been produced on very low budgets with a minimal crew or a single person and are either self-financed or supported through small grants.[4]
Experimental filmmakers generally begin as amateurs, and some use experimental films as a springboard into commercial film-making or transition into academic positions. The aim of experimental filmmaking may be to render the personal vision of an artist, or to promote interest in new technology rather than to entertain or to generate revenue, as is the case with commercial films.[5]
Definition
[edit]The term experimental film describes a range of filmmaking styles that frequently differ from, and are often opposed to, the practices of mainstream commercial and documentary filmmaking. Avant-garde is also used, for the films of the sort shot in the twenties in France, Germany or Russia, to describe this work, and ""underground"" was used in the sixties, though it has also",art_culture
"Animation
Animation is a filmmaking technique whereby still images are manipulated to create moving images. In traditional animation, images are drawn or painted by hand on transparent celluloid sheets to be photographed and exhibited on film. Animation has been recognized as an artistic medium, specifically within the entertainment industry. Many animations are either traditional animations or computer animations made with computer-generated imagery (CGI). Stop motion animation, in particular claymation, has continued to exist alongside these other forms.
Animation is contrasted with live action, although the two do not exist in isolation. Many moviemakers have produced films that are a hybrid of the two. As CGI increasingly approximates photographic imagery, filmmakers can easily composite 3D animations into their film rather than using practical effects for showy visual effects (VFX).
General overview
[edit]Computer animation can be very detailed 3D animation, while 2D computer animation (which may have the look of traditional animation) can be used for stylistic reasons, low bandwidth, or faster real-time renderings. Other common animation methods apply a stop motion technique to two- and three-dimensional objects like paper cutouts, puppets, or clay figures.
An animated cartoon, or simply a cartoon, is an animated film, usually short, that features an exaggerated visual style. This style is often inspired by comic strips, gag cartoons, and other non-animated art forms. C",art_culture
"Stop motion
Stop motion (also known as stop frame animation) is an animated filmmaking and special effects technique in which objects are physically manipulated in small increments between individually photographed frames so that they will appear to exhibit independent motion or change when the series of frames is played back. Any kind of object can thus be animated, but puppets with movable joints (puppet animation) or clay figures (claymation) are most commonly used. Puppets, models or clay figures built around an armature are used in model animation. Stop motion with live actors is often referred to as pixilation. Stop motion of flat materials such as paper, fabrics or photographs is usually called cutout animation.
Terminology
[edit]The term ""stop motion"", relating to the animation technique, is often spelled with a hyphen as ""stop-motion""—either standalone or as a compound modifier. Both orthographic variants, with and without the hyphen, are correct, but the hyphenated one has a second meaning that is unrelated to animation or cinema: ""a device for automatically stopping a machine or engine when something has gone wrong"".[2]
History
[edit]1849 to 1895: Before film
[edit]Before the advent of chronophotography in 1878, a small number of picture sequences were photographed with subjects in separate poses. These can now be regarded as a form of stop motion or pixilation, but very few results were meant to be animated. Until celluloid film base was established in 1888 and se",art_culture
"Auteur
An auteur (/oʊˈtɜːr/; French: [otœʁ], lit. 'author') is an artist with a distinctive approach, usually a film director whose filmmaking control is so unbounded and personal that the director is likened to the ""author"" of the film,[1] thus manifesting the director's unique style or thematic focus.[2] As an unnamed value, auteurism originated in French film criticism of the late 1940s,[3] and derives from the critical approach of André Bazin and Alexandre Astruc, whereas American critic Andrew Sarris in 1962 called it auteur theory.[4][5] Yet the concept first appeared in French in 1955 when director François Truffaut termed it policy of the authors, and interpreted the films of some directors, like Alfred Hitchcock, as a body revealing recurring themes and preoccupations.
American actor Jerry Lewis directed his own 1960 film The Bellboy via sweeping control, and was praised for ""personal genius"". By 1970, the New Hollywood era had emerged with studios granting directors broad leeway. Pauline Kael argued, however, that ""auteurs"" rely on creativity of others, like cinematographers.[6][7] Georges Sadoul deemed a film's putative ""author"" could potentially even be an actor, but a film is indeed collaborative.[8] Aljean Harmetz cited major control even by film executives.[9] David Kipen's view of the screenwriter as indeed the main author is termed Schreiber theory. In the 1980s, large failures prompted studios to reassert control. The auteur concept has also been applied to ",art_culture
"Film noir
Film noir (/nwɑːr/; French: [film nwaʁ]) is a style of Hollywood crime dramas that emphasizes cynical attitudes and motivations. The 1940s and 1950s are generally regarded as the ""classic period"" of American film noir. Film noir of this era is associated with a low-key, black-and-white visual style that has roots in German expressionist cinematography. Many of the prototypical stories and attitudes expressed in classic noir derive from the hardboiled school of crime fiction that emerged in the United States during the Great Depression, known as noir fiction.[1]
The term film noir, French for ""black film"" (literal) or ""dark film"" (closer meaning),[2] was first applied to Hollywood films by French critic Nino Frank in 1946, but was unrecognized by most American film industry professionals of that era.[3] Frank is believed to have been inspired by the French literary publishing imprint Série noire, founded in 1945.
Cinema historians and critics defined the category retrospectively. Before the notion was widely adopted in the 1970s, many of the classic films noir[a] were referred to as ""melodramas"". Whether film noir qualifies as a distinct genre or whether it should be considered a filmmaking style is a matter of ongoing and heavy debate among film scholars.
Film noir encompasses a range of plots; common archetypical protagonists include a private investigator (The Big Sleep), a plainclothes police officer (The Big Heat), an aging boxer (The Set-Up), a hapless grifter ",art_culture
"List of New Wave movements
Appearance
(Redirected from New Wave cinema)
Look up new wave in Wiktionary, the free dictionary.
New Wave may refer to various artistic movements in film, music and literature. These include:
Movements in film
[edit]- The New Wave, French New Wave, or Nouvelle Vague, the inaugural New Wave cinema movement
- Australian New Wave
- Indian New Wave, or Parallel cinema
- Japanese New Wave, or Nuberu Bagu, which also developed around the same time as the French Nouvelle Vague
- Persian New Wave, or Iranian New Wave, started in the 1960s
- New German Cinema, new wave of German cinema
- Berlin School (filmmaking), also Known as Nouvelle Vague Allemand, second new wave of German cinema
- New Nigerian Cinema, also known as Nigerian New Wave
- Czechoslovak New Wave
- Cinema Novo or Novo Cinema, a movement in Brazilian and Portuguese film
- Hong Kong New Wave, a movement in Hong Kong film led by Tsui Hark
- Philippine New Wave, also known as Filipino New Wave or Contemporary Philippine Cinema
- Romanian New Wave
- British New Wave
- Taiwan New Wave
- Thai New Wave
- Toronto New Wave
- New Hollywood, also known as the American New Wave
- New generation (Malayalam film movement), new wave of Indian Malayalam cinema
- Mexican ('Nuevo Cine Mexicano')
Movements in music
[edit]- Bossa nova a genre of Brazilian music (while it is commonly translated as ""new wave"", the word ""bossa"" originally means ""small elevation on a surface"" like the bump on a camel's back or a lu",art_culture
"Italian neorealism
Italian neorealism (Italian: Neorealismo), also known as the Golden Age of Italian Cinema, was a national film movement characterized by stories set amongst the poor and the working class. They are filmed on location, frequently with non-professional actors. They primarily address the difficult economic and moral conditions of post-World War II Italy, representing changes in the Italian psyche and conditions of everyday life, including poverty, oppression, injustice and desperation. Italian Neorealist filmmakers used their films to tell stories that explored the contemporary daily life and struggles of Italians in the post-war period. [1] Italian neorealist films have become explanatory discourse for future generations to understand the history of Italy during a specific period through the storytelling of social life in the context, reflecting the documentary and communicative nature of the film.[2] Some people believe that neorealistic films evolved from Soviet montage films. But in reality, compared to Soviet filmmakers describing the people's opposition to class struggle through their films, neorealist films aim to showcase individuals' resistance to reality in a social environment.[3]
History
[edit]Italian neorealism came about as World War II ended and Benito Mussolini's government fell, causing the Italian film industry to lose its centre. Neorealism was a sign of cultural and social change in Italy. New realism films are considered to be films with s",art_culture
"French New Wave
The New Wave (French: Nouvelle Vague, French pronunciation: [nuvɛl vaɡ]), also called the French New Wave, is a French art film movement that emerged in the late 1950s. The movement was characterized by its rejection of traditional filmmaking conventions in favor of experimentation and a spirit of iconoclasm. New Wave filmmakers explored new approaches to editing, visual style, and narrative, as well as engagement with the social and political upheavals of the era, often making use of irony or exploring existential themes. The New Wave is often considered one of the most influential movements in the history of cinema. However, contemporary critics have also argued that historians have not sufficiently credited its female co-founder, Agnès Varda,[3] and have criticized the movement's prevailing themes of sexism towards women.[4][5]
The term was first used by a group of French film critics and cinephiles associated with the magazine Cahiers du cinéma in the late 1950s and 1960s. These critics rejected the Tradition de qualité (""Tradition of Quality"") of mainstream French cinema,[6] which emphasized craft over innovation and old works over experimentation.[7] This was apparent in a manifesto-like 1954 essay by François Truffaut, Une certaine tendance du cinéma français, where he denounced the adaptation of safe literary works into unimaginative films.[8] Along with Truffaut, a number of writers for Cahiers du cinéma became leading New Wave filmmakers, including J",art_culture
"Dogme 95
Dogme 95 (pronounced [ˈtʌwmə]; Danish for ""Dogma 95"") was a Danish avant-garde filmmaking movement founded by Lars von Trier and Thomas Vinterberg, who created the ""Dogme 95 Manifesto"" and the ""Vows of Chastity"" (Danish: kyskhedsløfter). These were rules to create films based on the traditional values of story, acting, and theme, while excluding the use of elaborate special effects or technology. It was supposedly created as an attempt to ""take back power for the directors as artists"" as opposed to the movie studio.[1]
Von Trier and Vinterberg were later joined by Kristian Levring and Søren Kragh-Jacobsen, forming a group known as the Dogme 95 Collective or the Dogme Brethren. French-American filmmaker Jean-Marc Barr and American filmmaker Harmony Korine are also seen as major figures in the movement. Breaking the Waves (1996), von Trier's first film under his own production company Zentropa, became the precursor of the movement.[2]
History
[edit]Lars von Trier and Thomas Vinterberg wrote and co-signed the manifesto and its companion ""vows"". Vinterberg said that they wrote the pieces in 45 minutes.[3] The manifesto initially mimics the wording of François Truffaut's 1954 essay ""Une certaine tendance du cinéma français"" in Cahiers du cinéma.
They announced the Dogme movement on March 13, 1995, in Paris, at Le cinéma vers son deuxième siècle conference. The cinema world had gathered to celebrate the first century of motion pictures and contemplate the uncertain future ",art_culture
"Hindi cinema
Hindi cinema, popularly known as Bollywood and formerly as Bombay cinema,[1] is primarily produced in Mumbai. The popular term Bollywood is a portmanteau of ""Bombay"" (former name of Mumbai) and ""Hollywood"". The industry, producing films in the Hindi language, is a part of the larger Indian cinema industry, which also includes South Indian cinema and other smaller film industries.[2][3][4] The term 'Bollywood', often mistakenly used to refer to Indian cinema as a whole, only refers to Hindi-language films, with Indian cinema being an umbrella term that includes all the film industries in the country, each offering films in diverse languages and styles.
In 2017, Indian cinema produced 1,986 feature films, of which the largest number, 364, have been in Hindi.[2] In 2022, Hindi cinema represented 33% of box office revenue, followed by Telugu and Tamil representing 20% and 16% respectively.[5] Mumbai is one of the largest centres for film production in the world.[6][7][8] Hindi films sold an estimated 341 million tickets in India in 2019.[9][10] Earlier Hindi films tended to use vernacular Hindustani, mutually intelligible by speakers of either Hindi or Urdu, while modern Hindi productions increasingly incorporate elements of Hinglish.[11]
The most popular commercial genre in Hindi cinema since the 1970s has been the masala film, which freely mixes different genres including action, comedy, romance, drama and melodrama along with musical numbers.[12][13] Masala films ",art_culture
"Nollywood
Nollywood, a portmanteau of Nigeria and Hollywood, is a sobriquet that originally referred to the Nigerian film industry.[1] The origin of the term goes back to the early 2000s, traced to an article in The New York Times.[2][3] Due to the history of evolving meanings and contexts, there is no clear or agreed-upon definition for the term, which has made it a subject of several controversies.
Etymology
[edit]The origin of the term ""Nollywood"" remains unclear; Jonathan Haynes traced the earliest usage of the word to a 2002 article by Matt Steinglass in the New York Times, where it was used to describe Nigerian cinema.[2][3] Charles Igwe noted that Norimitsu Onishi also used the name in a September 2002 article he wrote for the New York Times.[4][5] The term continues to be used in the media to refer to the Nigerian film industry, with its definition later assumed to be a portmanteau of the words ""Nigeria"" and ""Hollywood"", the American major film hub.[6][7][8][9]
The definition of which films are considered Nollywood has always been debated. Alex Eyengho defined Nollywood as ""the totality of activities taking place in the Nigerian film industry, be it in English, Yoruba, Hausa, Igbo, Itsekiri, Edo, Efik, Ijaw, Urhobo, Ibibio, Annang or any other of the over 300 Nigerian languages"". He further stated that ""the historical trajectory of Nollywood started since the pre and post independent Nigeria, with the theatrical (stage) and cinematic (celluloid) efforts of the likes o",art_culture
"Film adaptation
A film adaptation transfers the details or story of an existing source text, such as a novel, into a feature film. This transfer can involve adapting most details of the source text closely, including characters or plot points, or the original source can serve as loose inspiration, with the implementation of only a few details.[1] Although often considered a type of derivative work, film adaptation has been conceptualized recently by academic scholars such as Robert Stam as a dialogic process.
While the most common form of film adaptation is the use of a novel as the basis, other works adapted into films include non-fiction (including journalism), autobiographical works, comic books, scriptures, plays, historical sources and even other films. Adaptation from such diverse resources has been a ubiquitous practice of filmmaking since the earliest days of cinema in nineteenth-century Europe. In contrast to when making a remake, movie directors usually take more creative liberties when creating a film adaptation, changing the context of factors such as audience or genre.[2]
Fidelity
[edit]The Fidelity Argument
[edit]One aspect that is usually considered for analyzing adaptations is the fidelity argument. This regards the discussion between scholars, reviewers, or fans, evaluating the effectiveness and success of an adaptation based on how faithfully it follows the original plot and details.[3] This can involve the common discourse of the ""book being better than the",art_culture
"Cinematography
Cinematography (from Ancient Greek κίνημα (kínēma) 'movement' and γράφειν (gráphein) 'to write, draw, paint, etc.') is the art of motion picture (and more recently, electronic video camera) photography.
Cinematographers use a lens to focus reflected light from objects into a real image that is transferred to some image sensor or light-sensitive material inside the movie camera.[1] These exposures are created sequentially and preserved for later processing and viewing as a motion picture. Capturing images with an electronic image sensor produces an electrical charge for each pixel in the image, which is electronically processed and stored in a video file for subsequent processing or display. Images captured with photographic emulsion result in a series of invisible latent images on the film stock, which are chemically ""developed"" into a visible image. The images on the film stock are projected for viewing in the same motion picture.
Cinematography finds uses in many fields of science and business, as well as for entertainment purposes and mass communication.
History
[edit]Precursors
[edit]In the 1830s, three different solutions for moving images were invented based on the concept of revolving drums and disks, the stroboscope by Simon von Stampfer in Austria, the phenakistoscope by Joseph Plateau in Belgium, and the zoetrope by William Horner in Britain.
In 1845, Francis Ronalds invented the first successful camera able to make continuous recordings of the varyin",art_culture
"Film editing
Film editing is both a creative and a technical part of the post-production process of filmmaking. The term is derived from the traditional process of working with film which increasingly involves the use of digital technology. When putting together some sort of video composition, typically, one would need a collection of shots and footages that vary from one another. The act of adjusting the shots someone has already taken, and turning them into something new is known as film editing.
The film editor works with raw footage, selecting shots and combining them into sequences which create a finished motion picture. Film editing is described as an art or skill, the only art that is unique to cinema, separating filmmaking from other art forms that preceded it, although there are close parallels to the editing process in other art forms such as poetry and novel writing. Film editing is an extremely important tool when attempting to intrigue a viewer. When done properly, a film's editing can captivate a viewer and fly completely under the radar. Because of this, film editing has been given the name ""the invisible art.""
On its most fundamental level, film editing is the art, technique and practice of assembling shots into a coherent sequence. The job of an editor is not simply to mechanically put pieces of a film together, cut off film slates or edit dialogue scenes. A film editor must creatively work with the layers of images, story, dialogue, music, pacing, as well as",art_culture
"Film score
A film score is original music written specifically to accompany a film. The score comprises a number of orchestral, instrumental, or choral pieces called cues, which are timed to begin and end at specific points during the film in order to enhance the dramatic narrative and the emotional impact of the scene in question.[1] Scores are written by one or more composers under the guidance of or in collaboration with the film's director or producer and are then most often performed by an ensemble of musicians – usually including an orchestra (most likely a symphony orchestra) or band, instrumental soloists, and choir or vocalists – known as playback singers – and recorded by a sound engineer. The term is less frequently applied to music written for media such as live theatre, television and radio programs, and video games, and said music is typically referred to as either the soundtrack or incidental music.
Film scores encompass an enormous variety of styles of music, depending on the nature of the films they accompany. While the majority of scores are orchestral works rooted in Western classical music, many scores are also influenced by jazz, rock, pop, blues, new-age and ambient music, and a wide range of ethnic and world music styles. Since the 1950s, a growing number of scores have also included electronic elements as part of the score, and many scores written today feature a hybrid of orchestral and electronic instruments.[2]
Since the invention of digital technol",art_culture
"Orchestration
Orchestration is the study or practice of writing music for an orchestra (or, more loosely, for any musical ensemble, such as a concert band) or of adapting music composed for another medium for an orchestra. Also called ""instrumentation"", orchestration is the assignment of different instruments to play the different parts (e.g., melody, bassline, etc.) of a musical work. For example, a work for solo piano could be adapted and orchestrated so that an orchestra could perform the piece, or a concert band piece could be orchestrated for a symphony orchestra.
In classical music, composers have historically orchestrated their own music. Only gradually over the course of music history did orchestration come to be regarded as a separate compositional art and profession in itself. In modern classical music, composers almost invariably orchestrate their own work. Two notable exceptions to this are Ravel's orchestration of Mussorgsky's solo piano work Pictures at an Exhibition[1] and Malcolm Arnold's orchestration of William Walton's String Quartet in A minor, producing the latter's Sonata for Strings.[2]
However, in musical theatre, film music and other commercial media, it is customary to use orchestrators and arrangers to one degree or another, since time constraints and/or the level of training of composers may preclude them orchestrating the music themselves.
The precise role of the orchestrator in film music is highly variable, and depends greatly on the needs and s",art_culture
"Musicology
Musicology is the academic, research-based study of music, as opposed to musical composition or performance.[1] Musicology research combines and intersects with many fields, including psychology, sociology, acoustics, neurology, natural sciences, formal sciences and computer science.
Musicology is traditionally divided into three branches: music history, systematic musicology, and ethnomusicology. Historical musicologists study the history of musical traditions, the origins of works, and the biographies of composers. Ethnomusicologists draw from anthropology (particularly field research) to understand how and why people make music. Systematic musicology includes music theory, aesthetics, pedagogy, musical acoustics, the science and technology of musical instruments, and the musical implications of physiology, psychology, sociology, philosophy and computing. Cognitive musicology is the set of phenomena surrounding the cognitive modeling of music. When musicologists carry out research using computers, their research often falls under the field of computational musicology. Music therapy is a specialized form of applied musicology which is sometimes considered more closely affiliated with health fields, and other times regarded as part of musicology proper.
Background
[edit]The word musicology comes from Greek μουσική mousikē 'music' and -λογια -logia, 'domain of study'.
The 19th-century philosophical trends that led to the re-establishment of formal musicology educati",art_culture
"Ethnomusicology
Ethnomusicology is the multidisciplinary study of music in its cultural context. The discipline investigates social, cognitive, biological, comparative, and other dimensions. Ethnomusicologists study music as a reflection of culture and investigate the act of music-making through various immersive, observational, and analytical approaches. This discipline emerged from comparative musicology, initially focusing on non-Western music, but later expanded to embrace the study of all different music.
The practice of ethnomusicology relies on direct engagement and performance, as well as academic work.[1] Fieldwork takes place among those who make the music, engaging local languages and culture as well as music. Ethnomusicologists can become participant observers, learning to perform the music they are studying.[2] Fieldworkers also collect recordings and contextual data.[3]
Definition
[edit]Ethnomusicology combines perspectives from folklore, psychology, cultural anthropology, linguistics, comparative musicology, music theory, and history.[4][5] This resulted in various definitions. In 1956, Rhodes called it a theoretical and empirical study amalgamating musicology and anthropology.[6] In 1992, Titon summarized ethnomusicology as the study of ""people making music"": people make the sounds called music, and people also make music into a cultural domain, with associated ideas, activities, and material culture.[7]
The word is a portmanteau of 'ethno' (people), and 'musi",art_culture
"Music theory
Music theory is the study of theoretical frameworks for understanding the practices and possibilities of music. The Oxford Companion to Music describes three interrelated uses of the term ""music theory"": The first is the ""rudiments"", that are needed to understand music notation (key signatures, time signatures, and rhythmic notation); the second is learning scholars' views on music from antiquity to the present; the third is a sub-topic of musicology that ""seeks to define processes and general principles in music"". The musicological approach to theory differs from music analysis ""in that it takes as its starting-point not the individual work or performance but the fundamental materials from which it is built.""[1]
Music theory is frequently concerned with describing how musicians and composers make music, including tuning systems and composition methods among other topics. Because of the ever-expanding conception of what constitutes music, a more inclusive definition could be the consideration of any sonic phenomena, including silence. This is not an absolute guideline, however; for example, the study of ""music"" in the Quadrivium liberal arts university curriculum, that was common in medieval Europe, was an abstract system of proportions that was carefully studied at a distance from actual musical practice.[n 1] But this medieval discipline became the basis for tuning systems in later centuries and is generally included in modern scholarship on the history of musi",art_culture
"Harmony
In music, harmony is the concept of combining different sounds in order to create new, distinct musical ideas.[1] Theories of harmony seek to describe or explain the effects created by distinct pitches or tones coinciding with one another; harmonic objects such as chords, textures and tonalities are identified, defined, and categorized in the development of these theories. Harmony is broadly understood to involve both a ""vertical"" dimension (frequency-space) and a ""horizontal"" dimension (time-space), and often overlaps with related musical concepts such as melody, timbre, and form.[2]
A particular emphasis on harmony is one of the core concepts underlying the theory and practice of Western music.[3] The study of harmony involves the juxtaposition of individual pitches to create chords, and in turn the juxtaposition of chords to create larger chord progressions. The principles of connection that govern these structures have been the subject of centuries worth of theoretical work and vernacular practice alike.[4]
Drawing both from music theoretical traditions and the field of psychoacoustics, its perception in large part consists of recognizing and processing consonance, a concept whose precise definition has varied throughout history, but is often associated with simple mathematical ratios between coincident pitch frequencies. In the physiological approach, consonance is viewed as a continuous variable measuring the human brain's ability to 'decode' aural sensory input",art_culture
"Melody
A melody (from Greek μελῳδία (melōidía) 'singing, chanting'),[1] also tune, voice, or line, is a linear succession of musical tones that the listener perceives as a single entity. In its most literal sense, a melody is a combination of pitch and rhythm, while more figuratively, the term can include other musical elements such as tonal color. It is the foreground to the background accompaniment. A line or part need not be a foreground melody.
Melodies often consist of one or more musical phrases or motifs, and are usually repeated throughout a composition in various forms. Melodies may also be described by their melodic motion or the pitches or the intervals between pitches (predominantly conjunct or disjunct or with further restrictions), pitch range, tension and release, continuity and coherence, cadence, and shape.
Function and elements
[edit]Johann Philipp Kirnberger argued:
The true goal of music—its proper enterprise—is melody. All the parts of harmony have as their ultimate purpose only beautiful melody. Therefore, the question of which is the more significant, melody or harmony, is futile. Beyond doubt, the means is subordinate to the end.
— Johann Philipp Kirnberger (1771)[2]
The Norwegian composer Marcus Paus has argued:
Melody is to music what a scent is to the senses: it jogs our memory. It gives face to form, and identity and character to the process and proceedings. It is not only a musical subject, but a manifestation of the musically subjective. It carri",art_culture
"Rhythm
Rhythm (from Greek ῥυθμός, rhythmos, ""any regular recurring motion, symmetry""[1]) generally means a ""movement marked by the regulated succession of strong and weak elements, or of opposite or different conditions"".[2] This general meaning of regular recurrence or pattern in time can apply to a wide variety of cyclical natural phenomena having a periodicity or frequency of anything from microseconds to several seconds (as with the riff in a rock music song); to several minutes or hours, or, at the most extreme, even over many years.
The Oxford English Dictionary defines rhythm as ""The measured flow of words or phrases in verse, forming various patterns of sound as determined by the relation of long and short or stressed and unstressed syllables in a metrical foot or line; an instance of this"".[3]
Rhythm is related to and distinguished from pulse, meter, and beats:
Rhythm may be defined as the way in which one or more unaccented beats are grouped in relation to an accented one. ... A rhythmic group can be apprehended only when its elements are distinguished from one another, rhythm...always involves an interrelationship between a single, accented (strong) beat and either one or two unaccented (weak) beats.[4]
In the performance arts, rhythm is the timing of events on a human scale; of musical sounds and silences that occur over time, of the steps of a dance, or the meter of spoken language and poetry. In some performing arts, such as hip hop music, the rhythmic delivery ",art_culture
"Jazz improvisation
Jazz improvisation is the spontaneous invention of melodic solo lines or accompaniment parts in a performance of jazz music. It is one of the defining elements of jazz. Improvisation is composing on the spot, when a singer or instrumentalist invents melodies and lines over a chord progression played by rhythm section instruments (piano, guitar, double bass) and accompanied by drums. Although blues, rock, and other genres use improvisation, it is done over relatively simple chord progressions which often remain in one key (or closely related keys using the circle of fifths, such as a song in C Major modulating to G Major).
Jazz improvisation is distinguished from this approach by chordal complexity, often with one or more chord changes per bar, altered chords, extended chords, tritone substitution, unusual chords (e.g., augmented chords), and extensive use of ii–V–I progression, all of which typically move through multiple keys within a single song. However, since the release of Kind of Blue by Miles Davis, jazz improvisation has come to include modal harmony and improvisation over static key centers, while the emergence of free jazz has led to a variety of types of improvisation, such as ""free blowing"", in which soloists improvise freely and ignore the chord changes.
Soloing
[edit]When soloing, a performer (instrumentalist or singer) creates a new melodic line to fit a song's chord progression. During a solo, the performer who is playing the solo is the mai",art_culture
"Blues
Blues is a music genre[3] and musical form that originated among African Americans in the Deep South of the United States around the 1860s.[2] Blues has incorporated spirituals, work songs, field hollers, shouts, chants, and rhymed simple narrative ballads from the African-American culture. The blues form is ubiquitous in jazz, rhythm and blues, and rock and roll, and is characterized by the call-and-response pattern, the blues scale, and specific chord progressions, of which the twelve-bar blues is the most common. Blue notes (or ""worried notes""), usually thirds, fifths or sevenths flattened in pitch, are also an essential part of the sound. Blues shuffles or walking bass reinforce the trance-like rhythm and form a repetitive effect known as the groove.
Blues music is characterized by its lyrics, bass lines, and instrumentation. Early traditional blues verses consisted of a single line repeated four times. It was only in the first decades of the 20th century that the most common current structure became standard: the AAB pattern, consisting of a line sung over the four first bars, its repetition over the next four, and then a longer concluding line over the last bars. Early blues frequently took the form of a loose narrative, often relating the racial discrimination and other challenges experienced by African Americans.[4]
Many elements, such as the call-and-response format and the use of blue notes, can be traced back to the music of Africa. The origins of the blues a",art_culture
"Rock music
Rock music is a genre of popular music that originated in the United States as ""rock and roll"" in the late 1940s and early 1950s, developing into a range of styles from the mid-1960s, primarily in the United States and United Kingdom. It has its roots in rock and roll, a style that drew from the black musical genres of blues and rhythm and blues, as well as from country music. Rock also drew strongly from genres such as electric blues and folk, and incorporated influences from jazz and other styles. Rock is typically centered on the electric guitar, usually as part of a rock group with electric bass guitar, drums, and one or more singers. Usually, rock is song-based music with a 4
4 time signature and using a verse–chorus form; however, the genre has become extremely diverse. Like pop music, lyrics often stress romantic love but also address a wide variety of other themes that are frequently social or political. Rock was the most popular genre of music in the U.S. and much of the Western world from the 1950s up to the 2010s.
Rock musicians in the mid-1960s began to advance the album ahead of the single as the dominant form of recorded music expression and consumption, with the Beatles at the forefront of this development. Their contributions lent the genre a cultural legitimacy in the mainstream and initiated a rock-informed album era in the music industry for the next several decades. By the late 1960s ""classic rock""[3] period, a few distinct rock music subgenres ",art_culture
"Psychedelic rock
Psychedelic rock is a rock music genre that is inspired, influenced, or representative of psychedelic culture, which is centered on perception-altering hallucinogenic drugs. The music incorporated new electronic sound effects and recording techniques, extended instrumental solos, and improvisation.[2] Many psychedelic groups differ in style, and the label is often applied spuriously.[3]
Originating in the mid-1960s among British and American musicians, the sound of psychedelic rock invokes three core effects of LSD: depersonalization, dechronicization (the bending of time), and dynamization (when fixed, ordinary objects dissolve into moving, dancing structures), all of which detach the user from everyday reality.[3] Musically, the effects may be represented via novelty studio tricks, electronic or non-Western instrumentation, disjunctive song structures, and extended instrumental segments.[4] Some of the earlier 1960s psychedelic rock musicians were based in folk, jazz, and the blues, while others showcased an explicit Indian classical influence called ""raga rock"". In the 1960s, there existed two main variants of the genre: the more whimsical, surrealist British psychedelia and the harder American West Coast ""acid rock"". While ""acid rock"" is sometimes deployed interchangeably with the term ""psychedelic rock"", it also refers more specifically to the heavier, harder, and more extreme ends of the genre.
The peak years of psychedelic rock were between 1967 and 19",art_culture
"Progressive rock
Progressive rock (shortened as prog rock or simply prog) is a broad genre of rock music[10] that primarily developed in the United Kingdom[1] through the mid- to late 1960s, peaking in the early-to-mid-1970s. Initially termed ""progressive pop"", the style emerged from psychedelic bands who abandoned standard pop or rock traditions in favour of instrumental and compositional techniques more commonly associated with jazz, folk, or classical music, while retaining the instrumentation typical of rock music. Additional elements contributed to its ""progressive"" label: lyrics were more poetic, technology was harnessed for new sounds, music approached the condition of ""art"", and the studio, rather than the stage, became the focus of musical activity, which often involved creating music for listening rather than dancing.
Progressive rock includes a fusion of styles, approaches and genres, and tends to be diverse and eclectic. Progressive rock is often associated with long solos, extended pieces, fantastic lyrics, grandiose stage sets and costumes, and an obsessive dedication to technical skill. While the genre is often cited for its merging of high culture and low culture, few artists incorporated classical themes in their work to a significant degree, and only a handful of groups, such as Emerson, Lake & Palmer and Renaissance, intentionally emulated or referenced classical music.
The genre arose during the mid-1960s. In the early-to-mid-1970s, progressive rock groups",art_culture
"Funk
Funk is a music genre that originated in African-American communities in the mid-1960s when musicians created a rhythmic, danceable new form of music through a mixture of various music genres that were popular among African-Americans in the mid-20th century. It deemphasizes melody and chord progressions and focuses on a strong rhythmic groove of a bassline played by an electric bassist and a drum part played by a percussionist, often at slower tempos than other popular music. Funk typically consists of a complex percussive groove with rhythm instruments playing interlocking grooves that create a ""hypnotic"" and ""danceable"" feel.[3] It uses the same richly colored extended chords found in bebop jazz, such as minor chords with added sevenths and elevenths, and dominant seventh chords with altered ninths and thirteenths.
Funk originated in the mid-1960s, with James Brown's development of a signature groove that emphasized the downbeat—with a heavy emphasis on the first beat of every measure (""The One""), and the application of swung 16th notes and syncopation on all basslines, drum patterns, and guitar riffs.[4] Rock- and psychedelia-influenced musicians Sly and the Family Stone and Parliament-Funkadelic fostered more eclectic examples of the genre beginning in the late 1960s.[5] Other musical groups developed Brown's innovations during the 1970s and the 1980s, including Kool and the Gang,[6] Ohio Players, Fatback Band, Jimmy Castor Bunch, Earth, Wind & Fire, B.T. Express, Sh",art_culture
"Disco
Disco is a genre of dance music and a subculture that emerged in the late 1960s from the United States' urban nightlife scene, particularly in African-American, Italian-American, Gay and Latino communities. Its sound is typified by four-on-the-floor beats, syncopated basslines, string sections, brass and horns, electric pianos, synthesizers, and electric rhythm guitars.
Discothèques as a venue were mostly a French invention, imported to the United States with the opening of Le Club, a members-only restaurant and nightclub located at 416 East 55th Street in Manhattan, by French expatriate Olivier Coquelin, on New Year's Eve 1960.[5]
Disco music as a genre started as a mixture of music from venues popular among African Americans, Latino Americans, and Italian Americans[6] in New York City (especially Brooklyn) and Philadelphia during the late 1960s to the mid-to-late 1970s. Disco can be seen as a reaction by the 1960s counterculture to both the dominance of rock music and the stigmatization of dance music at the time.[7] Several dance styles were developed during the period of '70s disco's popularity in the United States, including ""the Bump"", ""the Hustle"", ""the Watergate"", ""the Continental"",[8] and ""the Busstop"".[9]
During the 1970s, disco music was developed further, mainly by artists from the United States as well as from Europe. Well-known artists included the Bee Gees, Blondie, ABBA, Donna Summer, Gloria Gaynor, Giorgio Moroder, Baccara, George Michael, The Jacksons,",art_culture
"Hip-hop
Hip-hop or hip hop (originally disco rap) is a popular music genre that emerged in the early 1970s from the African-American community of New York City. The style is characterized by its synthesis of a wide range of musical techniques. Hip-hop includes rapping often enough that the terms can be used synonymously. However, ""hip-hop"" more properly denotes an entire subculture. Other key markers of the genre are the disc jockey, turntablism, scratching, beatboxing, and instrumental tracks. Cultural interchange has always been central to the hip-hop genre. It simultaneously borrows from its social environment while commenting on it.
The hip-hop genre and culture emerged from block parties in ethnic minority neighborhoods of New York City, particularly Bronx. DJs began expanding the instrumental breaks of popular records when they noticed how excited it would make the crowds. The extended instrumental breaks provided a platform for break dancers and rappers. These breakbeats enabled the subsequent evolution of the hip-hop style. Many of the records used were disco due to its popularity at the time.
This disco-inflected music is known as old-school hip-hop. The genre became more stylistically diverse in the 1980s as electro music started to inform new-school hip-hop. The transition between the mid-1980s and 1990s became known as hip-hop's Golden age as the genre started to earn wide critical acclaim and generate massive sales.
The popularity of hip-hop music expanded throug",art_culture
"Techno
Techno is a genre of electronic dance music[2] (EDM) which is generally produced for use in a continuous DJ set, with tempos being in the range from 120 to 150 beats per minute (bpm). The central rhythm is typically in common time (4
4) and often characterized by a repetitive four on the floor beat.[3] Artists may use electronic instruments such as drum machines, sequencers, and synthesizers, as well as digital audio workstations. Drum machines from the 1980s such as Roland's Roland TR-808 and Roland TR-909 are highly prized, and software emulations of such retro instruments are popular in this style.
Much of the instrumentation in techno is used to emphasize the role of rhythm over other musical aspects. Vocals and melodies are uncommon. The use of sound synthesis in developing distinctive timbres tends to feature more prominently. Typical harmonic practices found in other forms of music are often ignored in favor of repetitive sequences of notes. More generally the creation of techno is heavily dependent on music production technology.
Use of the term ""techno"" to refer to a type of electronic music originated in Germany in the early 1980s.[4] In 1988, following the UK release of the compilation Techno! The New Dance Sound of Detroit, the term came to be associated with a form of EDM produced in Detroit.[5][6] Detroit techno resulted from the melding of synth-pop by artists such as Kraftwerk, Giorgio Moroder and Yellow Magic Orchestra with African American styles such",art_culture
"House music
House is a genre of electronic dance music characterized by a repetitive four-on-the-floor beat and a typical tempo of 115–130 beats per minute.[11] It was created by DJs and music producers from Chicago's underground club culture and evolved slowly in the early/mid 1980s as DJs began altering disco songs to give them a more mechanical beat.[1][12] By early 1988, house became mainstream and supplanted the typical 80s music beat.[13]
House was created and pioneered by DJs and producers in Chicago such as Frankie Knuckles, Ron Hardy, Jesse Saunders, Chip E., Joe Smooth, Steve ""Silk"" Hurley, Farley ""Jackmaster"" Funk, Marshall Jefferson, Phuture, and others. House music initially expanded to New York City, then internationally to cities such as London, and ultimately became a worldwide phenomenon.[14]
House has a large influence on pop music, especially dance music. It was incorporated into works by major international artists including Whitney Houston, Mariah Carey, Janet Jackson, Madonna, Pet Shop Boys, Kylie Minogue and Lady Gaga, and produced many mainstream hits such as ""Pump Up the Jam"" by Technotronic, ""French Kiss"" by Lil Louis, ""Show Me Love"" by Robin S., and ""Push the Feeling On"" by the Nightcrawlers. Many house DJs also did and continue to do remixes for pop artists. House music has remained popular on radio and in clubs while retaining a foothold on the underground scenes across the globe.
Characteristics
[edit]In its most typical form, the genre is charac",art_culture
"Trance
Trance is a state of semi-consciousness in which a person is not self-aware and is either altogether unresponsive to external stimuli (but nevertheless capable of pursuing and realizing an aim) or is selectively responsive in following the directions of the person (if any) who has induced the trance. Trance states may occur involuntarily and unbidden.
The term trance may be associated with hypnosis, meditation, magic, flow, prayer, psychedelic drugs, and altered states of consciousness.
Etymology
[edit]Trance in its modern meaning comes from an earlier meaning of ""a dazed, half-conscious or insensible condition or state of fear"", via the Old French transe ""fear of evil"", from the Latin transīre ""to cross"", ""pass over"".[1]
Working models
[edit]Wier, in his 1995 book, Trance: from magic to technology, defines a simple trance (p. 58) as a state of mind being caused by cognitive loops where a cognitive object (a thought, an image, a sound, an intentional action) repeats long enough to result in various sets of disabled cognitive functions. Wier represents all trances (which include sleep and watching television) as taking place on a dissociated trance plane where at least some cognitive functions such as volition are disabled; as is seen in what is typically termed a 'hypnotic trance'.[2] With this definition, meditation, hypnosis, addictions and charisma are seen as being trance states. In Wier's 2007 book, The Way of Trance, he elaborates on these forms, adds ecstasy as ",Philosophy & Religion 
"Ambient music
Ambient music is a genre of music that emphasizes tone and atmosphere over traditional musical structure or rhythm. Often ""peaceful"" sounding and lacking composition, beat, and/or structured melody,[5] ambient music uses textural layers of sound that can reward both passive and active listening,[6] and encourage a sense of calm or contemplation.[7][8] The genre evokes an ""atmospheric"", ""visual"",[9] or ""unobtrusive"" quality.[10] Nature soundscapes may be included, and some works use sustained or repeated notes, as in drone music. Bearing elements associated with new-age music, instruments such as the piano, strings and flute may be emulated through a synthesizer.[11][12]
The genre originated in the 1960s and 1970s, when new musical instruments were being introduced to a wider market, such as the synthesizer.[13] It was presaged by Erik Satie's furniture music and styles such as musique concrète, minimal music, Jamaican dub reggae and German electronic music, but was prominently named and popularized by British musician Brian Eno in 1978 with his album Ambient 1: Music for Airports; Eno opined that ambient music ""must be as ignorable as it is interesting"", however, in early years, there were artists that were pioneers in this genre, like Jean-Michel Jarre, Vangelis, Mike Oldfield, Wendy Carlos, Kraftwerk, etc.[14] It saw a revival towards the late 1980s with the prominence of house and techno music, growing a cult following by the 1990s.[15]
Ambient music has not ",art_culture
"Classical music
Classical music generally refers to the art music of the Western world, considered to be distinct from Western folk music or popular music traditions. It is sometimes distinguished as Western classical music, as the term ""classical music"" can also be applied to non-Western art musics. Classical music is often characterized by formality and complexity in its musical form and harmonic organization,[1] particularly with the use of polyphony.[2] Since at least the ninth century, it has been primarily a written tradition,[2] spawning a sophisticated notational system, as well as accompanying literature in analytical, critical, historiographical, musicological and philosophical practices. A foundational component of Western culture, classical music is frequently seen from the perspective of individual or groups of composers, whose compositions, personalities and beliefs have fundamentally shaped its history.[citation needed]
Rooted in the patronage of churches and royal courts in Western Europe,[1] surviving early medieval music is chiefly religious, monophonic and vocal, with the music of ancient Greece and Rome influencing its thought and theory. The earliest extant music manuscripts date from the Carolingian Empire (800–887),[3] around the time which Western plainchant gradually unified into what is termed Gregorian chant.[4] Musical centers existed at the Abbey of Saint Gall, the Abbey of Saint Martial and Saint Emmeram's Abbey, while the 11th century saw the de",art_culture
"Baroque music
Baroque music (UK: /bəˈrɒk/ or US: /bəˈroʊk/) refers to the period or dominant style of Western classical music composed from about 1600 to 1750.[1] The Baroque style followed the Renaissance period, and was followed in turn by the Classical period after a short transition (the galant style). The Baroque period is divided into three major phases: early, middle, and late. Overlapping in time, they are conventionally dated from 1580 to 1650, from 1630 to 1700, and from 1680 to 1750. Baroque music forms a major portion of the ""classical music"" canon, and continues to be widely studied, performed, and listened to. The term ""baroque"" comes from the Portuguese word barroco, meaning ""misshapen pearl"".[2] Key composers of the Baroque era include Johann Sebastian Bach, Antonio Vivaldi, George Frideric Handel, Georg Philipp Telemann, Domenico Scarlatti, Claudio Monteverdi, Alessandro Stradella, Jean-Baptiste Lully, Jean-Philippe Rameau, Arcangelo Corelli, François Couperin, Heinrich Schütz, Dieterich Buxtehude, and Heinrich Ignaz Franz Biber.
The Baroque saw the formalization of common-practice tonality, an approach to writing music in which a song or piece is written in a particular key; this type of harmony has continued to be used extensively in Western classical and popular music. During the Baroque era, professional musicians were expected to be accomplished improvisers of both solo melodic lines and accompaniment parts. Baroque concerts were typically accompanied by",art_culture
"Renaissance music
Renaissance music is traditionally understood to cover European music of the 15th and 16th centuries, later than the Renaissance era as it is understood in other disciplines. Rather than starting from the early 14th-century ars nova, the Trecento music was treated by musicology as a coda to medieval music and the new era dated from the rise of triadic harmony and the spread of the contenance angloise style from the British Isles to the Burgundian School. A convenient watershed for its end is the adoption of basso continuo at the beginning of the Baroque period.
The period may be roughly subdivided, with an early period corresponding to the career of Guillaume Du Fay (c. 1397–1474) and the cultivation of cantilena style, a middle dominated by Franco-Flemish School and the four-part textures favored by Johannes Ockeghem (1410s or '20s–1497) and Josquin des Prez (late 1450s–1521), and culminating during the Counter-Reformation in the florid counterpoint of Palestrina (c. 1525–1594) and the Roman School.
Music was increasingly freed from medieval constraints, and more variety was permitted in range, rhythm, harmony, form, and notation. On the other hand, rules of counterpoint became more constrained, particularly with regard to treatment of dissonances. In the Renaissance, music became a vehicle for personal expression. Composers found ways to make vocal music more expressive of the texts they were setting. Secular music absorbed techniques from sacred music, an",art_culture
"Medieval music
Medieval music encompasses the sacred and secular music of Western Europe during the Middle Ages,[1] from approximately the 6th to 15th centuries. It is the first and longest major era of Western classical music and is followed by the Renaissance music; the two eras comprise what musicologists generally term as early music, preceding the common practice period. Following the traditional division of the Middle Ages, medieval music can be divided into Early (500–1000), High (1000–1300), and Late (1300–1400) medieval music.
Medieval music includes liturgical music used for the church, other sacred music, and secular or non-religious music. Much medieval music is purely vocal music, such as Gregorian chant. Other music used only instruments or both voices and instruments (typically with the instruments accompanying the voices).
The medieval period saw the creation and adaptation of systems of music notation which enabled creators to document and transmit musical ideas more easily, although notation coexisted with and complemented oral tradition.
Overview
[edit]Genres
[edit]Medieval music was created for a number of different uses and contexts, resulting in different music genres. Liturgical as well as more general sacred contexts were important, but secular types emerged as well, including love songs and dances. During the earlier medieval period, liturgical music was monophonic chant; Gregorian chant became the dominant style. Polyphonic genres, in which multiple ",art_culture
"Opera
Opera is a form of Western theatre in which music is a fundamental component and dramatic roles are taken by singers. Such a ""work"" (the literal translation of the Italian word ""opera"") is typically a collaboration between a composer and a librettist[1] and incorporates a number of the performing arts, such as acting, scenery, costume, and sometimes dance or ballet. The performance is typically given in an opera house, accompanied by an orchestra or smaller musical ensemble, which since the early 19th century has been led by a conductor. Although musical theatre is closely related to opera, the two are considered to be distinct from one another.[2]
Opera is a key part of Western classical music, and Italian tradition in particular.[3] Originally understood as an entirely sung piece, in contrast to a play with songs, opera has come to include numerous genres, including some that include spoken dialogue such as Singspiel and Opéra comique. In traditional number opera, singers employ two styles of singing: recitative, a speech-inflected style,[4] and self-contained arias. The 19th century saw the rise of the continuous music drama.
Opera originated in Italy at the end of the 16th century (with Jacopo Peri's mostly lost Dafne, produced in Florence in 1598) especially from works by Claudio Monteverdi, notably L'Orfeo, and soon spread through the rest of Europe: Heinrich Schütz in Germany, Jean-Baptiste Lully in France, and Henry Purcell in England all helped to establish the",art_culture
"Oratorio
An oratorio (Italian pronunciation: [oraˈtɔːrjo]) is a musical composition with dramatic or narrative text for choir, soloists and orchestra or other ensemble.[1]
Similar to opera, an oratorio includes the use of a choir, soloists, an instrumental ensemble, various distinguishable characters (e.g. soloists), and arias. However, opera is musical theatre, and typically involves significant theatrical spectacle, including sets, props, and costuming, as well as staged interactions between characters. In oratorio, there is generally minimal staging, with the chorus often assuming a more central dramatic role, and the work is typically presented as a concert piece – though oratorios are sometimes staged as operas, and operas are not infrequently presented in concert form.
A particularly important difference between opera and oratorio is in the typical subject matter of the text. An opera libretto may deal with any conceivable dramatic subject (e.g. history, mythology, Richard Nixon (Nixon in China), Anna Nicole Smith (Anna Nicole) and the Bible); the text of an oratorio often deals with sacred subjects, making it appropriate for performance in the church, which remains an important performance context for the genre. Catholic composers looked to the lives of saints and stories from the Bible. Protestant composers also often looked to biblical topics, but sometimes looked to the lives of notable religious figures, such as Carl Loewe's Jan Hus, an oratorio about the early ref",art_culture
"Modern dance
Modern dance is a broad genre of western concert or theatrical dance which includes dance styles such as ballet, folk, ethnic, religious, and social dancing; and primarily arose out of Europe and the United States in the late 19th and early 20th centuries. It was considered to have been developed as a rejection of, or rebellion against, classical ballet, and also a way to express social concerns like socioeconomic and cultural factors.[1][2][3]
In the late 19th century, modern dance artists such as Isadora Duncan, Maud Allan, and Loie Fuller were pioneering new forms and practices in what is now called improvisational or free dance. These dancers disregarded ballet's strict movement vocabulary (the particular, limited set of movements that were considered proper to ballet) and stopped wearing corsets and pointe shoes in the search for greater freedom of movement.[3]
Throughout the 20th century, sociopolitical concerns, major historical events, and the development of other art forms contributed to the continued development of modern dance in the United States and Europe. Moving into the 1960s, new ideas about dance began to emerge as a response to earlier dance forms and to social changes. Eventually, postmodern dance artists would reject the formalism of modern dance, and include elements such as performance art, contact improvisation, release technique, and improvisation.[3][4]
American modern dance can be divided (roughly) into three periods or eras. In the Ear",art_culture
"Hip-hop dance
Hip hop dance is a range of street dance styles primarily performed to hip hop music or that have evolved as part of hip hop culture. It is influenced by a wide range of styles that were created in the 1970s and made popular by dance crews in the United States. The television show Soul Train and the 1980s films Breakin', Beat Street, and Wild Style showcased these crews and dance styles in their early stages; therefore, giving hip-hop dance mainstream exposure.
The dance industry responded with a commercial, studio-based version of hip-hop—sometimes called ""new style""—and a hip-hop influenced style of jazz dance called ""jazz-funk"". Classically trained dancers developed these studio styles in order to create choreography from the hip-hop dances that were performed on the street. Because of this development, hip-hop dance is practiced in both dance studios and outdoor spaces.
The commercialization of hip-hop dance continued into the 1990s and 2000s with the production of several television shows and movies such as The Grind, Planet B-Boy, Rize, StreetDance 3D, America's Best Dance Crew, Saigon Electric, the Step Up film series, and The LXD, a web series. Though the dance is established in entertainment, including mild representation in theater, it maintains a strong presence in urban neighborhoods, which has led to the creation of street dance derivatives like Memphis jookin, turfing, jerkin', and krump. What distinguishes hip-hop from other forms of dance is that",art_culture
"Flamenco
Flamenco (Spanish pronunciation: [flaˈmeŋko]) is an art form based on the various folkloric music traditions of southern Spain, developed within the gitano subculture of the region of Andalusia, and also having historical presence in Extremadura and Murcia.[1][2][3] In a wider sense, the term is used to refer to a variety of both contemporary and traditional musical styles typical of southern Spain. Flamenco is closely associated to the gitanos of the Romani ethnicity who have contributed significantly to its origination and professionalization. However, its style is uniquely Andalusian and flamenco artists have historically included Spaniards of both gitano and non-gitano heritage.[4]
The oldest record of flamenco music dates to 1774 in the book Las Cartas Marruecas (The Moroccan Letters) by José Cadalso.[5] The development of flamenco over the past two centuries is well documented: ""the theatre movement of sainetes (one-act plays) and tonadillas, popular song books and song sheets, customs, studies of dances, and toques, perfection, newspapers, graphic documents in paintings and engravings. ... in continuous evolution together with rhythm, the poetic stanzas, and the ambiance.""[6]
On 16 November 2010, UNESCO declared flamenco one of the Masterpieces of the Oral and Intangible Heritage of Humanity.[7]
Etymology
[edit]Historically, the term Flamenco was used to identify the Romani people (Gitanos) of Spain.[8] The English traveller George Borrow who travelled through",art_culture
"Tango
Tango is a partner dance and social dance that originated in the 1880s along the Río de la Plata, the natural border between Argentina and Uruguay. The tango was born in the impoverished port areas of these countries from a combination of Argentine Milonga, Spanish-Cuban Habanera, and Uruguayan Candombe celebrations.[1] It was frequently practiced in the brothels and bars of ports, where business owners employed bands to entertain their patrons.[2] It then spread to the rest of the world.[3] Many variations of this dance currently exist around the world.
On August 31, 2009, UNESCO approved a joint proposal by Argentina and Uruguay to include the tango in the UNESCO Intangible Cultural Heritage Lists.[4][5]
History
[edit]Tango is a dance that has influences from African and European culture.[6][7] Dances from the Candombe ceremonies of former African enslaved people helped shape the modern day tango. The dance originated in working-class districts of Buenos Aires and Montevideo. Tango music derived from the fusion of various forms of music from Europe.[8] The words ""tango"" and ""tambo"" around the River Plate basin were initially used to refer to musical gatherings of slaves, with written records of colonial authorities attempting to ban such gatherings as early as 1789.[9]
Initially, it was just one of the many dances, but it soon[when?] became popular throughout society, as theatres and street barrel organs spread it from the suburbs to the working-class slums, which wer",art_culture
"World music
""World music"" is an English phrase for styles of music from non-English speaking countries, including quasi-traditional, intercultural, and traditional music. World music's broad nature and elasticity as a musical category pose obstacles to a universal definition, but its ethic of interest in the culturally exotic is encapsulated in Roots magazine's description of the genre as ""local music from out there"".[1][2]
Music that does not follow ""North American or British pop and folk traditions""[3] was given the term ""world music"" by music industries in Europe and North America.[4] The term was popularized in the 1980s as a marketing category for non-Western traditional music.[5][6] It has grown to include subgenres such as ethnic fusion (Clannad, Ry Cooder, Enya, etc.)[7] and worldbeat.[8][9]
Lexicology
[edit]The term ""world music"" has been credited to ethnomusicologist Robert E. Brown, who coined it in the early 1960s at Wesleyan University in Connecticut, where he developed undergraduate through doctoral programs in the discipline. To enhance the learning process (John Hill), he invited more than a dozen visiting performers from Africa and Asia and began a world music concert series.[10][11] The term became current in the 1980s as a marketing/classificatory device in the media and the music industry.[12] There are several conflicting definitions for world music. One is that it consists of ""all the music in the world"", though such a broad definition renders the term v",art_culture
"Reggae
Reggae (/ˈrɛɡeɪ/ ⓘ) is a music genre that originated in Jamaica during the late 1960s. The term also denotes the modern popular music of Jamaica and its diaspora.[1] A 1968 single by Toots and the Maytals, ""Do the Reggay"", was the first popular song to use the word reggae, effectively naming the genre and introducing it to a global audience.[2][3] Reggae is rooted in traditional Jamaican Kumina, Pukkumina, Revival Zion, Nyabinghi, and burru drumming. Jamaican reggae music evolved out of the earlier genres mento, ska and rocksteady.[4] Reggae usually relates news, social gossip, and political commentary.[5] It is recognizable from the counterpoint between the bass and drum downbeat and the offbeat rhythm section. The immediate origins of reggae were in ska and rocksteady; from the latter, reggae took over the use of the bass as a percussion instrument.[6]
Stylistically, reggae incorporates some of the musical elements of rhythm and blues, jazz, mento (a celebratory, rural folk form that served its largely rural audience as dance music and an alternative to the hymns and adapted chanteys of local church singing),[7] calypso,[8] and also draws influence from traditional African folk rhythms. One of the most easily recognizable elements is offbeat rhythms; staccato chords played by a guitar or piano (or both) on the offbeats of the measure. The tempo of reggae is usually slower-paced than both ska and rocksteady.[9] The concept of call and response can be found throughout ",art_culture
"Folk music
Folk music is a music genre that includes traditional folk music and the contemporary genre that evolved from the former during the 20th-century folk revival. Some types of folk music may be called world music. Traditional folk music has been defined in several ways: as music transmitted orally, music with unknown composers, music that is played on traditional instruments, music about cultural or national identity, music that changes between generations (folk process), music associated with a people's folklore, or music performed by custom over a long period of time. It has been contrasted with commercial and classical styles. The term originated in the 19th century, but folk music extends beyond that.
Starting in the mid-20th century, a new form of popular folk music evolved from traditional folk music. This process and period is called the (second) folk revival and reached a zenith in the 1960s. This form of music is sometimes called contemporary folk music or folk revival music to distinguish it from earlier folk forms.[1] Smaller, similar revivals have occurred elsewhere in the world at other times, but the term folk music has typically not been applied to the new music created during those revivals. This type of folk music also includes fusion genres such as folk rock, folk metal, and others. While contemporary folk music is a genre generally distinct from traditional folk music, in U.S. English it shares the same name, and it often shares the same performers ",art_culture
"Country music
Country (also called country and western) is a music genre originating in the southern regions of the United States, both the American South and the Southwest. First produced in the 1920s, country music is primarily focused on singing stories about working-class and blue-collar American life.[2][3]
Country music is known for its ballads and dance tunes (i.e., ""honky-tonk music"") with simple form, folk lyrics, and harmonies generally accompanied by instruments such as banjos, fiddles, harmonicas, and many types of guitar (including acoustic, electric, steel, and resonator guitars).[4][5][6] Though it is primarily rooted in various forms of American folk music, such as old-time music and Appalachian music,[7][8] many other traditions, including African-American, Mexican, Irish, and Hawaiian music, have had a formative influence on the genre.[9] Blues modes from blues music have been used extensively throughout its history as well.[10]
Once called ""hillbilly music"", the term country music gained popularity in the 1940s. The genre came to encompass western music, which evolved parallel to “hillbilly music” from similar roots, in the mid-20th century. Contemporary styles of western music include Texas country, red dirt, and Hispano- and Mexican American-led Tejano and New Mexico music,[11][12] which still exists alongside longstanding indigenous traditions.
In 2009, in the United States, country music was the most-listened-to rush-hour radio genre during the evening ",art_culture
"Singer-songwriter
A singer-songwriter is a musician who writes, composes, and performs their own musical material, including lyrics and melodies. In the United States, the category is built on the folk-acoustic tradition with a guitar,[1] although this role has transmuted through different eras of popular music. Traditionally, these musicians would write and sing songs personal to them. Singer-songwriters often provide the sole musical accompaniment to an entire song. The piano is also an instrument of choice.
Biography
[edit]The label ""singer-songwriter"" (or ""song-writer/singer""[2]) is used by record labels and critics to define popular music artists who write and perform their own material, which is often self-accompanied – generally on acoustic guitar or piano.[3] Such an artist performs the roles of composer, lyricist, vocalist, sometimes instrumentalist, and often self-manager.[4] According to AllMusic, singer-songwriters' lyrics are often personal but veiled by elaborate metaphors and vague imagery, and their creative concern is to place emphasis on the song rather than on their performance of it. Most records by such artists have a similarly straightforward and spare sound that places emphasis on the song itself.[5]
The term may also characterise songwriters in the rock, folk, country, and pop-music genres – including Henry Russell (1812–1900), Aristide Bruant (1851–1925), Hank Williams (1923–1953), and Buddy Holly (1936–1959). The phrase ""singer-songwriter"", recorded ",art_culture
"Choir
A choir (/ˈkwaɪər/ KWIRE), also known as a chorale or chorus (from Latin chorus, meaning 'a dance in a circle') is a musical ensemble of singers. Choral music, in turn, is the music written specifically for such an ensemble to perform or in other words is the music performed by the ensemble. Choirs may perform music from the classical music repertoire, which spans from the medieval era to the present, or popular music repertoire. Most choirs are led by a conductor, who leads the performances with arm, hand, and facial gestures.
The term choir is very often applied to groups affiliated with a church (whether or not they actually occupy the quire), whereas a chorus performs in theatres or concert halls, but this distinction is not rigid. Choirs may sing without instruments, or accompanied by a piano, accordion, pipe organ, a small ensemble, or an orchestra.
A choir can be a subset of an ensemble; thus one speaks of the ""woodwind choir"" of an orchestra, or different ""choirs"" of voices or instruments in a polychoral composition. In typical 18th century to 21st century oratorios and masses, 'chorus' or 'choir' implies that there is more than one singer per part, in contrast to the quartet of soloists also featured in these works.
Structure
[edit]Choirs are often led by a conductor, choirmaster or choir director. Most often, choirs consist of four sections intended to sing in four-part harmony, but there is no limit to the number of possible parts as long as there is a singer",art_culture
"Concert band
A concert band, also called a wind band, wind ensemble, wind symphony, wind orchestra, symphonic band, the symphonic winds, or symphonic wind ensemble,[1] is a performing ensemble consisting of members of the woodwind, brass, and percussion families of instruments,[2] and occasionally including the piano, double bass, and harp. On rare occasions, additional, non-traditional instruments may be added to such ensembles such as synthesizer, electric guitar, and bass guitar.[3]
Concert band music generally includes original wind compositions, concert marches, transcriptions of orchestral arrangements, light music, and popular music. Though the concert band does have similar instrumentation to the marching band, a marching band's main purpose is to perform while marching. In contrast, a concert band usually performs as a stationary ensemble[citation needed], though European ensembles often do both.
Origins
[edit]The origins of concert band can be traced back to the French Revolution, in which large bands would often gather for patriotic festivals and celebrations. These bands would play popular music that would immediately captivate the public's attention. Throughout the French Revolution, however, serious composers were often not interested in composing music for bands; this was due in large part to the instrumentation. Concert bands were (and still are) not standardized in their required type and number of instruments, making it nearly impossible to write the correct",art_culture
"Carnatic music
Carnatic music (known as Karnāṭaka saṃgīta or Karnāṭaka saṅgītam in the Dravidian languages) is a system of music commonly associated with South India, including the modern Indian states of Andhra Pradesh, Karnataka, Kerala, Tamil Nadu, Telangana and southern Odisha.
It is one of three main subgenres of Indian classical music that evolved from ancient Hindu texts and traditions, particularly the Samaveda.[1] (The other two are Hindustani music and Odissi music.) The main emphasis in Carnatic music is on vocal music; most compositions are written to be sung, and even when played on instruments, they are meant to be performed in gāyaki (singing) style.
Although there are stylistic differences, the basic elements of śruti (the relative musical pitch), svara (the musical sound of a single note), rāga (the mode or melodic formulae), and tala (the rhythmic cycles) form the foundation of improvisation and composition in both Carnatic and Hindustani music. Although improvisation plays an important role, Carnatic music is mainly sung through compositions, especially the kriti (or kirtanam) – a form developed between the 14th and 20th centuries by composers such as Purandara Dasa, and the Trinity of Carnatic music. Carnatic music is also usually taught and learned through compositions.[2][3] Telugu language predominates in the evolution of Carnatic music.[2][3] Most Carnatic compositions are in Telugu and Sanskrit.[4]
Carnatic music is usually performed by a small ensemb",art_culture
"Hindustani classical music
Hindustani classical music is the classical music of the Indian subcontinent's northern regions. It may also be called North Indian classical music or Uttar Bhartiya shastriya sangeet. The term shastriya sangeet literally means classical music, and is also used to refer to Indian classical music in general.[1] It is played on instruments like the veena, sitar and sarod. It diverged in the 12th century CE from Carnatic music, the classical tradition of Southern India. While Carnatic music largely uses compositions written in Sanskrit, Telugu, Kannada, Tamil, Malayalam, Hindustani music largely uses compositions written in Hindi, Urdu, Braj, Avadhi, Bhojpuri, Bengali, Rajasthani, Marathi and Punjabi.[2]
Knowledge of Hindustani classical music is taught through a network of classical music schools, called gharana. Hindustani classical music is an integral part of the culture of India and is performed across the country and internationally. Exponents of Hindustani classical music, including Ustad Bismillah Khan, Pandit Bhimsen Joshi, and Ravi Shankar have been awarded the Bharat Ratna, the highest civilian award of India, for their contributions to the arts.[3]
History
[edit]Around the 12th century, Hindustani classical music diverged from what eventually came to be identified as Carnatic classical music. The central notion in both systems is that of a melodic musical mode or raga, sung to a rhythmic cycle or tala. It is melodic music, with no concept o",art_culture
"Gamelan
Gamelan (/ˈɡæməlæn/;[2] Balinese: ᬕᬫ᭄ᬩᭂᬮ᭄ᬮᬦ᭄; Javanese: ꦒꦩꦼꦭꦤ꧀, romanized: gamelan (in the ngoko register), ꦒꦁꦱ, gangsa (in the krama register);[3] Sundanese: ᮌᮙᮨᮜᮔ᮪) is the traditional ensemble music of the Javanese, Sundanese, and Balinese peoples of Indonesia, made up predominantly of percussive instruments.[4][5] The most common instruments used are metallophones (played with mallets) and a set of hand-drums called kendang, which keep the beat. The kemanak, a banana-shaped idiophone, and the gangsa, another metallophone, are also commonly used gamelan instruments on Bali. Other notable instruments include xylophones, bamboo flutes (similar to the Indian bansuri), a bowed string instrument called a rebab (somewhat similar to the gadulka of Bulgaria), and a zither-like instrument called a siter, used in Javanese gamelan. Additionally, vocalists may be featured, being referred to as sindhen for females or gerong for males.[6]
Although the popularity of gamelan has declined slightly since the introduction of modern popular music to Indonesia, the art form is still widely respected, being commonly played in many traditional ceremonies. It may also be performed as entertainment for some modern events, such as official cultural, corporate, government or educational functions, both formal or informal. Gamelan is also, traditionally, arranged and performed to accompany religious rituals, ceremonies, dance theatre, dance-drama, traditional Indonesian theater, wayang puppets",art_culture
"J-pop
J-pop (often stylized in all caps; an abbreviated form of ""Japanese popular music""), natively known simply as pops (ポップス, poppusu), is the name for a form of popular music that entered the musical mainstream of Japan in the 1990s. Modern J-pop has its roots in traditional music of Japan, and significantly in 1960s pop and rock music. J-pop replaced kayōkyoku (""Lyric Singing Music""), a term for Japanese popular music from the 1920s to the 1980s in the Japanese music scene.[2]
Japanese rock bands such as Happy End fused the Beatles and Beach Boys-style rock with Japanese music in the 1960s–1970s.[3] J-pop was further defined by new wave and crossover fusion acts of the late 1970s, such as Yellow Magic Orchestra and Southern All Stars.[4] Popular styles of Japanese pop music include city pop and technopop during the 1970s–1980s, and J-Euro (such as Namie Amuro)[5] and Shibuya-kei during the 1990s and 2000s.
Japanese country had popularity during the international popularity of Westerns in the 1960s–1970s as well, and it still has appeal due to the work of musicians like Charlie Nagatani and Tomi Fujiyama, along with venues like Little Texas in Tokyo.[6][7] Japanese hip hop became mainstream with producer Nujabes during the 1990s–2000s, especially his work on Samurai Champloo,[8] and Japanese pop culture is often seen with anime in hip hop.[9] In addition, Latin music, CCM, and gospel music have scenes within J-pop.[10][11]
Form and definition
[edit]The origin of modern J-p",art_culture
"C-pop
C-pop is an abbreviation for Chinese popular music (simplified Chinese: 中文流行音乐; traditional Chinese: 中文流行音樂; pinyin: zhōngwén liúxíng yīnyuè; Jyutping: zung1man4 lau4hang4 jam1ngok6), a loosely defined musical genre by artists originating from mainland China, Hong Kong and Taiwan (the Greater China region). This also includes countries where Chinese languages are used by parts of the population, such as Singapore and Malaysia. C-pop is used as an umbrella term covering not only Chinese pop but also R&B, ballads, Chinese rock, Chinese hip hop and Chinese ambient music, although Chinese rock diverged during the early 1990s.
There are currently three main subgenres within C-pop: Cantopop, Mandopop and Hokkien pop. The gap between Cantopop and Mandopop has been narrowing in the new millennium. Hokkien pop, initially strongly influenced by Japanese enka, has been re-integrating into C-pop and narrowing its trend of development towards Mandopop. [citation needed]
Chinese popular music in China was initially a vehicle for the Cultural Revolution and Maoist ideologies; however, during the country's extensive political and cultural changes of the past 50 years, it has lost much political significance; and now closely resembles the styles of Taiwanese Mandopop, Cantopop, K-pop and J-pop, from Taiwan, Hong Kong, South Korea, and Japan, respectively. C-pop is an abbreviation for Chinese popular music, a loosely defined musical genre by artists originating from mainland China, Hong ",art_culture
"Bolero
Bolero is a genre of song which originated in eastern Cuba in the late 19th century as part of the trova tradition. Unrelated to the older Spanish dance of the same name, bolero is characterized by sophisticated lyrics dealing with love. It has been called the ""quintessential Latin American romantic song of the twentieth century"".[1]
Unlike the simpler, thematically diverse canción, bolero did not stem directly from the European lyrical tradition, which included Italian opera and canzone, popular in urban centers like Havana at the time. Instead, it was born as a form of romantic folk poetry cultivated by a new breed of troubadour from Santiago de Cuba, the trovadores.[1] Pepe Sánchez is considered the father of this movement and the author of the first bolero, ""Tristezas"", written in 1883.[2] Originally, boleros were sung by individual trovadores while playing guitar. Over time, it became common for trovadores to play in groups as dúos, tríos, cuartetos, etc. Thanks to the Trío Matamoros and, later, Trío Los Panchos, bolero achieved widespread popularity in Latin America, the United States and Spain. At the same time, Havana had become a fertile ground where bolero composers met to create compositions and improvise new tunes; it was the so-called filin movement, which derived its name from the English word ""feeling"". Many of the genre's most enduring pieces were written then and popularized in radio and cabaret performances by singers such as Olga Guillot and Elena Bu",art_culture
"Bossa nova
Bossa nova (Portuguese pronunciation: [ˈbɔsɐ ˈnɔvɐ] ⓘ) is a relaxed style of samba[nb 1] developed in the late 1950s and early 1960s in Rio de Janeiro, Brazil.[2] It is mainly characterized by a calm syncopated rhythm with chords and fingerstyle mimicking the beat of a samba groove, as if it was a simplification and stylization on the guitar of the rhythm produced by a samba school band. Another defining characteristic of the style is the use of unconventional chords in some cases with complex progressions and ""ambiguous"" harmonies.[3][4] A common misconception is that these complex chords and harmonies were derived from jazz, but samba guitar players have been using similar arrangement structures since the early 1920s, indicating a case of parallel evolution of styles rather than a simple transference from jazz to bossa nova.[5][6] Nevertheless, bossa nova was influenced by jazz, both in the harmonies used and also by the instrumentation of songs, and today many bossa nova songs are considered jazz standards. The popularity of bossa nova has helped to renew samba and contributed to the modernization of Brazilian music in general.
One of the major innovations of bossa nova was the way to synthesize the rhythm of samba on the classical guitar.[2][6] According to musicologist Gilberto Mendes, the bossa nova was one of the ""three rhythmic phases of samba"", in which the ""bossa beat"" had been extracted by João Gilberto from the traditional samba.[5] The synthesis perfor",art_culture
"Flamenco guitar
A flamenco guitar is a guitar similar to a classical guitar, but with lower action,[1] thinner tops, smaller bodies, and less internal bracing. It usually has nylon strings, like the classical guitar, but it generally possesses a livelier, grittier sound compared to the classical guitar.[2] It is used in toque, the guitar-playing part of the art of flamenco.
History
[edit]Traditionally, luthiers made guitars to sell at a wide range of prices, largely based on the materials used and the number of decorations, to cater to the popularity of the instrument across all classes of people in Spain.[3] The cheapest guitars were often simple, basic instruments made from the less expensive woods such as cypress. Antonio de Torres, one of the most renowned luthiers, did not differentiate between flamenco and classical guitars. Only after Andrés Avelar and others popularized classical guitar music, did this distinction emerge.[4]
Construction
[edit]The traditional flamenco guitar is made of Spanish Cypress, sycamore, or rosewood for the back and sides, and spruce for the top. This (in the case of cypress and sycamore) accounts for its characteristic body color. Flamenco guitars are built lighter with thinner tops than classical guitars, which produces a ""brighter"" and more percussive sound quality. Builders also use less internal bracing to keep the top more percussively resonant. The top is typically made of either spruce or cedar, though other tone woods are used today. ",art_culture
"Classical guitar
The classical guitar, also known as Spanish guitar,[1] is a member of the guitar family used in classical music and other styles. An acoustic wooden string instrument with strings made of gut or nylon, it is a precursor of the modern steel-string acoustic and electric guitars, both of which use metal strings. Classical guitars derive from instruments such as the lute, the vihuela, the gittern (the name being a derivative of the Greek ""kithara""), which evolved into the Renaissance guitar and into the 17th and 18th-century baroque guitar. Today's modern classical guitar was established by the late designs of the 19th-century Spanish luthier, Antonio Torres Jurado.
For a right-handed player, the traditional classical guitar has 12 frets clear of the body and is properly held up by the left leg, so that the hand that plucks or strums the strings does so near the back of the sound hole (this is called the classical position). However, the right-hand may move closer to the fretboard to achieve different tonal qualities. The player typically holds the left leg higher by the use of a foot rest. The modern steel string guitar, on the other hand, usually has 14 frets clear of the body (see Dreadnought) and is commonly held with a strap around the neck and shoulder.
The phrase ""classical guitar"" may refer to either of two concepts other than the instrument itself:
- The instrumental finger technique common to classical guitar—individual strings plucked with the fingerna",art_culture
"Electric guitar
An electric guitar is a guitar that requires external electric sound amplification in order to be heard at typical performance volumes, unlike a standard acoustic guitar. It uses one or more pickups to convert the vibration of its strings into electrical signals, which ultimately are reproduced as sound by loudspeakers. The sound is sometimes shaped or electronically altered to achieve different timbres or tonal qualities via amplifier settings or knobs on the guitar. Often, this is done through the use of effects such as reverb, distortion and ""overdrive""; the latter is considered to be a key element of electric blues guitar music and jazz, rock and heavy metal guitar playing. Designs also exist combining attributes of electric and acoustic guitars: the semi-acoustic and acoustic-electric guitars.
Invented in 1932, the electric guitar was adopted by jazz guitar players, who wanted to play single-note guitar solos in large big band ensembles. Early proponents of the electric guitar on record include Les Paul, Eddie Durham, George Barnes, Lonnie Johnson, Sister Rosetta Tharpe, T-Bone Walker, and Charlie Christian. During the 1950s and 1960s, the electric guitar became the most important instrument in popular music.[1] It has evolved into an instrument that is capable of a multitude of sounds and styles in genres ranging from pop and rock to folk to country music, blues and jazz. It served as a major component in the development of electric blues, rock and roll,",art_culture
"Drum kit
A drum kit or drum set[a] (also known as a trap set, or simply drums in popular music and jazz contexts) is a collection of drums, cymbals, and sometimes other auxiliary percussion instruments set up to be played by one person.[1] The drummer typically holds a pair of matching drumsticks or special wire or nylon brushes, using the feet to operate hi-hat and bass drum pedals.
A standard kit usually consists of:[2]
- A snare drum, mounted on a stand
- A bass drum, played with a beater moved by one or more foot-operated pedals
- One or more tom-toms, including rack toms or floor toms
- One or more cymbals, including a ride cymbal and crash cymbal
- Hi-hat cymbals, a pair of cymbals that can be played with a foot-operated pedal
The drum kit is a part of the standard rhythm section and is used in many types of popular and traditional music styles, ranging from rock and pop to blues and jazz.
History
[edit]Early development
[edit]Before the development of the classic drum kit, drums and cymbals used in military and orchestral music settings were played separately by different percussionists. In the 1840s, percussionists began to experiment with foot pedals as a way to enable them to play more than one instrument, but these devices would not be mass-produced for another 75 years.[3] By the 1860s, percussionists started combining multiple drums into a kit. The bass drum, snare drum, cymbals, and other percussion instruments were all struck with hand-held drumsticks. Drummers",art_culture
"Percussion instrument
A percussion instrument is a musical instrument that is sounded by being struck or scraped by a beater including attached or enclosed beaters or rattles struck, scraped or rubbed by hand or struck against another similar instrument. Excluding zoomusicological instruments and the human voice, the percussion family is believed to include the oldest musical instruments.[1] In spite of being a very common term to designate instruments, and to relate them to their players, the percussionists, percussion is not a systematic classificatory category of instruments, as described by the scientific field of organology. It is shown below that percussion instruments may belong to the organological classes of idiophone, membranophone, aerophone and chordophone.
The percussion section of an orchestra most commonly contains instruments such as the timpani, snare drum, bass drum, tambourine, belonging to the membranophones, and cymbals and triangle, which are idiophones. However, the section can also contain aerophones, such as whistles and sirens, or a blown conch shell. Percussive techniques can even be applied to the human body itself, as in body percussion. On the other hand, keyboard instruments, such as the celesta, are not normally part of the percussion section, but keyboard percussion instruments such as the glockenspiel and xylophone (which do not have piano keyboards) are included.
Function
[edit]Percussion instruments may play not only rhythm, but also melody",art_culture
"Orchestra
An orchestra (/ˈɔːrkɪstrə/ ⓘ; OR-ki-strə)[1] is a large instrumental ensemble typical of classical music, which combines instruments from different families. There are typically four main sections of instruments:
- String instruments, such as the violin, viola, cello, and double bass
- Brass instruments, such as the French horn (commonly known as the ""horn""), trumpet, trombone, cornet, and tuba, and sometimes euphonium
- Percussion instruments, such as the timpani, snare drum, bass drum, cymbals, triangle, tambourine, tam-tam and mallet percussion instruments
Other instruments such as the piano, harpsichord, pipe organ, and celesta may sometimes appear in a fifth keyboard section or may stand alone as soloist instruments, as may the concert harp and, for performances of some modern compositions, electronic instruments, and guitars.[note 1]
A full-size Western orchestra may sometimes be called a symphony orchestra or philharmonic orchestra (from Greek phil-, ""loving"", and ""harmony""). The number of musicians employed in a given performance may vary from seventy to over one hundred, depending on the work being played and the venue size. A chamber orchestra (sometimes a concert orchestra) is a smaller ensemble of not more than around fifty musicians.[2] Orchestras that specialize in the Baroque music of, for example, Johann Sebastian Bach and George Frideric Handel, or Classical repertoire, such as that of Haydn and Mozart, tend to be smaller than orchestras performing ",art_culture
"Symphony
A symphony is an extended musical composition in Western classical music, most often for orchestra. Although the term has had many meanings from its origins in the ancient Greek era, by the late 18th century the word had taken on the meaning common today: a work usually consisting of multiple distinct sections or movements, often four, with the first movement in sonata form. Symphonies are almost always scored for an orchestra consisting of a string section (violin, viola, cello, and double bass), brass, woodwind, and percussion instruments which altogether number about 30 to 100 musicians. Symphonies are notated in a musical score, which contains all the instrument parts. Orchestral musicians play from parts which contain just the notated music for their own instrument. Some symphonies also contain vocal parts (e.g., Beethoven's Ninth Symphony, or Mahler's Second Symphony).
Etymology and origins
[edit]The word symphony is derived from the Greek word συμφωνία (symphōnía), meaning ""agreement or concord of sound"", ""concert of vocal or instrumental music"", from σύμφωνος (sýmphōnos), ""harmonious"".[1] The word referred to a variety of different concepts before ultimately settling on its current meaning designating a musical form.
In late Greek and medieval theory, the word was used for consonance, as opposed to διαφωνία (diaphōnía), which was the word for ""dissonance"".[2] In the Middle Ages and later, the Latin form symphonia was used to describe various instruments, espe",art_culture
"Concerto
A concerto (/kənˈtʃɛərtoʊ/; plural concertos, or concerti from the Italian plural) is, from the late Baroque era, mostly understood as an instrumental composition, written for one or more soloists accompanied by an orchestra or other ensemble. The typical three-movement structure, a slow movement (e.g., lento or adagio) preceded and followed by fast movements (e.g., presto or allegro), became a standard from the early 18th century.
The concerto originated as a genre of vocal music in the late 16th century: the instrumental variant appeared around a century later, when Italians such as Giuseppe Torelli and Arcangelo Corelli started to publish their concertos. A few decades later, Venetian composers, such as Antonio Vivaldi, had written hundreds of violin concertos, while also producing solo concertos for other instruments such as a cello or a woodwind instrument, and concerti grossi for a group of soloists. The first keyboard concertos, such as George Frideric Handel's organ concertos and Johann Sebastian Bach's harpsichord concertos, were written around the same time.
In the second half of the 18th century, the piano became the most used keyboard instrument, and composers of the Classical Era such as Joseph Haydn, Wolfgang Amadeus Mozart and Ludwig van Beethoven each wrote several piano concertos, and, to a lesser extent, violin concertos, and concertos for other instruments. In the Romantic Era, many composers, including Niccolò Paganini, Felix Mendelssohn, Frédéric",art_culture
"Chamber music
Chamber music is a form of classical music that is composed for a small group of instruments—traditionally a group that could fit in a palace chamber or a large room. Most broadly, it includes any art music that is performed by a small number of performers, with one performer to a part (in contrast to orchestral music, in which each string part is played by a number of performers). However, by convention, it usually does not include solo instrument performances.
Because of its intimate nature, chamber music has been described as ""the music of friends"".[1] For more than 100 years, chamber music was played primarily by amateur musicians in their homes, and even today, when chamber music performance has migrated from the home to the concert hall, many musicians, amateur and professional, still play chamber music for their own pleasure. Playing chamber music requires special skills, both musical and social, that differ from the skills required for playing solo or symphonic works.[2]
Johann Wolfgang von Goethe described chamber music (specifically, string quartet music) as ""four rational people conversing"".[3] This conversational paradigm – which refers to the way one instrument introduces a melody or motif and then other instruments subsequently ""respond"" with a similar motif – has been a thread woven through the history of chamber music composition from the end of the 18th century to the present. The analogy to conversation recurs in descriptions and analyses of ch",art_culture
"Music festival
A music festival is a community event with performances of singing and instrument playing that is often presented with a theme such as musical genre (e.g., rock, blues, folk, jazz, classical music), nationality, locality of musicians, or holiday. Music festivals are generally organized by individuals or organizations within networks of music production, typically music scenes, the music industries, or institutions of music education.[2]
Music festivals are commonly held outdoors, with tents or roofed temporary stages for the performers.[3] Often music festivals host other attractions such as food and merchandise vending, dance, crafts, performance art, and social or cultural activities.[4][5] Many festivals are annual, or repeat at some other interval, while some are held only once. Some festivals are organized as for-profit concerts and others are benefits for a specific charitable cause.[6] At music festivals associated with charitable causes, there may be information about social or political issues.
History
[edit]Ancient and medieval
[edit]The Pythian Games at Delphi included musical performances, and may be one of the earliest festivals known.[7] During the Middle Ages, festivals were often held as competitions.[citation needed]
Modern
[edit]The music festival emerged in England in the 18th century, as an extension of urban concert life into a form of seasonal, cultural festivity, structured around a schedule of music performances, or concerts.[2]: 168 [8]",art_culture
"Concert
A concert, often known informally as a gig or show, is a live performance of music in front of an audience.[1] The performance may be carried by a single musician, in which case it is sometimes called a recital, or by a musical ensemble such as an orchestra, choir, or band. Concerts are held in a wide variety of settings and sizes, spanning from venues such as private houses and small nightclubs to mid-sized concert halls and finally to large arenas and stadiums, as well as outdoor venues such as amphitheatres and parks. Indoor concerts held in the largest venues are sometimes called arena concerts or amphitheatre concerts.
Regardless of the venue, musicians usually perform on a stage (if not an actual stage, then an area of the floor designated as such). Concerts often require live event support with professional audio equipment. Before recorded music, concerts provided the main opportunity to hear musicians play. For large concerts or concert tours, the challenging logistics of arranging the musicians, venue, equipment, audience, and tickets are handled by professional tour promoters.
History
[edit]While the first concerts did not officially appear until the late 17th century, similar gatherings had been around throughout the 17th century at several European universities, such as Oxford and Cambridge. Officially, though, the first public concerts that required an admission were created by the English violinist John Banister.[2] Over the next few centuries, concerts ",art_culture
"Mixing console
A mixing console or mixing desk is an electronic device for mixing audio signals, used in sound recording and reproduction and sound reinforcement systems. Inputs to the console include microphones, signals from electric or electronic instruments, or recorded sounds. Mixers may control analog or digital signals. The modified signals are summed to produce the combined output signals, which can then be broadcast, amplified through a sound reinforcement system or recorded.
Mixing consoles are used for applications including recording studios, public address systems, sound reinforcement systems, nightclubs, broadcasting, and post-production. A typical, simple application combines signals from microphones on stage into an amplifier that drives one set of loudspeakers for the audience. A DJ mixer may have only two channels, for mixing two record players. A coffeehouse's small stage might only have a six-channel mixer, enough for two singer-guitarists and a percussionist. A nightclub stage's mixer for rock music shows may have 24 channels for mixing the signals from a rhythm section, lead guitar and several vocalists. A mixing console in a professional recording studio may have as many as 96 channels.[1] Consoles used for live sound can go even higher, with some having up to 384 input channels.[2]
In practice, mixers do more than simply mix signals. They can provide phantom power for condenser microphones; pan control, which changes a sound's apparent position in the ",Technology & Computing 
"Modular synthesizer
Modular synthesizers are synthesizers composed of separate modules for different functions. The modules can be connected together by the user to create a patch. The outputs from the modules may include audio signals, analog control voltages, or digital signals for logic or timing conditions. Typical modules are voltage-controlled oscillators, voltage-controlled filters, voltage-controlled amplifiers and envelope generators.
History
[edit]The first modular synthesizer was developed by German engineer Harald Bode in the late 1950s.[1] The 1960s saw the introduction of the Moog synthesizer and the Buchla Modular Electronic Music System, created around the same period.[2] The Moog was composed of separate modules which created and shaped sounds, such as envelopes, noise generators, filters, and sequencers,[3][4] connected by patch cords.[5]
The Japanese company Roland released the Roland System 100 in 1975, followed by the System 700 in 1976 and the System 100m in 1979.[1]
In the late 1970s, modular synthesizers started to be largely supplanted by highly-integrated keyboard synthesizers, samplers, sound modules, and other MIDI-connected gear. By the 1990s, modular synthesizers had fallen out of favor compared to cheaper, smaller digital and software synthesizers.[1] However, there continued to be a community who chose the physically patched approach, the flexibility and the sound of traditional modular systems.
Since the late 1990s, [when?] there has been a re",Technology & Computing 
"Disc jockey
A disc jockey, more commonly abbreviated as DJ, is a person who plays recorded music for an audience. Types of DJs include radio DJs (who host programs on music radio stations), club DJs (who work at nightclubs or music festivals), mobile DJs (who are hired to work at public and private events such as weddings, parties, or festivals), and turntablists (who use record players, usually turntables, to manipulate sounds on phonograph records). Originally, the ""disc"" in ""disc jockey"" referred to shellac and later vinyl records, but nowadays DJ is used as an all-encompassing term to also describe persons who mix music from other recording media such as cassettes, CDs or digital audio files on a CDJ, controller, or even a laptop. DJs may adopt the title ""DJ"" in front of their real names, adopted pseudonyms, or stage names.[1]
DJs commonly use audio equipment that can play at least two sources of recorded music simultaneously. This enables them to blend tracks together to create transitions between recordings and develop unique mixes of songs. This can involve aligning the beats of the music sources so their rhythms and tempos do not clash when played together and enable a smooth transition from one song to another. DJs often use specialized DJ mixers, small audio mixers with crossfader and cue functions to blend or transition from one song to another. Mixers are also used to pre-listen to sources of recorded music in headphones and adjust upcoming tracks to mix with curr",art_culture
"Turntablism
Turntablism is the art of manipulating sounds and creating new music, sound effects, mixes and other creative sounds and beats, typically by using two or more turntables and a cross fader-equipped DJ mixer.[1] The mixer is plugged into a PA system (for live events) or broadcasting equipment (if the DJ is performing on radio, TV or Internet radio) so that a wider audience can hear the turntablist's music. Turntablists typically manipulate records on a turntable by moving the record with their hand to cue the stylus to exact points on a record, and by touching or moving the platter or record to stop, slow down, speed up or, spin the record backwards, or moving the turntable platter back and forth (the popular rhythmic ""scratching"" effect which is a key part of hip hop music),[2] all while using a DJ mixer's cross-fader control and the mixer's gain and equalization controls to adjust the sound and level of each turntable. Turntablists typically use two or more turntables and headphones to cue up desired start points on different records (Greasley & Prior, 2013).
Turntablists, often called DJs (or ""deejays""), generally prefer direct-drive turntables over belt-driven or other types, because the belt can be stretched or damaged by ""scratching"" and other turntable manipulation such as slowing down a record, whereas a direct drive turntable can be stopped, slowed down, or spun backwards without damaging the electric motor. The word turntablist is claimed to be originated ",art_culture
"Lo-fi music
Lo-fi (also typeset as lofi or low-fi; short for low fidelity) is a music or production quality in which elements usually regarded as imperfections in the context of a recording or performance are present, sometimes as a deliberate stylistic choice. The standards of sound quality (fidelity) and music production have evolved over the decades, meaning that some older examples of lo-fi may not have been originally recognized as such. Lo-fi began to be recognized as a style of popular music in the 1990s, when it became alternately referred to as DIY music (from ""do it yourself"").[1] Some subsets of lo-fi music have become popular for their perceived nostalgic and/or relaxing qualities, which originate from the imperfections that define the genre.
Traditionally, lo-fi has been characterized by the inclusion of elements normally viewed as undesirable in most professional contexts, such as misplayed notes, environmental interference, or phonographic imperfections (degraded audio signals, tape hiss, and so on). Pioneering, influential, or otherwise significant artists and bands include the Beach Boys (Smiley Smile and Wild Honey), R. Stevie Moore (often called ""the godfather of home recording""), Paul McCartney (McCartney), Todd Rundgren, Lee Scratch Perry, Peter Ivers, Jandek, Daniel Johnston, Martin Newell, Neutral Milk Hotel, Phil Elverum, Guided by Voices, Sebadoh, Beck, Pavement, and Ariel Pink.
Although ""lo-fi"" has been in the cultural lexicon for approximately as lo",art_culture
"Soundtrack
A soundtrack[2] is a recorded audio signal accompanying and synchronised to the images of a book, drama, motion picture, radio program, television program, or video game; colloquially, a commercially released soundtrack album of music as featured in the soundtrack of a film, video, or television presentation; or the physical area of a film that contains the synchronised recorded sound.[1]
In movie industry terminology usage, a sound track is an audio recording created or used in film production or post-production. Initially, the dialogue, sound effects, and music in a film each has its own separate track, and these are mixed together to make what is called the composite track, which is heard in the film. A dubbing track is often later created when films are dubbed into another language. This is also known as an M&E (music and effects) track. M&E tracks contain all sound elements minus dialogue, which is then supplied by the foreign distributor in the native language of its territory.
Current dictionary entries for soundtrack document soundtrack as a noun, and as a verb.[3][4] An early attempt at popularizing the term sound track was printed in the magazine Photoplay in 1929.[5] A 1992 technical dictionary entry in the Academic Press Dictionary of Science and Technology does not distinguish between the form sound track and soundtrack.[6]
The contraction soundtrack came into public consciousness with the advent of so-called soundtrack albums in the late 1940s. First ",art_culture
"Diplomacy
Diplomacy is the communication by representatives of state, intergovernmental, or non-governmental institutions intended to influence events in the international system.[1][2]
Diplomacy is the main instrument of foreign policy which represents the broader goals and strategies that guide a state's interactions with the rest of the world. International treaties, agreements, alliances, and other manifestations of international relations are usually the result of diplomatic negotiations and processes. Diplomats may also help shape a state by advising government officials.
Modern diplomatic methods, practices, and principles originated largely from 17th-century European customs. Beginning in the early 20th century, diplomacy became professionalized; the 1961 Vienna Convention on Diplomatic Relations, ratified by most of the world's sovereign states, provides a framework for diplomatic procedures, methods, and conduct. Most diplomacy is now conducted by accredited officials, such as envoys and ambassadors, through a dedicated foreign affairs office. Diplomats operate through diplomatic missions, most commonly consulates and embassies, and rely on a number of support staff; the term diplomat is thus sometimes applied broadly to diplomatic and consular personnel and foreign ministry officials.[3]
Etymology
[edit]The term diplomacy is derived from the 18th-century French term diplomate (""diplomat"" or ""diplomatist""), based on the ancient Greek diplōma, which roughly means ""an",history
"User guide
A user guide, user manual, owner's manual or instruction manual is intended to assist users in using a particular product, service or application. It is usually written by a technician, product developer, or a company's customer service staff.
Most user guides contain both a written guide and associated images. In the case of computer applications, it is usual to include screenshots of the human-machine interface(s), and hardware manuals often include clear, simplified diagrams. The language used is matched to the intended audience, with jargon kept to a minimum or explained thoroughly.
Until the last decade or two of the twentieth century it was common for an owner's manual to include detailed repair information, such as a circuit diagram; however as products became more complex this information was gradually relegated to specialized service manuals, or dispensed with entirely, as devices became too inexpensive to be economically repaired.
Owner's manuals for simpler devices are often multilingual so that the same boxed product can be sold in many different markets. Sometimes the same manual is shipped with a range of related products so the manual will contain a number of sections that apply only to some particular model in the product range.
With the increasing complexity of modern devices, many owner's manuals have become so large that a separate quickstart guide is provided. Some owner's manuals for computer equipment are supplied on CD-ROM to cut down on manu",Technology & Computing 
"API
An application programming interface (API) is a connection between computers or between computer programs. It is a type of software interface, offering a service to other pieces of software.[1] A document or standard that describes how to build such a connection or interface is called an API specification. A computer system that meets this standard is said to implement or expose an API. The term API may refer either to the specification or to the implementation.
In contrast to a user interface, which connects a computer to a person, an application programming interface connects computers or pieces of software to each other. It is not intended to be used directly by a person (the end user) other than a computer programmer[1] who is incorporating it into software. An API is often made up of different parts which act as tools or services that are available to the programmer. A program or a programmer that uses one of these parts is said to call that portion of the API. The calls that make up the API are also known as subroutines, methods, requests, or endpoints. An API specification defines these calls, meaning that it explains how to use or implement them.
One purpose of APIs is to hide the internal details of how a system works, exposing only those parts a programmer will find useful and keeping them consistent even if the internal details later change. An API may be custom-built for a particular pair of systems, or it may be a shared standard allowing interoperability amo",Technology & Computing 
"Software requirements specification
A software requirements specification (SRS) is a description of a software system to be developed. It is modeled after the business requirements specification (CONOPS). The software requirements specification lays out functional and non-functional requirements, and it may include a set of use cases that describe user interactions that the software must provide to the user for perfect interaction.
Software requirements specifications establish the basis for an agreement between customers and contractors or suppliers on how the software product should function (in a market-driven project, these roles may be played by the marketing and development divisions). Software requirements specification is a rigorous assessment of requirements before the more specific system design stages, and its goal is to reduce later redesign. It should also provide a realistic basis for estimating product costs, risks, and schedules.[1] Used appropriately, software requirements specifications can help prevent software project failure.[2]
The software requirements specification document lists sufficient and necessary requirements for the project development.[3] To derive the requirements, the developer needs to have a clear and thorough understanding of the products under development. This is achieved through detailed and continuous communications with the project team and customer throughout the software development process.
The SRS may be one of a contract's deli",Technology & Computing 
"Design pattern
A design pattern is the re-usable form of a solution to a design problem. The idea was introduced by the architect Christopher Alexander[1] and has been adapted for various other disciplines, particularly software engineering.[2]
Details
[edit]An organized collection of design patterns that relate to a particular field is called a pattern language. This language gives a common terminology for discussing the situations designers are faced with.
The elements of this language are entities called patterns. Each pattern describes a problem that occurs over and over again in our environment, and then describes the core of the solution to that problem, in such a way that you can use this solution a million times over, without ever doing it the same way twice.
— Christopher Alexander, A Pattern Language[1]
Documenting a pattern requires explaining why a particular situation causes problems, and how the components of the pattern relate to each other to give the solution.[3] Christopher Alexander describes common design problems as arising from ""conflicting forces""—such as the conflict between wanting a room to be sunny and wanting it not to overheat on summer afternoons. A pattern would not tell the designer how many windows to put in the room; instead, it would propose a set of values to guide the designer toward a decision that is best for their particular application. Alexander, for example, suggests that enough windows should be included to direct light all around t",Technology & Computing 
"Unified Modeling Language
The Unified Modeling Language (UML) is a general-purpose visual modeling language that is intended to provide a standard way to visualize the design of a system.[1]
UML provides a standard notation for many types of diagrams which can be roughly divided into three main groups: behavior diagrams, interaction diagrams, and structure diagrams.
The creation of UML was originally motivated by the desire to standardize the disparate notational systems and approaches to software design. It was developed at Rational Software in 1994–1995, with further development led by them through 1996.[2]
In 1997, UML was adopted as a standard by the Object Management Group (OMG) and has been managed by this organization ever since. In 2005, UML was also published by the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC) as the ISO/IEC 19501 standard.[3] Since then the standard has been periodically revised to cover the latest revision of UML.[4]
In software engineering, most practitioners do not use UML, but instead produce informal hand drawn diagrams; these diagrams, however, often include elements from UML.[5]: 536
History
[edit]Before UML 1.0
[edit]UML has evolved since the second half of the 1990s and has its roots in the object-oriented programming methods developed in the late 1980s and early 1990s. The timeline (see image) shows the highlights of the history of object-oriented modeling methods and notation",Technology & Computing 
"Flowchart
A flowchart is a type of diagram that represents a workflow or process. A flowchart can also be defined as a diagrammatic representation of an algorithm, a step-by-step approach to solving a task.
The flowchart shows the steps as boxes of various kinds, and their order by connecting the boxes with arrows. This diagrammatic representation illustrates a solution model to a given problem. Flowcharts are used in analyzing, designing, documenting or managing a process or program in various fields.[1]
Overview
[edit]Flowcharts are used to design and document simple processes or programs. Like other types of diagrams, they help visualize the process. Two of the many benefits are that flaws and bottlenecks may become apparent. Flowcharts typically use the following main symbols:
- A process step, usually called an activity, is denoted by a rectangular box.
- A decision is usually denoted by a diamond.
A flowchart is described as ""cross-functional"" when the chart is divided into different vertical or horizontal parts, to describe the control of different organizational units. A symbol appearing in a particular part is within the control of that organizational unit. A cross-functional flowchart allows the author to correctly locate the responsibility for performing an action or making a decision, and to show the responsibility of each organizational unit for different parts of a single process.
Flowcharts represent certain aspects of processes and are usually complemented by ",Technology & Computing 
"Data-flow diagram
A data-flow diagram is a way of representing a flow of data through a process or a system (usually an information system). The DFD also provides information about the outputs and inputs of each entity and the process itself. A data-flow diagram has no control flow — there are no decision rules and no loops. Specific operations based on the data can be represented by a flowchart.[1]
There are several notations for displaying data-flow diagrams. The notation presented above was described in 1979 by Tom DeMarco as part of structured analysis.
For each data flow, at least one of the endpoints (source and / or destination) must exist in a process. The refined representation of a process can be done in another data-flow diagram, which subdivides this process into sub-processes.
The data-flow diagram is a tool that is part of structured analysis, data modeling and threat modeling. When using UML, the activity diagram typically takes over the role of the data-flow diagram. A special form of data-flow plan is a site-oriented data-flow plan.
Data-flow diagrams can be regarded as inverted Petri nets, because places in such networks correspond to the semantics of data memories. Analogously, the semantics of transitions from Petri nets and data flows and functions from data-flow diagrams should be considered equivalent.
History
[edit]The DFD notation draws on graph theory, originally used in operational research to model workflow in organizations, and in computer science",Technology & Computing 
"Sequence diagram
In software engineering, a sequence diagram[1] shows process interactions arranged in time sequence. This diagram depicts the processes and objects involved and the sequence of messages exchanged as needed to carry out the functionality. Sequence diagrams are typically associated with use case realizations in the 4+1 architectural view model of the system under development. Sequence diagrams are sometimes called event diagrams or event scenarios.
For a particular scenario of a use case, the diagrams show the events that external actors generate, their order, and possible inter-system events.[2] The diagram emphasizes events that cross the system boundary from actors to systems. A system sequence diagram should be done for the main success scenario of the use case, and frequent or complex alternative scenarios.
There are two kinds of sequence diagrams:
- Sequence Diagram (SD): A regular version of sequence diagram describes how the system operates, and every object within a system is described specifically.
- System Sequence Diagram (SSD): All systems are treated as a black box, where all classes owned by the system are not depicted. Instead, only an object named System is depicted.
Key elements of sequence diagrams
[edit]A sequence diagram shows, as parallel vertical lines (lifelines), different processes or objects that live simultaneously, and, as horizontal arrows, the messages exchanged between them in the order in which they occur. This allows for the gr",Technology & Computing 
"Activity diagram
Activity diagrams[1] are graphical representations of workflows of stepwise activities and actions[2] with support for choice, iteration, and concurrency. In the Unified Modeling Language, activity diagrams are intended to model both computational and organizational processes (i.e., workflows), as well as the data flows intersecting with the related activities.[1][3] ""Object nodes hold data that is input to and output from executable nodes, and moves across object flow edges. Control nodes specify sequencing of executable nodes via control flow edges.""[1] In other words, although activity diagrams primarily show the overall control flow, they can also include elements showing the data flow between activities through one or more data stores.[1]
Construction
[edit]Activity diagrams are constructed from a limited number of shapes, connected with arrows.[4] The most important shape types are as follows:
- stadia represent actions;
- diamonds represent decisions;
- bars represent the start (split) or end (join) of concurrent activities;
- a black circle represents the start (initial node) of the workflow;
- an encircled black circle represents the end (final node).
Arrows run from the start towards the end and represent the order in which activities happen.
Activity diagrams can be regarded as a form of a structured flowchart combined with a traditional data flow diagram. Typical flowchart techniques lack constructs for expressing concurrency.[5] However, the join",Technology & Computing 
"Use case diagram
A use case diagram[1] is a graphical depiction of a user's possible interactions with a system. A use case diagram shows various use cases and different types of users the system has and will often be accompanied by other types of diagrams as well. The use cases are represented by either circles or ellipses. The actors are often shown as stick figures.
Application
[edit]While a use case itself might drill into a lot of detail about every possibility, a use-case diagram can help provide a higher-level view of the system. It has been said before that ""Use case diagrams are the blueprints for your system"".[2][3]
Due to their simplistic nature, use case diagrams can be a good communication tool for stakeholders. The drawings attempt to mimic the real world and provide a view for the stakeholder to understand how the system is going to be designed. Siau and Lee conducted research to determine if there was a valid situation for use case diagrams at all or if they were unnecessary. What was found was that the use case diagrams conveyed the intent of the system in a more simplified manner to stakeholders and that they were ""interpreted more completely than class diagrams"".[4]
See also
[edit]- Agile software development
- Business case
- Fundamental modeling concepts
- Object Process Methodology
- SysML
- Unified Modeling Language
- User story
References
[edit]- ^ ""Use case"". Unified Modeling Language 2.5.1. OMG Document Number formal/2017-12-05. Object Management Gro",Technology & Computing 
"DevOps
DevOps is the integration and automation of the software development and information technology operations[a]. DevOps encompasses necessary tasks of software development and can lead to shortening development time and improving the development life cycle.[1] According to Neal Ford, DevOps, particularly through continuous delivery, employs the ""Bring the pain forward"" principle, tackling tough tasks early, fostering automation and swift issue detection.[2] Software programmers and architects should use fitness functions to keep their software in check.[3]
Although debated,[b][c][d][e] DevOps is characterized by key principles: shared ownership, workflow automation, and rapid feedback. From an academic perspective, Len Bass, Ingo Weber, and Liming Zhu—three computer science researchers from the CSIRO and the Software Engineering Institute—suggested defining DevOps as ""a set of practices intended to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality"".[7] However, the term is used in multiple contexts. At its most successful, DevOps is a combination of specific practices, culture change, and tools.[8]
History
[edit]Proposals to combine software development methodologies with deployment and operations concepts began to appear in the late 80s and early 90s.[9]
In 2009, the first conference named DevOps Days was held in Ghent, Belgium. The conference was founded by Belgian consultant, project",Technology & Computing 
"CI/CD
In software engineering, CI/CD or CICD is the combined practices of continuous integration (CI) and continuous delivery (CD) or, less often, continuous deployment.[1] They are sometimes referred to collectively as continuous development or continuous software development.[2]
Components
[edit]- Continuous integration
- Frequent merging of several small changes into a main branch.
- Continuous delivery
- Producing software in short cycles with high speed and frequency so that reliable software can be released at any time, with a simple and repeatable deployment process when deciding to deploy.
- Continuous deployment
- Automatic rollout of new software functionality.
When these three processes occur in order, they may be described as a ""CI/CD pipeline"".[3]
Motivation
[edit]CI/CD bridges the gaps between development and operation activities and teams by enforcing automation in building, testing and deployment of applications. CI/CD services compile the incremental code changes made by developers, then link and package them into software deliverables.[4] Automated tests verify the software functionality, and automated deployment services deliver them to end users.[5] The aim is to increase early defect discovery, increase productivity, and provide faster release cycles. The process contrasts with traditional methods where a collection of software updates were integrated into one large batch before deploying the newer version.
Modern-day DevOps practices involve:
- continuou",Technology & Computing 
"Continuous integration
Continuous integration (CI) is the practice of integrating source code changes frequently and ensuring that the integrated codebase is in a workable state.
Typically, developers merge changes to an integration branch, and an automated system builds and tests the software system.[1] Often, the automated process runs on each commit or runs on a schedule such as once a day.
Grady Booch first proposed the term CI in 1991,[2] although he did not advocate integrating multiple times a day, but later, CI came to include that aspect.[3]
History
[edit]The earliest known work (1989) on continuous integration was the Infuse environment developed by G. E. Kaiser, D. E. Perry, and W. M. Schell.[4]
In 1994, Grady Booch used the phrase continuous integration in Object-Oriented Analysis and Design with Applications (2nd edition)[5] to explain how, when developing using micro processes, ""internal releases represent a sort of continuous integration of the system, and exist to force closure of the micro process"".
In 1997, Kent Beck and Ron Jeffries invented extreme programming (XP) while on the Chrysler Comprehensive Compensation System project, including continuous integration.[1][self-published source] Beck published about continuous integration in 1998, emphasising the importance of face-to-face communication over technological support.[6] In 1999, Beck elaborated more in his first full book on Extreme Programming.[7] CruiseControl, one of the first open-source CI tools",Technology & Computing 
"Continuous delivery
Continuous delivery (CD) is a software engineering approach in which teams produce software in short cycles, ensuring that the software can be reliably released at any time.[1][2] It aims at building, testing, and releasing software with greater speed and frequency. The approach helps reduce the cost, time,[citation needed] and risk of delivering changes by allowing for more incremental updates to applications in production. A straightforward and repeatable deployment process is important for continuous delivery.
Principles
[edit]According to Neal Ford, continuous delivery adopts ""Bring the pain forward,"" tackling tough tasks early, fostering automation and swift issue detection. [3]
Continuous delivery treats the commonplace notion of a deployment pipeline[4] as a lean Poka-Yoke:[5] a set of validations through which a piece of software must pass on its way to release. Code is compiled if necessary and then packaged by a build server every time a change is committed to a source control repository, then tested by a number of different techniques (possibly including manual testing) before it can be marked as releasable.
Developers used to a long cycle time may need to change their mindset when working in a CD environment. Any code commit may be released to customers at any point. Patterns such as feature toggles can be very useful for committing code early which is not yet ready for use by end users. Using NoSQL can eliminate the step of data migrations and",Technology & Computing 
"Continuous deployment
Continuous deployment (CD) is a software engineering approach in which software functionalities are delivered frequently and through automated deployments.[1][2][3]
Continuous deployment contrasts with continuous delivery (also abbreviated CD), a similar approach in which software functionalities are also frequently delivered and deemed to be potentially capable of being deployed, but are actually not deployed.[4] As such, continuous deployment can be viewed as a more complete form of automation than continuous delivery.[5]
Motivation
[edit]A major motivation for continuous deployment is that deploying software into the field more often makes it easier to find, catch, and fix bugs. A bug is easier to fix when it comes from code deployed five minutes ago instead of five days ago.[6]
Example
[edit]In an environment in which data-centric microservices provide the functionality, and where the microservices can have multiple instances, continuous deployment consists of instantiating the new version of a microservice and retiring the old version once it has drained all the requests in flight.[7][8][9]
See also
[edit]- CI/CD, the combined practices of either (more often) continuous integration and continuous delivery, or (less often) continuous integration and continuous deployment
- Canary release
- Blue–green deployment
References
[edit]- ^ Shahin, Mojtaba; Ali Babara, Muhammad; Zhu, Liming (2017). ""Continuous Integration, Delivery and Deployment: A Systemati",Technology & Computing 
"Infrastructure as code
Infrastructure as code (IaC) is the process of managing and provisioning computer data center resources through machine-readable definition files, rather than physical hardware configuration or interactive configuration tools.[1] The IT infrastructure managed by this process comprises both physical equipment, such as bare-metal servers, as well as virtual machines, and associated configuration resources. The definitions may be in a version control system, rather than maintaining the code through manual processes. The code in the definition files may use either scripts or declarative definitions, but IaC more often employs declarative approaches.
Overview
[edit]IaC grew as a response to the difficulty posed by utility computing and second-generation web frameworks. In 2006, the launch of Amazon Web Services’ Elastic Compute Cloud and the 1.0 version of Ruby on Rails just months before[2] created widespread scaling difficulties in the enterprise that were previously experienced only at large, multi-national companies.[3] With new tools emerging to handle this ever-growing field, the idea of IaC was born. The thought of modeling infrastructure with code, and then having the ability to design, implement, and deploy application infrastructure with known software best practices appealed to both software developers and IT infrastructure administrators. The ability to treat infrastructure as code and use the same tools as any other software project would allow ",Technology & Computing 
"Docker (software)
Docker is a set of platform as a service (PaaS) products that use OS-level virtualization to deliver software in packages called containers.[5] The service has both free and premium tiers. The software that hosts the containers is called Docker Engine.[6] It was first released in 2013 and is developed by Docker, Inc.[7]
Docker is a tool that is used to automate the deployment of applications in lightweight containers so that applications can work efficiently in different environments in isolation.
Background
[edit]Containers are isolated from one another and bundle their own software, libraries and configuration files; they can communicate with each other through well-defined channels.[8] Because all of the containers share the services of a single operating system kernel, they use fewer resources than virtual machines.[6]
Operation
[edit]Docker can package an application and its dependencies in a virtual container that can run on any Linux, Windows, or macOS computer. This enables the application to run in a variety of locations, such as on-premises, in public (see decentralized computing, distributed computing, and cloud computing) or private cloud.[10] When running on Linux, Docker uses the resource isolation features of the Linux kernel (such as cgroups and kernel namespaces) and a union-capable file system (such as OverlayFS)[11] to allow containers to run within a single Linux instance, avoiding the overhead of starting and maintaining virtual machines",Technology & Computing 
"Software versioning
Software versioning is the process of assigning either unique version names or unique version numbers to unique states of computer software. Within a given version number category (e.g., major or minor), these numbers are generally assigned in increasing order and correspond to new developments in the software. At a fine-grained level, revision control is used for keeping track of incrementally-different versions of information, whether or not this information is computer software, in order to be able to roll any changes back.
Modern computer software is often tracked using two different software versioning schemes: an internal version number that may be incremented many times in a single day, such as a revision control number, and a release version that typically changes far less often, such as semantic versioning[1] or a project code name.
History
[edit]File numbers were used especially in public administration, as well as companies, to uniquely identify files or cases. For computer files this practice was introduced for the first time with MIT's ITS file system, later the TENEX filesystem for the PDP-10 in 1972.[2]
Later lists of files including their versions were added, and dependencies amongst them. Linux distributions like Debian, with its dpkg, early on created package management software which could resolve dependencies between their packages. Debian's first try was that a package knew other packages which depended on it. From 1994 on this idea wa",Technology & Computing 
"Release notes
Release notes are documents that are distributed with software products or hardware products, sometimes when the product is still in the development or test state (e.g., a beta release).[1][2] For products that have already been in use by clients, the release note is delivered to the customer when an update is released. Another abbreviation for Release notes is Changelog or Release logs or Software changes or Revision history Updates or README file.[3] However, in some cases, the release notes and changelog are published separately. This split is for clarity and differentiation of feature-highlights from bugs, change requests (CRs) or improvements on the other side.[4][5]
Purpose
[edit]Release Notes are documents that are shared with end users, customers and clients of an organization. The definition of the terms 'End Users', 'Clients' and 'Customers' are very relative in nature and might have various interpretations based on the specific context. For instance, the Quality Assurance group within a software development organization can be interpreted as an internal customer.[6]
Content
[edit]Release notes detail the corrections, changes or enhancements (functional or non-functional) made to the service or product the company provides.[7][8][9]
They might also be provided as an artifact accompanying the deliverables for System Testing and System Integration Testing and other managed environments especially with reference to an information technology organization.
",Technology & Computing 
"Changelog
A changelog (also spelled change log)[1] is a log or record of all notable changes made to a project.[2] The project is often a website or software project, and the changelog usually includes records of changes such as bug fixes, new features, etc. Some open-source projects include a changelog as one of the top-level files in their distribution.
A changelog has historically included all changes made to a project. An alternative approach has been suggested that the log should instead contain ""a curated, chronologically ordered list of notable changes for each version of a project"" and should not be a ""dump"" of a git log ""because this helps nobody"".[3]
Although the GNU (Automake) canonical naming convention for the file is ChangeLog,[4] it is sometimes alternatively named as CHANGES or HISTORY (NEWS is usually a different file reflecting changes between releases, not between the commits). Another convention is to call it a CHANGELOG.[3] Some project maintainers will append a .txt suffix to the file name if the changelog is plain text, a .md suffix if it is in Markdown, or a .rst suffix if it is in reStructuredText.
Some revision control systems are able to generate the relevant information for a changelog, if the goal is to include all changes.[5]
Format
[edit]Changelog files are organized by paragraphs, which define a unique change within a function or file. The GNU Coding standards recommend the following format:[6]
YYYY-MM-DD␣␣John Doe␣␣<johndoe@example.com> * myfi",Technology & Computing 
"REST
REST (Representational State Transfer) is a software architectural style that was created to describe the design and guide the development of the architecture for the World Wide Web. REST defines a set of constraints for how the architecture of a distributed, Internet-scale hypermedia system, such as the Web, should behave. The REST architectural style emphasizes uniform interfaces, independent deployment of components, the scalability of interactions between them, and creating a layered architecture to promote caching to reduce user-perceived latency, enforce security, and encapsulate legacy systems.[1]
REST has been employed throughout the software industry to create stateless, reliable, web-based applications. An application that adheres to the REST architectural constraints may be informally described as RESTful, although this term is more commonly associated with the design of HTTP-based APIs and what are widely considered best practices regarding the ""verbs"" (HTTP methods) a resource responds to, while having little to do with REST as originally formulated—and is often even at odds with the concept.[2]
Principle
[edit]The term representational state transfer was introduced and defined in 2000 by computer scientist Roy Fielding in his doctoral dissertation. It means that a server will respond with the representation of a resource (today, it will most often be an HTML document) and that resource will contain hypermedia links that can be followed to make the state of ",Technology & Computing 
"gRPC
gRPC (acronym for Google Remote Procedure Calls[2]) is a cross-platform high-performance remote procedure call (RPC) framework. gRPC was initially created by Google, but is open source and is used in many organizations. Use cases range from microservices to the ""last mile"" of computing (mobile, web, and Internet of Things). gRPC uses HTTP/2 for transport, Protocol Buffers as the interface description language, and provides features such as authentication, bidirectional streaming and flow control, blocking or nonblocking bindings, and cancellation and timeouts. It generates cross-platform client and server bindings for many languages. The most common usage scenarios include connecting services in a microservices style architecture, or connecting mobile device clients to backend services.[3]
As of 2019, gRPC's use of HTTP/2 makes it impossible to implement a gRPC client in a browser, instead requiring a proxy.[4]
History
[edit]From about 2001, Google created a general-purpose RPC infrastructure called Stubby to connect the large number of microservices running within and across its data centers.[5] In March 2015, Google decided to build the next version of Stubby and make it open source. The result was gRPC.
Authentication
[edit]gRPC supports the usage of Transport Layer Security (TLS) and token-based authentication. Connection to Google services must use TLS. There are two types of credentials: channel credentials and call credentials.
For token-based authorization, gRPC ",Technology & Computing 
"WebSocket
WebSocket is a computer communications protocol, providing a simultaneous two-way communication channel over a single Transmission Control Protocol (TCP) connection. The WebSocket protocol was standardized by the IETF as RFC 6455 in 2011. The current specification allowing web applications to use this protocol is known as WebSockets.[1] It is a living standard maintained by the WHATWG and a successor to The WebSocket API from the W3C.[2]
WebSocket is distinct from HTTP used to serve most webpages. Although they are different, RFC 6455 states that WebSocket ""is designed to work over HTTP ports 443 and 80 as well as to support HTTP proxies and intermediaries"", thus making it compatible with HTTP. To achieve compatibility, the WebSocket handshake uses the HTTP Upgrade header[3] to change from the HTTP protocol to the WebSocket protocol.
The WebSocket protocol enables full-duplex interaction between a web browser (or other client application) and a web server with lower overhead than half-duplex alternatives such as HTTP polling, facilitating real-time data transfer from and to the server. This is made possible by providing a standardized way for the server to send content to the client without being first requested by the client, and allowing messages to be passed back and forth while keeping the connection open. In this way, a two-way ongoing conversation can take place between the client and the server. The communications are usually done over TCP port number 443 (or",Technology & Computing 
"OAuth
OAuth (short for open authorization[1][2]) is an open standard for access delegation, commonly used as a way for internet users to grant websites or applications access to their information on other websites but without giving them the passwords.[3][4] This mechanism is used by companies such as Amazon,[5] Google, Meta Platforms, Microsoft, and Twitter to permit users to share information about their accounts with third-party applications or websites.
Generally, the OAuth protocol provides a way for resource owners to provide a client application with secure delegated access to server resources. It specifies a process for resource owners to authorize third-party access to their server resources without providing credentials. Designed specifically to work with Hypertext Transfer Protocol (HTTP), OAuth essentially allows access tokens to be issued to third-party clients by an authorization server, with the approval of the resource owner. The third party then uses the access token to access the protected resources hosted by the resource server.[2]
History
[edit]OAuth began in November 2006 when Blaine Cook was developing an OpenID implementation for Twitter. Meanwhile, Ma.gnolia needed a solution to allow its members with OpenIDs to authorize Mac OS X Dashboard widgets to access their service. Cook, Chris Messina and Larry Halff from Magnolia met with David Recordon to discuss using OpenID with the Twitter and Magnolia APIs to delegate authentication. They concluded that t",Technology & Computing 
"OpenID
OpenID is an open standard and decentralized authentication protocol promoted by the non-profit OpenID Foundation. It allows users to be authenticated by co-operating sites (known as relying parties, or RP) using a third-party identity provider (IDP) service, eliminating the need for webmasters to provide their own ad hoc login systems, and allowing users to log in to multiple unrelated websites without having to have a separate identity and password for each.[1] Users create accounts by selecting an OpenID identity provider,[1] and then use those accounts to sign on to any website that accepts OpenID authentication. Several large organizations either issue or accept OpenIDs on their websites.[2]
The OpenID standard provides a framework for the communication that must take place between the identity provider and the OpenID acceptor (the ""relying party"").[3] An extension to the standard (the OpenID Attribute Exchange) facilitates the transfer of user attributes, such as name and gender, from the OpenID identity provider to the relying party (each relying party may request a different set of attributes, depending on its requirements).[4] The OpenID protocol does not rely on a central authority to authenticate a user's identity. Moreover, neither services nor the OpenID standard may mandate a specific means by which to authenticate users, allowing for approaches ranging from the common (such as passwords) to the novel (such as smart cards or biometrics).
The final version",Technology & Computing 
"Lightweight Directory Access Protocol
The Lightweight Directory Access Protocol (LDAP /ˈɛldæp/) is an open, vendor-neutral, industry standard application protocol for accessing and maintaining distributed directory information services over an Internet Protocol (IP) network.[1] Directory services play an important role in developing intranet and Internet applications by allowing the sharing of information about users, systems, networks, services, and applications throughout the network.[2] As examples, directory services may provide any organized set of records, often with a hierarchical structure, such as a corporate email directory. Similarly, a telephone directory is a list of subscribers with an address and a phone number.
LDAP is specified in a series of Internet Engineering Task Force (IETF) Standard Track publications known as Request for Comments (RFCs), using the description language ASN.1. The latest specification is Version 3, published as RFC 4511[3] (a road map to the technical specifications is provided by RFC4510).
A common use of LDAP is to provide a central place to store usernames and passwords. This allows many different applications and services to connect to the LDAP server to validate users.[4]
LDAP is a simpler (""lightweight"") subset of the standards in the X.500 series, particularly the X.511 Directory Access Protocol.[5][6] Because of this relationship, LDAP is sometimes called X.500 Lite.[7]
History
[edit]Telecommunication companies' understanding of",Technology & Computing 
"Active Directory
Active Directory (AD) is a directory service developed by Microsoft for Windows domain networks. Windows Server operating systems include it as a set of processes and services.[1][2] Originally, only centralized domain management used Active Directory. However, it ultimately became an umbrella title for various directory-based identity-related services.[3]
A domain controller is a server running the Active Directory Domain Services (AD DS) role. It authenticates and authorizes all users and computers in a Windows domain-type network, assigning and enforcing security policies for all computers and installing or updating software. For example, when a user logs into a computer which is part of a Windows domain, Active Directory checks the submitted username and password and determines whether the user is a system administrator or a non-admin user.[4] Furthermore, it allows the management and storage of information, provides authentication and authorization mechanisms, and establishes a framework to deploy other related services: Certificate Services, Active Directory Federation Services, Lightweight Directory Services, and Rights Management Services.[5]
Active Directory uses Lightweight Directory Access Protocol (LDAP) versions 2 and 3, Microsoft's version of Kerberos,[6] and DNS.[7]
Robert R. King defined it in the following way:[8]
""A domain represents a database. That database holds records about network services-things like computers, users, groups and other",Technology & Computing 
"Single sign-on
Single sign-on (SSO) is an authentication scheme that allows a user to log in with a single ID to any of several related, yet independent, software systems.
True single sign-on allows the user to log in once and access services without re-entering authentication factors.
It should not be confused with same-sign on (Directory Server Authentication), often accomplished by using the Lightweight Directory Access Protocol (LDAP) and stored LDAP databases on (directory) servers.[1][2]
A simple version of single sign-on can be achieved over IP networks using cookies but only if the sites share a common DNS parent domain.[3]
For clarity, a distinction is made between Directory Server Authentication (same-sign on) and single sign-on: Directory Server Authentication refers to systems requiring authentication for each application but using the same credentials from a directory server, whereas single sign-on refers to systems where a single authentication provides access to multiple applications by passing the authentication token seamlessly to configured applications.
Conversely, single sign-off or single log-out (SLO) is the property whereby a single action of signing out terminates access to multiple software systems.
As different applications and resources support different authentication mechanisms, single sign-on must internally store the credentials used for initial authentication and translate them to the credentials required for the different mechanisms.
Other sha",Technology & Computing 
"Multi-factor authentication
Multi-factor authentication (MFA; two-factor authentication, or 2FA) is an electronic authentication method in which a user is granted access to a website or application only after successfully presenting two or more distinct types of evidence (or factors) to an authentication mechanism. MFA protects personal data—which may include personal identification or financial assets—from being accessed by an unauthorized third party that may have been able to discover, for example, a single password.
Usage of MFA has increased in recent years. Security issues which can cause the bypass of MFA are fatigue attacks, phishing and SIM swapping.[1]
Accounts with MFA enabled are significantly less likely to be compromised. [2]
Authentication factors
[edit]Authentication takes place when someone tries to log into a computer resource (such as a computer network, device, or application). The resource requires the user to supply the identity by which the user is known to the resource, along with evidence of the authenticity of the user's claim to that identity. Simple authentication requires only one such piece of evidence (factor), typically a password, or occasionally multiple pieces of evidence all of the same type, as with a credit card number and a card verification code (CVC). For additional security, the resource may require more than one factor—multi-factor authentication, or two-factor authentication in cases where exactly two types of evidence are to be sup",Technology & Computing 
"Transport Layer Security
Transport Layer Security (TLS) is a cryptographic protocol designed to provide communications security over a computer network, such as the Internet. The protocol is widely used in applications such as email, instant messaging, and voice over IP, but its use in securing HTTPS remains the most publicly visible.
The TLS protocol aims primarily to provide security, including privacy (confidentiality), integrity, and authenticity through the use of cryptography, such as the use of certificates, between two or more communicating computer applications. It runs in the presentation layer and is itself composed of two layers: the TLS record and the TLS handshake protocols.
The closely related Datagram Transport Layer Security (DTLS) is a communications protocol that provides security to datagram-based applications. In technical writing, references to ""(D)TLS"" are often seen when it applies to both versions.[1]
TLS is a proposed Internet Engineering Task Force (IETF) standard, first defined in 1999, and the current version is TLS 1.3, defined in August 2018. TLS builds on the now-deprecated SSL (Secure Sockets Layer) specifications (1994, 1995, 1996) developed by Netscape Communications for adding the HTTPS protocol to their Netscape Navigator web browser.
Description
[edit]Client-server applications use the TLS protocol to communicate across a network in a way designed to prevent eavesdropping and tampering.
Since applications can communicate either with or wi",Technology & Computing 
"Public key certificate
In cryptography, a public key certificate, also known as a digital certificate or identity certificate, is an electronic document used to prove the validity of a public key.[1][2] The certificate includes the public key and information about it, information about the identity of its owner (called the subject), and the digital signature of an entity that has verified the certificate's contents (called the issuer). If the device examining the certificate trusts the issuer and finds the signature to be a valid signature of that issuer, then it can use the included public key to communicate securely with the certificate's subject. In email encryption, code signing, and e-signature systems, a certificate's subject is typically a person or organization. However, in Transport Layer Security (TLS) a certificate's subject is typically a computer or other device, though TLS certificates may identify organizations or individuals in addition to their core role in identifying devices. TLS, sometimes called by its older name Secure Sockets Layer (SSL), is notable for being a part of HTTPS, a protocol for securely browsing the web.
In a typical public-key infrastructure (PKI) scheme, the certificate issuer is a certificate authority (CA),[3] usually a company that charges customers a fee to issue certificates for them. By contrast, in a web of trust scheme, individuals sign each other's keys directly, in a format that performs a similar function to a public key certif",Technology & Computing 
"Public key infrastructure
A public key infrastructure (PKI) is a set of roles, policies, hardware, software and procedures needed to create, manage, distribute, use, store and revoke digital certificates and manage public-key encryption.
The purpose of a PKI is to facilitate the secure electronic transfer of information for a range of network activities such as e-commerce, internet banking and confidential email. It is required for activities where simple passwords are an inadequate authentication method and more rigorous proof is required to confirm the identity of the parties involved in the communication and to validate the information being transferred.
In cryptography, a PKI is an arrangement that binds public keys with respective identities of entities (like people and organizations).[1][2] The binding is established through a process of registration and issuance of certificates at and by a certificate authority (CA). Depending on the assurance level of the binding, this may be carried out by an automated process or under human supervision. When done over a network, this requires using a secure certificate enrollment or certificate management protocol such as CMP.
The PKI role that may be delegated by a CA to assure valid and correct registration is called a registration authority (RA). An RA is responsible for accepting requests for digital certificates and authenticating the entity making the request.[3] The Internet Engineering Task Force's RFC 3647 defines an RA as ",Technology & Computing 
"Secure Shell
The Secure Shell Protocol (SSH Protocol) is a cryptographic network protocol for operating network services securely over an unsecured network.[1] Its most notable applications are remote login and command-line execution.
SSH was designed for Unix-like operating systems as a replacement for Telnet and unsecured remote Unix shell protocols, such as the Berkeley Remote Shell (rsh) and the related rlogin and rexec protocols, which all use insecure, plaintext methods of authentication, like passwords.
Since mechanisms like Telnet and Remote Shell are designed to access and operate remote computers, sending the authentication tokens (e.g. username and password) for this access to these computers across a public network in an unsecured way poses a great risk of 3rd parties obtaining the password and achieving the same level of access to the remote system as the telnet user. Secure Shell mitigates this risk through the use of encryption mechanisms that are intended to hide the contents of the transmission from an observer, even if the observer has access to the entire data stream.[2]
Finnish computer scientist Tatu Ylönen designed SSH in 1995 and provided an implementation in the form of two commands, ssh and slogin, as secure replacements for rsh and rlogin, respectively. Subsequent development of the protocol suite proceeded in several developer groups, producing several variants of implementation. The protocol specification distinguishes two major versions, referred ",Technology & Computing 
"Network topology
Network topology is the arrangement of the elements (links, nodes, etc.) of a communication network.[1][2] Network topology can be used to define or describe the arrangement of various types of telecommunication networks, including command and control radio networks,[3] industrial fieldbusses and computer networks.
Network topology is the topological[4] structure of a network and may be depicted physically or logically. It is an application of graph theory[3] wherein communicating devices are modeled as nodes and the connections between the devices are modeled as links or lines between the nodes. Physical topology is the placement of the various components of a network (e.g., device location and cable installation), while logical topology illustrates how data flows within a network. Distances between nodes, physical interconnections, transmission rates, or signal types may differ between two different networks, yet their logical topologies may be identical. A network's physical topology is a particular concern of the physical layer of the OSI model.
Examples of network topologies are found in local area networks (LAN), a common computer network installation. Any given node in the LAN has one or more physical links to other devices in the network; graphically mapping these links results in a geometric shape that can be used to describe the physical topology of the network. A wide variety of physical topologies have been used in LANs, including ring, bus, mesh ",Technology & Computing 
"Local area network
A local area network (LAN) is a computer network that interconnects computers within a limited area such as a residence, campus, or building,[1][2][3] and has its network equipment and interconnects locally managed. LANs facilitate the distribution of data and sharing network devices, such as printers.
The LAN contrasts the wide area network (WAN), which not only covers a larger geographic distance, but also generally involves leased telecommunication circuits or Internet links. An even greater contrast is the Internet, which is a system of globally connected business and personal computers.
Ethernet and Wi-Fi are the two most common technologies used for local area networks; historical network technologies include ARCNET, Token Ring, and LocalTalk.
Cabling
[edit]Most wired network infrastructures utilize Category 5 or Category 6 twisted pair cabling with RJ45 compatible terminations. This medium provides physical connectivity between the Ethernet interfaces present on a large number of IP-aware devices. Depending on the grade of cable and quality of installation, speeds of up to 10 Mbit/s, 100 Mbit/s, 1 Gbit/s, or 10 Gbit/s are supported.
Wireless LAN
[edit]In a wireless LAN, users have unrestricted movement within the coverage area. Wireless networks have become popular in residences and small businesses because of their ease of installation, convenience, and flexibility.[4] Most wireless LANs consist of devices containing wireless radio technology that c",Technology & Computing 
"Edge computing
Edge computing is a distributed computing model that brings computation and data storage closer to the sources of data. More broadly, it refers to any design that pushes computation physically closer to a user, so as to reduce the latency compared to when an application runs on a centralized data centre.[1]
The term began being used in the 1990s to describe content delivery networks—these were used to deliver website and video content from servers located near users.[2] In the early 2000s, these systems expanded their scope to hosting other applications,[3] leading to early edge computing services.[4] These services could do things like find dealers, manage shopping carts, gather real-time data, and place ads.
The Internet of Things (IoT), where devices are connected to the internet, is often linked with edge computing.[5]
Definition
[edit]Edge computing involves running computer programs that deliver quick responses close to where requests are made. Karim Arabi, during an IEEE DAC 2014 keynote[6] and later at an MIT MTL Seminar in 2015, described edge computing as computing that occurs outside the cloud, at the network's edge, particularly for applications needing immediate data processing.[7]
Edge computing is often equated with fog computing, particularly in smaller setups.[8] However, in larger deployments, such as smart cities, fog computing serves as a distinct layer between edge computing and cloud computing, with each layer having its own responsibiliti",Technology & Computing 
"Fog computing
Fog computing[1][2] or fog networking, also known as fogging,[3][4] is an architecture that uses edge devices to carry out a substantial amount of computation (edge computing), storage, and communication locally and routed over the Internet backbone.
Concept
[edit]In 2011, the need to extend cloud computing with fog computing emerged, in order to cope with huge number of IoT devices and big data volumes for real-time low-latency applications.[5] Fog computing, also called edge computing, is intended for distributed computing where numerous ""peripheral"" devices connect to a cloud. The word ""fog"" refers to its cloud-like properties, but closer to the ""ground"", i.e. IoT devices.[6] Many of these devices will generate voluminous raw data (e.g., from sensors), and rather than forward all this data to cloud-based servers to be processed, the idea behind fog computing is to do as much processing as possible using computing units co-located with the data-generating devices, so that processed rather than raw data is forwarded, and bandwidth requirements are reduced. An additional benefit is that the processed data is most likely to be needed by the same devices that generated the data, so that by processing locally rather than remotely, the latency between input and response is minimized. This idea is not entirely new: in non-cloud-computing scenarios, special-purpose hardware (e.g., signal-processing chips performing fast Fourier transforms) has long been used to reduce",Technology & Computing 
"Cloud computing
Cloud computing is ""a paradigm for enabling network access to a scalable and elastic pool of shareable physical or virtual resources with self-service provisioning and administration on-demand,"" according to ISO.[1]
Essential characteristics
In 2011, the National Institute of Standards and Technology (NIST) identified five ""essential characteristics"" for cloud systems.[2] Below are the exact definitions according to NIST:[2]
- On-demand self-service: ""A consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with each service provider.""
- Broad network access: ""Capabilities are available over the network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, tablets, laptops, and workstations).""
- Resource pooling: "" The provider's computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to consumer demand.""
- Rapid elasticity: ""Capabilities can be elastically provisioned and released, in some cases automatically, to scale rapidly outward and inward commensurate with demand. To the consumer, the capabilities available for provisioning often appear unlimited and can be appropriated in any quantity at any time.""
- Measured service: ""Cloud systems automatically control",Technology & Computing 
"Serverless computing
Serverless computing is ""a cloud service category in which the customer can use different cloud capability types without the customer having to provision, deploy and manage either hardware or software resources, other than providing customer application code or providing customer data. Serverless computing represents a form of virtualized computing."" according to ISO/IEC 22123-2.[1] Serverless computing is a broad ecosystem that includes the cloud provider, Function as a Service, managed services, tools, frameworks, engineers, stakeholders, and other interconnected elements, according to Sheen Brisals.[2]
Overview
[edit]Serverless is a misnomer in the sense that servers are still used by cloud service providers to execute code for developers. The definition of serverless computing has evolved over time, leading to varied interpretations. According to Ben Kehoe, serverless represents a spectrum rather than a rigid definition. Emphasis should shift from strict definitions and specific technologies to adopting a serverless mindset, focusing on leveraging serverless solutions to address business challenges.[3]
Serverless computing does not eliminate complexity but shifts much of it from the operations team to the development team. However, this shift is not absolute, as operations teams continue to manage aspects such as identity and access management (IAM), networking, security policies, and cost optimization. Additionally, while breaking down applications i",Technology & Computing 
"Microservices
In software engineering, a microservice architecture is an architectural pattern that organizes an application into a collection of loosely coupled, fine-grained services that communicate through lightweight protocols. This pattern is characterized by the ability to develop and deploy services independently, improving modularity, scalability, and adaptability. However, it introduces additional complexity, particularly in managing distributed systems and inter-service communication, making the initial implementation more challenging compared to a monolithic architecture.[1]
Definition
[edit]There is no single, universally agreed-upon definition of microservices. However, they are generally characterized by a focus on modularity, with each service designed around a specific business capability. These services are loosely coupled, independently deployable, and often developed and scaled separately, enabling greater flexibility and agility in managing complex systems. Microservices architecture is closely associated with principles such as domain-driven design, decentralization of data and governance, and the flexibility to use different technologies for individual services to best meet their requirements. [2][3][4]
Usage
[edit]It is common for microservices architectures to be adopted for cloud-native applications, serverless computing, and applications using lightweight container deployment. According to Fowler, because of the large number (when compared to monoli",Technology & Computing 
"Service-oriented architecture
In software engineering, service-oriented architecture (SOA) is an architectural style that focuses on discrete services instead of a monolithic design.[1] SOA is a good choice for system integration.[2] By consequence, it is also applied in the field of software design where services are provided to the other components by application components, through a communication protocol over a network. A service is a discrete unit of functionality that can be accessed remotely and acted upon and updated independently, such as retrieving a credit card statement online. SOA is also intended to be independent of vendors, products and technologies.[3]
Service orientation is a way of thinking in terms of services and service-based development and the outcomes of services.[1]
A service has four properties according to one of many definitions of SOA:[4]
- It logically represents a repeatable business activity with a specified outcome.
- It is self-contained.
- It is a black box for its consumers, meaning the consumer does not have to be aware of the service's inner workings.
- It may be composed of other services.[5]
Different services can be used in conjunction as a service mesh to provide the functionality of a large software application,[6] a principle SOA shares with modular programming. Service-oriented architecture integrates distributed, separately maintained and deployed software components. It is enabled by technologies and standards that facilitate c",Technology & Computing 
"Message queue
In computer science, message queues and mailboxes are software-engineering components typically used for inter-process communication (IPC), or for inter-thread communication within the same process. They use a queue for messaging – the passing of control or of content. Group communication systems provide similar kinds of functionality.
The message queue paradigm is a sibling of the publisher/subscriber pattern, and is typically one part of a larger message-oriented middleware system. Most messaging systems support both the publisher/subscriber and message queue models in their API, e.g. Java Message Service (JMS).
Competing Consumers pattern enables multiple concurrent consumers to process messages on the same message queue. [1]
Remit and ownership
[edit]Message queues implement an asynchronous communication pattern between two or more processes/threads whereby the sending and receiving party do not need to interact with the message queue at the same time. Messages placed onto the queue are stored until the recipient retrieves them. Message queues have implicit or explicit limits on the size of data that may be transmitted in a single message and the number of messages that may remain outstanding on the queue.[2]
Remit
[edit]Many implementations of message queues function internally within an operating system or within an application. Such queues exist for the purposes of that system only.[3][4][5]
Other implementations allow the passing of messages between diff",Technology & Computing 
"RabbitMQ
RabbitMQ is an open-source message-broker software (sometimes called message-oriented middleware) that originally implemented the Advanced Message Queuing Protocol (AMQP) and has since been extended with a plug-in architecture to support Streaming Text Oriented Messaging Protocol (STOMP), MQ Telemetry Transport (MQTT), and other protocols.[2]
Written in Erlang, the RabbitMQ server is built on the Open Telecom Platform framework for clustering and failover. Client libraries to interface with the broker are available for all major programming languages. The source code is released under the Mozilla Public License.
Since November 2020, there are commercial offerings available of RabbitMQ, for support and enterprise features: ""VMware RabbitMQ OVA"", ""VMware RabbitMQ"" and ""VMware RabbitMQ for Kubernetes"" (different feature levels) [3] Open-Source RabbitMQ is also packaged by Bitnami[4] and commercially for VMware's Tanzu Application Service.
History
[edit]Originally developed by Rabbit Technologies Ltd. which started as a joint venture between LShift and CohesiveFT in 2007,[5] RabbitMQ was acquired in April 2010 by SpringSource, a division of VMware.[6] The project became part of Pivotal Software in May 2013.[7] Which then got acquired back by VMware in December 2019.[8]
The project consists of:
- The RabbitMQ exchange server
- Gateways for AMQP, HTTP, STOMP, and MQTT protocols
- AMQP client libraries for Java, .NET Framework and Erlang. (AMQP clients for other languages a",Technology & Computing 
"MQTT
MQTT[a] is a lightweight, publish–subscribe, machine-to-machine network protocol for message queue/message queuing service. It is designed for connections with remote locations that have devices with resource constraints or limited network bandwidth, such as in the Internet of things (IoT). It must run over a transport protocol that provides ordered, lossless, bi-directional connections—typically, TCP/IP.[1] It is an open OASIS standard and an ISO recommendation (ISO/IEC 20922).
History
[edit]Andy Stanford-Clark (IBM) and Arlen Nipper (then working for Eurotech, Inc.) authored the first version of the protocol in 1999.[5] It was used to monitor oil pipelines within the SCADA industrial control system.[6] The goal was to have a protocol that is bandwidth-efficient, lightweight and uses little battery power, because the devices were connected via satellite link, which was extremely expensive at that time.[7]
Historically, the ""MQ"" in ""MQTT"" came from the IBM MQ (then ""MQSeries"") product line, where it stands for ""Message Queue"". However, the protocol provides publish-and-subscribe messaging (no queues, in spite of the name).[8] In the specification opened by IBM, as version 3.1, the protocol was referred to as ""MQ Telemetry Transport"".[9][10] Subsequent versions released by OASIS strictly refer to the protocol as just ""MQTT"", although the technical committee itself is named ""OASIS Message Queuing Telemetry Transport Technical Committee"".[3] Since 2013, ""MQTT"" does not stan",Technology & Computing 
"Constrained Application Protocol
Constrained Application Protocol (CoAP) is a specialized UDP-based Internet application protocol for constrained devices, as defined in RFC 7252 (published in 2014). It enables those constrained devices called ""nodes"" to communicate with the wider Internet using similar protocols. CoAP is designed for use between devices on the same constrained network (e.g., low-power, lossy networks), between devices and general nodes on the Internet, and between devices on different constrained networks both joined by an internet. CoAP is also being used via other mechanisms, such as SMS on mobile communication networks.
CoAP is an application-layer protocol that is intended for use in resource-constrained Internet devices, such as wireless sensor network nodes. CoAP is designed to easily translate to HTTP for simplified integration with the web, while also meeting specialized requirements such as multicast support, very low overhead, and simplicity.[1][2] Multicast, low overhead, and simplicity are important for Internet of things (IoT) and machine-to-machine (M2M) communication, which tend to be embedded and have much less memory and power supply than traditional Internet devices have. Therefore, efficiency is very important. CoAP can run on most devices that support UDP or a UDP analogue.
The Internet Engineering Task Force (IETF) Constrained RESTful Environments Working Group (CoRE) has done the major standardization work for this protocol. In order to ",Technology & Computing 
"Advanced Message Queuing Protocol
The Advanced Message Queuing Protocol (AMQP) is an open standard application layer protocol for message-oriented middleware. The defining features of AMQP are message orientation, queuing, routing (including point-to-point and publish-and-subscribe), reliability and security.[1]
AMQP mandates the behavior of the messaging provider and client to the extent that implementations from different vendors are interoperable, in the same way as SMTP, HTTP, FTP, etc. have created interoperable systems. Previous standardizations of middleware have happened at the API level (e.g. JMS) and were focused on standardizing programmer interaction with different middleware implementations, rather than on providing interoperability between multiple implementations.[2] Unlike JMS, which defines an API and a set of behaviors that a messaging implementation must provide, AMQP is a wire-level protocol. A wire-level protocol is a description of the format of the data that is sent across the network as a stream of bytes. Consequently, any tool that can create and interpret messages that conform to this data format can interoperate with any other compliant tool irrespective of implementation language.
Overview
[edit]AMQP is a binary application layer protocol, designed to efficiently support a wide variety of messaging applications and communication patterns. It provides flow controlled,[3] message-oriented communication with message-delivery guarantees such as at-most",Technology & Computing 
"ZeroMQ
ZeroMQ (also spelled ØMQ, 0MQ or ZMQ) is an asynchronous messaging library, aimed at use in distributed or concurrent applications. It provides a message queue, but unlike message-oriented middleware, a ZeroMQ system can run without a dedicated message broker; the zero in the name is for ""zero broker"".[3] The library's API is designed to resemble Berkeley sockets.
ZeroMQ is developed by a large community of contributors, founded by iMatix, which holds the domain name and trademarks. There are third-party bindings for many popular programming languages.
Technology
[edit]The ZeroMQ API provides sockets (a kind of generalization over the traditional IP and Unix domain sockets), each of which can represent a many-to-many connection between endpoints. Operating with a message-wise granularity, they require that a messaging pattern be used, and are particularly optimized for that kind of pattern.
The basic ZeroMQ patterns are:
- Request–reply
- Connects a set of clients to a set of services. This is a remote procedure call and task distribution pattern.
- Publish–subscribe
- Connects a set of publishers to a set of subscribers. This is a data distribution pattern.
- Push–pull (pipeline)
- Connects nodes in a fan-out / fan-in pattern that can have multiple steps, and loops. This is a parallel task distribution and collection pattern.
- Exclusive pair
- Connects two sockets in an exclusive pair. (This is an advanced low-level pattern for specific use cases.)
Each pattern defin",Technology & Computing 
"Redis
Redis (/ˈrɛdɪs/;[8][9] Remote Dictionary Server)[8] is an in-memory key–value database, used as a distributed cache and message broker, with optional durability.[10] Because it holds all data in memory and because of its design, Redis offers low-latency reads and writes, making it particularly suitable for use cases that require a cache. Redis is the most popular NoSQL database,[11][12][13] and one of the most popular databases overall.[14]
The project was developed and maintained by Salvatore Sanfilippo, starting in 2009.[15] From 2015 until 2020, he led a project core team sponsored by Redis Ltd.[16] Salvatore Sanfilippo left Redis as the maintainer in 2020.[17] In 2021 Redis Labs dropped the Labs from its name and now is known simply as ""Redis"".[18]
In 2018, some modules for Redis adopted a modified Apache 2.0 with a Commons Clause.[19] In 2024, the main Redis code switched from the open-source BSD-3 license to being dual-licensed under the Redis Source Available License v2 and the Server Side Public License v1.[6] On May 1, 2025, Redis became tri-licensed beginning with version 8.0, with the GNU Affero General Public License as the third option.[7]
History
[edit]The name Redis means Remote Dictionary Server.[8] The Redis project began when Salvatore Sanfilippo, nicknamed antirez, the original developer of Redis, was trying to improve the scalability of his Italian startup, developing a real-time web log analyzer. After encountering significant problems in scaling so",Technology & Computing 
"Memcached
Memcached (pronounced variously /mɛmkæʃˈdiː/ mem-cash-dee or /ˈmɛmkæʃt/ mem-cashed) is a general-purpose distributed memory-caching system. It is often used to speed up dynamic database-driven websites by caching data and objects in RAM to reduce the number of times an external data source (such as a database or API) must be read. Memcached is free and open-source software, licensed under the Revised BSD license.[2] Memcached runs on Unix-like operating systems (Linux and macOS) and on Microsoft Windows. It depends on the libevent library.
Memcached's APIs provide a very large hash table distributed across multiple machines. When the table is full, subsequent inserts cause older data to be purged in least recently used (LRU) order.[3][4] Applications using Memcached typically layer requests and additions into RAM before falling back on a slower backing store, such as a database.
Memcached has no internal mechanism to track misses which may happen. However, some third party utilities provide this functionality.
Memcached was first developed by Brad Fitzpatrick for his website LiveJournal, on May 22, 2003.[5][6] It was originally written in Perl, then later rewritten in C by Anatoly Vorobey, then employed by LiveJournal.[7] Memcached is now used by many other systems, including YouTube,[8] Reddit,[9] Facebook,[10][11] Pinterest,[12][13] Twitter,[14] Wikipedia,[15] and Method Studios.[16] Google App Engine, Google Cloud Platform, Microsoft Azure, IBM Bluemix and Amazon",Technology & Computing 
"Database schema
The database schema is the structure of a database described in a formal language supported typically by a relational database management system (RDBMS). The term ""schema"" refers to the organization of data as a blueprint of how the database is constructed (divided into database tables in the case of relational databases). The formal definition of a database schema is a set of formulas (sentences) called integrity constraints imposed on a database.[citation needed] These integrity constraints ensure compatibility between parts of the schema. All constraints are expressible in the same language. A database can be considered a structure in realization of the database language.[1] The states of a created conceptual schema are transformed into an explicit mapping, the database schema. This describes how real-world entities are modeled in the database.
""A database schema specifies, based on the database administrator's knowledge of possible applications, the facts that can enter the database, or those of interest to the possible end-users.""[2] The notion of a database schema plays the same role as the notion of theory in predicate calculus. A model of this ""theory"" closely corresponds to a database, which can be seen at any instant of time as a mathematical object. Thus a schema can contain formulas representing integrity constraints specifically for an application and the constraints specifically for a type of database, all expressed in the same database language.",Technology & Computing 
"Relational database
A relational database (RDB[1]) is a database based on the relational model of data, as proposed by E. F. Codd in 1970.[2]
A Relational Database Management System (RDBMS) is a type of database management system that stores data in a structured format using rows and columns.
Many relational database systems are equipped with the option of using SQL (Structured Query Language) for querying and updating the database.[3]
History
[edit]The concept of relational database was defined by E. F. Codd at IBM in 1970. Codd introduced the term relational in his research paper ""A Relational Model of Data for Large Shared Data Banks"".[2] In this paper and later papers, he defined what he meant by relation. One well-known definition of what constitutes a relational database system is composed of Codd's 12 rules.
However, no commercial implementations of the relational model conform to all of Codd's rules,[4] so the term has gradually come to describe a broader class of database systems, which at a minimum:
- Present the data to the user as relations (a presentation in tabular form, i.e. as a collection of tables with each table consisting of a set of rows and columns);
- Provide relational operators to manipulate the data in tabular form.
In 1974, IBM began developing System R, a research project to develop a prototype RDBMS.[5][6] The first system sold as an RDBMS was Multics Relational Data Store (June 1976).[7][8][citation needed] Oracle was released in 1979 by Relation",Technology & Computing 
"Document-oriented database
A document-oriented database, or document store, is a computer program and data storage system designed for storing, retrieving and managing document-oriented information, also known as semi-structured data.[1]
Document-oriented databases are one of the main categories of NoSQL databases, and the popularity of the term ""document-oriented database"" has grown[2] with the use of the term NoSQL itself. XML databases are a subclass of document-oriented databases that are optimized to work with XML documents. Graph databases are similar, but add another layer, the relationship, which allows them to link documents for rapid traversal.
Document-oriented databases are inherently a subclass of the key-value store, another NoSQL database concept. The difference[contradictory] lies in the way the data is processed; in a key-value store, the data is considered to be inherently opaque to the database, whereas a document-oriented system relies on internal structure in the document in order to extract metadata that the database engine uses for further optimization. Although the difference is often negligible due to tools in the systems,[a] conceptually the document-store is designed to offer a richer experience with modern programming techniques.
Document databases[b] contrast strongly with the traditional relational database (RDB). Relational databases generally store data in separate tables that are defined by the programmer, and a single object may be spread acr",Technology & Computing 
"Key–value database
A key–value database, or key–value store, is a data storage paradigm designed for storing, retrieving, and managing associative arrays, a data structure more commonly known today as a dictionary or hash table. Dictionaries contain a collection of objects, or records, which in turn have many different fields within them, each containing data. These records are stored and retrieved using a key that uniquely identifies the record, and is used to find the data within the database.[1][2]
Key–value databases work in a very different fashion from the better known relational databases (RDB). RDBs predefine the data structure in the database as a series of tables containing fields with well defined data types. Exposing the data types to the database program allows it to apply a number of optimizations. In contrast, key–value systems treat the data as a single opaque collection, which may have different fields for every record. This offers considerable flexibility and more closely follows modern concepts like object-oriented programming. Because optional values are not represented by placeholders or input parameters, as in most RDBs, key–value databases often use far less memory to store the same data, which can lead to large performance gains in certain workloads.[citation needed]
Performance, a lack of standardization and other issues have limited key–value systems to niche uses for many years, but the rapid move to cloud computing after 2010 has led to a renaissan",Technology & Computing 
"Graph database
A graph database (GDB) is a database that uses graph structures for semantic queries with nodes, edges, and properties to represent and store data.[1] A key concept of the system is the graph (or edge or relationship). The graph relates the data items in the store to a collection of nodes and edges, the edges representing the relationships between the nodes. The relationships allow data in the store to be linked together directly and, in many cases, retrieved with one operation. Graph databases hold the relationships between data as a priority. Querying relationships is fast because they are perpetually stored in the database. Relationships can be intuitively visualized using graph databases, making them useful for heavily inter-connected data.[2]
Graph databases are commonly referred to as a NoSQL database. Graph databases are similar to 1970s network model databases in that both represent general graphs, but network-model databases operate at a lower level of abstraction[3] and lack easy traversal over a chain of edges.[4]
The underlying storage mechanism of graph databases can vary. Relationships are first-class citizens in a graph database and can be labelled, directed, and given properties. Some depend on a relational engine and store the graph data in a table (although a table is a logical element, therefore this approach imposes a level of abstraction between the graph database management system and physical storage devices). Others use a key–value store",Technology & Computing 
"NewSQL
NewSQL is a class of relational database management systems that seek to provide the scalability of NoSQL systems for online transaction processing (OLTP) workloads while maintaining the ACID guarantees of a traditional database system.[1][2][3][4]
Many enterprise systems that handle high-profile data (e.g., financial and order processing systems) are too large for conventional relational databases, but have transactional and consistency requirements that are not practical for NoSQL systems.[5][6] The only options previously available for these organizations were to either purchase more powerful computers or to develop custom middleware that distributes requests over conventional DBMS. Both approaches feature high infrastructure costs and/or development costs. NewSQL systems attempt to reconcile the conflicts.
History
[edit]The term was first used by 451 Group analyst Matthew Aslett in a 2011 research paper discussing the rise of a new generation of database management systems.[5] One of the first NewSQL systems was the H-Store parallel database system.[7][8]
Applications
[edit]Typical applications are characterized by heavy OLTP transaction volumes. OLTP transactions;
- are short-lived (i.e., no user stalls)
- touch small amounts of data per transaction
- use indexed lookups (no table scans)
- have a small number of forms (a small number of queries with different arguments).[9]
However, some support hybrid transactional/analytical processing (HTAP) applications. Such ",Technology & Computing 
"In-memory database
An in-memory database (IMDb, or main memory database system (MMDB) or memory resident database) is a database management system that primarily relies on main memory for computer data storage. It is contrasted with database management systems that employ a disk storage mechanism. In-memory databases are faster than disk-optimized databases because disk access is slower than memory access and the internal optimization algorithms are simpler and execute fewer CPU instructions. Accessing data in memory eliminates seek time when querying the data, which provides faster and more predictable performance than disk.[1][2]
Applications where response time is critical, such as those running telecommunications network equipment and mobile advertising networks, often use main-memory databases.[3] IMDBs have gained much traction, especially in the data analytics space, starting in the mid-2000s – mainly due to multi-core processors that can address large memory and due to less expensive RAM.[4][5]
A potential technical hurdle with in-memory data storage is the volatility of RAM. Specifically in the event of a power loss, intentional or otherwise, data stored in volatile RAM is lost.[6] With the introduction of non-volatile random-access memory technology, in-memory databases will be able to run at full speed and maintain data in the event of power failure.[7][8][9]
ACID support
[edit]In its simplest form, main memory databases store data on volatile memory devices. These",Technology & Computing 
"Distributed database
A distributed database is a database in which data is stored across different physical locations.[1] It may be stored in multiple computers located in the same physical location (e.g. a data centre); or maybe dispersed over a network of interconnected computers. Unlike parallel systems, in which the processors are tightly coupled and constitute a single database system, a distributed database system consists of loosely coupled sites that share no physical components.
System administrators can distribute collections of data (e.g. in a database) across multiple physical locations. A distributed database can reside on organised network servers or decentralised independent computers on the Internet, on corporate intranets or extranets, or on other organisation networks. Because distributed databases store data across multiple computers, distributed databases may improve performance at end-user worksites by allowing transactions to be processed on many machines, instead of being limited to one.[2]
Two processes ensure that the distributed databases remain up-to-date and current: replication[3] and duplication.
- Replication involves using specialized software that looks for changes in the distributive database. Once the changes have been identified, the replication process makes all the databases look the same. The replication process can be complex and time-consuming, depending on the size and number of the distributed databases. This process can also require",Technology & Computing 
"CAP theorem
In database theory, the CAP theorem, also named Brewer's theorem after computer scientist Eric Brewer, states that any distributed data store can provide at most two of the following three guarantees:[1][2][3]
- Consistency
- Every read receives the most recent write or an error. Consistency as defined in the CAP theorem is quite different from the consistency guaranteed in ACID database transactions.[4]
- Availability
- Every request received by a non-failing node in the system must result in a response. This is the definition of availability in CAP theorem as defined by Gilbert and Lynch.[1] Availability as defined in CAP theorem is different from high availability in software architecture.[5]
- Partition tolerance
- The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes.
When a network partition failure happens, it must be decided whether to do one of the following:
- cancel the operation and thus decrease the availability but ensure consistency
- proceed with the operation and thus provide availability but risk inconsistency. This does not necessarily mean that system is highly available to its users.[5]
Thus, if there is a network partition, one has to choose between consistency or availability.
Explanation
[edit]No distributed system is safe from network failures, thus network partitioning generally has to be tolerated.[6][7] In the presence of a partition, one is then left with two opt",Technology & Computing 
"ACID
In computer science, ACID (atomicity, consistency, isolation, durability) is a set of properties of database transactions intended to guarantee data validity despite errors, power failures, and other mishaps. In the context of databases, a sequence of database operations that satisfies the ACID properties (which can be perceived as a single logical operation on the data) is called a transaction. For example, a transfer of funds from one bank account to another, even involving multiple changes such as debiting one account and crediting another, is a single transaction.
In 1983,[1] Andreas Reuter and Theo Härder coined the acronym ACID, building on earlier work by Jim Gray[2] who named atomicity, consistency, and durability, but not isolation, when characterizing the transaction concept. These four properties are the major guarantees of the transaction paradigm, which has influenced many aspects of development in database systems.
According to Gray and Reuter, the IBM Information Management System supported ACID transactions as early as 1973 (although the acronym was created later).[3]
BASE stands for basically available, soft state, and eventually consistent: the acronym highlights that BASE is opposite of ACID, like their chemical equivalents.[4] ACID databases prioritize consistency over availability — the whole transaction fails if an error occurs in any step within the transaction; in contrast, BASE databases prioritize availability over consistency: instead of failin",Technology & Computing 
"Data warehouse
In computing, a data warehouse (DW or DWH), also known as an enterprise data warehouse (EDW), is a system used for reporting and data analysis and is a core component of business intelligence.[1] Data warehouses are central repositories of data integrated from disparate sources. They store current and historical data organized in a way that is optimized for data analysis, generation of reports, and developing insights across the integrated data.[2] They are intended to be used by analysts and managers to help make organizational decisions.[3]
The data stored in the warehouse is uploaded from operational systems (such as marketing or sales). The data may pass through an operational data store and may require data cleansing for additional operations to ensure data quality before it is used in the data warehouse for reporting.
The two main workflows for building a data warehouse system are extract, transform, load (ETL) and extract, load, transform (ELT).
Components
[edit]The environment for data warehouses and marts includes the following:
- Source systems of data (often, the company's operational databases, such as relational databases[3]);
- Data integration technology and processes to extract data from source systems, transform them, and load them into a data mart or warehouse;[3]
- Architectures to store data in the warehouse or marts;
- Tools and applications for varied users;
- Metadata, data quality, and governance processes. Metadata includes data sources",Technology & Computing 
"Data lake
A data lake is a system or repository of data stored in its natural/raw format,[1] usually object blobs or files. A data lake is usually a single store of data including raw copies of source system data, sensor data, social data etc.,[2] and transformed data used for tasks such as reporting, visualization, advanced analytics, and machine learning. A data lake can include structured data from relational databases (rows and columns), semi-structured data (CSV, logs, XML, JSON), unstructured data (emails, documents, PDFs), and binary data (images, audio, video).[3] A data lake can be established on premises (within an organization's data centers) or in the cloud (using cloud services).
Background
[edit]James Dixon, then chief technology officer at Pentaho, coined the term by 2011[4] to contrast it with data mart, which is a smaller repository of interesting attributes derived from raw data.[5] In promoting data lakes, he argued that data marts have several inherent problems, such as information siloing. PricewaterhouseCoopers (PwC) said that data lakes could ""put an end to data silos"".[6] In their study on data lakes they noted that enterprises were ""starting to extract and place data for analytics into a single, Hadoop-based repository.""
Examples
[edit]Many companies use cloud storage services such as Google Cloud Storage and Amazon S3 or a distributed file system such as Apache Hadoop distributed file system (HDFS).[7] There is a gradual academic interest in the conc",Technology & Computing 
"Pipeline (computing)
In computing, a pipeline, also known as a data pipeline, is a set of data processing elements connected in series, where the output of one element is the input of the next one. The elements of a pipeline are often executed in parallel or in time-sliced fashion. Some amount of buffer storage is often inserted between elements.
Concept and motivation
[edit]Pipelining is a commonly used concept in everyday life. For example, in the assembly line of a car factory, each specific task—such as installing the engine, installing the hood, and installing the wheels—is often done by a separate work station. The stations carry out their tasks in parallel, each on a different car. Once a car has had one task performed, it moves to the next station. Variations in the time needed to complete the tasks can be accommodated by ""buffering"" (holding one or more cars in a space between the stations) and/or by ""stalling"" (temporarily halting the upstream stations), until the next station becomes available.
Suppose that assembling one car requires three tasks that take 20, 10, and 15 minutes, respectively. Then, if all three tasks were performed by a single station, the factory would output one car every 45 minutes. By using a pipeline of three stations, the factory would output the first car in 45 minutes, and then a new one every 20 minutes.
As this example shows, pipelining does not decrease the latency, that is, the total time for one item to go through the whole system. It",Technology & Computing 
"Data mesh
Data mesh is a sociotechnical approach to building a decentralized data architecture by leveraging a domain-oriented, self-serve design (in a software development perspective), and borrows Eric Evans’ theory of domain-driven design[1] and Manuel Pais’ and Matthew Skelton’s theory of team topologies.[2] Data mesh mainly concerns itself with the data itself, taking the data lake and the pipelines as a secondary concern. [3] The main proposition is scaling analytical data by domain-oriented decentralization.[4] With data mesh, the responsibility for analytical data is shifted from the central data team to the domain teams, supported by a data platform team that provides a domain-agnostic data platform.[5] This enables a decrease in data disorder or the existence of isolated data silos, due to the presence of a centralized system that ensures the consistent sharing of fundamental principles across various nodes within the data mesh and allows for the sharing of data across different areas.[6]
History
[edit]The term data mesh was first defined by Zhamak Dehghani in 2019[7] while she was working as a principal consultant at the technology company Thoughtworks.[8][9] Dehghani introduced the term in 2019 and then provided greater detail on its principles and logical architecture throughout 2020. The process was predicted to be a “big contender” for companies in 2022.[10][11] Data meshes have been implemented by companies such as Zalando,[12] Netflix,[13] Intuit,[14] VistaPr",Technology & Computing 
"Internet of Military Things
The Internet of Military Things (IoMT) is a class of Internet of things for combat operations and warfare. It is a complex network of interconnected entities, or ""things"", in the military domain that continually communicate with each other to coordinate, learn, and interact with the physical environment to accomplish a broad range of activities in a more efficient and informed manner.[1][2] The concept of IoMT is largely driven by the idea that future military battles will be dominated by machine intelligence and cyber warfare and will likely take place in urban environments.[3][4] By creating a miniature ecosystem of smart technology capable of distilling sensory information and autonomously governing multiple tasks at once, the IoMT is conceptually designed to offload much of the physical and mental burden that warfighters encounter in a combat setting.[5]
Over time, several different terms have been introduced to describe the use of IoT technology for reconnaissance, environment surveillance, unmanned warfare and other combat purposes. These terms include the Military Internet of Things (MIoT),[6] the Internet of Battle Things,[7] and the Internet of Battlefield Things (IoBT).[8]
Overview
[edit]The Internet of Military Things encompasses a large range of devices that possess intelligent physical sensing, learning, and actuation capabilities through virtual or cyber interfaces that are integrated into systems. These devices include items such as ",Technology & Computing 
"Big data
Big data primarily refers to data sets that are too large or complex to be dealt with by traditional data-processing software. Data with many entries (rows) offer greater statistical power, while data with higher complexity (more attributes or columns) may lead to a higher false discovery rate.[1]
Big data analysis challenges include capturing data, data storage, data analysis, search, sharing, transfer, visualization, querying, updating, information privacy, and data source. Big data was originally associated with three key concepts: volume, variety, and velocity.[2] The analysis of big data presents challenges in sampling, and thus previously allowing for only observations and sampling. Thus a fourth concept, veracity, refers to the quality or insightfulness of the data.[3] Without sufficient investment in expertise for big data veracity, the volume and variety of data can produce costs and risks that exceed an organization's capacity to create and capture value from big data.[4]
Current usage of the term big data tends to refer to the use of predictive analytics, user behavior analytics, or certain other advanced data analytics methods that extract value from big data, and seldom to a particular size of data set. ""There is little doubt that the quantities of data now available are indeed large, but that's not the most relevant characteristic of this new data ecosystem.""[5] Analysis of data sets can find new correlations to ""spot business trends, prevent diseases, ",Technology & Computing 
"Apache Hadoop
Apache Hadoop (/həˈduːp/) is a collection of open-source software utilities for reliable, scalable, distributed computing. It provides a software framework for distributed storage and processing of big data using the MapReduce programming model. Hadoop was originally designed for computer clusters built from commodity hardware, which is still the common use.[3] It has since also found use on clusters of higher-end hardware.[4][5] All the modules in Hadoop are designed with a fundamental assumption that hardware failures are common occurrences and should be automatically handled by the framework.[6]
Overview
[edit]The core of Apache Hadoop consists of a storage part, known as Hadoop Distributed File System (HDFS), and a processing part which is a MapReduce programming model. Hadoop splits files into large blocks and distributes them across nodes in a cluster. It then transfers packaged code into nodes to process the data in parallel. This approach takes advantage of data locality,[7] where nodes manipulate the data they have access to. This allows the dataset to be processed faster and more efficiently than it would be in a more conventional supercomputer architecture that relies on a parallel file system where computation and data are distributed via high-speed networking.[8][9]
The base Apache Hadoop framework is composed of the following modules:
- Hadoop Common – contains libraries and utilities needed by other Hadoop modules;
- Hadoop Distributed File System",Technology & Computing 
"Apache Kafka
Apache Kafka is a distributed event store and stream-processing platform. It is an open-source system developed by the Apache Software Foundation written in Java and Scala. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds. Kafka can connect to external systems (for data import/export) via Kafka Connect, and provides the Kafka Streams libraries for stream processing applications. Kafka uses a binary TCP-based protocol that is optimized for efficiency and relies on a ""message set"" abstraction that naturally groups messages together to reduce the overhead of the network roundtrip. This ""leads to larger network packets, larger sequential disk operations, contiguous memory blocks [...] which allows Kafka to turn a bursty stream of random message writes into linear writes.""[4]
History
[edit]Kafka was originally developed at LinkedIn, and was subsequently open sourced in early 2011. Jay Kreps, Neha Narkhede and Jun Rao helped co-create Kafka.[5] Graduation from the Apache Incubator occurred on 23 October 2012.[6] Jay Kreps chose to name the software after the author Franz Kafka because it is ""a system optimized for writing"", and he liked Kafka's work.[7]
Operation
[edit]Apache Kafka is a distributed log-based messaging system that guarantees ordering within individual partitions rather than across the entire topic. Unlike queue-based systems, Kafka retains messages in a durable, append-only log, allowing mult",Technology & Computing 
"ClickHouse
ClickHouse is an open-source column-oriented DBMS (columnar database management system) for online analytical processing (OLAP) that allows users to generate analytical reports using SQL queries in real-time. ClickHouse Inc. is headquartered in the San Francisco Bay Area with the subsidiary, ClickHouse B.V., based in Amsterdam, Netherlands.
In September 2021 in San Francisco, CA, ClickHouse incorporated to house the open source technology with an initial $50 million investment from Index Ventures and Benchmark Capital with participation by Yandex N.V.[2] and others. On October 28, 2021 the company received Series B funding totaling $250 million at a valuation of $2 billion from Coatue Management, Altimeter Capital, and other investors. The company continues to build the open source project and engineering cloud technology.
History
[edit]ClickHouse’s technology was first developed over 10 years ago at Yandex, Russia's largest technology company.[3] In 2009, Alexey Milovidov and developers started an experimental project to check the hypothesis if it was viable to generate analytical reports in real-time from non-aggregated data that is also constantly added in real-time. The developers spent 3 years to prove this hypothesis, and in 2012 ClickHouse launched in production for the first time to power Yandex.Metrica.
Unlike custom data structures used before, ClickHouse was applicable more generally to work as a database management system. The power and utility of Click",Technology & Computing 
"Kibana
Kibana is a source-available[3] data visualization dashboard software for Elasticsearch.
History
[edit]Kibana provides visualization capabilities on top of the content indexed on an Elasticsearch cluster. Users can create bar, line and scatter plots, or pie charts and maps on top of large volumes of data.[4]
Kibana also provides a presentation tool, referred to as Canvas, that allows users to create slide decks that pull live data directly from Elasticsearch.[5]
The combination of Elasticsearch, Logstash, and Kibana, referred to as the ""Elastic Stack"" (formerly the ""ELK stack""), is available as a product or service.[6] Logstash provides an input stream to Elasticsearch for storage and search, and Kibana accesses the data for visualizations such as dashboards.[7] Elastic also provides ""Beats"" packages which can be configured to provide pre-made Kibana visualizations and dashboards about various database and application technologies.[8]
In December 2019, Elastic introduced Kibana Lens product, which is a simpler drag-and-drop user interface than the original aggregation based visualizations.[9]
In May 2021, OpenSearch released the first beta of OpenSearch Dashboards, the Apache-licensed fork of Kibana sponsored by Amazon Web Services after Elastic discontinued the open source project and switched to proprietary software development.[10]
In August 2024 the GNU Affero General Public License was added as an option, making Kibana free and open-source once again.[11]
See also",Technology & Computing 
"Time series
In mathematics, a time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data. Examples of time series are heights of ocean tides, counts of sunspots, and the daily closing value of the Dow Jones Industrial Average.
A time series is very frequently plotted via a run chart (which is a temporal line chart). Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and largely in any domain of applied science and engineering which involves temporal measurements.
Time series analysis comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data. Time series forecasting is the use of a model to predict future values based on previously observed values. Generally, time series data is modelled as a stochastic process. While regression analysis is often employed in such a way as to test relationships between one or more different time series, this type of analysis is not usually called ""time series analysis"", which refers in particular to relationships between different points in time within a single series.
Time series data have a natural temporal ordering. This make",Technology & Computing 
"Machine learning
Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions.[1] Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.[2]
ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine.[3][4] The application of ML to business problems is known as predictive analytics.
Statistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.[6][7]
From a theoretical viewpoint, probably approximately correct learning provides a framework for describing machine learning.
History
[edit]The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym self-teaching computers was also used in this time period.[10][11]
The earliest machine learning program was introduced in the 1950s when Arthur Samuel invented a computer program that calculated the winning chance in checkers",Technology & Computing 
"Supervised learning
In machine learning, supervised learning (SL) is a paradigm where a model is trained using input objects (e.g. a vector of predictor variables) and desired output values (also known as a supervisory signal), which are often human-made labels. The training process builds a function that maps new data to expected output values.[1] An optimal scenario will allow for the algorithm to accurately determine output values for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a reasonable way (see inductive bias). This statistical quality of an algorithm is measured via a generalization error.
Steps to follow
[edit]To solve a given problem of supervised learning, the following steps must be performed:
- Determine the type of training samples. Before doing anything else, the user should decide what kind of data is to be used as a training set. In the case of handwriting analysis, for example, this might be a single handwritten character, an entire handwritten word, an entire sentence of handwriting, or a full paragraph of handwriting.
- Gather a training set. The training set needs to be representative of the real-world use of the function. Thus, a set of input objects is gathered together with corresponding outputs, either from human experts or from measurements.
- Determine the input feature representation of the learned function. The accuracy of the learned function depends strongly on how the inpu",Technology & Computing 
"Unsupervised learning
Unsupervised learning is a framework in machine learning where, in contrast to supervised learning, algorithms learn patterns exclusively from unlabeled data.[1] Other frameworks in the spectrum of supervisions include weak- or semi-supervision, where a small portion of the data is tagged, and self-supervision. Some researchers consider self-supervised learning a form of unsupervised learning.[2]
Conceptually, unsupervised learning divides into the aspects of data, training, algorithm, and downstream applications. Typically, the dataset is harvested cheaply ""in the wild"", such as massive text corpus obtained by web crawling, with only minor filtering (such as Common Crawl). This compares favorably to supervised learning, where the dataset (such as the ImageNet1000) is typically constructed manually, which is much more expensive.
There were algorithms designed specifically for unsupervised learning, such as clustering algorithms like k-means, dimensionality reduction techniques like principal component analysis (PCA), Boltzmann machine learning, and autoencoders. After the rise of deep learning, most large-scale unsupervised learning have been done by training general-purpose neural network architectures by gradient descent, adapted to performing unsupervised learning by designing an appropriate training procedure.
Sometimes a trained model can be used as-is, but more often they are modified for downstream applications. For example, the generative pretrai",Technology & Computing 
"Reinforcement learning
Reinforcement learning (RL) is an interdisciplinary area of machine learning and optimal control concerned with how an intelligent agent should take actions in a dynamic environment in order to maximize a reward signal. Reinforcement learning is one of the three basic machine learning paradigms, alongside supervised learning and unsupervised learning.
Reinforcement learning differs from supervised learning in not needing labelled input-output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead, the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge) with the goal of maximizing the cumulative reward (the feedback of which might be incomplete or delayed).[1] The search for this balance is known as the exploration–exploitation dilemma.
The environment is typically stated in the form of a Markov decision process (MDP), as many reinforcement learning algorithms use dynamic programming techniques.[2] The main difference between classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the Markov decision process, and they target large MDPs where exact methods become infeasible.[3]
Principles
[edit]Due to its generality, reinforcement learning is studied in many disciplines, such as game theory, control theory, operations research, information theory, simulati",Technology & Computing 
"Deep learning
In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and ""training"" them to process data. The adjective ""deep"" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.[2]
Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.[3][4][5]
Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.[6]
Overview
[edit]Most modern deep learning mod",Technology & Computing 
"Neural network
A neural network is a group of interconnected units called neurons that send signals to one another. Neurons can be either biological cells or signal pathways. While individual neurons are simple, many of them together in a network can perform complex tasks. There are two main types of neural networks.
- In neuroscience, a biological neural network is a physical structure found in brains and complex nervous systems – a population of nerve cells connected by synapses.
- In machine learning, an artificial neural network is a mathematical model used to approximate nonlinear functions. Artificial neural networks are used to solve artificial intelligence problems.
In biology
[edit]In the context of biology, a neural network is a population of biological neurons chemically connected to each other by synapses. A given neuron can be connected to hundreds of thousands of synapses.[1] Each neuron sends and receives electrochemical signals called action potentials to its connected neighbors. A neuron can serve an excitatory role, amplifying and propagating signals it receives, or an inhibitory role, suppressing signals instead.[1]
Populations of interconnected neurons that are smaller than neural networks are called neural circuits. Very large interconnected networks are called large scale brain networks, and many of these together form brains and nervous systems.
Signals generated by neural networks in the brain eventually travel through the nervous system and across neu",Technology & Computing 
"Convolutional neural network
A convolutional neural network (CNN) is a type of feedforward neural network that learns features via filter (or kernel) optimization. This type of deep learning network has been applied to process and make predictions from many different types of data including text, images and audio.[1] Convolution-based networks are the de-facto standard in deep learning-based approaches to computer vision[2] and image processing, and have only recently been replaced—in some cases—by newer deep learning architectures such as the transformer.
Vanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by the regularization that comes from using shared weights over fewer connections.[3][4] For example, for each neuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 × 100 pixels. However, applying cascaded convolution (or cross-correlation) kernels,[5][6] only 25 weights for each convolutional layer are required to process 5x5-sized tiles.[7][8] Higher-layer features are extracted from wider context windows, compared to lower-layer features.
Some applications of CNNs include:
- image and video recognition,[9]
- recommender systems,[10]
- image classification,
- image segmentation,
- medical image analysis,
- natural language processing,[11]
- brain–computer interfaces,[12] and
- financial time series.[13]
CNNs are also known as shift invariant or space invariant",Technology & Computing 
"Recurrent neural network
In artificial neural networks, recurrent neural networks (RNNs) are designed for processing sequential data, such as text, speech, and time series,[1] where the order of elements is important. Unlike feedforward neural networks, which process inputs independently, RNNs utilize recurrent connections, where the output of a neuron at one time step is fed back as input to the network at the next time step. This enables RNNs to capture temporal dependencies and patterns within sequences.
The fundamental building block of RNN is the recurrent unit, which maintains a hidden state—a form of memory that is updated at each time step based on the current input and the previous hidden state. This feedback mechanism allows the network to learn from past inputs and incorporate that knowledge into its current processing. RNNs have been successfully applied to tasks such as unsegmented, connected handwriting recognition,[2] speech recognition,[3][4] natural language processing, and neural machine translation.[5][6]
However, traditional RNNs suffer from the vanishing gradient problem, which limits their ability to learn long-range dependencies. This issue was addressed by the development of the long short-term memory (LSTM) architecture in 1997, making it the standard RNN variant for handling long-term dependencies. Later, gated recurrent units (GRUs) were introduced as a more computationally efficient alternative.
In recent years, transformers, which rely on self-att",Technology & Computing 
"Autoencoder
An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). An autoencoder learns two functions: an encoding function that transforms the input data, and a decoding function that recreates the input data from the encoded representation. The autoencoder learns an efficient representation (encoding) for a set of data, typically for dimensionality reduction, to generate lower-dimensional embeddings for subsequent use by other machine learning algorithms.[1]
Variants exist which aim to make the learned representations assume useful properties.[2] Examples are regularized autoencoders (sparse, denoising and contractive autoencoders), which are effective in learning representations for subsequent classification tasks,[3] and variational autoencoders, which can be used as generative models.[4] Autoencoders are applied to many problems, including facial recognition,[5] feature detection,[6] anomaly detection, and learning the meaning of words.[7][8] In terms of data synthesis, autoencoders can also be used to randomly generate new data that is similar to the input (training) data.[6]
Mathematical principles
[edit]Definition
[edit]An autoencoder is defined by the following components:
Two sets: the space of decoded messages ; the space of encoded messages . Typically and are Euclidean spaces, that is, with
Two parametrized families of functions: the encoder family , parametrized by ; the decoder family , ",Technology & Computing 
"Variational autoencoder
In machine learning, a variational autoencoder (VAE) is an artificial neural network architecture introduced by Diederik P. Kingma and Max Welling.[1] It is part of the families of probabilistic graphical models and variational Bayesian methods.[2]
In addition to being seen as an autoencoder neural network architecture, variational autoencoders can also be studied within the mathematical formulation of variational Bayesian methods, connecting a neural encoder network to its decoder through a probabilistic latent space (for example, as a multivariate Gaussian distribution) that corresponds to the parameters of a variational distribution.
Thus, the encoder maps each point (such as an image) from a large complex dataset into a distribution within the latent space, rather than to a single point in that space. The decoder has the opposite function, which is to map from the latent space to the input space, again according to a distribution (although in practice, noise is rarely added during the decoding stage). By mapping a point to a distribution instead of a single point, the network can avoid overfitting the training data. Both networks are typically trained together with the usage of the reparameterization trick, although the variance of the noise model can be learned separately.[citation needed]
Although this type of model was initially designed for unsupervised learning,[3][4] its effectiveness has been proven for semi-supervised learning[5][6] and sup",Technology & Computing 
"Graph neural network
Graph neural networks (GNN) are specialized artificial neural networks that are designed for tasks whose inputs are graphs.[1][2][3][4][5]
One prominent example is molecular drug design.[6][7][8] Each input sample is a graph representation of a molecule, where atoms form the nodes and chemical bonds between atoms form the edges. In addition to the graph representation, the input also includes known chemical properties for each of the atoms. Dataset samples may thus differ in length, reflecting the varying numbers of atoms in molecules, and the varying number of bonds between them. The task is to predict the efficacy of a given molecule for a specific medical application, like eliminating E. coli bacteria.
The key design element of GNNs is the use of pairwise message passing, such that graph nodes iteratively update their representations by exchanging information with their neighbors. Several GNN architectures have been proposed,[2][3][9][10][11] which implement different flavors of message passing,[12][13] started by recursive[2] or convolutional constructive[3] approaches. As of 2022[update], it is an open question whether it is possible to define GNN architectures ""going beyond"" message passing, or instead every GNN can be built on message passing over suitably defined graphs.[14]
In the more general subject of ""geometric deep learning"", certain existing neural network architectures can be interpreted as GNNs operating on suitably defined graphs.[12] A ",Technology & Computing 
"Meta-learning
Meta-learning is a branch of metacognition concerned with learning about one's own learning and learning processes.
The term comes from the meta prefix's modern meaning of an abstract recursion, or ""X about X"", similar to its use in metaknowledge, metamemory, and meta-emotion.
Meta learning model for teams and relationships
[edit]Marcial Losada and other researchers have attempted to create a meta learning model to analyze teams and relationships.[1] A 2013 paper provided a strong critique[2] of this attempt, arguing that it was based on misapplication of complex mathematical modelling. This led to its abandonment by at least one former proponent.[3]
The meta learning model proposed by Losada is identical to the Lorenz system, which was originally proposed as a simplified mathematical model for atmospheric convection. It comprises one control parameter and three state variables, which in this case have been mapped to ""connectivity"", ""inquiry-advocacy"", ""positivity-negativity"", and ""other-self"" (external-internal focus) respectively. The state variables are linked by a set of nonlinear differential equations.[4] This has been criticized as a poorly defined, poorly justified, and invalid application of differential equations.[2]
Losada and colleagues claim to have arrived at the meta learning model from thousands of time series data generated at two human interaction laboratories in Ann Arbor, Michigan, and Cambridge, Massachusetts,[1] although the details of the ",Technology & Computing 
"Jump to content
Main menu
Main menu
move to sidebar
hide
Navigation
Main page
Contents
Current events
Random article
About Wikipedia
Contact us
Contribute
Help
Learn to edit
Community portal
Recent changes
Upload file
Special pages
Search
Search
Appearance
Donate
Create account
Log in
Personal tools
Donate
Create account
Log in
Pages for logged out editors
learn more
Contributions
Talk
Few-shot learning
1 language
한국어
Edit links
Article
Talk
English
Read
Edit
View history
Tools
Tools
move to sidebar
hide
Actions
Read
Edit
View history
General
What links here
Related changes
Upload file
Permanent link
Page information
Cite this page
Get shortened URL
Download QR code
Print/export
Download as PDF
Printable version
In other projects
Wikidata item
Appearance
move to sidebar
hide
From Wikipedia, the free encyclopedia
Few-shot learning
and
one-shot learning
may refer to:
Few-shot learning, a form of
prompt engineering
in generative AI
One-shot learning (computer vision)
Topics referred to by the same term
This
disambiguation
page lists articles associated with the title
Few-shot learning
.
If an
internal link
led you here, you may wish to change the link to point directly to the intended article.
Category
:
Disambiguation pages
Hidden categories:
Short description is different from Wikidata
All article disambiguation pages
All disambiguation pages
Search
Search
Few-shot learning
1 language
Add topic",Technology & Computing 
"Zero-shot learning
Zero-shot learning (ZSL) is a problem setup in deep learning where, at test time, a learner observes samples from classes which were not observed during training, and needs to predict the class that they belong to. The name is a play on words based on the earlier concept of one-shot learning, in which classification can be learned from only one, or a few, examples.
Zero-shot methods generally work by associating observed and non-observed classes through some form of auxiliary information, which encodes observable distinguishing properties of objects.[1] For example, given a set of images of animals to be classified, along with auxiliary textual descriptions of what animals look like, an artificial intelligence model which has been trained to recognize horses, but has never been given a zebra, can still recognize a zebra when it also knows that zebras look like striped horses. This problem is widely studied in computer vision, natural language processing, and machine perception.[2]
Background and history
[edit]The first paper on zero-shot learning in natural language processing appeared in a 2008 paper by Chang, Ratinov, Roth, and Srikumar, at the AAAI’08, but the name given to the learning paradigm there was dataless classification.[3] The first paper on zero-shot learning in computer vision appeared at the same conference, under the name zero-data learning.[4] The term zero-shot learning itself first appeared in the literature in a 2009 paper from Palatucc",Technology & Computing 
"Transfer learning
Transfer learning (TL) is a technique in machine learning (ML) in which knowledge learned from a task is re-used in order to boost performance on a related task.[1] For example, for image classification, knowledge gained while learning to recognize cars could be applied when trying to recognize trucks. This topic is related to the psychological literature on transfer of learning, although practical ties between the two fields are limited. Reusing/transferring information from previously learned tasks to new tasks has the potential to significantly improve learning efficiency.[2]
Since transfer learning makes use of training with multiple objective functions it is related to cost-sensitive machine learning and multi-objective optimization.[3]
History
[edit]In 1976, Bozinovski and Fulgosi published a paper addressing transfer learning in neural network training.[4][5] The paper gives a mathematical and geometrical model of the topic. In 1981, a report considered the application of transfer learning to a dataset of images representing letters of computer terminals, experimentally demonstrating positive and negative transfer learning.[6]
In 1992, Lorien Pratt formulated the discriminability-based transfer (DBT) algorithm.[7]
By 1998, the field had advanced to include multi-task learning,[8] along with more formal theoretical foundations.[9] Influential publications on transfer learning include the book Learning to Learn in 1998,[10] a 2009 survey[11] and a 2019 ",Technology & Computing 
"Federated learning
Federated learning (also known as collaborative learning) is a machine learning technique in a setting where multiple entities (often called clients) collaboratively train a model while keeping their data decentralized,[1] rather than centrally stored. A defining characteristic of federated learning is data heterogeneity. Because client data is decentralized, data samples held by each client may not be independently and identically distributed.
Federated learning is generally concerned with and motivated by issues such as data privacy, data minimization, and data access rights. Its applications involve a variety of research areas including defence, telecommunications, the Internet of things, and pharmaceuticals.
Definition
[edit]Federated learning aims at training a machine learning algorithm, for instance deep neural networks, on multiple local datasets contained in local nodes without explicitly exchanging data samples. The general principle consists in training local models on local data samples and exchanging parameters (e.g. the weights and biases of a deep neural network) between these local nodes at some frequency to generate a global model shared by all nodes.
The main difference between federated learning and distributed learning lies in the assumptions made on the properties of the local datasets,[2] as distributed learning originally aims at parallelizing computing power where federated learning originally aims at training on heterogeneous datase",Technology & Computing 
"Jump to content
Main menu
Main menu
move to sidebar
hide
Navigation
Main page
Contents
Current events
Random article
About Wikipedia
Contact us
Contribute
Help
Learn to edit
Community portal
Recent changes
Upload file
Special pages
Search
Search
Appearance
Donate
Create account
Log in
Personal tools
Donate
Create account
Log in
Pages for logged out editors
learn more
Contributions
Talk
Online learning
Add languages
Add links
Article
Talk
English
Read
Edit
View history
Tools
Tools
move to sidebar
hide
Actions
Read
Edit
View history
General
What links here
Related changes
Upload file
Permanent link
Page information
Cite this page
Get shortened URL
Download QR code
Print/export
Download as PDF
Printable version
In other projects
Wikidata item
Appearance
move to sidebar
hide
From Wikipedia, the free encyclopedia
Online learning
may refer to study in home
Educational technology
, or e-learning
E-learning (theory)
List of online educational resources
Distance education
Online school
Online learning in higher education
Online tutoring
Massive open online courses
Online machine learning
, in computer science and statistics
Topics referred to by the same term
This
disambiguation
page lists articles associated with the title
Online learning
.
If an
internal link
led you here, you may wish to change the link to point directly to the intended article.
Category
:
Disambiguation pages
Hidden categories:
Short description is different from Wikidata
All article disambiguation pages
All disam",Technology & Computing 
"Online machine learning
In computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once. Online learning is a common technique used in areas of machine learning where it is computationally infeasible to train over the entire dataset, requiring the need of out-of-core algorithms. It is also used in situations where it is necessary for the algorithm to dynamically adapt to new patterns in the data, or when the data itself is generated as a function of time, e.g., prediction of prices in the financial international markets. Online learning algorithms may be prone to catastrophic interference, a problem that can be addressed by incremental learning approaches.
Introduction
[edit]In the setting of supervised learning, a function of is to be learned, where is thought of as a space of inputs and as a space of outputs, that predicts well on instances that are drawn from a joint probability distribution on . In reality, the learner never knows the true distribution over instances. Instead, the learner usually has access to a training set of examples . In this setting, the loss function is given as , such that measures the difference between the predicted value and the true value . The ideal goal is to select a function , wher",Technology & Computing 
"Weak supervision
Weak supervision (also known as semi-supervised learning) is a paradigm in machine learning, the relevance and notability of which increased with the advent of large language models due to large amount of data required to train them. It is characterized by using a combination of a small amount of human-labeled data (exclusively used in more expensive and time-consuming supervised learning paradigm), followed by a large amount of unlabeled data (used exclusively in unsupervised learning paradigm). In other words, the desired output values are provided only for a subset of the training data. The remaining data is unlabeled or imprecisely labeled. Intuitively, it can be seen as an exam and labeled data as sample problems that the teacher solves for the class as an aid in solving another set of problems. In the transductive setting, these unsolved problems act as exam questions. In the inductive setting, they become practice problems of the sort that will make up the exam.
Problem
[edit]The acquisition of labeled data for a learning problem often requires a skilled human agent (e.g. to transcribe an audio segment) or a physical experiment (e.g. determining the 3D structure of a protein or determining whether there is oil at a particular location). The cost associated with the labeling process thus may render large, fully labeled training sets infeasible, whereas acquisition of unlabeled data is relatively inexpensive. In such situations, semi-supervised learning ",Technology & Computing 
"Self-supervised learning
Self-supervised learning (SSL) is a paradigm in machine learning where a model is trained on a task using the data itself to generate supervisory signals, rather than relying on externally-provided labels. In the context of neural networks, self-supervised learning aims to leverage inherent structures or relationships within the input data to create meaningful training signals. SSL tasks are designed so that solving them requires capturing essential features or relationships in the data. The input data is typically augmented or transformed in a way that creates pairs of related samples, where one sample serves as the input, and the other is used to formulate the supervisory signal. This augmentation can involve introducing noise, cropping, rotation, or other transformations. Self-supervised learning more closely imitates the way humans learn to classify objects.[1]
During SSL, the model learns in two steps. First, the task is solved based on an auxiliary or pretext classification task using pseudo-labels, which help to initialize the model parameters.[2][3] Next, the actual task is performed with supervised or unsupervised learning.[4][5][6]
Self-supervised learning has produced promising results in recent years, and has found practical application in fields such as audio processing, and is being used by Facebook and others for speech recognition.[7]
Types
[edit]Autoassociative self-supervised learning
[edit]Autoassociative self-supervised learning is",Technology & Computing 
"Multi-task learning
Multi-task learning (MTL) is a subfield of machine learning in which multiple learning tasks are solved at the same time, while exploiting commonalities and differences across tasks. This can result in improved learning efficiency and prediction accuracy for the task-specific models, when compared to training the models separately.[1][2][3] Inherently, Multi-task learning is a multi-objective optimization problem having trade-offs between different tasks.[4] Early versions of MTL were called ""hints"".[5][6]
In a widely cited 1997 paper, Rich Caruana gave the following characterization:
Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better.[3]
In the classification context, MTL aims to improve the performance of multiple classification tasks by learning them jointly. One example is a spam-filter, which can be treated as distinct but related classification tasks across different users. To make this more concrete, consider that different people have different distributions of features which distinguish spam emails from legitimate ones, for example an English speaker may find that all emails in Russian are spam, not so for Russian speakers. Yet there is a definite commonality in th",Technology & Computing 
"Ensemble learning
In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.[1][2][3] Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.
Overview
[edit]Supervised learning algorithms search through a hypothesis space to find a suitable hypothesis that will make good predictions with a particular problem.[4] Even if this space contains hypotheses that are very well-suited for a particular problem, it may be very difficult to find a good one. Ensembles combine multiple hypotheses to form one which should be theoretically better.
Ensemble learning trains two or more machine learning algorithms on a specific classification or regression task. The algorithms within the ensemble model are generally referred as ""base models"", ""base learners"", or ""weak learners"" in literature. These base models can be constructed using a single modelling algorithm, or several different algorithms. The idea is to train a diverse set of weak models on the same modelling task, such that the outputs of each weak learner have poor predictive ability (i.e., high bias), and among all weak learners, the outcome and error values exhibit high variance. Fundamen",Technology & Computing 
"Random forest
Random forests or random decision forests is an ensemble learning method for classification, regression and other tasks that works by creating a multitude of decision trees during training. For classification tasks, the output of the random forest is the class selected by most trees. For regression tasks, the output is the average of the predictions of the trees.[1][2] Random forests correct for decision trees' habit of overfitting to their training set.[3]: 587–588
The first algorithm for random decision forests was created in 1995 by Tin Kam Ho[1] using the random subspace method,[2] which, in Ho's formulation, is a way to implement the ""stochastic discrimination"" approach to classification proposed by Eugene Kleinberg.[4][5][6]
An extension of the algorithm was developed by Leo Breiman[7] and Adele Cutler,[8] who registered[9] ""Random Forests"" as a trademark in 2006 (as of 2019[update], owned by Minitab, Inc.).[10] The extension combines Breiman's ""bagging"" idea and random selection of features, introduced first by Ho[1] and later independently by Amit and Geman[11] in order to construct a collection of decision trees with controlled variance.
History
[edit]The general method of random decision forests was first proposed by Salzberg and Heath in 1993,[12] with a method that used a randomized decision tree algorithm to create multiple trees and then combine them using majority voting. This idea was developed further by Ho in 1995.[1] Ho established that forest",Technology & Computing 
"Gradient boosting
Gradient boosting is a machine learning technique based on boosting in a functional space, where the target is pseudo-residuals instead of residuals as in traditional boosting. It gives a prediction model in the form of an ensemble of weak prediction models, i.e., models that make very few assumptions about the data, which are typically simple decision trees.[1][2] When a decision tree is the weak learner, the resulting algorithm is called gradient-boosted trees; it usually outperforms random forest.[1] As with other boosting methods, a gradient-boosted trees model is built in stages, but it generalizes the other methods by allowing optimization of an arbitrary differentiable loss function.
History
[edit]The idea of gradient boosting originated in the observation by Leo Breiman that boosting can be interpreted as an optimization algorithm on a suitable cost function.[3] Explicit regression gradient boosting algorithms were subsequently developed, by Jerome H. Friedman,[4][2] (in 1999 and later in 2001) simultaneously with the more general functional gradient boosting perspective of Llew Mason, Jonathan Baxter, Peter Bartlett and Marcus Frean.[5][6] The latter two papers introduced the view of boosting algorithms as iterative functional gradient descent algorithms. That is, algorithms that optimize a cost function over function space by iteratively choosing a function (weak hypothesis) that points in the negative gradient direction. This functional gradient v",Technology & Computing 
"XGBoost
XGBoost[2] (eXtreme Gradient Boosting) is an open-source software library which provides a regularizing gradient boosting framework for C++, Java, Python,[3] R,[4] Julia,[5] Perl,[6] and Scala. It works on Linux, Microsoft Windows,[7] and macOS.[8] From the project description, it aims to provide a ""Scalable, Portable and Distributed Gradient Boosting (GBM, GBRT, GBDT) Library"". It runs on a single machine, as well as the distributed processing frameworks Apache Hadoop, Apache Spark, Apache Flink, and Dask.[9][10]
XGBoost gained much popularity and attention in the mid-2010s as the algorithm of choice for many winning teams of machine learning competitions.[11]
History
[edit]XGBoost initially started as a research project by Tianqi Chen[12] as part of the Distributed (Deep) Machine Learning Community (DMLC) group at the University of Washington. Initially, it began as a terminal application which could be configured using a libsvm configuration file. It became well known in the ML competition circles after its use in the winning solution of the Higgs Machine Learning Challenge. Soon after, the Python and R packages were built, and XGBoost now has package implementations for Java, Scala, Julia, Perl, and other languages. This brought the library to more developers and contributed to its popularity among the Kaggle community, where it has been used for a large number of competitions.[11]
It was soon integrated with a number of other packages making it easier to use in t",Technology & Computing 
"LightGBM
LightGBM, short for Light Gradient-Boosting Machine, is a free and open-source distributed gradient-boosting framework for machine learning, originally developed by Microsoft.[4][5] It is based on decision tree algorithms and used for ranking, classification and other machine learning tasks. The development focus is on performance and scalability.
Overview
[edit]The LightGBM framework supports different algorithms including GBT, GBDT, GBRT, GBM, MART[6][7] and RF.[8] LightGBM has many of XGBoost's advantages, including sparse optimization, parallel training, multiple loss functions, regularization, bagging, and early stopping. A major difference between the two lies in the construction of trees. LightGBM does not grow a tree level-wise — row by row — as most other implementations do.[9] Instead it grows trees leaf-wise. It will choose the leaf with max delta loss to grow. [10] Besides, LightGBM does not use the widely used sorted-based decision tree learning algorithm, which searches the best split point on sorted feature values,[11] as XGBoost or other implementations do. Instead, LightGBM implements a highly optimized histogram-based decision tree learning algorithm, which yields great advantages on both efficiency and memory consumption.[12] The LightGBM algorithm utilizes two novel techniques called Gradient-Based One-Side Sampling (GOSS) and Exclusive Feature Bundling (EFB) which allow the algorithm to run faster while maintaining a high level of accuracy.[13]
L",Technology & Computing 
"CatBoost
CatBoost[6] is an open-source software library developed by Yandex. It provides a gradient boosting framework which, among other features, attempts to solve for categorical features using a permutation-driven alternative to the classical algorithm.[7] It works on Linux, Windows, macOS, and is available in Python,[8] R,[9] and models built using CatBoost can be used for predictions in C++, Java,[10] C#, Rust, Core ML, ONNX, and PMML. The source code is licensed under Apache License and available on GitHub.[6]
InfoWorld magazine awarded the library ""The best machine learning tools"" in 2017.[11] along with TensorFlow, Pytorch, XGBoost and 8 other libraries.
Kaggle listed CatBoost as one of the most frequently used machine learning (ML) frameworks in the world. It was listed as the top-8 most frequently used ML framework in the 2020 survey[12] and as the top-7 most frequently used ML framework in the 2021 survey.[13]
As of April 2022, CatBoost is installed about 100000 times per day from PyPI repository[14]
Features
[edit]CatBoost has gained popularity compared to other gradient boosting algorithms primarily due to the following features[15]
- Native handling for categorical features[16]
- Fast GPU training[17]
- Visualizations and tools for model and feature analysis
- Using oblivious trees or symmetric trees for faster execution
- Ordered boosting to overcome overfitting[7]
History
[edit]In 2009 Andrey Gulin developed MatrixNet, a proprietary gradient boosting library ",Technology & Computing 
"Support vector machine
In machine learning, support vector machines (SVMs, also support vector networks[1]) are supervised max-margin models with associated learning algorithms that analyze data for classification and regression analysis. Developed at AT&T Bell Laboratories,[1][2] SVMs are one of the most studied models, being based on statistical learning frameworks of VC theory proposed by Vapnik (1982, 1995) and Chervonenkis (1974).
In addition to performing linear classification, SVMs can efficiently perform non-linear classification using the kernel trick, representing the data only through a set of pairwise similarity comparisons between the original data points using a kernel function, which transforms them into coordinates in a higher-dimensional feature space. Thus, SVMs use the kernel trick to implicitly map their inputs into high-dimensional feature spaces, where linear classification can be performed.[3] Being max-margin models, SVMs are resilient to noisy data (e.g., misclassified examples). SVMs can also be used for regression tasks, where the objective becomes -sensitive.
The support vector clustering[4] algorithm, created by Hava Siegelmann and Vladimir Vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data.[citation needed] These data sets require unsupervised learning approaches, which attempt to find natural clustering of the data into groups, and then to map new data according to ",Technology & Computing 
"k-nearest neighbors algorithm
In statistics, the k-nearest neighbors algorithm (k-NN) is a non-parametric supervised learning method. It was first developed by Evelyn Fix and Joseph Hodges in 1951,[1] and later expanded by Thomas Cover.[2] Most often, it is used for classification, as a k-NN classifier, the output of which is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.
The k-NN algorithm can also be generalized for regression. In k-NN regression, also known as nearest neighbor smoothing, the output is the property value for the object. This value is the average of the values of k nearest neighbors. If k = 1, then the output is simply assigned to the value of that single nearest neighbor, also known as nearest neighbor interpolation.
For both classification and regression, a useful technique can be to assign weights to the contributions of the neighbors, so that nearer neighbors contribute more to the average than distant ones. For example, a common weighting scheme consists of giving each neighbor a weight of 1/d, where d is the distance to the neighbor.[3]
The input consists of the k closest training examples in a data set. The neighbors are taken from a set of objects for which the class (for k-NN classification) or the",Technology & Computing 
"Naive Bayes classifier
In statistics, naive (sometimes simple or idiot's) Bayes classifiers are a family of ""probabilistic classifiers"" which assumes that the features are conditionally independent, given the target class.[1] In other words, a naive Bayes model assumes the information about the class provided by each variable is unrelated to the information from the others, with no information shared between the predictors. The highly unrealistic nature of this assumption, called the naive independence assumption, is what gives the classifier its name. These classifiers are some of the simplest Bayesian network models.[2]
Naive Bayes classifiers generally perform worse than more advanced models like logistic regressions, especially at quantifying uncertainty (with naive Bayes models often producing wildly overconfident probabilities). However, they are highly scalable, requiring only one parameter for each feature or predictor in a learning problem. Maximum-likelihood training can be done by evaluating a closed-form expression (simply by counting observations in each group),[3]: 718 rather than the expensive iterative approximation algorithms required by most other models.
Despite the use of Bayes' theorem in the classifier's decision rule, naive Bayes is not (necessarily) a Bayesian method, and naive Bayes models can be fit to data using either Bayesian or frequentist methods.[1][3]
Introduction
[edit]Naive Bayes is a simple technique for constructing classifiers: models tha",Technology & Computing 
"Logistic regression
In statistics, a logistic model (or logit model) is a statistical model that models the log-odds of an event as a linear combination of one or more independent variables. In regression analysis, logistic regression[1] (or logit regression) estimates the parameters of a logistic model (the coefficients in the linear or non linear combinations). In binary logistic regression there is a single binary dependent variable, coded by an indicator variable, where the two values are labeled ""0"" and ""1"", while the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value). The corresponding probability of the value labeled ""1"" can vary between 0 (certainly the value ""0"") and 1 (certainly the value ""1""), hence the labeling;[2] the function that converts log-odds to probability is the logistic function, hence the name. The unit of measurement for the log-odds scale is called a logit, from logistic unit, hence the alternative names. See § Background and § Definition for formal mathematics, and § Example for a worked example.
Binary variables are widely used in statistics to model the probability of a certain class or event taking place, such as the probability of a team winning, of a patient being healthy, etc. (see § Applications), and the logistic model has been the most commonly used model for binary regression since about 1970.[3] Binary variables can be generalized to categorical varia",Technology & Computing 
"Linear regression
In statistics, linear regression is a model that estimates the relationship between a scalar response (dependent variable) and one or more explanatory variables (regressor or independent variable). A model with exactly one explanatory variable is a simple linear regression; a model with two or more explanatory variables is a multiple linear regression.[1] This term is distinct from multivariate linear regression, which predicts multiple correlated dependent variables rather than a single dependent variable.[2]
In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Most commonly, the conditional mean of the response given the values of the explanatory variables (or predictors) is assumed to be an affine function of those values; less commonly, the conditional median or some other quantile is used. Like all forms of regression analysis, linear regression focuses on the conditional probability distribution of the response given the values of the predictors, rather than on the joint probability distribution of all of these variables, which is the domain of multivariate analysis.
Linear regression is also a type of machine learning algorithm, more specifically a supervised algorithm, that learns from the labelled datasets and maps the data points to the most optimized linear functions that can be used for prediction on new datasets.[3]
Linear regression was the first type of",Technology & Computing 
"Decision tree
A decision tree is a decision support recursive partitioning structure that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.
Decision trees are commonly used in operations research, specifically in decision analysis,[1] to help identify a strategy most likely to reach a goal, but are also a popular tool in machine learning.
Overview
[edit]A decision tree is a flowchart-like structure in which each internal node represents a test on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.
In decision analysis, a decision tree and the closely related influence diagram are used as a visual and analytical decision support tool, where the expected values (or expected utility) of competing alternatives are calculated.
A decision tree consists of three types of nodes:[2]
- Decision nodes – typically represented by squares
- Chance nodes – typically represented by circles
- End nodes – typically represented by triangles
Decision trees are commonly used in operations research and operations management. If, in practice, decisions have to be taken online with no recall under incomplete knowledge, a d",Technology & Computing 
"k-means clustering
k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells. k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances. For instance, better Euclidean solutions can be found using k-medians and k-medoids.
The problem is computationally difficult (NP-hard); however, efficient heuristic algorithms converge quickly to a local optimum. These are usually similar to the expectation–maximization algorithm for mixtures of Gaussian distributions via an iterative refinement approach employed by both k-means and Gaussian mixture modeling. They both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the Gaussian mixture model allows clusters to have different shapes.
The unsupervised k-means algorithm has a loose relationship to the k-nearest neighbor classifier, a popular supervised machine learning technique for classification that is often confused with k-means due to the name. Applying th",Technology & Computing 
"DBSCAN
Density-based spatial clustering of applications with noise (DBSCAN) is a data clustering algorithm proposed by Martin Ester, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu in 1996.[1] It is a density-based clustering non-parametric algorithm: given a set of points in some space, it groups together points that are closely packed (points with many nearby neighbors), and marks as outliers points that lie alone in low-density regions (those whose nearest neighbors are too far away). DBSCAN is one of the most commonly used and cited clustering algorithms.[2]
In 2014, the algorithm was awarded the Test of Time Award (an award given to algorithms which have received substantial attention in theory and practice) at the leading data mining conference, ACM SIGKDD.[3] As of July 2020[update], the follow-up paper ""DBSCAN Revisited, Revisited: Why and How You Should (Still) Use DBSCAN""[4] appears in the list of the 8 most downloaded articles of the prestigious ACM Transactions on Database Systems (TODS) journal.[5]
Another follow-up, HDBSCAN*, was initially published by Ricardo J. G. Campello, David Moulavi, and Jörg Sander in 2013,[6] then expanded upon with Arthur Zimek in 2015.[7] It revises some of the original decisions such as the border points, and produces a hierarchical instead of a flat result.
History
[edit]In 1972, Robert F. Ling published a closely related algorithm in ""The Theory and Construction of k-Clusters""[8] in The Computer Journal with an estimated runtime co",Technology & Computing 
"Hierarchical clustering
In data mining and statistics, hierarchical clustering[1] (also called hierarchical cluster analysis or HCA) is a method of cluster analysis that seeks to build a hierarchy of clusters. Strategies for hierarchical clustering generally fall into two categories:
- Agglomerative: Agglomerative: Agglomerative clustering, often referred to as a ""bottom-up"" approach, begins with each data point as an individual cluster. At each step, the algorithm merges the two most similar clusters based on a chosen distance metric (e.g., Euclidean distance) and linkage criterion (e.g., single-linkage, complete-linkage)[2]. This process continues until all data points are combined into a single cluster or a stopping criterion is met. Agglomerative methods are more commonly used due to their simplicity and computational efficiency for small to medium-sized datasets [3].
- Divisive: Divisive clustering, known as a ""top-down"" approach, starts with all data points in a single cluster and recursively splits the cluster into smaller ones. At each step, the algorithm selects a cluster and divides it into two or more subsets, often using a criterion such as maximizing the distance between resulting clusters. Divisive methods are less common but can be useful when the goal is to identify large, distinct clusters first.
In general, the merges and splits are determined in a greedy manner. The results of hierarchical clustering[1] are usually presented in a dendrogram.
Hierarchical cl",Technology & Computing 
"Principal component analysis
Principal component analysis (PCA) is a linear dimensionality reduction technique with applications in exploratory data analysis, visualization and data preprocessing.
The data is linearly transformed onto a new coordinate system such that the directions (principal components) capturing the largest variation in the data can be easily identified.
The principal components of a collection of points in a real coordinate space are a sequence of unit vectors, where the -th vector is the direction of a line that best fits the data while being orthogonal to the first vectors. Here, a best-fitting line is defined as one that minimizes the average squared perpendicular distance from the points to the line. These directions (i.e., principal components) constitute an orthonormal basis in which different individual dimensions of the data are linearly uncorrelated. Many studies use the first two principal components in order to plot the data in two dimensions and to visually identify clusters of closely related data points.[1]
Principal component analysis has applications in many fields such as population genetics, microbiome studies, and atmospheric science.[2]
Overview
[edit]When performing PCA, the first principal component of a set of variables is the derived variable formed as a linear combination of the original variables that explains the most variance. The second principal component explains the most variance in what is left once the effect of the first",Technology & Computing 
"t-distributed stochastic neighbor embedding
t-distributed stochastic neighbor embedding (t-SNE) is a statistical method for visualizing high-dimensional data by giving each datapoint a location in a two or three-dimensional map. It is based on Stochastic Neighbor Embedding originally developed by Geoffrey Hinton and Sam Roweis,[1] where Laurens van der Maaten and Hinton proposed the t-distributed variant.[2] It is a nonlinear dimensionality reduction technique for embedding high-dimensional data for visualization in a low-dimensional space of two or three dimensions. Specifically, it models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points with high probability.
The t-SNE algorithm comprises two main stages. First, t-SNE constructs a probability distribution over pairs of high-dimensional objects in such a way that similar objects are assigned a higher probability while dissimilar points are assigned a lower probability. Second, t-SNE defines a similar probability distribution over the points in the low-dimensional map, and it minimizes the Kullback–Leibler divergence (KL divergence) between the two distributions with respect to the locations of the points in the map. While the original algorithm uses the Euclidean distance between objects as the base of its similarity metric, this can be changed as appropriate. A Riemannian variant is UMAP.
t-S",Technology & Computing 
"Jump to content
Main menu
Main menu
move to sidebar
hide
Navigation
Main page
Contents
Current events
Random article
About Wikipedia
Contact us
Contribute
Help
Learn to edit
Community portal
Recent changes
Upload file
Special pages
Search
Search
Appearance
Donate
Create account
Log in
Personal tools
Donate
Create account
Log in
Pages for logged out editors
learn more
Contributions
Talk
UMAP
Add languages
Add links
Article
Talk
English
Read
Edit
View history
Tools
Tools
move to sidebar
hide
Actions
Read
Edit
View history
General
What links here
Related changes
Upload file
Permanent link
Page information
Cite this page
Get shortened URL
Download QR code
Print/export
Download as PDF
Printable version
In other projects
Wikidata item
Appearance
move to sidebar
hide
From Wikipedia, the free encyclopedia
UMAP
may refer to:
Military Units to Aid Production
University Mobility in Asia and the Pacific
Uniform Manifold Approximation and Projection
Topics referred to by the same term
This
disambiguation
page lists articles associated with the title
UMAP
.
If an
internal link
led you here, you may wish to change the link to point directly to the intended article.
Category
:
Disambiguation pages
Hidden categories:
Short description is different from Wikidata
All article disambiguation pages
All disambiguation pages
Search
Search
UMAP
Add languages
Add topic",Technology & Computing 
"Latent Dirichlet allocation
In natural language processing, latent Dirichlet allocation (LDA) is a Bayesian network (and, therefore, a generative statistical model) for modeling automatically extracted topics in textual corpora. The LDA is an example of a Bayesian topic model. In this, observations (e.g., words) are collected into documents, and each word's presence is attributable to one of the document's topics. Each document will contain a small number of topics.
History
[edit]In the context of population genetics, LDA was proposed by J. K. Pritchard, M. Stephens and P. Donnelly in 2000.[1][2]
LDA was applied in machine learning by David Blei, Andrew Ng and Michael I. Jordan in 2003.[3]
Overview
[edit]Population genetics
[edit]In population genetics, the model is used to detect the presence of structured genetic variation in a group of individuals. The model assumes that alleles carried by individuals under study have origin in various extant or past populations. The model and various inference algorithms allow scientists to estimate the allele frequencies in those source populations and the origin of alleles carried by individuals under study. The source populations can be interpreted ex-post in terms of various evolutionary scenarios. In association studies, detecting the presence of genetic structure is considered a necessary preliminary step to avoid confounding.
Clinical psychology, mental health, and social science
[edit]In clinical psychology research, LDA has been ",Technology & Computing 
"Topic model
In statistics and natural language processing, a topic model is a type of statistical model for discovering the abstract ""topics"" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: ""dog"" and ""bone"" will appear more often in documents about dogs, ""cat"" and ""meow"" will appear in documents about cats, and ""the"" and ""is"" will appear approximately equally in both. A document typically concerns multiple topics in different proportions; thus, in a document that is 10% about cats and 90% about dogs, there would probably be about 9 times more dog words than cat words. The ""topics"" produced by topic modeling techniques are clusters of similar words. A topic model captures this intuition in a mathematical framework, which allows examining a set of documents and discovering, based on the statistics of the words in each, what the topics might be and what each document's balance of topics is.
Topic models are also referred to as probabilistic topic models, which refers to statistical algorithms for discovering the latent semantic structures of an extensive text body. In the age of information, the amount of the written material we encounter each day is simply beyond our processing capacity. Topic models can help to organize and of",Technology & Computing 
"Tokenization
Appearance
Look up tokenization or tokenisation in Wiktionary, the free dictionary.
Tokenization may refer to:
- Tokenization (lexical analysis) in language processing
- Tokenization in search engine indexing
- Tokenization (data security) in the field of data security
- Word segmentation
- A procedure during the Transformer architecture
See also
[edit]- Tokenism of minorities",Technology & Computing 
"Stemming
In linguistic morphology and information retrieval, stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form—generally a written word form. The stem need not be identical to the morphological root of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root. Algorithms for stemming have been studied in computer science since the 1960s. Many search engines treat words with the same stem as synonyms as a kind of query expansion, a process called conflation.
A computer program or subroutine that stems word may be called a stemming program, stemming algorithm, or stemmer.
Examples
[edit]A stemmer for English operating on the stem cat should identify such strings as cats, catlike, and catty. A stemming algorithm might also reduce the words fishing, fished, and fisher to the stem fish. The stem need not be a word, for example the Porter algorithm reduces argue, argued, argues, arguing, and argus to the stem argu.
History
[edit]The first published stemmer was written by Julie Beth Lovins in 1968.[1] This paper was remarkable for its early date and had great influence on later work in this area.[citation needed] Her paper refers to three earlier major attempts at stemming algorithms, by Professor John W. Tukey of Princeton University, the algorithm developed at Harvard University by Michael Lesk, under the direction of Professor Gerard Salton, and a third",Technology & Computing 
"Named-entity recognition
Named-entity recognition (NER) (also known as (named) entity identification, entity chunking, and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names (PER), organizations (ORG), locations (LOC), geopolitical entities (GPE), vehicles (VEH), medical codes, time expressions, quantities, monetary values, percentages, etc.
Most research on NER/NEE systems has been structured as taking an unannotated block of text, such as transducing:
Jim bought 300 shares of Acme Corp. in 2006.
into an annotated block of text that highlights the names of entities:
[Jim]Person bought 300 shares of [Acme Corp.]Organization in [2006]Time.
In this example, a person name consisting of one token, a two-token company name and a temporal expression have been detected and classified.
Problem
[edit]Definition
[edit]In the expression named entity, the word named restricts the task to those entities for which one or many strings, such as words or phrases, stand (fairly) consistently for some referent. This is closely related to rigid designators, as defined by Kripke,[1][2] although in practice NER deals with many names and referents that are not philosophically ""rigid"". For instance, the automotive company created by Henry Ford in 1903 can be referred to as Ford or Ford Motor Company, although ""Ford"" can refer to many other entities as well (see Ford",Technology & Computing 
"Sentiment analysis
Sentiment analysis (also known as opinion mining or emotion AI) is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine. With the rise of deep language models, such as RoBERTa, also more difficult data domains can be analyzed, e.g., news texts where authors typically express their opinion/sentiment less explicitly.[1]
Simple cases
[edit]- ""Coronet has the best lines of all day cruisers.""
- ""Bertram has a deep V hull and runs easily through seas.""
- ""Pastel-colored 1980s day cruisers from Florida are ugly.""
- ""I dislike old cabin cruisers.""
More challenging examples
[edit]- ""I do not dislike cabin cruisers."" (Negation handling)
- ""Disliking watercraft is not really my thing."" (Negation, inverted word order)
- ""Sometimes I really hate RIBs."" (Adverbial modifies the sentiment)
- ""I'd really truly love going out in this weather!"" (Possibly sarcastic)
- ""Chris Craft is better looking than Limestone."" (Two brand names, identifying the target of attitude is difficult)
- ""Chris Craft is better looking than Limestone, but Limestone projects seaworthiness and reliability."" (Two attitu",Technology & Computing 
"Machine translation
Machine translation is use of computational techniques to translate text or speech from one language to another, including the contextual, idiomatic and pragmatic nuances of both languages.
Early approaches were mostly rule-based or statistical. These methods have since been superseded by neural machine translation[1] and large language models.[2]
History
[edit]Origins
[edit]The origins of machine translation can be traced back to the work of Al-Kindi, a ninth-century Arabic cryptographer who developed techniques for systemic language translation, including cryptanalysis, frequency analysis, and probability and statistics, which are used in modern machine translation.[3] The idea of machine translation later appeared in the 17th century. In 1629, René Descartes proposed a universal language, with equivalent ideas in different tongues sharing one symbol.[4]
The idea of using digital computers for translation of natural languages was proposed as early as 1947 by England's A. D. Booth[5] and Warren Weaver at Rockefeller Foundation in the same year. ""The memorandum written by Warren Weaver in 1949 is perhaps the single most influential publication in the earliest days of machine translation.""[6][7] Others followed. A demonstration was made in 1954 on the APEXC machine at Birkbeck College (University of London) of a rudimentary translation of English into French. Several papers on the topic were published at the time, and even articles in popular journals (for ",Technology & Computing 
"Speech recognition
Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers. It is also known as automatic speech recognition (ASR), computer speech recognition or speech-to-text (STT). It incorporates knowledge and research in the computer science, linguistics and computer engineering fields. The reverse process is speech synthesis.
Some speech recognition systems require ""training"" (also called ""enrollment"") where an individual speaker reads text or isolated vocabulary into the system. The system analyzes the person's specific voice and uses it to fine-tune the recognition of that person's speech, resulting in increased accuracy. Systems that do not use training are called ""speaker-independent""[1] systems. Systems that use training are called ""speaker dependent"".
Speech recognition applications include voice user interfaces such as voice dialing (e.g. ""call home""), call routing (e.g. ""I would like to make a collect call""), domotic appliance control, search key words (e.g. find a podcast where particular words were spoken), simple data entry (e.g., entering a credit card number), preparation of structured documents (e.g. a radiology report), determining speaker characteristics,[2] speech-to-text processing (e.g., word processors or emails), and aircraft (usually termed direct voice input). Automatic pr",Technology & Computing 
"Speech synthesis
Speech synthesis is the artificial production of human speech. A computer system used for this purpose is called a speech synthesizer, and can be implemented in software or hardware products. A text-to-speech (TTS) system converts normal language text into speech; other systems render symbolic linguistic representations like phonetic transcriptions into speech.[1] The reverse process is speech recognition.
Synthesized speech can be created by concatenating pieces of recorded speech that are stored in a database. Systems differ in the size of the stored speech units; a system that stores phones or diphones provides the largest output range, but may lack clarity.[citation needed] For specific usage domains, the storage of entire words or sentences allows for high-quality output. Alternatively, a synthesizer can incorporate a model of the vocal tract and other human voice characteristics to create a completely ""synthetic"" voice output.[2]
The quality of a speech synthesizer is judged by its similarity to the human voice and by its ability to be understood clearly. An intelligible text-to-speech program allows people with visual impairments or reading disabilities to listen to written words on a home computer. Many computer operating systems have included speech synthesizers since the early 1990s.[citation needed]
A text-to-speech system (or ""engine"") is composed of two parts:[3] a front-end and a back-end. The front-end has two major tasks. First, it converts ra",Technology & Computing 
"Information retrieval
Information retrieval (IR) in computing and information science is the task of identifying and retrieving information system resources that are relevant to an information need. The information need can be specified in the form of a search query. In the case of document retrieval, queries can be based on full-text or other content-based indexing. Information retrieval is the science[1] of searching for information in a document, searching for documents themselves, and also searching for the metadata that describes data, and for databases of texts, images or sounds.
Automated information retrieval systems are used to reduce what has been called information overload. An IR system is a software system that provides access to books, journals and other documents; it also stores and manages those documents. Web search engines are the most visible IR applications.
Overview
[edit]An information retrieval process begins when a user enters a query into the system. Queries are formal statements of information needs, for example search strings in web search engines. In information retrieval, a query does not uniquely identify a single object in the collection. Instead, several objects may match the query, perhaps with different degrees of relevance.
An object is an entity that is represented by information in a content collection or database. User queries are matched against the database information. However, as opposed to classical SQL queries of a database, in info",Technology & Computing 
"Search engine
A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user's query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news.
For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine's response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers.
There have been many search engines since the dawn of the Web in the 1990s, however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89–90 % of the worldwide search share, with competitors trailing far behind: Bing (~4 %), Yandex (~2.5 %), Yahoo! (~1.3 %), DuckDuckGo (~0.8 %), and Baidu (~0.7 %).[1] Notably, this marks the first time in over a decade that Google's share has fallen below the 90 % threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focu",Technology & Computing 
"Apache Solr
Solr (pronounced ""solar"") is an open-source enterprise-search platform, written in Java. Its major features include full-text search, hit highlighting, faceted search, real-time indexing, dynamic clustering, database integration, NoSQL features[2] and rich document (e.g., Word, PDF) handling. Providing distributed search and index replication, Solr is designed for scalability and fault tolerance.[3] Solr is widely used for enterprise search and analytics use cases and has an active development community and regular releases.
Solr runs as a standalone full-text search server. It uses the Lucene Java search library at its core for full-text indexing and search, and has REST-like HTTP/XML and JSON APIs that make it usable from most popular programming languages. Solr's external configuration allows it to be tailored to many types of applications without Java coding, and it has a plugin architecture to support more advanced customization.
Apache Solr is developed in an open, collaborative manner by the Apache Solr project at the Apache Software Foundation.
History
[edit]In 2004, Solr was created by Yonik Seeley at CNET Networks as an in-house project to add search capability for the company website.[4]
In January 2006, CNET Networks decided to openly publish the source code by donating it to the Apache Software Foundation.[5] Like any new Apache project, it entered an incubation period that helped solve organizational, legal, and financial issues.
In January 2007, Sol",Technology & Computing 
"PageRank
PageRank (PR) is an algorithm used by Google Search to rank web pages in their search engine results. It is named after both the term ""web page"" and co-founder Larry Page. PageRank is a way of measuring the importance of website pages. According to Google:
PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website is. The underlying assumption is that more important websites are likely to receive more links from other websites.[1]
Currently, PageRank is not the only algorithm used by Google to order search results, but it is the first algorithm that was used by the company, and it is the best known.[2][3] As of September 24, 2019, all patents associated with PageRank have expired.[4]
Description
[edit]PageRank is a link analysis algorithm and it assigns a numerical weighting to each element of a hyperlinked set of documents, such as the World Wide Web, with the purpose of ""measuring"" its relative importance within the set. The algorithm may be applied to any collection of entities with reciprocal quotations and references. The numerical weight that it assigns to any given element E is referred to as the PageRank of E and denoted by
A PageRank results from a mathematical algorithm based on the Webgraph, created by all World Wide Web pages as nodes and hyperlinks as edges, taking into consideration authority hubs such as cnn.com or mayoclinic.org. The rank value indicates an importance of a particular",Technology & Computing 
"Recommender system
A recommender system (RecSys), or a recommendation system (sometimes replacing system with terms such as platform, engine, or algorithm) and sometimes only called ""the algorithm"" or ""algorithm"",[1] is a subclass of information filtering system that provides suggestions for items that are most pertinent to a particular user.[2][3][4] Recommender systems are particularly useful when an individual needs to choose an item from a potentially overwhelming number of items that a service may offer.[2][5] Modern recommendation systems such as those used on large social media sites make extensive use of AI, machine learning and related techniques to learn the behavior and preferences of each user and categorize content to tailor their feed individually.[6]
Typically, the suggestions refer to various decision-making processes, such as what product to purchase, what music to listen to, or what online news to read.[2] Recommender systems are used in a variety of areas, with commonly recognised examples taking the form of playlist generators for video and music services, product recommenders for online stores, or content recommenders for social media platforms and open web content recommenders.[7][8] These systems can operate using a single type of input, like music, or multiple inputs within and across platforms like news, books and search queries. There are also popular recommender systems for specific topics like restaurants and online dating. Recommender systems have",Technology & Computing 
"Collaborative filtering
Collaborative filtering (CF) is, besides content-based filtering, one of two major techniques used by recommender systems.[1] Collaborative filtering has two senses, a narrow one and a more general one.[2]
In the newer, narrower sense, collaborative filtering is a method of making automatic predictions (filtering) about a user's interests by utilizing preferences or taste information collected from many users (collaborating). This approach assumes that if persons A and B share similar opinions on one issue, they are more likely to agree on other issues compared to a random pairing of A with another person. For instance, a collaborative filtering system for television programming could predict which shows a user might enjoy based on a limited list of the user's tastes (likes or dislikes).[3] These predictions are specific to the user, but use information gleaned from many users. This differs from the simpler approach of giving an average (non-specific) score for each item of interest, for example based on its number of votes.
In the more general sense, collaborative filtering is the process of filtering information or patterns using techniques involving collaboration among multiple agents, viewpoints, data sources, etc.[2] Applications of collaborative filtering typically involve very large data sets. Collaborative filtering methods have been applied to many kinds of data including: sensing and monitoring data, such as in mineral exploration, environmen",Technology & Computing 
"Recommender system
A recommender system (RecSys), or a recommendation system (sometimes replacing system with terms such as platform, engine, or algorithm) and sometimes only called ""the algorithm"" or ""algorithm"",[1] is a subclass of information filtering system that provides suggestions for items that are most pertinent to a particular user.[2][3][4] Recommender systems are particularly useful when an individual needs to choose an item from a potentially overwhelming number of items that a service may offer.[2][5] Modern recommendation systems such as those used on large social media sites make extensive use of AI, machine learning and related techniques to learn the behavior and preferences of each user and categorize content to tailor their feed individually.[6]
Typically, the suggestions refer to various decision-making processes, such as what product to purchase, what music to listen to, or what online news to read.[2] Recommender systems are used in a variety of areas, with commonly recognised examples taking the form of playlist generators for video and music services, product recommenders for online stores, or content recommenders for social media platforms and open web content recommenders.[7][8] These systems can operate using a single type of input, like music, or multiple inputs within and across platforms like news, books and search queries. There are also popular recommender systems for specific topics like restaurants and online dating. Recommender systems have",Technology & Computing 
"Ontology
Ontology is the philosophical study of being. It is traditionally understood as the subdiscipline of metaphysics focused on the most general features of reality. As one of the most fundamental concepts, being encompasses all of reality and every entity within it. To articulate the basic structure of being, ontology examines the commonalities among all things and investigates their classification into basic types, such as the categories of particulars and universals. Particulars are unique, non-repeatable entities, such as the person Socrates, whereas universals are general, repeatable entities, like the color green. Another distinction exists between concrete objects existing in space and time, such as a tree, and abstract objects existing outside space and time, like the number 7. Systems of categories aim to provide a comprehensive inventory of reality by employing categories such as substance, property, relation, state of affairs, and event.
Ontologists disagree regarding which entities exist at the most basic level. Platonic realism asserts that universals have objective existence, while conceptualism maintains that universals exist only in the mind, and nominalism denies their existence altogether. Similar disputes pertain to mathematical objects, unobservable objects assumed by scientific theories, and moral facts. Materialism posits that fundamentally only matter exists, whereas dualism asserts that mind and matter are independent principles. According to some",Philosophy & Religion 
"Semantic Web
The Semantic Web, sometimes known as Web 3.0, is an extension of the World Wide Web through standards[1] set by the World Wide Web Consortium (W3C). The goal of the Semantic Web is to make Internet data machine-readable.
To enable the encoding of semantics with the data, technologies such as Resource Description Framework (RDF)[2] and Web Ontology Language (OWL)[3] are used. These technologies are used to formally represent metadata. For example, ontology can describe concepts, relationships between entities, and categories of things. These embedded semantics offer significant advantages such as reasoning over data and operating with heterogeneous data sources.[4] These standards promote common data formats and exchange protocols on the Web, fundamentally the RDF. According to the W3C, ""The Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries.""[5] The Semantic Web is therefore regarded as an integrator across different content and information applications and systems.
History
[edit]The term was coined by Tim Berners-Lee for a web of data (or data web)[6] that can be processed by machines[7]—that is, one in which much of the meaning is machine-readable. While its critics have questioned its feasibility, proponents argue that applications in library and information science, industry, biology and human sciences research have already proven the validity of the original concept.[8]
B",Technology & Computing 
"SPARQL
SPARQL (pronounced ""sparkle"", a recursive acronym[2] for SPARQL Protocol and RDF Query Language) is an RDF query language—that is, a semantic query language for databases—able to retrieve and manipulate data stored in Resource Description Framework (RDF) format.[3][4] It was made a standard by the RDF Data Access Working Group (DAWG) of the World Wide Web Consortium, and is recognized as one of the key technologies of the semantic web. On 15 January 2008, SPARQL 1.0 was acknowledged by W3C as an official recommendation,[5][6] and SPARQL 1.1 in March, 2013.[7]
SPARQL allows for a query to consist of triple patterns, conjunctions, disjunctions, and optional patterns.[10]
Implementations for multiple programming languages exist.[11] There exist tools that allow one to connect and semi-automatically construct a SPARQL query for a SPARQL endpoint, for example ViziQuer.[12] In addition, tools exist to translate SPARQL queries to other query languages, for example to SQL[13] and to XQuery.[14]
Features
[edit]SPARQL allows users to write queries that follow the RDF specification of the W3C. Thus, the entire dataset is ""subject-predicate-object"" triples. Subjects and predicates are always URI identifiers, but objects can be URIs or literal values. This single physical schema of 3 ""columns"" is hypernormalized in that what would be 1 relational record with (for example) 4 columns is now 4 triples with the subject being repeated over and over, the predicate essentially being the c",Technology & Computing 
"Linked data
In computing, linked data is structured data which is interlinked with other data so it becomes more useful through semantic queries. It builds upon standard Web technologies such as HTTP, RDF and URIs, but rather than using them to serve web pages only for human readers, it extends them to share information in a way that can be read automatically by computers. Part of the vision of linked data is for the Internet to become a global database.[1]
Tim Berners-Lee, director of the World Wide Web Consortium (W3C), coined the term in a 2006 design note about the Semantic Web project.[2]
Linked data may also be open data, in which case it is usually described as Linked Open Data.[3]
Principles
[edit]In his 2006 ""Linked Data"" note, Tim Berners-Lee outlined four principles of linked data, paraphrased along the following lines:[2]
- Uniform Resource Identifiers (URIs) should be used to name and identify individual things.
- HTTP URIs should be used to allow these things to be looked up, interpreted, and subsequently ""dereferenced"".
- Useful information about what a name identifies should be provided through open standards such as RDF, SPARQL, etc.
- When publishing data on the Web, other things should be referred to using their HTTP URI-based names.
Tim Berners-Lee later restated these principles at a 2009 TED conference, again paraphrased along the following lines:[4]
- All conceptual things should have a name starting with HTTP.
- Looking up an HTTP name should return us",Technology & Computing 
"DBpedia
DBpedia (from ""DB"" for ""database"") is a project aiming to extract structured content from the information created in the Wikipedia project. This structured information is made available on the World Wide Web using OpenLink Virtuoso.[1][2] DBpedia allows users to semantically query relationships and properties of Wikipedia resources, including links to other related datasets.[3]
The project was heralded as ""one of the more famous pieces"" of the decentralized Linked Data effort by Tim Berners-Lee, one of the Web's pioneers.[4] As of June 2021, DBPedia contained over 850 million semantic triples.
Background
[edit]The project was started by people at the Free University of Berlin and Leipzig University[5] in collaboration with OpenLink Software, and is now maintained by people at the University of Mannheim and Leipzig University.[6][7] The first publicly available dataset was published in 2007.[5] The data is made available under free licenses (CC BY-SA), allowing others to reuse the dataset; it does not use an open data license to waive the sui generis database rights.
Wikipedia articles consist mostly of free text, but also include structured information embedded in the articles, such as ""infobox"" tables (the pull-out panels that appear in the top right of the default view of many Wikipedia articles, or at the start of the mobile versions), categorization information, images, geo-coordinates and links to external Web pages. This structured information is extracted and p",Technology & Computing 
"Schema.org
Schema.org is a reference website that publishes documentation and guidelines for using structured data mark-up on web-pages (in the form of microdata, RDFa or JSON-LD). Its main objective is to standardize HTML tags to be used by webmasters for creating rich results (displayed as visual data or infographic tables on search engine results) about a certain topic of interest.[2] It is a part of the semantic web project, which aims to make document mark-up codes more readable and meaningful to both humans and machines.
History
[edit]Schema.org is an initiative launched on June 2, 2011, by Bing, Google and Yahoo![3][4][5] (operators of the world's largest search engines at that time)[6] to create and support a common set of schemas for structured data markup on web pages. In November 2011, Yandex (whose search engine is the largest in Russia) joined the initiative.[7][8] They propose using the schema.org vocabulary along with the Microdata, RDFa, or JSON-LD formats[9] to mark up website content with metadata about itself. Such markup can be recognized by search engine spiders and other parsers, thus granting access to the meaning of the sites (see Semantic Web). The initiative also describes an extension mechanism for adding additional properties.[10] In 2012, the GoodRelations ontology was integrated into Schema.org.[11] Public discussion of the initiative largely takes place on the W3C public vocabularies mailing list.[12]
Much of the vocabulary on Schema.org was ins",Technology & Computing 
"Microformat
Microformats (μF)[note 1] are predefined HTML markup (like HTML classes) created to serve as descriptive and consistent metadata about elements, designating them as representing a certain type of data (such as contact information, geographic coordinates, events, products, recipes, etc.).[1] They allow software to process the information reliably by having set classes refer to a specific type of data rather than being arbitrary.
Microformats emerged around 2005 and were predominantly designed for use by search engines, web syndication and aggregators such as RSS.[2] Google confirmed in 2020 that it still parses microformats for use in content indexing.[3] Microformats are referenced in several W3C social web specifications, including IndieAuth [4] and Webmention.[5]
Although the content of web pages has been capable of some ""automated processing"" since the inception of the web, such processing is difficult because the markup elements used to display information on the web do not describe what the information means.[6] Microformats can bridge this gap by attaching semantics, and thereby obviating other, more complicated, methods of automated processing, such as natural language processing or screen scraping. The use, adoption and processing of microformats enables data items to be indexed, searched for, saved or cross-referenced, so that information can be reused or combined.[6]
As of 2013[update], microformats allow the encoding and extraction of event details, con",Technology & Computing 
"JSON-LD
JSON-LD (JavaScript Object Notation for Linked Data) is a method of encoding linked data using JSON and of serializing data similarly to traditional JSON.[1] It is meant to be simple to create by modifying JSON documents.[2] JSON-LD is a World Wide Web Consortium Recommendation initially developed by the JSON for Linking Data Community Group,[3] transferred to the RDF Working Group[4] for review, improvement and standardization,[5] and now maintained by the JSON-LD Working Group.[6]
Design
[edit]JSON-LD is based on the concept of a ""context"" that maps JSON object properties to concepts in an ontology using an RDF model. In order to map the JSON-LD syntax to RDF, JSON-LD allows values to be coerced to a specified type or tagged with a language. A context can be embedded directly in a JSON-LD document or put into a separate file and referenced from traditional JSON documents via an HTTP Link header.
Example
[edit]{
""@context"": {
""name"": ""http://xmlns.com/foaf/0.1/name"",
""homepage"": {
""@id"": ""http://xmlns.com/foaf/0.1/workplaceHomepage"",
""@type"": ""@id""
},
""Person"": ""http://xmlns.com/foaf/0.1/Person""
},
""@id"": ""https://me.example.com"",
""@type"": ""Person"",
""name"": ""John Smith"",
""homepage"": ""https://www.example.com/""
}
The example above describes a person, based on the FOAF (friend of a friend) ontology. First, the two JSON properties name
and homepage
and the type Person
are mapped to concepts in the FOAF vocabulary and the value of the homepage
property is specified to be ",Technology & Computing 
"HTML5
HTML5 (Hypertext Markup Language 5) is a markup language used for structuring and presenting hypertext documents on the World Wide Web. It was the fifth and final[4] major HTML version that is now a retired World Wide Web Consortium (W3C) recommendation. The current specification is known as the HTML Living Standard. It is maintained by the Web Hypertext Application Technology Working Group (WHATWG), a consortium of the major browser vendors (Apple, Google, Mozilla, and Microsoft).
HTML5 was first released in a public-facing form on 22 January 2008,[2] with a major update and ""W3C Recommendation"" status in October 2014.[5][6] Its goals were to improve the language with support for the latest multimedia and other new features; to keep the language both easily readable by humans and consistently understood by computers and devices such as web browsers, parsers, etc., without XHTML's rigidity; and to remain backward-compatible with older software. HTML5 is intended to subsume not only HTML 4 but also XHTML1 and even the DOM Level 2 HTML itself.[7]
HTML5 includes detailed processing models to encourage more interoperable implementations; it extends, improves, and rationalizes the markup available for documents and introduces markup and application programming interfaces (APIs) for complex web applications.[8] For the same reasons, HTML5 is also a candidate for cross-platform mobile applications because it includes features designed with low-powered devices in mind.
Many new",Technology & Computing 
"CSS
Cascading Style Sheets (CSS) is a style sheet language used for specifying the presentation and styling of a document written in a markup language such as HTML or XML (including XML dialects such as SVG, MathML or XHTML).[2] CSS is a cornerstone technology of the World Wide Web, alongside HTML and JavaScript.[3]
CSS is designed to enable the separation of content and presentation, including layout, colors, and fonts.[4] This separation can improve content accessibility, since the content can be written without concern for its presentation; provide more flexibility and control in the specification of presentation characteristics; enable multiple web pages to share formatting by specifying the relevant CSS in a separate .css file, which reduces complexity and repetition in the structural content; and enable the .css file to be cached to improve the page load speed between the pages that share the file and its formatting.
Separation of formatting and content also makes it feasible to present the same markup page in different styles for different rendering methods, such as on-screen, in print, by voice (via speech-based browser or screen reader), and on Braille-based tactile devices. CSS also has rules for alternative formatting if the content is accessed on a mobile device.[5]
The name cascading comes from the specified priority scheme to determine which declaration applies if more than one declaration of a property match a particular element. This cascading priority scheme ",Technology & Computing 
"JavaScript
JavaScript (/ˈdʒɑːvəskrɪpt/ ⓘ), often abbreviated as JS, is a programming language and core technology of the World Wide Web, alongside HTML and CSS. Ninety-nine percent of websites use JavaScript on the client side for webpage behavior.[10]
Web browsers have a dedicated JavaScript engine that executes the client code. These engines are also utilized in some servers and a variety of apps. The most popular runtime system for non-browser usage is Node.js.
JavaScript is a high-level, often just-in-time–compiled language that conforms to the ECMAScript standard.[11] It has dynamic typing, prototype-based object-orientation, and first-class functions. It is multi-paradigm, supporting event-driven, functional, and imperative programming styles. It has application programming interfaces (APIs) for working with text, dates, regular expressions, standard data structures, and the Document Object Model (DOM).
The ECMAScript standard does not include any input/output (I/O), such as networking, storage, or graphics facilities. In practice, the web browser or other runtime system provides JavaScript APIs for I/O.
Although Java and JavaScript are similar in name and syntax, the two languages are distinct and differ greatly in design.
History
Creation at Netscape
The first popular web browser with a graphical user interface, Mosaic, was released in 1993. The lead developers of Mosaic then founded the Netscape corporation, which released a more polished browser, Netscape Navigator,",Technology & Computing 
"TypeScript
TypeScript (abbreviated as TS) is a high-level programming language that adds static typing with optional type annotations to JavaScript. It is designed for developing large applications and transpiles to JavaScript.[6] It is developed by Microsoft as free and open-source software released under an Apache License 2.0.
TypeScript may be used to develop JavaScript applications for both client-side and server-side execution (as with Node.js, Deno or Bun). Multiple options are available for transpiling. The default TypeScript Compiler can be used,[7] or the Babel compiler can be invoked to convert TypeScript to JavaScript.
TypeScript supports definition files that can contain type information of existing JavaScript libraries, much like C++ header files can describe the structure of existing object files. This enables other programs to use the values defined in the files as if they were statically typed TypeScript entities. There are third-party header files for popular libraries such as jQuery, MongoDB, and D3.js. TypeScript headers for the Node.js library modules are also available, allowing development of Node.js programs within TypeScript.[8]
The TypeScript compiler is written in TypeScript and compiled to JavaScript. It is licensed under the Apache License 2.0. Anders Hejlsberg, lead architect of C# and creator of Delphi and Turbo Pascal, has worked on developing TypeScript.[9][10][11][12]
History
[edit]TypeScript was released to the public in October 2012, with ve",Technology & Computing 
"Svelte
Svelte is a free and open-source component-based front-end software framework,[2] and language[3] created by Rich Harris and maintained by the Svelte core team members.[4]
Svelte is not a monolithic JavaScript library imported by applications: instead, Svelte compiles HTML templates to specialized code that manipulates the DOM directly, which may reduce the size of transferred files and give better client performance.[5] Application code is also processed by the compiler, inserting calls to automatically recompute data[2] and re-render UI elements when the data they depend on is modified.[6] This also avoids the overhead associated with runtime intermediate representations, such as virtual DOM,[7] unlike traditional frameworks (such as React and Vue) which carry out the bulk of their work at runtime, i.e. in the browser.[5][6][4][8][2][7]
The compiler itself is written in JavaScript.[9][8] Its source code is licensed under MIT License and hosted on GitHub.[8] Among comparable frontend libraries, Svelte has one of the smallest bundle footprints at merely 2KB.[10]
History
[edit]The predecessor of Svelte is Ractive.js, which Rich Harris created in 2013.[11]
Version 1 of Svelte was written in JavaScript and was released on 29 November 2016.[12] The name Svelte was chosen by Rich Harris and his coworkers at The Guardian.[12]
Version 2 of Svelte was released on 19 April 2018. It set out to correct what the maintainers viewed as mistakes in the earlier version such as replaci",Technology & Computing 
"Next.js
Next.js is an open-source web development framework created by the private company Vercel providing React-based web applications with server-side rendering and static rendering.
React documentation mentions Next.js among ""Recommended Toolchains"" advising it to developers when ""building a server-rendered website with Node.js"".[5] Where traditional React apps can only render their content in the client-side browser, Next.js extends this functionality to include applications rendered on the server-side.
The copyright and trademarks for Next.js are owned by Vercel,[6] which also maintains and leads its open-source development.[7]
Background
[edit]Next.js is a React framework that enables several extra features, including server-side rendering and static rendering.[8] React is a JavaScript library that is traditionally used to build web applications rendered in the client's browser with JavaScript.[9] Developers recognize several problems with this strategy however, such as not catering to users who do not have access to JavaScript or have disabled it, potential security issues, significantly extended page loading times, and harm to the site's overall search engine optimization.[9] Frameworks such as Next.js sidestep these problems by allowing some or all of the website to be rendered on the server-side before being sent to the client.[9][10] Next.js is one of the most popular frameworks for React.[11] It is one of several recommended ""toolchains"" available when starting a",Technology & Computing 
"Nuxt
Nuxt is a free and open source JavaScript library based on Vue.js, Nitro, and Vite. Nuxt is inspired by Next.js,[4] which is a similar framework based on React rather than Vue.
The main advantage of Nuxt over using Vue alone is its universal rendering system. The framework works as both an in-browser single page application (SPA) as well as a server-rendered static website, by ""hydrating"" a server-rendered page to a full SPA after it's loaded. This allows websites to have the SEO and performance benefits of a server-rendered site in addition to the interactivity of a client-rendered application.[5][6] Nuxt largely abstracts the server-rendering features from the developer, and it's therefore able to have a similar development experience to a traditional SPA using Vue's single file component (SFC) system.[7]
In addition to its flagship universal rendering mechanism, Nuxt also provides many other benefits and quality-of-life features, such as path-based routing, hot module replacement (HMR), TypeScript support out of the box, and middleware and server logic.[8]
Features
[edit]Path-based routing
[edit]Rather than a regular Vue.js application, which ordinarily requires every route to be manually registered, Nuxt uses path-based routing to automatically register every route in an application.[9]
Pages are declared in the pages/
folder, where the name of the page file becomes the name of the route. Dynamic parameters can be added using square brackets, and catch-all routes can",Technology & Computing 
"Remix
A remix, also sometimes called reorchestration or rework, is a piece of media which has been altered or contorted from its original state by adding, removing, or changing pieces of the item. A song, piece of artwork, book, poem, or photograph can be remixes. The only characteristic of a remix is that it appropriates and changes other materials to create something new.
Most commonly, remixes are a subset of audio mixing in music and song recordings. Songs may be remixed for a variety of reasons:
- to adapt or revise a song for radio or nightclub play
- to create a stereo or surround sound version of a song where none was previously available
- to improve the fidelity of an older song for which the original master has been lost or degraded
- to alter a song to suit a specific music genre or radio format
- to use some of the original song's materials in a new context, allowing the original song to reach a different audience
- to alter a song for artistic purposes
- to provide additional versions of a song for use as bonus tracks or for a B-side, for example, in times when a CD single might carry a total of 4 tracks
- to create a connection between a smaller artist and a more successful one, as was the case with Fatboy Slim's remix of ""Brimful of Asha"" by Cornershop
- to improve the first or demo mix of the song, generally to ensure a professional product
- to improve a song from its original state
Remixes should not be confused with edits, which usually involve shortening ",art_culture
"Backbone.js
Backbone.js is a JavaScript rich-client web app framework based on the model–view–controller design paradigm, intended to connect to an API over a RESTful JSON interface. Backbone has only hard dependency, which is on one JavaScript library,[2] Underscore.js,. jQuery can also be optionally used for the library.[3] It is designed for developing single-page web applications,[4] and for keeping various parts of web applications (e.g. multiple clients and the server) synchronized.[5] Backbone was created by Jeremy Ashkenas, who is also known for CoffeeScript and Underscore.js.
When handling the DOM Backbone.js adopts an imperative programming style, in contrast with a declarative programming style (common in AngularJS using data-attributes).[6] Trying to provide ""the minimal set of data-structuring (models and collections) and user interface (views and URLs)"",[7] leaves to the developer the choice of extensions for enhanced functionality. For example, one can use nested views with Backbone Layout Manager or model-view binding with ReSTbasis.
Use
[edit]The following web applications are built with Backbone.js:[8]
- 500px Web[9]
- Airbnb[7]
- Diaspora[7]
- Digg[10]
- DocumentCloud[7]
- Drupal 8[11]
- Foursquare[7]
- Grooveshark[7]
- Groupon Now[7]
- Hearsay Systems Advisor Cloud
- Hulu[7]
- NewsBlur[12]
- Nextcloud
- Openbravo Mobile (with Enyo).[13]
- Pandora Radio[7]
- ReSTbasis
- SoundCloud[7]
- Trello[7]
- USA Today.com[7]
- WordPress.com[7]
- verizon.com[7]
- xTupl",Technology & Computing 
"jQuery
jQuery is a JavaScript library designed to simplify HTML DOM tree traversal and manipulation, as well as event handling, CSS animations, and Ajax.[4] It is free, open-source software using the permissive MIT License.[5] As of August 2022[update], jQuery is used by 77% of the 10 million most popular websites.[6] Web analysis indicates that it is the most widely deployed JavaScript library by a large margin, having at least three to four times more usage than any other JavaScript library.[6][7]
jQuery's syntax is designed to make it easier to navigate a document, select DOM elements, create animations, handle events, and develop Ajax applications. jQuery also provides capabilities for developers to create plug-ins on top of the JavaScript library. This enables developers to create abstractions for low-level interaction and animation, advanced effects and high-level, theme-able widgets. The modular approach to the jQuery library allows the creation of powerful dynamic web pages and Web applications.
The set of jQuery core features—DOM element selections, traversal, and manipulation—enabled by its selector engine (named ""Sizzle"" from v1.3), created a new ""programming style"", fusing algorithms and DOM data structures. This style influenced the architecture of other JavaScript frameworks like YUI v3 and Dojo, later stimulating the creation of the standard Selectors API.[8]
Microsoft and Nokia bundle jQuery on their platforms.[9] Microsoft includes it with Visual Studio[10] f",Technology & Computing 
"D3.js
D3.js (also known as D3, short for Data-Driven Documents) is a JavaScript library for producing dynamic, interactive data visualizations in web browsers. It makes use of Scalable Vector Graphics (SVG), HTML5, and Cascading Style Sheets (CSS) standards. It is the successor to the earlier Protovis framework.[2] Its development was noted in 2011,[3] as version 2.0.0 was released in August 2011.[4] With the release of version 4.0.0 in June 2016, D3 was changed from a single library into a collection of smaller, modular libraries that can be used independently.[5]
Context
[edit]There have been various previous attempts to bring data visualization to web browsers. The most notable examples were the Prefuse, Flare, and Protovis toolkits, which can all be considered as direct predecessors of D3.js.[citation needed]
Prefuse was a visualization toolkit created in 2005 that required usage of Java, and visualizations were rendered within browsers with a Java plug-in. Flare was a similar toolkit from 2007 that used ActionScript, and required a Flash plug-in for rendering.[citation needed]
In 2009, based on the experience of developing and utilizing Prefuse and Flare, Jeffrey Heer, Mike Bostock, and Vadim Ogievetsky of Stanford University's Stanford Visualization Group created Protovis, a JavaScript library to generate SVG graphics from data. The library was known to data visualization practitioners and academics.[6]
In 2011, the development of Protovis was stopped to focus on a new ",Technology & Computing 
"Three.js
Three.js is a cross-browser JavaScript library and application programming interface (API) used to create and display animated 3D computer graphics in a web browser using WebGL. The source code is hosted in a repository on GitHub.[3]
Overview
[edit]Three.js allows the creation of graphical processing unit (GPU)-accelerated 3D animations using the JavaScript language as part of a website without relying on proprietary browser plugins.[4][5] This is possible due to the advent of WebGL,[6] a low-level graphics API created specifically for the web.[7]
High-level libraries such as Three.js, Babylon.js, Verge3D and many more make it possible to author complex 3D computer animations for display in the browser without the effort required for a traditional standalone application or a plugin.[8]
History
[edit]Three.js was first released by Ricardo Cabello on GitHub in April 2010.[2] The origins of the library can be traced back to his involvement with the demoscene in the early 2000s.[9] The code was originally developed in the ActionScript language used by Adobe Flash, later being ported to JavaScript in 2009. In Cabello's mind, there were two strong points that justified the shift away from ActionScript: Firstly, JavaScript provided greater platform independence. Secondly, applications written in JavaScript would not need to be compiled by the developer beforehand, unlike Flash applications.
Additional contributions by Cabello include API design, CanvasRenderer, SVGRenderer,",Technology & Computing 
"WebGL
WebGL (short for Web Graphics Library) is a JavaScript API for rendering interactive 2D and 3D graphics within any compatible web browser without the use of plug-ins.[2] WebGL is fully integrated with other web standards, allowing GPU-accelerated usage of physics, image processing, and effects in the HTML canvas. WebGL elements can be mixed with other HTML elements and composited with other parts of the page or page background.[3]
WebGL programs consist of control code written in JavaScript, and shader code written in OpenGL ES Shading Language (GLSL ES, sometimes referred to as ESSL), a language similar to C or C++. WebGL code is executed on a computer's GPU.
WebGL is designed and maintained by the non-profit Khronos Group.[4] On February 9, 2022, Khronos Group announced WebGL 2.0 support from all major browsers.[5]
From 2024, a new graphics API, WebGPU, is being developed to supersede WebGL. WebGPU provides extended capabilities, a more modern interface, and direct GPU access, which is useful for demanding graphics as well as AI applications.
Design
[edit]WebGL 1.0 is based on OpenGL ES 2.0 and provides an API for 3D graphics.[6] It uses the HTML5 canvas element and is accessed using Document Object Model (DOM) interfaces.
WebGL 2.0 is based on OpenGL ES 3.0. It guarantees the availability of many optional extensions of WebGL 1.0, and exposes new APIs.[7] Automatic memory management is provided implicitly by JavaScript.[4]
Like OpenGL ES 2.0, WebGL lacks the fixed-fun",Technology & Computing 
"WebAssembly
WebAssembly (Wasm) defines a portable binary-code format and a corresponding text format for executable programs[2] as well as software interfaces for facilitating communication between such programs and their host environment.[3][4][5][6]
The main goal of WebAssembly is to facilitate high-performance applications on web pages, but it is also designed to be usable in non-web environments.[7] It is an open standard[8][9] intended to support any language on any operating system,[10] and in practice many of the most popular languages already have at least some level of support.
Announced in 2015World Wide Web Consortium recommendation on 5 December 2019[11][12][13] and it received the Programming Languages Software Award from ACM SIGPLAN in 2021.[14] The World Wide Web Consortium (W3C) maintains the standard with contributions from Mozilla, Microsoft, Google, Apple, Fastly, Intel, and Red Hat.[15][16]
and first released in March 2017 , WebAssembly became aHistory
[edit]The name WebAssembly is intended to suggest bringing assembly language programming to the World Wide Web, where it will be executed client-side, by the website-user's computer via the user's web browser. To accomplish this, WebAssembly must be much more hardware-independent than a true assembly language.
WebAssembly was first announced in 2015,[17] and the first demonstration was executing Unity's Angry Bots in Firefox,[18] Google Chrome,[19] and Microsoft Edge [Legacy].[20] The precursor technologies ",Technology & Computing 
"Progressive web app
A progressive web application (PWA), or progressive web app, is a type of web app that can be installed on a device as a standalone application.[1] PWAs are installed using the offline cache of the device's web browser.[2]
PWAs were introduced from 2016 as an alternative to native (device-specific) applications, with the advantage that they do not require separate bundling or distribution for different platforms. They can be used on a range of different systems, including desktop and mobile devices. Publishing the app to digital distribution systems, such as the Apple App Store, Google Play, or the Microsoft Store on Windows, is optional.[2]
Because a PWA is delivered in the form of a webpage or website built using common web technologies including HTML, CSS, JavaScript, and WebAssembly,[3] it can work on any platform with a PWA-compatible browser. As of 2025, PWA features are supported to varying degrees by Google Chrome, Apple Safari, Brave, Firefox for Android, and Microsoft Edge[4][5] but not by Firefox for desktop.[6]
History
[edit]Predecessors
[edit]At Apple's Worldwide Developers Conference in 2007, Steve Jobs announced that the iPhone would ""run applications created with Web 2.0 Internet standards"".[7] No software development kit (SDK) was required, and the apps would be fully integrated into the device through the Safari browser engine.[8] This model was later switched to the App Store, as a means of appeasing frustrated developers.[9] In October ",Technology & Computing 
"Web performance
Web performance refers to the speed in which web pages are downloaded and displayed on the user's web browser. Web performance optimization (WPO), or website optimization is the field of knowledge about increasing web performance.
Faster website download speeds have been shown to increase visitor retention and loyalty[1][2] and user satisfaction, especially for users with slow internet connections and those on mobile devices.[3] Web performance also leads to less data travelling across the web, which in turn lowers a website's power consumption and environmental impact.[4] Some aspects which can affect the speed of page load include browser/server cache, image optimization, and encryption (for example SSL), which can affect the time it takes for pages to render. The performance of the web page can be improved through techniques such as multi-layered cache, light weight design of presentation layer components and asynchronous communication with server side components.
History
[edit]In the first decade or so of the web's existence, web performance improvement was focused mainly on optimizing website code and pushing hardware limitations. According to the 2002 book Web Performance Tuning by Patrick Killelea, some of the early techniques used were to use simple servlets or CGI, increase server memory, and look for packet loss and retransmission.[5] Although these principles now comprise much of the optimized foundation of internet applications, they differ from cu",Technology & Computing 
"Internationalization
Internationalization or Internationalisation is the process of increasing involvement of enterprises in international markets, although there is no agreed definition of internationalization.[1] Internationalization is a crucial strategy not only for companies that seek horizontal integration globally but also for countries that addresses the sustainability of its development in different manufacturing as well as service sectors especially in higher education which is a very important context that needs internationalization to bridge the gap between different cultures and countries.[2] There are several internationalization theories which try to explain why there are international activities.
Entrepreneurs and enterprises
[edit]Those entrepreneurs who are interested in the field of internationalization of business need to possess the ability to think globally and have an understanding of international cultures. By appreciating and understanding different beliefs, values, behaviors and business strategies of a variety of companies within other countries, entrepreneurs will be able to internationalize successfully. Entrepreneurs must also have an ongoing concern for innovation, maintaining a high level of quality, be committed to corporate social responsibility, and continue to strive to provide the best business strategies and either goods or services possible while adapting to different countries and cultures.
Trade theories
[edit]Absolute cost advantage (",economics_finance
"Internet security
Internet security is a branch of computer security. It encompasses the Internet, browser security, web site security,[1] and network security as it applies to other applications or operating systems as a whole. Its objective is to establish rules and measures to use against attacks over the Internet.[2] The Internet is an inherently insecure channel for information exchange, with high risk of intrusion or fraud, such as phishing,[3] online viruses, trojans, ransomware and worms.
Many methods are used to combat these threats, including encryption and ground-up engineering.[4]
Threats
[edit]Emerging Threats
[edit]Emerging cyberthreats are a result of recent technological breakthroughs. For example, deepfakes use AI to produce audio and video that seems real but are actually fake, which increases the danger of fraud and false information. Furthermore, traditional risks can be automated and strengthened by AI-driven attacks, making them harder to identify and neutralize.
Malicious software
[edit]Malicious software comes in many forms, such as viruses, Trojan horses, spyware, and worms.
- Malware, a portmanteau of malicious software, is any software used to disrupt computer operation, gather sensitive information, or gain access to private computer systems. Malware is defined by its malicious intent, acting against the requirements of the computer user, and does not include software that unintentionally causes harm due to some deficiency. The term badware applies",Technology & Computing 
"Cross-origin resource sharing
Cross-origin resource sharing (CORS) is a mechanism to safely bypass the same-origin policy; that is, it allows a web page to access restricted resources from a server on a domain different than the domain that served the web page.
A web page may freely embed cross-origin images, stylesheets, scripts, iframes, and videos. Certain ""cross-domain"" requests, notably Ajax requests, are forbidden by default by the same-origin security policy. CORS defines a way in which a browser and server can interact to determine whether it is safe to allow the cross-origin request.[1] It allows for more freedom and functionality than purely same-origin requests, but is more secure than simply allowing all cross-origin requests.
The specification for CORS is included as part of the WHATWG's Fetch Living Standard.[2] This specification describes how CORS is currently implemented in browsers.[3] An earlier specification was published as a W3C Recommendation.[4]
Technical overview
[edit]For HTTP requests made from JavaScript that can't be made by using a <form> tag pointing to another domain or containing non-safelisted headers, the specification mandates that browsers ""preflight"" the request, soliciting supported methods from the server with an HTTP OPTIONS request method, and then, upon ""approval"" from the server, sending the actual request with the actual HTTP request method. Servers can also notify clients whether ""credentials"" (including Cookies and HTTP Authentic",Technology & Computing 
"Cross-site request forgery
Cross-site request forgery, also known as one-click attack or session riding and abbreviated as CSRF (sometimes pronounced sea-surf[1]) or XSRF, is a type of malicious exploit of a website or web application where unauthorized commands are submitted from a user that the web application trusts.[2] There are many ways in which a malicious website can transmit such commands; specially-crafted image tags, hidden forms, and JavaScript fetch or XMLHttpRequests, for example, can all work without the user's interaction or even knowledge. Unlike cross-site scripting (XSS), which exploits the trust a user has for a particular site, CSRF exploits the trust that a site has in a user's browser.[3] In a CSRF attack, an innocent end user is tricked by an attacker into submitting a web request that they did not intend. This may cause actions to be performed on the website that can include inadvertent client or server data leakage, change of session state, or manipulation of an end user's account.
The term ""CSRF"" is also used as an abbreviation in defences against CSRF attacks, such as techniques that use header data, form data, or cookies, to test for and prevent such attacks.
Characteristics
[edit]In a CSRF attack, the attacker's goal is to cause an innocent victim to unknowingly submit a maliciously crafted web request to a website that the victim has privileged access to. This web request can be crafted to include URL parameters, cookies and other data that appe",Technology & Computing 
"Cross-site scripting
Cross-site scripting (XSS)[a] is a type of security vulnerability that can be found in some web applications. XSS attacks enable attackers to inject client-side scripts into web pages viewed by other users. A cross-site scripting vulnerability may be used by attackers to bypass access controls such as the same-origin policy. During the second half of 2007, XSSed documented 11,253 site-specific cross-site vulnerabilities, compared to 2,134 ""traditional"" vulnerabilities documented by Symantec.[1] XSS effects vary in range from petty nuisance to significant security risk, depending on the sensitivity of the data handled by the vulnerable site and the nature of any security mitigation implemented by the site's owner network.
OWASP considers the term cross-site scripting to be a misnomer. It initially was an attack that was used for breaching data across sites, but gradually started to include other forms of data injection attacks.[2]
Background
[edit]Security on the web depends on a variety of mechanisms, including an underlying concept of trust known as the same-origin policy. This states that if content from one site (such as https://mybank.example1.com) is granted permission to access resources (like cookies etc.) on a web browser, then content from any URL with the same (1) URI scheme (e.g. ftp, http, or https), (2) host name, and (3) port number will share these permissions. Content from URLs where any of these three attributes are different will have to",Technology & Computing 
"SQL injection
In computing, SQL injection is a code injection technique used to attack data-driven applications, in which malicious SQL statements are inserted into an entry field for execution (e.g. to dump the database contents to the attacker).[1][2] SQL injection must exploit a security vulnerability in an application's software, for example, when user input is either incorrectly filtered for string literal escape characters embedded in SQL statements or user input is not strongly typed and unexpectedly executed. SQL injection is mostly known as an attack vector for websites but can be used to attack any type of SQL database.
SQL injection attacks allow attackers to spoof identity, tamper with existing data, cause repudiation issues such as voiding transactions or changing balances, allow the complete disclosure of all data on the system, destroy the data or make it otherwise unavailable, and become administrators of the database server. Document-oriented NoSQL databases can also be affected by this security vulnerability.[citation needed]
SQL injection remains a widely recognized security risk due to its potential to compromise sensitive data. The Open Web Application Security Project (OWASP) describes it as a vulnerability that occurs when applications construct database queries using unvalidated user input. Exploiting this flaw, attackers can execute unintended database commands, potentially accessing, modifying, or deleting data. OWASP outlines several mitigation stra",Technology & Computing 
"Clickjacking
Clickjacking (classified as a user interface redress attack or UI redressing) is a malicious technique of tricking a user into clicking on something different from what the user perceives, thus potentially revealing confidential information or allowing others to take control of their computer while clicking on seemingly innocuous objects, including web pages.[1][2][3][4][5]
Clickjacking is an instance of the confused deputy problem, wherein a computer is tricked into misusing its authority.[6]
History
[edit]In 2002, it had been noted that it was possible to load a transparent layer over a web page and have the user's input affect the transparent layer without the user noticing.[7] However, fixes only started to trickle in around 2004,[8] and the general problem was mostly ignored as a major issue until 2008.[7]
In 2008, Jeremiah Grossman and Robert Hansen (of SecTheory) had discovered that Adobe Flash Player was able to be clickjacked, allowing an attacker to gain access to a user's computer without the user's knowledge.[7] Grossman and Hansen coined the term ""clickjacking"",[9][10] a portmanteau of the words ""click"" and ""hijacking"".[7]
As more attacks of a similar nature were discovered, the focus of the term ""UI redressing"" was changed to describe the category of these attacks, rather than just clickjacking itself.[7]
Description
[edit]One form of clickjacking takes advantage of vulnerabilities that are present in applications or web pages to allow the attacker ",Technology & Computing 
"Content Security Policy
Content Security Policy (CSP) is a computer security standard introduced to prevent cross-site scripting (XSS), clickjacking and other code injection attacks resulting from execution of malicious content in the trusted web page context.[1] It is a Candidate Recommendation of the W3C working group on Web Application Security,[2] widely supported by modern web browsers.[3] CSP provides a standard method for website owners to declare approved origins of content that browsers should be allowed to load on that website—covered types are JavaScript, CSS, HTML frames, web workers, fonts, images, embeddable objects such as Java applets, ActiveX, audio and video files, and other HTML5 features.
Status
[edit]The standard, originally named Content Restrictions, was proposed by Robert Hansen in 2004,[4] first implemented in Firefox 4 and quickly picked up by other browsers. Version 1 of the standard was published in 2012 as W3C candidate recommendation[5] and quickly with further versions (Level 2) published in 2014. As of 2023[update], the draft of Level 3 is being developed with the new features being quickly adopted by the web browsers.[6]
The following header names are in use as part of experimental CSP implementations:[3]
Content-Security-Policy
– standard header name proposed by the W3C document. Google Chrome supports this as of version 25.[7] Firefox supports this as of version 23,[8] released on 6 August 2013.[9] WebKit supports this as of version 528 (nig",Technology & Computing 
"HTTP/2
HTTP/2 (originally named HTTP/2.0) is a major revision of the HTTP network protocol used by the World Wide Web. It was derived from the earlier experimental SPDY protocol, originally developed by Google.[1][2] HTTP/2 was developed by the HTTP Working Group (also called httpbis, where ""bis"" means ""twice"") of the Internet Engineering Task Force (IETF).[3][4][5] HTTP/2 is the first new version of HTTP since HTTP/1.1, which was standardized in RFC 2068 in 1997. The Working Group presented HTTP/2 to the Internet Engineering Steering Group (IESG) for consideration as a Proposed Standard in December 2014,[6][7] and IESG approved it to publish as Proposed Standard on February 17, 2015 (and was updated in February 2020 in regard to TLS 1.3 and again in June 2022). The initial HTTP/2 specification was published as on May 14, 2015.[8]
The standardization effort was supported by Chrome, Opera, Firefox, Internet Explorer 11, Safari, Amazon Silk, and Edge browsers. Most major browsers had added HTTP/2 support by the end of 2015.[9] About 97% of web browsers used have the capability (and 100% of ""tracked desktop"" web browsers).[9] As of July 2023[update], 36% (after topping out at just over 50%) of the top 10 million websites support HTTP/2.[10]
Its successor is HTTP/3, a major revision that builds on the concepts established by HTTP/2.[2][11][9][12]
Goals
[edit]The working group charter mentions several goals and issues of concern:[4]
- Create a negotiation mechanism that allows cli",Technology & Computing 
"HTTP/3
HTTP/3 is the third major version of the Hypertext Transfer Protocol used to exchange information on the World Wide Web, complementing the widely deployed HTTP/1.1 and HTTP/2. Unlike previous versions which relied on the well-established TCP (published in 1974),[2] HTTP/3 uses QUIC (officially introduced in 2021),[3] a multiplexed transport protocol built on UDP.[4]
HTTP/3 uses similar semantics compared to earlier revisions of the protocol, including the same request methods, status codes, and message fields, but encodes them and maintains session state differently. However, partially due to the protocol's adoption of QUIC, HTTP/3 has lower latency and loads more quickly in real-world usage when compared with previous versions: in some cases over four times as fast than with HTTP/1.1 (which, for many websites, is the only HTTP version deployed).[5][6]
As of September 2024, HTTP/3 is supported by more than 95% of major web browsers in use[7] and 34% of the top 10 million websites.[8] It has been supported by Chromium (and derived projects including Google Chrome, Microsoft Edge, Samsung Internet, and Opera)[9] since April 2020 and by Mozilla Firefox since May 2021.[7][10] Safari 14 implemented the protocol but it remains disabled by default.[11]
History
[edit]HTTP/3 originates from an Internet Draft adopted by the QUIC working group. The original proposal was named ""HTTP/2 Semantics Using The QUIC Transport Protocol"",[12] and later renamed ""Hypertext Transfer Protocol ",Technology & Computing 
"QUIC
QUIC (/kwɪk/) is a general-purpose transport layer network protocol initially designed by Jim Roskind at Google.[1][2][3] It was first implemented and deployed in 2012[4] and was publicly announced in 2013 as experimentation broadened. It was also described at an IETF meeting.[5][6][7][8] The Chrome web browser,[9] Microsoft Edge,[10][11] Firefox,[12] and Safari all support it.[13] In Chrome, QUIC is used by more than half of all connections to Google's servers.[9]
QUIC improves performance of connection-oriented web applications that before QUIC used Transmission Control Protocol (TCP).[2][9] It does this by establishing a number of multiplexed connections between two endpoints using User Datagram Protocol (UDP), and is designed to obsolete TCP at the transport layer for many applications. Although its name was initially proposed as an acronym for Quick UDP Internet Connections, in IETF's use of the word, QUIC is not an acronym; it is simply the name of the protocol.[3][8][1]
QUIC works hand-in-hand with HTTP/3's multiplexed connections, allowing multiple streams of data to reach all the endpoints independently, and hence independent of packet losses involving other streams. In contrast, HTTP/2 carried over TCP can suffer head-of-line-blocking delays if multiple streams are multiplexed on a TCP connection and any of the TCP packets on that connection are delayed or lost.
QUIC's secondary goals include reduced connection and transport latency, and bandwidth estimation in",Technology & Computing 
"Internet protocol suite
The Internet protocol suite, commonly known as TCP/IP, is a framework for organizing the communication protocols used in the Internet and similar computer networks according to functional criteria. The foundational protocols in the suite are the Transmission Control Protocol (TCP), the User Datagram Protocol (UDP), and the Internet Protocol (IP). Early versions of this networking model were known as the Department of Defense (DoD) model because the research and development were funded by the United States Department of Defense through DARPA.
The Internet protocol suite provides end-to-end data communication specifying how data should be packetized, addressed, transmitted, routed, and received. This functionality is organized into four abstraction layers, which classify all related protocols according to each protocol's scope of networking.[1][2] An implementation of the layers for a particular application forms a protocol stack. From lowest to highest, the layers are the link layer, containing communication methods for data that remains within a single network segment (link); the internet layer, providing internetworking between independent networks; the transport layer, handling host-to-host communication; and the application layer, providing process-to-process data exchange for applications.
The technical standards underlying the Internet protocol suite and its constituent protocols are maintained by the Internet Engineering Task Force (IETF). The In",Technology & Computing 
"Internet Control Message Protocol
The Internet Control Message Protocol (ICMP) is a supporting protocol[2] in the Internet protocol suite. It is used by network devices, including routers, to send error messages and operational information indicating success or failure when communicating with another IP address. For example, an error is indicated when a requested service is not available or that a host or router could not be reached.[3] ICMP differs from transport protocols such as TCP and UDP in that it is not typically used to exchange data between systems, nor is it regularly employed by end-user network applications (with the exception of some diagnostic tools like ping and traceroute).
A separate Internet Control Message Protocol (called ICMPv6) is used with IPv6.[4]
Technical details
[edit]ICMP is part of the Internet protocol suite as defined in RFC 792. ICMP messages are typically used for diagnostic or control purposes or generated in response to errors in IP operations (as specified in RFC 1122). ICMP errors are directed to the source IP address of the originating packet.[3]
For example, every device (such as an intermediate router) forwarding an IP datagram first decrements the time to live (TTL) field in the IP header by one. If the resulting TTL is 0, the packet is discarded and an ICMP time exceeded message is sent to the datagram's source address.
Many commonly used network utilities are based on ICMP messages. The traceroute command can be implemented by trans",Technology & Computing 
"Border Gateway Protocol
Border Gateway Protocol (BGP) is a standardized exterior gateway protocol designed to exchange routing and reachability information among autonomous systems (AS) on the Internet.[2] BGP is classified as a path-vector routing protocol,[3] and it makes routing decisions based on paths, network policies, or rule-sets configured by a network administrator.
BGP used for routing within an autonomous system is called Interior Border Gateway Protocol (iBGP). In contrast, the Internet application of the protocol is called Exterior Border Gateway Protocol (EBGP).
History
[edit]The genesis of BGP was in 1989 when Kirk Lougheed, Len Bosack and Yakov Rekhter were sharing a meal at an IETF conference. They famously sketched the outline of their new routing protocol on the back of some napkins, hence often referenced to as the “Two Napkin Protocol”.[4][5][6]
It was first described in 1989 in RFC 1105, and has been in use on the Internet since 1994.[7] IPv6 BGP was first defined in RFC 1654 in 1994, and it was improved to RFC 2283 in 1998.
The current version of BGP is version 4 (BGP4), which was first published as RFC 1654 in 1994, subsequently updated by RFC 1771 in 1995 and RFC 4271 in 2006.[8] RFC 4271 corrected errors, clarified ambiguities and updated the specification with common industry practices. The major enhancement of BGP4 was the support for Classless Inter-Domain Routing (CIDR) and use of route aggregation to decrease the size of routing tables. RFC 427",Technology & Computing 
"Open Shortest Path First
Open Shortest Path First (OSPF) is a routing protocol for Internet Protocol (IP) networks. It uses a link state routing (LSR) algorithm and falls into the group of interior gateway protocols (IGPs), operating within a single autonomous system (AS).
OSPF gathers link state information from available routers and constructs a topology map of the network. The topology is presented as a routing table to the internet layer for routing packets by their destination IP address. OSPF supports Internet Protocol version 4 (IPv4) and Internet Protocol version 6 (IPv6) networks and is widely used in large enterprise networks. IS-IS, another LSR-based protocol, is more common in large service provider networks.
Originally designed in the 1980s, OSPF version 2 is defined in RFC 2328 (1998).[1] The updates for IPv6 are specified as OSPF version 3 in RFC 5340 (2008).[2] OSPF supports the Classless Inter-Domain Routing (CIDR) addressing model.
Concepts
[edit]OSPF is an interior gateway protocol (IGP) for routing Internet Protocol (IP) packets within a single routing domain, such as an autonomous system. It gathers link state information from available routers and constructs a topology map of the network. The topology is presented as a routing table to the internet layer which routes packets based solely on their destination IP address.
OSPF detects changes in the topology, such as link failures, and converges on a new loop-free routing structure within seconds.[3] It co",Technology & Computing 
"Rest in peace
Rest in peace (R.I.P.),[1] a phrase from the Latin requiescat in pace (Ecclesiastical Latin: [rekwiˈeskat in ˈpatʃe]), is sometimes used in traditional Christian services and prayers, such as in the Catholic,[2] Lutheran,[3] Anglican, and Methodist[4] denominations, to wish the soul of a decedent eternal rest and peace.
It became ubiquitous on headstones in the 19th century, and is widely used today when mentioning someone's death.
Description
[edit]The phrase dormit in pace (English: ""[he] sleeps in peace"") was found in the catacombs of the early Christians and indicated that ""they died in the peace of the Church, that is, united in Christ.""[5][6][7] The abbreviation R.I.P., meaning Requiescat in pace, ""May he/she rest in peace"" (present/subjunctive/active/3rd person/singular), continues to be engraved on the gravestones of Christians,[8] especially in the Catholic, Lutheran, and Anglican denominations.[9]
In the Tridentine Requiem Mass of the Catholic Church the phrase appears several times.[10]
Other variations include ""Requiescat in pace et in amore"" for ""May he/she rest in peace and love"" and ""In pace requiescat et in amore"". The word order is variable because Latin syntactical relationships are indicated by the inflexional endings, not by word order. If ""Rest in peace"" is used in an imperative mood, it would be ""Requiesce in pace"" (acronym R.I.P.) in the second person singular, or ""Requiescite in pace"" in the second person plural.[11]
History
[edit]The phr",history
"Multiprotocol Label Switching
Multiprotocol Label Switching (MPLS) is a routing technique in telecommunications networks that directs data from one node to the next based on labels rather than network addresses.[1] Whereas network addresses identify endpoints, the labels identify established paths between endpoints. MPLS can encapsulate packets of various network protocols, hence the multiprotocol component of the name. MPLS supports a range of access technologies, including T1/E1, ATM, Frame Relay, and DSL.
Role and functioning
[edit]In an MPLS network, labels are assigned to data packets. Packet-forwarding decisions are made solely on the contents of this label, without the need to examine the packet itself. This allows one to create end-to-end circuits across any type of transport medium, using any protocol. The primary benefit is to eliminate dependence on a particular OSI model data link layer (layer 2) technology, and eliminate the need for multiple layer-2 networks to satisfy different types of traffic. Multiprotocol label switching belongs to the family of packet-switched networks.
MPLS operates at a layer that is generally considered to lie between traditional definitions of OSI Layer 2 (data link layer) and Layer 3 (network layer), and thus is often referred to as a layer 2.5 protocol. It was designed to provide a unified data-carrying service for both circuit-based clients and packet-switching clients which provide a datagram service model. It can be used to carry ",Technology & Computing 
"WireGuard
WireGuard is a communication protocol and free and open-source software that implements encrypted virtual private networks (VPNs).[5] It aims to be lighter and better performing than IPsec and OpenVPN, two common tunneling protocols.[6] The WireGuard protocol passes traffic over UDP.[7]
In March 2020, the Linux version of the software reached a stable production release and was incorporated into the Linux 5.6 kernel, and backported to earlier Linux kernels in some Linux distributions.[4] The Linux kernel components are licensed under the GNU General Public License (GPL) version 2; other implementations are under GPLv2 or other free/open-source licenses.[5]
Protocol
[edit]The WireGuard protocol is a variant of the Noise Protocol Framework IK
handshake pattern, as illustrated by the choice of Noise_IKpsk2_25519_ChaChaPoly_BLAKE2s
for the value of the Construction string listed on p10 of the Whitepaper.
WireGuard uses the following:[8]
- Curve25519 for key exchange
- ChaCha20 for symmetric encryption
- Poly1305 for message authentication codes
- SipHash24 for hashtable keys
- BLAKE2s for cryptographic hash function
- HKDF for key derivation function
- UDP-based only[7]
- Base64-encoded private keys, public keys and preshared keys
In May 2019, researchers from INRIA published a machine-checked proof of the WireGuard protocol, produced using the CryptoVerif proof assistant.[9]
Optional pre-shared symmetric key mode
[edit]WireGuard supports pre-shared symmetric key mode, ",Technology & Computing 
"OpenVPN
OpenVPN is a virtual private network (VPN) system that implements techniques to create secure point-to-point or site-to-site connections in routed or bridged configurations and remote access facilities. It implements both client and server applications.
OpenVPN allows peers to authenticate each other using pre-shared secret keys, certificates or username/password. When used in a multiclient-server configuration, it allows the server to release an authentication certificate for every client, using signatures and certificate authority.
It uses the OpenSSL encryption library extensively, as well as the TLS protocol, and contains many security and control features. It uses a custom security protocol[11] that utilizes SSL/TLS for key exchange. It is capable of traversing network address translators (NATs) and firewalls.[citation needed]
OpenVPN has been ported and embedded to several systems. For example, DD-WRT has the OpenVPN server function. SoftEther VPN, a multi-protocol VPN server, also has an implementation of OpenVPN protocol.[12]
It was written by James Yonan and is free software, released under the terms of the GNU General Public License version 2 (GPLv2).[13] Additionally, commercial licenses are available.[14]
Architecture
[edit]Encryption
[edit]OpenVPN uses the OpenSSL library to provide encryption of both the data and control channels. It lets OpenSSL do all the encryption and authentication work, allowing OpenVPN to use all the ciphers available in the OpenS",Technology & Computing 
"IPsec
In computing, Internet Protocol Security (IPsec) is a secure network protocol suite that authenticates and encrypts packets of data to provide secure encrypted communication between two computers over an Internet Protocol network. It is used in virtual private networks (VPNs).
IPsec includes protocols for establishing mutual authentication between agents at the beginning of a session and negotiation of cryptographic keys to use during the session. IPsec can protect data flows between a pair of hosts (host-to-host), between a pair of security gateways (network-to-network), or between a security gateway and a host (network-to-host).[1] IPsec uses cryptographic security services to protect communications over Internet Protocol (IP) networks. It supports network-level peer authentication, data origin authentication, data integrity, data confidentiality (encryption), and protection from replay attacks.
The protocol was designed by a committee instead of being designed via a competition. Some experts criticized it, stating that it is complex and with a lot of options, which has a devastating effect on a security standard.[2] There is alleged interference of NSA to weaken its security features.
History
[edit]Starting in the early 1970s, the Advanced Research Projects Agency sponsored a series of experimental ARPANET encryption devices, at first for native ARPANET packet encryption and subsequently for TCP/IP packet encryption; some of these were certified and fielded. From 198",Technology & Computing 
"FTPS
FTPS (also known as FTP-SSL and FTP Secure) is an extension to the commonly used File Transfer Protocol (FTP) that adds support for the Transport Layer Security (TLS) and, formerly, the Secure Sockets Layer (SSL, which is now prohibited by RFC7568) cryptographic protocols.
FTPS should not be confused with the SSH File Transfer Protocol (SFTP), a secure file transfer subsystem for the Secure Shell (SSH) protocol with which it is not compatible. It is also different from FTP over SSH, which is the practice of tunneling FTP through an SSH connection.
Background
[edit]The File Transfer Protocol was drafted in 1971 for use with the scientific and research network, ARPANET.[1] Access to the ARPANET during this time was limited to a small number of military sites and universities and a narrow community of users who could operate without data security and privacy requirements within the protocol.
As the ARPANET gave way to the NSFNET and then the Internet, a broader population potentially had access to the data as it traversed increasingly longer paths from client to server. The opportunity for unauthorized third parties to eavesdrop on data transmissions increased proportionally.
In 1994, the Internet browser company Netscape developed and released the application layer wrapper, Secure Sockets Layer.[2] This protocol enabled applications to communicate across a network in a private and secure fashion, discouraging eavesdropping, tampering, and message forgery. While it could ad",Technology & Computing 
"SFTP
Appearance
SFTP may refer to:
Computing
[edit]- SSH File Transfer Protocol, a network protocol used for secure file transfer over secure shell
- Secure file transfer program, an SSH File Transfer Protocol client from the OpenSSH project
- Simple File Transfer Protocol, an unsecured file transfer protocol from the early days of the Internet
- Screened fully shielded twisted pair, a kind of network cable
Other
[edit]- Science for the People, a U.S. left-wing organization and magazine
- Six Flags Theme Parks, chain of amusement parks and theme parks
- Stray from the Path, an American metalcore band
- Supplemental Federal Test Procedure, EPA fuel economy testing procedures which supplement FTP-75 standard
See also
[edit]- FTPS, or FTP over SSL, another name used to encompass a number of ways in which FTP software can perform secure file transfers",Technology & Computing 
"SMB
Appearance
Look up SMB in Wiktionary, the free dictionary.
SMB may refer to:
Business
[edit]- Small and medium-sized enterprises (SMEs), also known as small and medium-sized businesses (SMBs)
Arts and entertainment
[edit]- Sveriges Medeltida Ballader, a compilation of Swedish medieval ballads
- Michigan State University Spartan Marching Band
- Super Mario Bros., a 1985 NES video game
- Super Mario Bros. (disambiguation), other articles related to the NES game
- Super Monkey Ball, a video game series
- Super Monkey Ball (video game), the first game in the series
- Super Meat Boy, a 2010 platform video game
- Super Mega Baseball, a sports video game series
Music
[edit]- ""SMB"", a song by Tech N9ne from Something Else, 2013
- ""SMB"" (Odetari and Hongjoong song), 2025
Science
[edit]- Society for Mathematical Biology
- Surface mass balance of a glacier or ice sheet
Technology
[edit]Electronics and computing
[edit]- SMB connector, SubMiniature B connector
- System Management Bus, for computer communication
- Server Message Block (SMB or SMB/CIFS), a network protocol
Other technologies
[edit]- Simulated moving bed for chromatographic separation
- Surface marker buoy, to indicate a diver's position
- Survey motor boat, for hydrographic survey
Other uses
[edit]- San Miguel Beermen (disambiguation), the name of several Philippine basketball teams
- Sean Murphy-Bunting, an American footballer
- Sekolah Menengah Berakas (Berakas Secondary School), Brunei
- Seven Mile Beach, Grand Cayma",Sports & Recreation 
"Server Message Block
Server Message Block (SMB) is a communication protocol[1] used to share files, printers, serial ports, and miscellaneous communications between nodes on a network. On Microsoft Windows, the SMB implementation consists of two vaguely named Windows services: ""Server"" (ID: LanmanServer
) and ""Workstation"" (ID: LanmanWorkstation
).[2] It uses NTLM or Kerberos protocols for user authentication. It also provides an authenticated inter-process communication (IPC) mechanism.
SMB was originally developed in 1983 by Barry A. Feigenbaum at IBM[3] to share access to files and printers across a network of systems running IBM's IBM PC DOS. In 1987, Microsoft and 3Com implemented SMB in LAN Manager for OS/2, at which time SMB used the NetBIOS service atop the NetBIOS Frames protocol as its underlying transport. Later, Microsoft implemented SMB in Windows NT 3.1 and has been updating it ever since, adapting it to work with newer underlying transports: TCP/IP and NetBT. SMB over QUIC was introduced in Windows Server 2022.
In 1996, Microsoft published a version of SMB 1.0[4] with minor modifications under the Common Internet File System (CIFS /sɪfs/) moniker. CIFS was compatible with even the earliest incarnation of SMB, including LAN Manager's.[4] It supports symbolic links, hard links, and larger file size, but none of the features of SMB 2.0 and later.[4][5] Microsoft's proposal, however, remained an Internet Draft and never achieved standard status.[6] Microsoft has si",Technology & Computing 
"Secure Shell
The Secure Shell Protocol (SSH Protocol) is a cryptographic network protocol for operating network services securely over an unsecured network.[1] Its most notable applications are remote login and command-line execution.
SSH was designed for Unix-like operating systems as a replacement for Telnet and unsecured remote Unix shell protocols, such as the Berkeley Remote Shell (rsh) and the related rlogin and rexec protocols, which all use insecure, plaintext methods of authentication, like passwords.
Since mechanisms like Telnet and Remote Shell are designed to access and operate remote computers, sending the authentication tokens (e.g. username and password) for this access to these computers across a public network in an unsecured way poses a great risk of 3rd parties obtaining the password and achieving the same level of access to the remote system as the telnet user. Secure Shell mitigates this risk through the use of encryption mechanisms that are intended to hide the contents of the transmission from an observer, even if the observer has access to the entire data stream.[2]
Finnish computer scientist Tatu Ylönen designed SSH in 1995 and provided an implementation in the form of two commands, ssh and slogin, as secure replacements for rsh and rlogin, respectively. Subsequent development of the protocol suite proceeded in several developer groups, producing several variants of implementation. The protocol specification distinguishes two major versions, referred ",Technology & Computing 
"Telnet
Telnet (sometimes stylized TELNET[1]) is a client-server application protocol that provides access to virtual terminals of remote systems on local area networks or the Internet.[2] It is a protocol for bidirectional 8-bit communications. Its main goal was to connect terminal devices and terminal-oriented processes.[1]
The name ""Telnet"" refers to two things: a protocol itself specifying how two parties are to communicate and a software application that implements the protocol as a service.[2] User data is interspersed in-band with Telnet control information in an 8-bit byte oriented data connection over the Transmission Control Protocol (TCP). Telnet transmits all information including usernames and passwords in plaintext so it is not recommended for security-sensitive applications such as remote management of routers.[2][3] Telnet's use for this purpose has waned significantly in favor of SSH.[4] Some extensions to Telnet which would provide encryption have been proposed.[5]
Description
[edit]The telnet protocol is a client-server protocol that runs on a reliable connection-oriented transport.[citation needed] Most often, a telnet client connects over TCP to port 23 or 2323, where a Telnet server application is listening.[1][6][7] The Telnet protocol abstracts any terminal as a Network Virtual Terminal (NVT). The client must simulate a NVT using the NVT codes when messaging the server.
Telnet predated UDP/IP and originally ran over Network Control Protocol (NCP).[8] Th",Technology & Computing 
"Bluetooth
Bluetooth is a short-range wireless technology standard that is used for exchanging data between fixed and mobile devices over short distances and building personal area networks (PANs). In the most widely used mode, transmission power is limited to 2.5 milliwatts, giving it a very short range of up to 10 metres (33 ft). It employs UHF radio waves in the ISM bands, from 2.402 GHz to 2.48 GHz.[3] It is mainly used as an alternative to wired connections to exchange files between nearby portable devices and connect cell phones and music players with wireless headphones, wireless speakers, HIFI systems, car audio and wireless transmission between TVs and soundbars.
Bluetooth is managed by the Bluetooth Special Interest Group (SIG), which has more than 35,000 member companies in the areas of telecommunication, computing, networking, and consumer electronics. The IEEE standardized Bluetooth as IEEE 802.15.1 but no longer maintains the standard. The Bluetooth SIG oversees the development of the specification, manages the qualification program, and protects the trademarks.[4] A manufacturer must meet Bluetooth SIG standards to market it as a Bluetooth device.[5] A network of patents applies to the technology, which is licensed to individual qualifying devices. As of 2021[update], 4.7 billion Bluetooth integrated circuit chips are shipped annually.[6] Bluetooth was first demonstrated in space in 2024, an early test envisioned to enhance IoT capabilities.[7]
Etymology
The nam",Technology & Computing 
"Zigbee
Zigbee is an IEEE 802.15.4-based specification for a suite of high-level communication protocols used to create personal area networks with small, low-power digital radios, such as for home automation, medical device data collection, and other low-power low-bandwidth needs, designed for small scale projects which need wireless connection. Hence, Zigbee is a low-power, low-data-rate, and close proximity (i.e., personal area) wireless ad hoc network.
The technology defined by the Zigbee specification is intended to be simpler and less expensive than other wireless personal area networks (WPANs), such as Bluetooth or more general wireless networking such as Wi-Fi (or Li-Fi). Applications include wireless light switches, home energy monitors, traffic management systems, and other consumer and industrial equipment that requires short-range low-rate wireless data transfer.
Its low power consumption limits transmission distances to 10–100 meters (33–328 ft) line-of-sight, depending on power output and environmental characteristics.[1] Zigbee devices can transmit data over long distances by passing data through a mesh network of intermediate devices to reach more distant ones. Zigbee is typically used in low data rate applications that require long battery life and secure networking. (Zigbee networks are secured by 128-bit symmetric encryption keys.) Zigbee has a defined rate of up to 250 kbit/s, best suited for intermittent data transmissions from a sensor or input device.
Zi",Technology & Computing 
"Z-Wave
Z-Wave is a wireless communications protocol used primarily for residential and commercial building automation. It is a mesh network using low-energy radio waves to communicate from device to device,[2] allowing for wireless control of smart home devices, such as smart lights, security systems, thermostats, sensors, smart door locks, and garage door openers.[3][4] The Z-Wave brand and technology are owned by Silicon Labs. Over 300 companies involved in this technology are gathered within the Z-Wave Alliance.
Like other protocols and systems aimed at the residential, commercial, MDU and building markets, a Z-Wave system can be controlled from a smart phone, tablet, or computer, and locally through a smart speaker, wireless keyfob, or wall-mounted panel with a Z-Wave gateway or central control device serving as both the hub or controller.[3][5] Z-Wave provides the application layer interoperability between home control systems of different manufacturers that are a part of its alliance. There is a growing number of interoperable Z-Wave products; over 1,700 in 2017,[6] over 2,600 by 2019,[7] and over 4,000 by 2022.[8][9]
History
[edit]The Z-Wave protocol was developed by Zensys, a Danish company based in Copenhagen, in 1999.[10][11][12] That year, Zensys introduced a consumer light-control system, which evolved into Z-Wave as a proprietary system on a chip (SoC) home automation protocol on an unlicensed frequency band in the 900 MHz range.[13] Its 100 series chip set was r",Technology & Computing 
"LoRa
LoRa (from ""long range"", sometimes abbreviated as ""LR"") is a physical proprietary radio communication technique.[2] It is based on spread spectrum modulation techniques derived from chirp spread spectrum (CSS) technology.[3] It was developed by Cycleo, a company of Grenoble, France, and patented in 2014.[4] In March 2012, Cycleo was acquired by the US company Semtech.[5]
LoRaWAN (long range wide area network) defines the communication protocol and system architecture. LoRaWAN is an official standard of the International Telecommunication Union (ITU), ITU-T Y.4480.[6] The continued development of the LoRaWAN protocol is managed by the open, non-profit LoRa Alliance, of which Semtech is a founding member.
Together, LoRa and LoRaWAN define a low-power, wide-area (LPWA) networking protocol designed to wirelessly connect battery operated devices to the Internet in regional, national or global networks, and targets key Internet of things (IoT) requirements, such as bi-directional communication, end-to-end security, mobility and localization services. The low power, low bit rate, and IoT use distinguish this type of network from a wireless WAN that is designed to connect users or businesses, and carry more data, using more power. The LoRaWAN data rate ranges from 0.3 kbit/s to 50 kbit/s per channel.[7]
Features
[edit]LoRa uses license-free sub-gigahertz radio frequency bands EU433 (LPD433) or EU868 (863–870/873 MHz) in Europe; AU915/AS923-1 (915–928 MHz) in South America; US915",Technology & Computing 
"Sigfox
Sigfox 0G technology is a global Low-Power Wide-Area (LPWA) networking protocol founded in 2010[1] and adopted by 70+ Sigfox 0G Network Operators globally. This wireless network was designed to connect low-power objects such as electricity meters securely, at low-cost, emitting small amounts of data.
Sigfox is based in Labège near Toulouse, France, and once had over 375 employees in Madrid, San Francisco, Sydney and Paris.[2][3]
The former Sigfox entity had raised more than $300 million from investors that included Salesforce, Intel, Samsung, NTT, SK Telecom, energy groups Total and Air Liquide. In November 2016 Sigfox was valued at around €600 million. In January 2022 it filed for bankruptcy.[4]
In April 2022 Singapore-based IoT company UnaBiz acquired the Sigfox 0G technology and its French network operations for a reported €25 million ($27m).[5]
As of December 2024, the Sigfox 0G network managed by UnaBiz supports over 14 million active connected devices worldwide.[6]
Technology
[edit]Sigfox employs differential binary phase-shift keying (DBPSK) and Gaussian frequency shift keying (GFSK) over the Short-range device band of 868 MHz in Europe, and the Industrial, Scientific and Medical radio band of 902 MHz in the US. It utilizes a wide-reaching signal that passes freely through solid objects, called ""Ultra Narrowband"" and requires little energy, being termed a ""low-power wide-area network"" (LPWAN). The network is based on one-hop star topology.[7] The signal can also",Technology & Computing 
"Radio-frequency identification
Radio-frequency identification (RFID) uses electromagnetic fields to automatically identify and track tags attached to objects. An RFID system consists of a tiny radio transponder called a tag, a radio receiver, and a transmitter. When triggered by an electromagnetic interrogation pulse from a nearby RFID reader device, the tag transmits digital data, usually an identifying inventory number, back to the reader. This number can be used to track inventory goods.[1]
Passive tags are powered by energy from the RFID reader's interrogating radio waves. Active tags are powered by a battery and thus can be read at a greater range from the RFID reader, up to hundreds of meters.
Unlike a barcode, the tag does not need to be within the line of sight of the reader, so it may be embedded in the tracked object. RFID is one method of automatic identification and data capture (AIDC).[2]
RFID tags are used in many industries. For example, an RFID tag attached to an automobile during production can be used to track its progress through the assembly line,[citation needed] RFID-tagged pharmaceuticals can be tracked through warehouses,[citation needed] and implanting RFID microchips in livestock and pets enables positive identification of animals.[3] Tags can also be used in shops to expedite checkout, and to prevent theft by customers and employees.[4]
Since RFID tags can be attached to physical money, clothing, and possessions, or implanted in animals and people, ",Technology & Computing 
"NFC
Appearance
Look up NFC in Wiktionary, the free dictionary.
NFC usually refers to:
- Near-field communication, a set of communication protocols for electronic devices
- National Football Conference, part of US National Football League
NFC may also refer to:
Psychology
[edit]- Need for cognition, in psychology
- Need for closure, social psychological term
Sports
[edit]- NFC Championship Game, the National Football Conference Championship Game
- NCAA Football Championship (Philippines)
- National football centre, soccer centre in several countries
- Newcastle F.C., Northern Irish football team
- Newington F.C., Northern Irish football team
- Newtowne F.C., Northern Irish football team
- Northeast Football Conference, junior college football conference
Organizations
[edit]- National Fertilizer Corporation, a state-owned enterprise in Pakistan
- National Finance Center of the US Department of Agriculture
- Nuclear Fuel Complex, a division of the Department of Atomic Energy in India
- National Finance Commission Award, a series of economic reforms in Pakistan
Other
[edit]- New Friends Colony, a residential neighborhood in India
- News First Class, a news website
- No Fem el CIM, Catalan social movement
- Normalization Form Canonical Composition, one of the forms of Unicode normalization
- Norwegian Forest cat, a breed of domestic cat
See also
[edit]Search for ""nfc"" on Wikipedia.",Sports & Recreation 
"Global Positioning System
The Global Positioning System (GPS) is a satellite-based hyperbolic navigation system owned by the United States Space Force and operated by Mission Delta 31.[2][3] It is one of the global navigation satellite systems (GNSS) that provide geolocation and time information to a GPS receiver anywhere on or near the Earth where there is an unobstructed line of sight to four or more GPS satellites.[4] It does not require the user to transmit any data, and operates independently of any telephone or Internet reception, though these technologies can enhance the usefulness of the GPS positioning information.[5] It provides critical positioning capabilities to military, civil, and commercial users around the world. Although the United States government created, controls, and maintains the GPS system, it is freely accessible to anyone with a GPS receiver.[6]
Overview
[edit]The GPS project was started by the U.S. Department of Defense in 1973.[7] The first prototype spacecraft was launched in 1978 and the full constellation of 24 satellites became operational in 1993.[7] After Korean Air Lines Flight 007 was shot down when it mistakenly entered Soviet airspace, President Ronald Reagan determined that the GPS system would be made available for civilian use as of 1988;[8] however, initially this civilian use was limited to an average accuracy of 100 meters (330 ft) by use of Selective Availability (SA), a deliberate error introduced into the GPS data that military ",Technology & Computing 
"GLONASS
GLONASS (ГЛОНАСС, IPA: [ɡɫɐˈnas]; Russian: Глобальная навигационная спутниковая система, romanized: Global'naya Navigatsionnaya Sputnikovaya Sistema, lit. 'Global Navigation Satellite System') is a Russian satellite navigation system operating as part of a radionavigation-satellite service. It provides an alternative to Global Positioning System (GPS) and is the second navigational system in operation with global coverage and of comparable precision.
Satellite navigation devices supporting both GPS and GLONASS have more satellites available, meaning positions can be fixed more quickly and accurately, especially in built-up areas where buildings may obscure the view to some satellites.[1][2][3] Owing to its higher orbital inclination, GLONASS supplementation of GPS systems also improves positioning in high latitudes (near the poles).[4]
Development of GLONASS began in the Soviet Union in 1976. Beginning on 12 October 1982, numerous rocket launches added satellites to the system until the completion of the constellation in 1995. In 2001, after a decline in capacity during the late 1990s, the restoration of the system was made a government priority, and funding increased substantially. GLONASS is the most expensive program of Roscosmos, consuming a third of its budget in 2010.
By 2010, GLONASS had achieved full coverage of Russia's territory. In October 2011, the full orbital constellation of 24 satellites was restored, enabling full global coverage. The GLONASS satellit",Technology & Computing 
"Satellite navigation
A satellite navigation (or satnav) is a system that uses satellites to provide autonomous geopositioning. A global navigation satellite system (GNSS) is a satellite navigation system with global coverage. There are four globally operational GNSS systems: the United States Global Positioning System (GPS), Russia's Global Navigation Satellite System (GLONASS), China's BeiDou Navigation Satellite System (BDS),[1] and the European Union's Galileo.[2]
A satellite-based augmentation system (SBAS) is a system that designed to enhance the accuracy of the global GNSS systems.[3] The SBAS systems include Japan's Quasi-Zenith Satellite System (QZSS),[3] India's GAGAN, and the European EGNOS, all of them based on GPS. Previous iterations of the BeiDou navigation system and the present Indian Regional Navigation Satellite System (IRNSS), operationally known as NavIC, are examples of stand-alone operating regional navigation satellite systems (RNSS).[4]
Satellite navigation devices determine their location (longitude, latitude, and altitude/elevation) to high precision (within a few centimeters to meters) using time signals transmitted along a line of sight by radio from satellites. The system can be used for providing position, navigation or for tracking the position of something fitted with a receiver (satellite tracking). The signals also allow the electronic receiver to calculate the current local time to a high precision, which allows time synchronisation. These u",Technology & Computing 
"Computer vision
Computer vision tasks include methods for acquiring, processing, analyzing, and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the form of decisions.[1][2][3][4] ""Understanding"" in this context signifies the transformation of visual images (the input to the retina) into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.
The scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images. Image data can take many forms, such as video sequences, views from multiple cameras, multi-dimensional data from a 3D scanner, 3D point clouds from LiDaR sensors, or medical scanning devices. The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems.
Subdisciplines of computer vision include scene reconstruction, object detection, event detection, activity recognition, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modeling, and image restoration.
Definition
[edit]Computer vision is an interdisciplinary field that deals wit",Technology & Computing 
"Computer vision
Computer vision tasks include methods for acquiring, processing, analyzing, and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the form of decisions.[1][2][3][4] ""Understanding"" in this context signifies the transformation of visual images (the input to the retina) into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.
The scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images. Image data can take many forms, such as video sequences, views from multiple cameras, multi-dimensional data from a 3D scanner, 3D point clouds from LiDaR sensors, or medical scanning devices. The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems.
Subdisciplines of computer vision include scene reconstruction, object detection, event detection, activity recognition, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modeling, and image restoration.
Definition
[edit]Computer vision is an interdisciplinary field that deals wit",Technology & Computing 
"Object detection
Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos.[1] Well-researched domains of object detection include face detection and pedestrian detection. Object detection has applications in many areas of computer vision, including image retrieval and video surveillance.
Uses
[edit]It is widely used in computer vision tasks such as image annotation,[2] vehicle counting,[3] activity recognition,[4] face detection, face recognition, video object co-segmentation. It is also used in tracking objects, for example tracking a ball during a football match, tracking movement of a cricket bat, or tracking a person in a video.
Often, the test images are sampled from a different data distribution, making the object detection task significantly more difficult.[5] To address the challenges caused by the domain gap between training and test data, many unsupervised domain adaptation approaches have been proposed.[5][6][7][8][9] A simple and straightforward solution for reducing the domain gap is to apply an image-to-image translation approach, such as cycle-GAN.[10] Among other uses, cross-domain object detection is applied in autonomous driving, where models can be trained on a vast amount of video game scenes, since the labels can be generated without manual labor.
Concept
[edit]Every object class has ",Technology & Computing 
"Image segmentation
In digital image processing and computer vision, image segmentation is the process of partitioning a digital image into multiple image segments, also known as image regions or image objects (sets of pixels). The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze.[1][2] Image segmentation is typically used to locate objects and boundaries (lines, curves, etc.) in images. More precisely, image segmentation is the process of assigning a label to every pixel in an image such that pixels with the same label share certain characteristics.
The result of image segmentation is a set of segments that collectively cover the entire image, or a set of contours extracted from the image (see edge detection). Each of the pixels in a region are similar with respect to some characteristic or computed property,[3] such as color, intensity, or texture. Adjacent regions are significantly different with respect to the same characteristic(s).[1] When applied to a stack of images, typical in medical imaging, the resulting contours after image segmentation can be used to create 3D reconstructions with the help of geometry reconstruction algorithms like marching cubes.[4]
Applications
[edit]Some of the practical applications of image segmentation are:
- Content-based image retrieval[5]
- Machine vision
- Medical imaging,[6][7] and imaging studies in biomedical research, including volume render",Technology & Computing 
"Optical character recognition
Optical character recognition or optical character reader (OCR) is the electronic or mechanical conversion of images of typed, handwritten or printed text into machine-encoded text, whether from a scanned document, a photo of a document, a scene photo (for example the text on signs and billboards in a landscape photo) or from subtitle text superimposed on an image (for example: from a television broadcast).[1]
Widely used as a form of data entry from printed paper data records – whether passport documents, invoices, bank statements, computerized receipts, business cards, mail, printed data, or any suitable documentation – it is a common method of digitizing printed texts so that they can be electronically edited, searched, stored more compactly, displayed online, and used in machine processes such as cognitive computing, machine translation, (extracted) text-to-speech, key data and text mining. OCR is a field of research in pattern recognition, artificial intelligence and computer vision.
Early versions needed to be trained with images of each character, and worked on one font at a time. Advanced systems capable of producing a high degree of accuracy for most fonts are now common, and with support for a variety of image file format inputs.[2] Some systems are capable of reproducing formatted output that closely approximates the original page including images, columns, and other non-textual components.
History
[edit]Early optical character recogni",Technology & Computing 
"Neural style transfer
Neural style transfer (NST) refers to a class of software algorithms that manipulate digital images, or videos, in order to adopt the appearance or visual style of another image. NST algorithms are characterized by their use of deep neural networks for the sake of image transformation. Common uses for NST are the creation of artificial artwork from photographs, for example by transferring the appearance of famous paintings to user-supplied photographs. Several notable mobile apps use NST techniques for this purpose, including DeepArt and Prisma. This method has been used by artists and designers around the globe to develop new artwork based on existent style(s).
History
[edit]NST is an example of image stylization, a problem studied for over two decades within the field of non-photorealistic rendering. The first two example-based style transfer algorithms were image analogies[1] and image quilting.[2] Both of these methods were based on patch-based texture synthesis algorithms.
Given a training pair of images–a photo and an artwork depicting that photo–a transformation could be learned and then applied to create new artwork from a new photo, by analogy. If no training photo was available, it would need to be produced by processing the input artwork; image quilting did not require this processing step, though it was demonstrated on only one style.
NST was first published in the paper ""A Neural Algorithm of Artistic Style"" by Leon Gatys et al., originally ",Technology & Computing 
"Super-resolution imaging
Super-resolution imaging (SR) is a class of techniques that improve the resolution of an imaging system. In optical SR the diffraction limit of systems is transcended, while in geometrical SR the resolution of digital imaging sensors is enhanced.
In some radar and sonar imaging applications (e.g. magnetic resonance imaging (MRI), high-resolution computed tomography), subspace decomposition-based methods (e.g. MUSIC[1]) and compressed sensing-based algorithms (e.g., SAMV[2]) are employed to achieve SR over standard periodogram algorithm.
Super-resolution imaging techniques are used in general image processing and in super-resolution microscopy.
Basic concepts
[edit]Because some of the ideas surrounding super-resolution raise fundamental issues, there is need at the outset to examine the relevant physical and information-theoretical principles:
- Diffraction limit: The detail of a physical object that an optical instrument can reproduce in an image has limits that are mandated by laws of physics, whether formulated by the diffraction equations in the wave theory of light[3] or equivalently the uncertainty principle for photons in quantum mechanics.[4] Information transfer can never be increased beyond this boundary, but packets outside the limits can be cleverly swapped for (or multiplexed with) some inside it.[5] One does not so much “break” as “run around” the diffraction limit. New procedures probing electro-magnetic disturbances at the molecular lev",Technology & Computing 
"3D reconstruction
In computer vision and computer graphics, 3D reconstruction is the process of capturing the shape and appearance of real objects. This process can be accomplished either by active or passive methods.[1] If the model is allowed to change its shape in time, this is referred to as non-rigid or spatio-temporal reconstruction.[2]
Motivation and applications
[edit]The research of 3D reconstruction has always been a difficult goal. By Using 3D reconstruction one can determine any object's 3D profile, as well as knowing the 3D coordinate of any point on the profile. The 3D reconstruction of objects is a generally scientific problem and core technology of a wide variety of fields, such as Computer Aided Geometric Design (CAGD), computer graphics, computer animation, computer vision, medical imaging, computational science, virtual reality, digital media, etc.[3] For instance, the lesion information of the patients can be presented in 3D on the computer, which offers a new and accurate approach in diagnosis and thus has vital clinical value.[4] Digital elevation models can be reconstructed using methods such as airborne laser altimetry[5] or synthetic aperture radar.[6]
Active methods
[edit]Active methods, i.e. range data methods, given the depth map, reconstruct the 3D profile by numerical approximation approach and build the object in scenario based on model. These methods actively interfere with the reconstructed object, either mechanically or radiometrically using ",Technology & Computing 
"Augmented reality
Augmented reality (AR), also known as mixed reality (MR), is a technology that overlays real-time 3D-rendered computer graphics onto a portion of the real world through a display, such as a handheld device or head-mounted display. This experience is seamlessly interwoven with the physical world such that it is perceived as an immersive aspect of the real environment.[1] In this way, augmented reality alters one's ongoing perception of a real-world environment, compared to virtual reality, which aims to completely replace the user's real-world environment with a simulated one.[2][3] Augmented reality is typically visual, but can span multiple sensory modalities, including auditory, haptic, and somatosensory.[4]
The primary value of augmented reality is the manner in which components of a digital world blend into a person's perception of the real world, through the integration of immersive sensations, which are perceived as real in the user's environment. The earliest functional AR systems that provided immersive mixed reality experiences for users were invented in the early 1990s, starting with the Virtual Fixtures system developed at the U.S. Air Force's Armstrong Laboratory in 1992.[1][5][6] Commercial augmented reality experiences were first introduced in entertainment and gaming businesses.[7] Subsequently, augmented reality applications have spanned industries such as education, communications, medicine, and entertainment.
Augmented reality can be used t",Technology & Computing 
"Virtual reality
Virtual reality (VR) is a simulated experience that employs 3D near-eye displays and pose tracking to give the user an immersive feel of a virtual world. Applications of virtual reality include entertainment (particularly video games), education (such as medical, safety, or military training)[1], research [2] [3] [4] and business (such as virtual meetings). VR is one of the key technologies in the reality-virtuality continuum. As such, it is different from other digital visualization solutions, such as augmented virtuality and augmented reality.[5]
Currently, standard virtual reality systems use either virtual reality headsets or multi-projected environments to generate some realistic images, sounds, and other sensations that simulate a user's physical presence in a virtual environment. A person using virtual reality equipment is able to look around the artificial world, move around in it, and interact with virtual features or items. The effect is commonly created by VR headsets consisting of a head-mounted display with a small screen in front of the eyes but can also be created through specially designed rooms with multiple large screens. Virtual reality typically incorporates auditory and video feedback but may also allow other types of sensory and force feedback through haptic technology.
Etymology
""Virtual"" has had the meaning of ""being something in essence or effect, though not actually or in fact"" since the mid-1400s.[6] The term ""virtual"" has been used ",Technology & Computing 
"Augmented reality
Augmented reality (AR), also known as mixed reality (MR), is a technology that overlays real-time 3D-rendered computer graphics onto a portion of the real world through a display, such as a handheld device or head-mounted display. This experience is seamlessly interwoven with the physical world such that it is perceived as an immersive aspect of the real environment.[1] In this way, augmented reality alters one's ongoing perception of a real-world environment, compared to virtual reality, which aims to completely replace the user's real-world environment with a simulated one.[2][3] Augmented reality is typically visual, but can span multiple sensory modalities, including auditory, haptic, and somatosensory.[4]
The primary value of augmented reality is the manner in which components of a digital world blend into a person's perception of the real world, through the integration of immersive sensations, which are perceived as real in the user's environment. The earliest functional AR systems that provided immersive mixed reality experiences for users were invented in the early 1990s, starting with the Virtual Fixtures system developed at the U.S. Air Force's Armstrong Laboratory in 1992.[1][5][6] Commercial augmented reality experiences were first introduced in entertainment and gaming businesses.[7] Subsequently, augmented reality applications have spanned industries such as education, communications, medicine, and entertainment.
Augmented reality can be used t",Technology & Computing 
"Extended reality
Extended reality (XR) is both an umbrella term to refer to and interpolate between augmented reality (AR), mixed reality (MR), and virtual reality (VR), as well as to extrapolate (extend) beyond these, e.g. allowing us to see sound waves, radio waves, and otherwise invisible phenomena[1][2][3]. The technology is intended to combine or mirror the physical world with a ""digital twin world"" able to interact with it,[4][5] giving users an immersive experience by being in a virtual or augmented environment.
XR is rapidly growing beyond an academic discipline, and is now having real-world impact in medicine[6][7], architecture[8], education[9], industry[10], and is being applied in a wide range of areas such as entertainment, cinema, marketing, real estate, manufacturing[11], education, maintenance[12] and remote work.[13] Extended reality has the ability to be used for joint effort in the workplace, training, educational purposes, therapeutic treatments, and data exploration and analysis.
Extended reality works by using visual data acquisition that is either accessed locally or shared and transfers over a network and to the human senses. By enabling real-time responses in a virtual stimulus these devices create customized experiences. Advancing in 5G and edge computing – a type of computing that is done ""at or near the source of data"" – could aid in data rates, increase user capacity, and reduce latency. These applications will likely expand extended reality into ",Technology & Computing 
"XR
Appearance
XR or Xr may refer to:
Science and technology
[edit]- Extended reality, an umbrella term for virtual reality, augmented reality, and mixed reality
- Cisco IOS XR, router software
- Xr, original name of cairo graphics library
- Extended release, a modified-release dosage for medication
- iPhone XR, a smartphone released in 2018
Transportation
[edit]- Ford Falcon (XR), an Australian car
- Honda XR series, motorcycles
Other uses
[edit]- XR, a fictional character in animated TV series Buzz Lightyear of Star Command
- Extinction Rebellion, environmental movement and advocacy group
- Extrapolated Runs, a baseball statistic
- Corendon Airlines Europe, IATA airline code XR
- Chi Rho (☧ or ΧΡ]], a Christogram
See also
[edit]- Exchange rate, rate at which one currency will be exchanged for another
- OpenXR, a standard for access to virtual reality and augmented reality platforms",Technology & Computing 
"Kernel method
In machine learning, kernel machines are a class of algorithms for pattern analysis, whose best known member is the support-vector machine (SVM). These methods involve using linear classifiers to solve nonlinear problems.[1] The general task of pattern analysis is to find and study general types of relations (for example clusters, rankings, principal components, correlations, classifications) in datasets. For many algorithms that solve these tasks, the data in raw representation have to be explicitly transformed into feature vector representations via a user-specified feature map: in contrast, kernel methods require only a user-specified kernel, i.e., a similarity function over all pairs of data points computed using inner products. The feature map in kernel machines is infinite dimensional but only requires a finite dimensional matrix from user-input according to the representer theorem. Kernel machines are slow to compute for datasets larger than a couple of thousand examples without parallel processing.
Kernel methods owe their name to the use of kernel functions, which enable them to operate in a high-dimensional, implicit feature space without ever computing the coordinates of the data in that space, but rather by simply computing the inner products between the images of all pairs of data in the feature space. This operation is often computationally cheaper than the explicit computation of the coordinates. This approach is called the ""kernel trick"".[2] Kern",Technology & Computing 
"Nonlinear dimensionality reduction
Nonlinear dimensionality reduction, also known as manifold learning, is any of various related techniques that aim to project high-dimensional data, potentially existing across non-linear manifolds which cannot be adequately captured by linear decomposition methods, onto lower-dimensional latent manifolds, with the goal of either visualizing the data in the low-dimensional space, or learning the mapping (either from the high-dimensional space to the low-dimensional embedding or vice versa) itself.[1][2] The techniques described below can be understood as generalizations of linear decomposition methods used for dimensionality reduction, such as singular value decomposition and principal component analysis.
Applications of NLDR
[edit]High dimensional data can be hard for machines to work with, requiring significant time and space for analysis. It also presents a challenge for humans, since it's hard to visualize or understand data in more than three dimensions. Reducing the dimensionality of a data set, while keep its essential features relatively intact, can make algorithms more efficient and allow analysts to visualize trends and patterns.
The reduced-dimensional representations of data are often referred to as ""intrinsic variables"". This description implies that these are the values from which the data was produced. For example, consider a dataset that contains images of a letter 'A', which has been scaled and rotated by varying amounts. Ea",Technology & Computing 
"Dimensionality reduction
Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension. Working in high-dimensional spaces can be undesirable for many reasons; raw data are often sparse as a consequence of the curse of dimensionality, and analyzing the data is usually computationally intractable. Dimensionality reduction is common in fields that deal with large numbers of observations and/or large numbers of variables, such as signal processing, speech recognition, neuroinformatics, and bioinformatics.[1]
Methods are commonly divided into linear and nonlinear approaches.[1] Linear approaches can be further divided into feature selection and feature extraction.[2] Dimensionality reduction can be used for noise reduction, data visualization, cluster analysis, or as an intermediate step to facilitate other analyses.
Feature selection
[edit]The process of feature selection aims to find a suitable subset of the input variables (features, or attributes) for the task at hand. The three strategies are: the filter strategy (e.g., information gain), the wrapper strategy (e.g., accuracy-guided search), and the embedded strategy (features are added or removed while building the model based on prediction errors).
Data analysis such as regression or classification can be done",Technology & Computing 
"Wavelet transform
In mathematics, a wavelet series is a representation of a square-integrable (real- or complex-valued) function by a certain orthonormal series generated by a wavelet. This article provides a formal, mathematical definition of an orthonormal wavelet and of the integral wavelet transform.[1][2][3][4]
Definition
[edit]A function is called an orthonormal wavelet if it can be used to define a Hilbert basis, that is, a complete orthonormal system for the Hilbert space of square-integrable functions on the real line.
The Hilbert basis is constructed as the family of functions by means of dyadic translations and dilations of , for integers .
If, under the standard inner product on , this family is orthonormal, then it is an orthonormal system: where is the Kronecker delta.
Completeness is satisfied if every function may be expanded in the basis as
with convergence of the series understood to be convergence in norm. Such a representation of is known as a wavelet series. This implies that an orthonormal wavelet is self-dual.
The integral wavelet transform is the integral transform defined as The wavelet coefficients are then given by
Here, is called the binary dilation or dyadic dilation, and is the binary or dyadic position.
Principle
[edit]The fundamental idea of wavelet transforms is that the transformation should allow only changes in time extension, but not shape, imposing a restriction on choosing suitable basis functions. Changes in the time extension are expec",Technology & Computing 
"Signal processing
Signal processing is an electrical engineering subfield that focuses on analyzing, modifying and synthesizing signals, such as sound, images, potential fields, seismic signals, altimetry processing, and scientific measurements.[1] Signal processing techniques are used to optimize transmissions, digital storage efficiency, correcting distorted signals, improve subjective video quality, and to detect or pinpoint components of interest in a measured signal.[2]
History
[edit]According to Alan V. Oppenheim and Ronald W. Schafer, the principles of signal processing can be found in the classical numerical analysis techniques of the 17th century. They further state that the digital refinement of these techniques can be found in the digital control systems of the 1940s and 1950s.[3]
In 1948, Claude Shannon wrote the influential paper ""A Mathematical Theory of Communication"" which was published in the Bell System Technical Journal.[4] The paper laid the groundwork for later development of information communication systems and the processing of signals for transmission.[5]
Signal processing matured and flourished in the 1960s and 1970s, and digital signal processing became widely used with specialized digital signal processor chips in the 1980s.[5]
Definition of a signal
[edit]A signal is a function , where this function is either[6]
- deterministic (then one speaks of a deterministic signal) or
- a path , a realization of a stochastic process
Categories
[edit]Analog
[",Technology & Computing 
"Digital signal processing
Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations. The digital signals processed in this manner are a sequence of numbers that represent samples of a continuous variable in a domain such as time, space, or frequency. In digital electronics, a digital signal is represented as a pulse train,[1][2] which is typically generated by the switching of a transistor.[3]
Digital signal processing and analog signal processing are subfields of signal processing. DSP applications include audio and speech processing, sonar, radar and other sensor array processing, spectral density estimation, statistical signal processing, digital image processing, data compression, video coding, audio coding, image compression, signal processing for telecommunications, control systems, biomedical engineering, and seismology, among others.
DSP can involve linear or nonlinear operations. Nonlinear signal processing is closely related to nonlinear system identification[4] and can be implemented in the time, frequency, and spatio-temporal domains.
The application of digital computation to signal processing allows for many advantages over analog processing in many applications, such as error detection and correction in transmission as well as data compression.[5] Digital signal processing is also fundamental to digital technology, such as digital",Technology & Computing 
"Filter design
Filter design is the process of designing a signal processing filter that satisfies a set of requirements, some of which may be conflicting. The purpose is to find a realization of the filter that meets each of the requirements to an acceptable degree.
The filter design process can be described as an optimization problem. Certain parts of the design process can be automated, but an experienced designer may be needed to get a good result.
The design of digital filters is a complex topic.[1] Although filters are easily understood and calculated, the practical challenges of their design and implementation are significant and are the subject of advanced research.
Typical design requirements
[edit]Typical requirements which may be considered in the design process are:
- Frequency response
- Phase shift or group delay
- impulse response
- Causal filter required?
- Stable filter required?
- Finite (in duration) impulse response required?
- Computational complexity
- Technology
The frequency function
[edit]The required frequency response is an important parameter. The steepness and complexity of the response curve determines the filter order and feasibility.
A first-order recursive filter will only have a single frequency-dependent component. This means that the slope of the frequency response is limited to 6 dB per octave. For many purposes, this is not sufficient. To achieve steeper slopes, higher-order filters are required.
In relation to the desired frequency functi",Technology & Computing 
"Control system
A control system manages, commands, directs, or regulates the behavior of other devices or systems using control loops. It can range from a single home heating controller using a thermostat controlling a domestic boiler to large industrial control systems which are used for controlling processes or machines. The control systems are designed via control engineering process.
For continuously modulated control, a feedback controller is used to automatically control a process or operation. The control system compares the value or status of the process variable (PV) being controlled with the desired value or setpoint (SP), and applies the difference as a control signal to bring the process variable output of the plant to the same value as the setpoint.
For sequential and combinational logic, software logic, such as in a programmable logic controller, is used.[clarification needed]
Open-loop and closed-loop control
[edit]Fundamentally, there are two types of control loop: open-loop control (feedforward), and closed-loop control (feedback).
- In open-loop control, the control action from the controller is independent of the ""process output"" (or ""controlled process variable""). A good example of this is a central heating boiler controlled only by a timer, so that heat is applied for a constant time, regardless of the temperature of the building. The control action is the switching on/off of the boiler, but the controlled variable should be the building temperature, but ",Technology & Computing 
"Proportional–integral–derivative controller
A proportional–integral–derivative controller (PID controller or three-term controller) is a feedback-based control loop mechanism commonly used to manage machines and processes that require continuous control and automatic adjustment. It is typically used in industrial control systems and various other applications where constant control through modulation is necessary without human intervention. The PID controller automatically compares the desired target value (setpoint or SP) with the actual value of the system (process variable or PV). The difference between these two values is called the error value, denoted as .
It then applies corrective actions automatically to bring the PV to the same value as the SP using three methods: The proportional (P) component responds to the current error value by producing an output that is directly proportional to the magnitude of the error. This provides immediate correction based on how far the system is from the desired setpoint. The integral (I) component, in turn, considers the cumulative sum of past errors to address any residual steady-state errors that persist over time, eliminating lingering discrepancies. Lastly, the derivative (D) component predicts future error by assessing the rate of change of the error, which helps to mitigate overshoot and enhance system stability, particularly when the system undergoes rapid changes. The PID output signal can directly control actuators through v",Technology & Computing 
"Frequency response
In signal processing and electronics, the frequency response of a system is the quantitative measure of the magnitude and phase of the output as a function of input frequency.[1] The frequency response is widely used in the design and analysis of systems, such as audio and control systems, where they simplify mathematical analysis by converting governing differential equations into algebraic equations. In an audio system, it may be used to minimize audible distortion by designing components (such as microphones, amplifiers and loudspeakers) so that the overall response is as flat (uniform) as possible across the system's bandwidth. In control systems, such as a vehicle's cruise control, it may be used to assess system stability, often through the use of Bode plots. Systems with a specific frequency response can be designed using analog and digital filters.
The frequency response characterizes systems in the frequency domain, just as the impulse response characterizes systems in the time domain. In linear systems (or as an approximation to a real system neglecting second order non-linear properties), either response completely describes the system and thus there is a one-to-one correspondence: the frequency response is the Fourier transform of the impulse response. The frequency response allows simpler analysis of cascaded systems such as multistage amplifiers, as the response of the overall system can be found through multiplication of the individual stages",Technology & Computing 
"Nyquist stability criterion
In control theory and stability theory, the Nyquist stability criterion or Strecker–Nyquist stability criterion, independently discovered by the German electrical engineer Felix Strecker at Siemens in 1930[1][2][3] and the Swedish-American electrical engineer Harry Nyquist at Bell Telephone Laboratories in 1932,[4] is a graphical technique for determining the stability of a linear dynamical system.
Because it only looks at the Nyquist plot of the open loop systems, it can be applied without explicitly computing the poles and zeros of either the closed-loop or open-loop system (although the number of each type of right-half-plane singularities must be known). As a result, it can be applied to systems defined by non-rational functions, such as systems with delays. In contrast to Bode plots, it can handle transfer functions with right half-plane singularities. In addition, there is a natural generalization to more complex systems with multiple inputs and multiple outputs, such as control systems for airplanes.
The Nyquist stability criterion is widely used in electronics and control system engineering, as well as other fields, for designing and analyzing systems with feedback. While Nyquist is one of the most general stability tests, it is still restricted to linear time-invariant (LTI) systems. Nevertheless, there are generalizations of the Nyquist criterion (and plot) for non-linear systems, such as the circle criterion and the scaled relative graph",Technology & Computing 
"Root locus analysis
In control theory and stability theory, root locus analysis is a graphical method for examining how the roots of a system change with variation of a certain system parameter, commonly a gain within a feedback system. This is a technique used as a stability criterion in the field of classical control theory developed by Walter R. Evans which can determine stability of the system. The root locus plots the poles of the closed loop transfer function in the complex s-plane as a function of a gain parameter (see pole–zero plot).
Evans also invented in 1948 an analog computer to compute root loci, called a ""Spirule"" (after ""spiral"" and ""slide rule""); it found wide use before the advent of digital computers.[1][2][3][4][5][6][7][8][9]
Uses
[edit]In addition to determining the stability of the system, the root locus can be used to design the damping ratio (ζ) and natural frequency (ωn) of a feedback system. Lines of constant damping ratio can be drawn radially from the origin and lines of constant natural frequency can be drawn as arccosine whose center points coincide with the origin. By selecting a point along the root locus that coincides with a desired damping ratio and natural frequency, a gain K can be calculated and implemented in the controller. More elaborate techniques of controller design using the root locus are available in most control textbooks: for instance, lag, lead, PI, PD and PID controllers can be designed approximately with this technique.
The",Technology & Computing 
"Robotics
Robotics is the interdisciplinary study and practice of the design, construction, operation, and use of robots.[1]
Within mechanical engineering, robotics is the design and construction of the physical structures of robots, while in computer science, robotics focuses on robotic automation algorithms. Other disciplines contributing to robotics include electrical, control, software, information, electronic, telecommunication, computer, mechatronic, and materials engineering.
The goal of most robotics is to design machines that can help and assist humans. Many robots are built to do jobs that are hazardous to people, such as finding survivors in unstable ruins, and exploring space, mines and shipwrecks. Others replace people in jobs that are boring, repetitive, or unpleasant, such as cleaning, monitoring, transporting, and assembling. Today, robotics is a rapidly growing field, as technological advances continue; researching, designing, and building new robots serve various practical purposes.
Robotics aspects
[edit]Robotics usually combines three aspects of design work to create robot systems:
- Mechanical construction: a frame, form or shape designed to achieve a particular task. For example, a robot designed to travel across heavy dirt or mud might use caterpillar tracks. Origami inspired robots can sense and analyze in extreme environments.[2] The mechanical aspect of the robot is mostly the creator's solution to completing the assigned task and dealing with the phy",Technology & Computing 
"Industrial robot
An industrial robot is a robot system used for manufacturing. Industrial robots are automated, programmable and capable of movement on three or more axes.[1]
Typical applications of robots include welding, painting, assembly, disassembly,[2] pick and place for printed circuit boards, packaging and labeling, palletizing, product inspection, and testing; all accomplished with high endurance, speed, and precision. They can assist in material handling.
In the year 2023, an estimated 4,281,585 industrial robots were in operation worldwide according to International Federation of Robotics (IFR).[3][4]
Types and features
[edit]There are six types of industrial robots.[5]
Articulated robots
[edit]Articulated robots[5] are the most common industrial robots.[6] They look like a human arm, which is why they are also called robotic arm or manipulator arm.[7] Their articulations with several degrees of freedom allow the articulated arms a wide range of movements.
Autonomous robot
[edit]An autonomous robot is a robot that acts without recourse to human control. The first autonomous robots environment were known as Elmer and Elsie, which were constructed in the late 1940s by W. Grey Walter. They were the first robots in history that were programmed to ""think"" the way biological brains do and meant to have free will.[8] Elmer and Elsie were often labeled as tortoises because of how they were shaped and the manner in which they moved. They were capable of phototaxis which is ",Technology & Computing 
"Service robot
Service robots assist human beings, typically by performing a job that is dirty, dull, distant, dangerous or repetitive. They typically are autonomous and/or operated by a built-in control system, with manual override options. The term ""service robot"" does not have a strict technical definition. The International Organization for Standardization defines a “service robot” as a robot “that performs useful tasks for humans or equipment excluding industrial automation applications”.[1]
The first industrial robot arm, ""Unimate,"" was developed by Joseph F. Engelberger, known as the ""father of the robot arm,"" using George Devel.[2]
According to ISO 8373 robots require “a degree of autonomy”, which is the “ability to perform intended tasks based on current state and sensing, without human intervention”. For service robots this ranges from partial autonomy - including human-robot interaction - to full autonomy - without active human robot intervention. The International Federation of Robotics (IFR) statistics for service robots therefore include systems based on some degree of human robot interaction or even full tele-operation as well as fully autonomous systems.
Service robots are categorized according to personal or professional use. They have many forms and structures as well as application areas.
Types
[edit]The possible applications of robots to assist in human chores is widespread. At present there are a few main categories that these robots fall into.
Industrial
",Technology & Computing 
"Humanoid robot
A humanoid robot is a robot resembling the human body in shape. The design may be for functional purposes, such as interacting with human tools and environments and working alongside humans, for experimental purposes, such as the study of bipedal locomotion, or for other purposes. In general, humanoid robots have a torso, a head, two arms, and two legs, though some humanoid robots may replicate only part of the body. Androids are humanoid robots built to aesthetically resemble humans.
History
[edit]The concept of a humanoid robot originated in many different cultures around the world. Some of the earliest accounts of the idea of humanoid automata date to the 4th century BCE in Greek mythologies and various religious and philosophical texts from China. Physical prototypes of humanoid automata were later created in the Middle East, Italy, Japan, France and South Korea.
Greece
[edit]The Greek god of blacksmiths, Hephaestus, created several different humanoid automata in various myths. In Homer's Iliad, Hephaestus created golden handmaidens and imbued them with human-like voices to serve as speaking tools or instruments.[2] Another Greek myth details how Hephaestus crafted a giant bronze automaton named Talos to protect the island of Crete from invaders.[3]
China
[edit]In the 3rd century BCE, a Taoist philosophical text called the Liezi, written by Chinese philosopher Lie Yukou, detailed the idea of a humanoid automaton. The text includes mention of an engineer nam",Technology & Computing 
"Cobot
A cobot, or collaborative robot, also known as a companion robot, is a robot intended for direct human-robot interaction within a shared space, or where humans and robots are in close proximity. Cobot applications contrast with traditional industrial robot applications in which robots are isolated from human contact or the humans are protected by robotic tech vests.[1][2] Cobot safety may rely on lightweight construction materials, rounded edges, and inherent limitation of speed and force, or on sensors and software that ensure safe behavior.[3][4]
Uses
[edit]The International Federation of Robotics (IFR),[5] a global industry association of robot manufacturers and national robot associations, recognizes two main groups of robots: industrial robots used in automation and service robots for domestic and professional use. Service robots could be considered to be cobots as they are intended to work alongside humans. Industrial robots have traditionally worked separately from humans behind fences or other protective barriers, but cobots remove that separation.
As COBOTS operates safely and efficiently in a shared environment with humans, their versatility allows them to support a wide range of tasks in different settings, and their applications have also expanded rapidly in both public and industrial fields.[6] Cobots can have many uses, from information robots in public spaces (an example of service robots),[7] logistics robots that transport materials within a building,[8",Technology & Computing 
"Swarm robotics
Swarm robotics is the study of how to design independent systems of robots without centralized control. The emerging swarming behavior of robotic swarms is created through the interactions between individual robots and the environment.[1][2] This idea emerged on the field of artificial swarm intelligence, as well as the studies of insects, ants and other fields in nature, where swarm behavior occurs.[3]
Relatively simple individual rules can produce a large set of complex swarm behaviors. A key component is the communication between the members of the group that build a system of constant feedback. The swarm behavior involves constant change of individuals in cooperation with others, as well as the behavior of the whole group.
Key Attributes of Robotic Swarms
[edit]The design of swarm robotics systems is guided by swarm intelligence principles, which promote fault tolerance, scalability, and flexibility.[1] Unlike distributed robotic systems in general, swarm robotics emphasizes a large number of robots. While various formulations of swarm intelligence principles exist, one widely recognized set includes:
- Robots are autonomous.
- Robots can interact with the surroundings and give feedback to modify the environment.
- Robots possess local perceiving and communicating capabilities, such as wireless transmission systems, like radio frequency or infrared.[4]
- Robots do not exploit centralized swarm control or global knowledge.
- Robots cooperate with each other ",Technology & Computing 
"Soft robotics
Soft robotics is a subfield of robotics that concerns the design, control, and fabrication of robots composed of compliant materials, instead of rigid links.[1][2] In contrast to rigid-bodied robots built from metals, ceramics and hard plastics, the compliance of soft robots can improve their safety when working in close contact with humans.[2]
Types and designs
[edit]The goal of soft robotics is the design and construction of robots with physically flexible bodies and electronics. In some applications, softness is restricted to a localized region of a machine. For example, rigid-bodied robotic arms can employ soft end effectors to gently grab and manipulate delicate or irregularly shaped objects.[3] Most rigid-bodied mobile robots also strategically employ soft components, such as foot pads to absorb shock or springy joints to store/release elastic energy. However, the field of soft robotics generally focuses on the creation of machines that are predominately or entirely soft. Robots with entirely soft bodies have tremendous potential such as flexibility which allows them to squeeze into places rigid bodies cannot, which could prove useful in disaster relief scenarios. Soft robots are also safer for human interaction and for internal deployment inside a human body.[4]
Nature is often a source of inspiration for soft robot design given that animals themselves are mostly composed of soft components and they appear to exploit their softness for efficient movement ",Technology & Computing 
"Telerobotics
Telerobotics is the area of robotics concerned with the control of semi-autonomous robots from a distance, chiefly using television, wireless networks (like Wi-Fi, Bluetooth and the Deep Space Network) or tethered connections. It is a combination of two major subfields, which are teleoperation and telepresence.
Teleoperation
[edit]Teleoperation indicates operation of a machine at a distance. It is similar in meaning to the phrase ""remote control"" but is usually encountered in research, academic and technical environments. It is most commonly associated with robotics and mobile robots but can be applied to a whole range of circumstances in which a device or machine is operated by a person from a distance.[1]
Teleoperation is the most standard term, used both in research and technical communities, for referring to operation at a distance. This is opposed to ""telepresence"", which refers to the subset of telerobotic systems configured with an immersive interface such that the operator feels present in the remote environment, projecting their presence through the remote robot. One of the first telepresence systems that enabled operators to feel present in a remote environment through all of the primary senses (sight, sound, and touch) was the Virtual Fixtures system developed at US Air Force Research Laboratories in the early 1990s. The system enabled operators to perform dexterous tasks (inserting pegs into holes) remotely such that the operator would feel as if he o",Technology & Computing 
"Robot kinematics
Robot kinematics applies geometry to the study of the movement of multi-degree of freedom kinematic chains that form the structure of robotic systems.[1][2] The emphasis on geometry means that the links of the robot are modeled as rigid bodies and its joints are assumed to provide pure rotation or translation.
Robot kinematics studies the relationship between the dimensions and connectivity of kinematic chains and the position, velocity and acceleration of each of the links in the robotic system, in order to plan and control movement and to compute actuator forces and torques. The relationship between mass and inertia properties, motion, and the associated forces and torques is studied as part of robot dynamics.
Kinematic equations
[edit]A fundamental tool in robot kinematics is the kinematics equations of the kinematic chains that form the robot. These non-linear equations are used to map the joint parameters to the configuration of the robot system. Kinematics equations are also used in biomechanics of the skeleton and computer animation of articulated characters.
Forward kinematics uses the kinematic equations of a robot to compute the position of the end-effector from specified values for the joint parameters.[3] The reverse process that computes the joint parameters that achieve a specified position of the end-effector is known as inverse kinematics. The dimensions of the robot and its kinematics equations define the volume of space reachable by the robo",Technology & Computing 
"Motion planning
Motion planning, also path planning (also known as the navigation problem or the piano mover's problem) is a computational problem to find a sequence of valid configurations that moves the object from the source to destination. The term is used in computational geometry, computer animation, robotics and computer games.
For example, consider navigating a mobile robot inside a building to a distant waypoint. It should execute this task while avoiding walls and not falling down stairs. A motion planning algorithm would take a description of these tasks as input, and produce the speed and turning commands sent to the robot's wheels. Motion planning algorithms might address robots with a larger number of joints (e.g., industrial manipulators), more complex tasks (e.g. manipulation of objects), different constraints (e.g., a car that can only drive forward), and uncertainty (e.g. imperfect models of the environment or robot).
Motion planning has several robotics applications, such as autonomy, automation, and robot design in CAD software, as well as applications in other fields, such as animating digital characters, video game, architectural design, robotic surgery, and the study of biological molecules.
Concepts
[edit]A basic motion planning problem is to compute a continuous path that connects a start configuration S and a goal configuration G, while avoiding collision with known obstacles. The robot and obstacle geometry is described in a 2D or 3D workspace, whil",Technology & Computing 
"Slam
Appearance
(Redirected from SLAM)
Look up slam in Wiktionary, the free dictionary.
Slam, SLAM or SLAMS may refer to:
Arts, entertainment, and media
[edit]Fictional elements
[edit]- S.L.A.M. (Strategic Long-Range Artillery Machine), a fictional weapon in the G.I. Joe universe
- SLAMS (Space-Land-Air Missile Shield), a fictional anti-ballistic missile system featured in Tom Clancy's EndWar and briefly mentioned in other Tom Clancy's video games
Films
[edit]- Slam (1998 film), an American film starring Saul Williams and Beau Sia
- Slam (2016 film), an Italian film based on the novel of the same name by Nick Hornby
- Slam (2018 film), an Australian feature directed by Partho Sen-Gupta
Literature
[edit]- Slam (novel), a novel by Nick Hornby
- Slam!, a novel by Walter Dean Myers about a high school basketball star from Harlem
- Slam, a novel by Lewis Shiner
Music
[edit]Albums
[edit]- Slam (Big Dipper album), 1990
- Slam (Joe Lynn Turner album), 2001
- Slam (soundtrack), from the 1998 film
- Slam (Dan Reed Network album) , a 1989 album by Dan Reed Network
- Slam, a 1978 album by Suburban Studs
Songs
[edit]- ""Slam"" (Humanoid song), 1989
- ""Slam"" (Onyx song), 1993
- ""Slam"" (Pendulum song), 2005
- ""Slam"", a song by Bow Wow
- ""Slam"", a song by Seaway from Colour Blind
- ""Slam"", a 2002 song by A-Teens from Pop 'til You Drop!
- ""Slam"", a 2009 song by Anna Arbeu from Just a Pretty Face?
Other uses in music
[edit]- Slam (DJs), an electronic music production and DJ duo from Glasgow
- Sa",Sports & Recreation 
"Robot Operating System
Robot Operating System (ROS or ros) is an open-source robotics middleware suite. Although ROS is not an operating system (OS) but a set of software frameworks for robot software development, it provides services designed for a heterogeneous computer cluster such as hardware abstraction, low-level device control, implementation of commonly used functionality, message-passing between processes, and package management. Running sets of ROS-based processes are represented in a graph architecture where processing takes place in nodes that may receive, post, and multiplex sensor data, control, state, planning, actuator, and other messages. Despite the importance of reactivity and low latency in robot control, ROS is not a real-time operating system (RTOS). However, it is possible to integrate ROS with real-time computing code.[3] The lack of support for real-time systems has been addressed in the creation of ROS 2,[4][5][6] a major revision of the ROS API which will take advantage of modern libraries and technologies for core ROS functions and add support for real-time code and embedded system hardware.
Software in the ROS Ecosystem[7] can be separated into three groups:
- language- and platform-independent tools used for building and distributing ROS-based software;
- ROS client library implementations such as roscpp,[8] rospy,[9] and roslisp;[10]
- packages containing application-related code that uses one or more ROS client libraries.[11]
Both the language-",Technology & Computing 
"Webots
Webots is a free and open-source 3D robot simulator used in industry, education and research.
The Webots project started in 1996, initially developed by Dr. Olivier Michel at the Swiss Federal Institute of Technology (EPFL) in Lausanne, Switzerland and then from 1998 by Cyberbotics Ltd. as a proprietary licensed software. Since December 2018, it is released under the free and open-source Apache 2 license.[1]
Webots includes a large collection of freely modifiable models of robots, sensors, actuators and objects. In addition, it is also possible to build new models from scratch or import them from 3D CAD software. When designing a robot model, the user specifies both the graphical and the physical properties of the objects. The graphical properties include the shape, dimensions, position and orientation, colors, and texture of the object. The physical properties include the mass, friction factor, as well as the spring and damping constants. Simple fluid dynamics is present in the software.
Webots uses a fork of the ODE (Open Dynamics Engine) for detecting of collisions and simulating rigid body dynamics. The ODE library allows one to accurately simulate physical properties of objects such as velocity, inertia and friction.
Webots includes a set of sensors and actuators frequently used in robotic experiments, e.g. lidars, radars, proximity sensors, light sensors, touch sensors, GPS, accelerometers, cameras, emitters and receivers, servo motors (rotational & linear), posi",Technology & Computing 
"CoppeliaSim
CoppeliaSim, formerly known as V-REP, is a robot simulator used in industry, education and research.[1][2] It was originally developed within Toshiba R&D and is currently being actively developed and maintained by Coppelia Robotics AG, a small company located in Zurich, Switzerland.
It is built around a distributed control architecture having Python and Lua scripts, or C/C++ plug-ins acting as individual, synchronous controllers. Additional asynchronous controllers can execute in another process, thread or machine via various middleware solutions (ROS, remote API,[3] ZeroMQ) with programming languages such as C/C++, Python, Java and Matlab.
CoppeliaSim uses a kinematics engine for forward and inverse kinematics calculations, and several physics simulation libraries (MuJoCo, Bullet, ODE, Vortex, Newton Game Dynamics) to perform rigid body simulation. Models and scenes are built by assembling various objects (meshes, joints, various sensors, Point clouds, octrees, etc.) into a hierarchical structure. Additional functionality, provided by plug-ins, include: motion planning (via OMPL), synthetic vision and imaging processing (e.g. via OpenCV), collision detection, minimum distance calculation, custom graphical user interfaces and Data visualization (e.g. via plots).
The main fields of application of CoppeliaSim are robotics research[4] and education.[5][6][7]
References
[edit]- ^ Rohmer, Eric; Singh, Surya P. N.; Freese, Marc (3 November 2013). CoppeliaSim (formerly V",Technology & Computing 
"MATLAB
MATLAB (an abbreviation of ""MATrix LABoratory""[18]) is a proprietary multi-paradigm programming language and numeric computing environment developed by MathWorks. MATLAB allows matrix manipulations, plotting of functions and data, implementation of algorithms, creation of user interfaces, and interfacing with programs written in other languages.
Although MATLAB is intended primarily for numeric computing, an optional toolbox uses the MuPAD symbolic engine allowing access to symbolic computing abilities. An additional package, Simulink, adds graphical multi-domain simulation and model-based design for dynamic and embedded systems.
As of 2020[update], MATLAB has more than four million users worldwide.[19] They come from various backgrounds of engineering, science, and economics. As of 2017[update], more than 5000 global colleges and universities use MATLAB to support instruction and research.[20]
History
[edit]Origins
[edit]MATLAB was invented by mathematician and computer programmer Cleve Moler.[21] The idea for MATLAB was based on his 1960s PhD thesis.[21] Moler became a math professor at the University of New Mexico and started developing MATLAB for his students[21] as a hobby.[22] He developed MATLAB's initial linear algebra programming in 1967 with his one-time thesis advisor, George Forsythe.[21] This was followed by Fortran code for linear equations in 1971.[21]
Before version 1.0, MATLAB ""was not a programming language; it was a simple interactive matrix calculat",Technology & Computing 
"Simulink
Simulink is a MATLAB-based graphical programming environment for modeling, simulating and analyzing multidomain dynamical systems. Its primary interface is a graphical block diagramming tool and a customizable set of block libraries. It offers tight integration with the rest of the MATLAB environment and can either drive MATLAB or be scripted from it. Simulink is widely used in automatic control and digital signal processing for multidomain simulation and model-based design.[3][4]
Add-on products
[edit]MathWorks and other third-party hardware and software products can be used with Simulink. For example, Stateflow extends Simulink with a design environment for developing state machines and flow charts.
Coupled with another of their products,[5] Simulink can automatically generate C source code for real-time implementation of systems. As the efficiency and flexibility of the code improves, this is becoming more widely adopted for production systems,[6][7] in addition to being a tool for embedded system design work because of its flexibility and capacity for quick iteration[citation needed]. Embedded Coder creates code efficient enough for use in embedded systems.[8][9][10]
Simulink Real-Time (formerly known as xPC Target), together with x86-based real-time systems, is an environment for simulating and testing Simulink and Stateflow models in real-time on the physical system. Another MathWorks product[11] also supports specific embedded targets. When used with other gen",Technology & Computing 
"LabVIEW
Laboratory Virtual Instrument Engineering Workbench (LabVIEW)[1]: 3 is a graphical system design and development platform produced and distributed by National Instruments, based on a programming environment that uses a visual programming language. It is widely used for data acquisition, instrument control, and industrial automation. It provides tools for designing and deploying complex test and measurement systems.[2]
The visual (aka graphical) programming language is called ""G"" (not to be confused with G-code). It is a dataflow language originally developed by National Instruments.[3] LabVIEW is supported on a variety of operating systems (OSs), including macOS and other versions of Unix and Linux, as well as Microsoft Windows.
The latest versions of LabVIEW are LabVIEW 2024 Q3 (released in July 2024) and LabVIEW NXG 5.1 (released in January 2021).[4] National Instruments released the free for non-commercial use LabVIEW and LabVIEW NXG Community editions on April 28, 2020.[5]
Dataflow programming
[edit]The programming paradigm used in the LabVIEW ""G"" language is based on data availability. If there is enough data available to a function, it will execute. The execution flow is determined by the structure of a graphical block diagram (the LabVIEW-source code) on which the programmer places nodes and connects them by drawing wires. A node can be a control, indicator, structure, function, or recursively, another block diagram. An example of a simple four-node block diagr",Technology & Computing 
"Arduino
Arduino (/ɑːrˈdwiːnoʊ/) is an Italian open-source hardware and software company, project, and user community that designs and manufactures single-board microcontrollers and microcontroller kits for building digital devices. Its hardware products are licensed under a CC BY-SA license, while the software is licensed under the GNU Lesser General Public License (LGPL) or the GNU General Public License (GPL),[1] permitting the manufacture of Arduino boards and software distribution by anyone. Arduino boards are available commercially from the official website or through authorized distributors.[2]
Arduino board designs use a variety of microprocessors and controllers. The boards are equipped with sets of digital and analog input/output (I/O) pins that may be interfaced to various expansion boards ('shields') or breadboards (for prototyping) and other circuits. The boards feature serial communications interfaces, including Universal Serial Bus (USB) on some models, which are also used for loading programs. The microcontrollers can be programmed using the C and C++ programming languages (Embedded C), using a standard API which is also known as the Arduino Programming Language, inspired by the Processing language and used with a modified version of the Processing IDE. In addition to using traditional compiler toolchains, the Arduino project provides an integrated development environment (IDE) and a command line tool developed in Go.
The Arduino project began in 2005 as a tool",Technology & Computing 
"Raspberry Pi
Raspberry Pi (/paɪ/ PY) is a series of small single-board computers (SBCs) developed in the United Kingdom by the Raspberry Pi Foundation in collaboration with Broadcom. To commercialize the product and support its growing demand, the Foundation established a commercial entity, Raspberry Pi Holdings, a public company that trades on the London Stock Exchange.
The Raspberry Pi was originally created to help teach computer science in schools, but gained popularity for many other uses due to its low cost, compact size, and flexibility. It is now used in areas such as industrial automation, robotics, home automation, IoT devices, and hobbyist projects.
The company's products range from simple microcontrollers to computers that the company markets as being powerful enough to be used as a general purpose PC. Computers are built around a custom designed system on a chip and offer features such as HDMI video/audio output, USB ports, wireless networking, GPIO pins, and up to 16 GB of RAM. Storage is typically provided via microSD cards.
In 2015, the Raspberry Pi surpassed the ZX Spectrum as the best-selling British computer of all time. As of March 2025[update], 68 million units had been sold.
History
[edit]Origins and Launch (2008–2012)
[edit]The Raspberry Pi Foundation was established in 2008 by a group including Eben Upton,[1] in response to a noticeable decline in both the number and skill level of students applying to study computer science University of Cambridge Com",Technology & Computing 
"BeagleBoard
The BeagleBoard is a low-power open-source single-board computer produced by Texas Instruments in association with Digi-Key and Newark element14. The BeagleBoard was also designed with open source software development in mind, and as a way of demonstrating the Texas Instrument's OMAP3530 system-on-a-chip.[8] The board was developed by a small team of engineers as an educational board that could be used in colleges around the world to teach open source hardware and software capabilities. It is also sold to the public under the Creative Commons share-alike license. The board was designed using Cadence OrCAD for schematics and Cadence Allegro for PCB manufacturing; no simulation software was used.[citation needed]
Features
[edit]The BeagleBoard measures approximately 75 by 75 mm and has all the functionality of a basic computer.[9] The OMAP3530 includes an ARM Cortex-A8 CPU (which can run Linux, Minix,[10] FreeBSD,[11] OpenBSD,[12] RISC OS,[13] or Symbian; a number of unofficial Android ports exist[14][15]), a TMS320C64x+ DSP for accelerated video and audio decoding, and an Imagination Technologies PowerVR SGX530 GPU to provide accelerated 2D and 3D rendering that supports OpenGL ES 2.0. Video out is provided through separate S-Video and HDMI connections. A single SD/MMC card slot supporting SDIO, a USB On-The-Go port, an RS-232 serial connection, a JTAG connection, and two stereo 3.5 mm jacks for audio in/out are provided.
Built-in storage and memory are provided th",Technology & Computing 
"Field-programmable gate array
A field-programmable gate array (FPGA) is a type of configurable integrated circuit that can be repeatedly programmed after manufacturing. FPGAs are a subset of logic devices referred to as programmable logic devices (PLDs). They consist of an array of programmable logic blocks with a connecting grid, that can be configured ""in the field"" to interconnect with other logic blocks to perform various digital functions. FPGAs are often used in limited (low) quantity production of custom-made products, and in research and development, where the higher cost of individual FPGAs is not as important, and where creating and manufacturing a custom circuit would not be feasible. Other applications for FPGAs include the telecommunications, automotive, aerospace, and industrial sectors, which benefit from their flexibility, high signal processing speed, and parallel processing abilities.
A FPGA configuration is generally written using a hardware description language (HDL) e.g. VHDL, similar to the ones used for application-specific integrated circuits (ASICs). Circuit diagrams were formerly used to write the configuration.
The logic blocks of an FPGA can be configured to perform complex combinational functions, or act as simple logic gates like AND and XOR. In most FPGAs, logic blocks also include memory elements, which may be simple flip-flops or more sophisticated blocks of memory.[1] Many FPGAs can be reprogrammed to implement different logic functions, allo",Technology & Computing 
"VHDL
VHDL (VHSIC Hardware Description Language) is a hardware description language that can model the behavior and structure of digital systems at multiple levels of abstraction, ranging from the system level down to that of logic gates, for design entry, documentation, and verification purposes. The language was developed for the US military VHSIC program in the 1980s, and has been standardized by the Institute of Electrical and Electronics Engineers (IEEE) as IEEE Std 1076; the latest version of which is IEEE Std 1076-2019. To model analog and mixed-signal systems, an IEEE-standardized HDL based on VHDL called VHDL-AMS (officially IEEE 1076.1) has been developed.
History
[edit]In 1983, VHDL was originally developed at the behest of the U.S. Department of Defense in order to document the behavior of the ASICs that supplier companies were including in equipment. The standard MIL-STD-454N[2] in Requirement 64 in section 4.5.1 ""ASIC documentation in VHDL"" explicitly requires documentation of ""Microelectronic Devices"" in VHDL.
The idea of being able to simulate the ASICs from the information in this documentation was so obviously attractive that logic simulators were developed that could read the VHDL files. The next step was the development of logic synthesis tools that read the VHDL and output a definition of the physical implementation of the circuit.
Due to the Department of Defense requiring as much of the syntax as possible to be based on Ada, in order to avoid re-inventin",Technology & Computing 
"Verilog
Verilog, standardized as IEEE 1364, is a hardware description language (HDL) used to model electronic systems. It is most commonly used in the design and verification of digital circuits, with the highest level of abstraction being at the register-transfer level. It is also used in the verification of analog circuits and mixed-signal circuits, as well as in the design of genetic circuits.[1]
In 2009, the Verilog standard (IEEE 1364-2005) was merged into the SystemVerilog standard, creating IEEE Standard 1800-2009. Since then, Verilog has been officially part of the SystemVerilog language. The current version is IEEE standard 1800-2023.[2]
Overview
[edit]Hardware description languages such as Verilog are similar to software programming languages because they include ways of describing the propagation time and signal strengths (sensitivity). There are two types of assignment operators; a blocking assignment (=), and a non-blocking (<=) assignment. The non-blocking assignment allows designers to describe a state-machine update without needing to declare and use temporary storage variables. Since these concepts are part of Verilog's language semantics, designers could quickly write descriptions of large circuits in a relatively compact and concise form. At the time of Verilog's introduction (1984), Verilog represented a tremendous productivity improvement for circuit designers who were already using graphical schematic capture software and specially written software progr",Technology & Computing 
"SystemVerilog
SystemVerilog, standardized as IEEE 1800 by the Institute of Electrical and Electronics Engineers (IEEE), is a hardware description and hardware verification language commonly used to model, design, simulate, test and implement electronic systems in the semiconductor and electronic design industry. SystemVerilog is an extension of Verilog.
History
[edit]SystemVerilog started with the donation of the Superlog language to Accellera in 2002 by the startup company Co-Design Automation.[1] The bulk of the verification functionality is based on the OpenVera language donated by Synopsys. In 2005, SystemVerilog was adopted as IEEE Standard 1800-2005.[2] In 2009, the standard was merged with the base Verilog (IEEE 1364-2005) standard, creating IEEE Standard 1800-2009.
The SystemVerilog standard was subsequently updated in 2012,[3] 2017,[4] and most recently in December 2023.[5]
Design features
[edit]The feature-set of SystemVerilog can be divided into two distinct roles:
- SystemVerilog for register-transfer level (RTL) design is an extension of Verilog-2005; all features of that language are available in SystemVerilog. Therefore, Verilog is a subset of SystemVerilog.
- SystemVerilog for verification uses extensive object-oriented programming techniques and is more closely related to Java than Verilog. These constructs are generally not synthesizable.
The remainder of this article discusses the features of SystemVerilog not present in Verilog-2005.
Data lifetime
[edit]Th",Technology & Computing 
"Printed circuit board
A printed circuit board (PCB), also called printed wiring board (PWB), is a laminated sandwich structure of conductive and insulating layers, each with a pattern of traces, planes and other features (similar to wires on a flat surface) etched from one or more sheet layers of copper laminated onto or between sheet layers of a non-conductive substrate.[1] PCBs are used to connect or ""wire"" components to one another in an electronic circuit. Electrical components may be fixed to conductive pads on the outer layers, generally by soldering, which both electrically connects and mechanically fastens the components to the board. Another manufacturing process adds vias, metal-lined drilled holes that enable electrical interconnections between conductive layers, to boards with more than a single side.
Printed circuit boards are used in nearly all electronic products today. Alternatives to PCBs include wire wrap and point-to-point construction, both once popular but now rarely used. PCBs require additional design effort to lay out the circuit, but manufacturing and assembly can be automated. Electronic design automation software is available to do much of the work of layout. Mass-producing circuits with PCBs is cheaper and faster than with other wiring methods, as components are mounted and wired in one operation. Large numbers of PCBs can be fabricated at the same time, and the layout has to be done only once. PCBs can also be made manually in small quantities, wi",Technology & Computing 
"KiCad
KiCad (/ˈkiːˌkæd/ KEE-kad[7]) is a free software suite for electronic design automation (EDA). It facilitates the design and simulation of electronic hardware for PCB manufacturing. It features an integrated environment for schematic capture, PCB layout, manufacturing file viewing, ngspice-provided SPICE simulation, and engineering calculation. Tools exist within the package to create bill of materials, artwork, Gerber files, and 3D models of the PCB and its components.
History
[edit]Early history
[edit]KiCad was created in 1992 by Jean-Pierre Charras while working at IUT de Grenoble.[8] The name came from the first letters in the name of a company of Jean-Pierre's friend in combination with the term CAD.[9] KiCad originally was a collection of electronics programs intended to be used in conjunction with each other. The main tools were EESchema, PCBnew, a Gerber viewer, and a calculator.
2010s to present
[edit]With the price of professionally made printed circuit boards rapidly dropping, hobbyist electronic design became much more popular. As a result, KiCad started gaining significant traction and a larger developer base.
In 2013 the CERN BE-CO-HT section started contributing resources towards KiCad to help foster open hardware development by helping improve KiCad to be on par with commercial EDA tools.[10] From 2013 until approximately 2018 CERN provided two developers part time to help improve KiCad. Much of the work provided by CERN involved massive refactoring of t",Technology & Computing 
"Altium Designer
Altium Designer (AD) is a printed circuit board (PCB) and electronic design automation software package for printed circuit boards. It is developed by American software company Altium Limited. Altium Designer was formerly named under the brand Protel.
History
[edit]Altium Designer was originally launched in 2005 by Altium, then named Protel Systems Pty Ltd. It has roots in 1985, when the company launched the DOS-based PCB design tool named Protel PCB (which later emerged into Autotrax and Easytrax). Originally it was sold only in Australia.[2][3] Protel PCB was marketed internationally by HST Technology since 1986.[3] The product became available in the United States, Canada, and Mexico beginning in 1986, marketed by San Diego–based ACCEL Technologies, Inc., under the name Tango PCB.[3] In 1987, Protel launched the circuit diagram editor Protel Schematic for DOS.
In 1991, Protel released Advanced Schematic and Advanced PCB 1.0 for Windows (1991–1993), followed by Advanced Schematic/PCB 2.x (1993–1995) and 3.x (1995–1998). In 1998, Protel 98 consolidated all components, including Advanced Schematic and Advanced PCB, into one environment. Protel 99 in 1999 introduced the first integrated 3D visualization of the PCB assembly. It was followed by Protel 99 SE in 2000. Protel DXP was issued in 2003, Protel 2004 in 2004, Altium Designer 6.0 in 2005. Altium Designer version 6.8 from 2007 was the first to offer 3D visualization and clearance checking of PCBs directly w",Technology & Computing 
"Electronic circuit simulation
Electronic circuit simulation uses mathematical models to replicate the behavior of an actual electronic device or circuit. Simulation software allows for the modeling of circuit operation and is an invaluable analysis tool. Due to its highly accurate modeling capability, many colleges and universities use this type of software for the teaching of electronics technician and electronics engineering programs. Electronics simulation software engages its users by integrating them into the learning experience. These kinds of interactions actively engage learners to analyze, synthesize, organize, and evaluate content and result in learners constructing their own knowledge.[1]
Simulating a circuit’s behavior before actually building it can greatly improve design efficiency by making faulty designs known as such, and providing insight into the behavior of electronic circuit designs. In particular, for integrated circuits, the tooling (photomasks) is expensive, breadboards are impractical, and probing the behavior of internal signals is extremely difficult. Therefore, almost all IC design relies heavily on simulation. The most well known analog simulator is SPICE. Probably the best known digital simulators are those based on Verilog and VHDL.
Some electronics simulators integrate a schematic editor, a simulation engine, and an on-screen waveform display (see Figure 1), allowing designers to rapidly modify a simulated circuit and see what effect the change",Technology & Computing 
"SPICE
SPICE (Simulation Program with Integrated Circuit Emphasis)[1][2] is a general-purpose, open-source analog electronic circuit simulator. It is a program used in integrated circuit and board-level design to check the integrity of circuit designs and to predict circuit behavior.
Introduction
[edit]Unlike board-level designs composed of discrete parts, it is not practical to breadboard integrated circuits before manufacture. Further, the high costs of photolithographic masks and other manufacturing prerequisites make it essential to design the circuit to be as close to perfect as possible before the integrated circuit is first built.
Simulating the circuit with SPICE is the industry-standard way to verify circuit operation at the transistor level before committing to manufacturing an integrated circuit. The SPICE simulators help to predict the behavior of the IC under different operating conditions, such as different voltage and current levels, temperature variations, and noise.[3]
Board-level circuit designs can often be breadboarded for testing. Even with a breadboard, some circuit properties may not be accurate compared to the final printed wiring board, such as parasitic resistances and capacitances, whose effects can often be estimated more accurately using simulation. Also, designers may want more information about the circuit than is available from a single mock-up. For instance, circuit performance is affected by component manufacturing tolerances. In these cases i",Technology & Computing 
"LTspice
LTspice is a SPICE-based analog electronic circuit simulator computer software, produced by semiconductor manufacturer Analog Devices (originally by Linear Technology).[2] It is the most widely distributed and used SPICE software in the industry.[6] Though it is freeware,[4][5] it is not artificially restricted to limit its abilities (no limits on: features, nodes, components, subcircuits).[6][7] It ships with a library of SPICE models from Analog Devices, Linear Technology, Maxim Integrated, and third-party sources.
Overview
[edit]LTspice provides schematic capture to enter an electronic schematic for an electronic circuit, an enhanced SPICE type analog electronic circuit simulator, and a waveform viewer to show the results of the simulation.[2] Circuit simulation analysis based on transient, noise, AC, DC, DC transfer function, DC operating point can be performed and plotted as well as fourier analysis.[8] Heat dissipation of components can be calculated and efficiency reports can also be generated.[citation needed] It has enhancements and specialized models to speed the simulation of switched-mode power supplies (SMPS) in DC-to-DC converters.[2][9]
LTspice does not generate printed circuit board (PCB) layouts, but netlists can be exported to PCB layout software.[10] While LTspice does support simple logic gate simulation, it is not designed specifically for simulating logic circuits.
It is used by many users in fields including radio frequency electronics, power el",Technology & Computing 
"NI Multisim
NI Multisim (formerly MultiSIM) is an electronic schematic capture and simulation program which is part of a suite of circuit design programs,[1] along with NI Ultiboard. Multisim is one of the few circuit design programs to employ the original Berkeley SPICE based software simulation.[2] Multisim was originally created by a company named Electronics Workbench Group, which is now a division of National Instruments. Multisim includes microcontroller simulation (formerly known as MultiMCU),[3] as well as integrated import and export features to the printed circuit board layout software in the suite, NI Ultiboard.[4]
Multisim is widely used in academia and industry for circuits education, electronic schematic design and SPICE simulation.[5]
History
[edit]Multisim was originally called Electronics Workbench[6] and created by a company called Interactive Image Technologies.[7] At the time it was mainly used as an educational tool to teach electronics technician and electronics engineering programs in colleges and universities. National Instruments has maintained this educational legacy, with a specific version of Multisim with features developed for teaching electronics.[citation needed]
In 1999, Multisim was integrated with Ultiboard after the original company merged with Ultimate Technology, a PCB layout software company.[citation needed]
In 2005, Interactive Image Technologies was acquired by National Instruments[8] Electronics Workbench Group and Multisim was renam",Technology & Computing 
"Embedded system
An embedded system is a specialized computer system—a combination of a computer processor, computer memory, and input/output peripheral devices—that has a dedicated function within a larger mechanical or electronic system.[1][2] It is embedded as part of a complete device often including electrical or electronic hardware and mechanical parts. Because an embedded system typically controls physical operations of the machine that it is embedded within, it often has real-time computing constraints. Embedded systems control many devices in common use.[3] In 2009[update], it was estimated that ninety-eight percent of all microprocessors manufactured were used in embedded systems.[4][needs update]
Modern embedded systems are often based on microcontrollers (i.e. microprocessors with integrated memory and peripheral interfaces), but ordinary microprocessors (using external chips for memory and peripheral interface circuits) are also common, especially in more complex systems. In either case, the processor(s) used may be types ranging from general purpose to those specialized in a certain class of computations, or even custom designed for the application at hand. A common standard class of dedicated processors is the digital signal processor (DSP).
Since the embedded system is dedicated to specific tasks, design engineers can optimize it to reduce the size and cost of the product and increase its reliability and performance. Some embedded systems are mass-produced, ben",Technology & Computing 
"Real-time operating system
A real-time operating system (RTOS) is an operating system (OS) for real-time computing applications that processes data and events that have critically defined time constraints. A RTOS is distinct from a time-sharing operating system, such as Unix, which manages the sharing of system resources with a scheduler, data buffers, or fixed task prioritization in multitasking or multiprogramming environments. All operations must verifiably complete within given time and resource constraints or else the RTOS will fail safe. Real-time operating systems are event-driven and preemptive, meaning the OS can monitor the relevant priority of competing tasks, and make changes to the task priority.
Characteristics
[edit]A key characteristic of an RTOS is the level of its consistency concerning the amount of time it takes to accept and complete an application's task; the variability is ""jitter"".[1] The chief design goal is not high throughput, but rather a guarantee of a soft or hard performance category. An RTOS that can usually or generally meet a deadline is a soft real-time OS, but if it can meet a deadline deterministically it is a hard real-time OS.[2]
An RTOS has an advanced algorithm for scheduling. Scheduler flexibility enables a wider, computer-system orchestration of process priorities, but a real-time OS is more frequently dedicated to a narrow set of applications. Key factors in a real-time OS are minimal interrupt latency and minimal thread switching l",Technology & Computing 
"FreeRTOS
FreeRTOS is a real-time operating system kernel[3][4][5] for embedded devices that has been ported to 40 microcontroller platforms. It is distributed under the MIT License.
History
[edit]The FreeRTOS kernel was originally developed by Richard Barry around 2003, and was later developed and maintained by Barry's company, Real Time Engineers Ltd. In 2017, the firm passed stewardship of the FreeRTOS project to Amazon Web Services (AWS). Barry continues to work on FreeRTOS as part of an AWS team.[6] With the transition to Amazon control, subsequent releases of the project also switched licensing from GPL version 2 (with special exceptions for static linking to proprietary code outside the FreeRTOS kernel itself) to MIT.[7]
Implementation
[edit]FreeRTOS is designed to be small and simple. It is mostly written in the C programming language to make it easy to port and maintain. It also comprises a few assembly language functions where needed, mostly in architecture-specific scheduler routines.
Process management
[edit]FreeRTOS provides methods for multiple threads or tasks, mutexes, semaphores and software timers. A tickless mode is provided for low power applications. Thread priorities are supported. FreeRTOS applications can be statically allocated, but objects can also be dynamically allocated with five schemes of memory management (allocation):
- allocate only;
- allocate and free with a very simple, fast, algorithm;
- a more complex but fast allocate and free algorithm ",Technology & Computing 
"Linux on embedded systems
The Linux Operating system is prevalent in embedded systems. As of 2024, developer surveys and industry reports find that Embedded Linux is used in 44%-46% of embedded systems.[1][2][3] Due to its versatility, its large community of developers, as well as its adaptability to devices with size and power constraints, Linux is a popular choice for devices used in Edge Computing[4] and autonomous systems.[citation needed]
History
[edit]- additional source for this section [5]
Early Days
[edit]Prior to becoming the de-facto standard for microprocessor-based devices,[6] a linux distribution was created for the Linux Router Project, with the intent of transforming PCs to routers.
Starting in the late 1990s and the first decade of the 21st century, the introduction of uCLinux enabled ports to a large variety of microprocessors.[7] Linux is also used as an alternative to using a proprietary operating system and its associated toolchain.[8]
The introduction of busybox in 1999, enabled packaging critical tools in an embedded system, with a minimal footprint.
As mentioned in the article ARM architecture family, due to their low costs, low power consumption, and low heat generation, arm processors are prevalent in many embedded devices. The open source nature, the flexibility, and the stability of Linux contributes to its wide-spread adoption to ARM devices.[9]
Development Toolchains
[edit]The development of the GNU cross-compiler facilitated the adoption of Linu",Technology & Computing 
"Buildroot
Buildroot is a set of Makefiles and patches that simplifies and automates the process of building a complete and bootable Linux environment for an embedded system, while using cross-compilation to allow building for multiple target platforms on a single Linux-based development system. Buildroot can automatically build the required cross-compilation toolchain, create a root file system, compile a Linux kernel image, and generate a boot loader for the targeted embedded system, or it can perform any independent combination of these steps. For example, an already installed cross-compilation toolchain can be used independently, while Buildroot only creates the root file system.[3][4][5]: 2–3, 10–12 [6]
Buildroot is primarily intended to be used with small or embedded systems based on various computer architectures and instruction set architectures (ISAs), including x86, ARM, MIPS, PowerPC and RISC-V.[7] Numerous architectures and their variants are supported; Buildroot also comes with default configurations for several off-the-shelf available embedded boards, such as Cubieboard, Raspberry Pi and SheevaPlug.[8][9]: 25 Several third-party projects and products use Buildroot as the basis for their build systems, including the OpenWrt project that creates an embedded operating system, and firmware for the customer-premises equipment (CPE) used by the Google Fiber broadband service.[9]: 15 [10]
Multiple C standard libraries are supported as part of the toolchain, including th",Technology & Computing 
"Interrupt
In digital computers, an interrupt[a] is a request for the processor to interrupt currently executing code (when permitted), so that the event can be processed in a timely manner. If the request is accepted, the processor will suspend its current activities, save its state, and execute a function called an interrupt handler (or an interrupt service routine, ISR) to deal with the event. This interruption is often temporary, allowing the software to resume[b] normal activities after the interrupt handler finishes, although the interrupt could instead indicate a fatal error.[3]
Interrupts are commonly used by hardware devices to indicate electronic or physical state changes that require time-sensitive attention. Interrupts are also commonly used to implement computer multitasking and system calls, especially in real-time computing. Systems that use interrupts in these ways are said to be interrupt-driven.[4]
History
[edit]Hardware interrupts were introduced as an optimization, eliminating unproductive waiting time in polling loops, waiting for external events. The first system to use this approach was the DYSEAC, completed in 1954, although earlier systems provided error trap functions.[5]
The UNIVAC 1103A computer is generally credited with the earliest use of interrupts in 1953.[6][7] Earlier, on the UNIVAC I (1951) ""Arithmetic overflow either triggered the execution of a two-instruction fix-up routine at address 0, or, at the programmer's option, caused the computer",Technology & Computing 
"Microcontroller
A microcontroller (MC, uC, or μC) or microcontroller unit (MCU) is a small computer on a single integrated circuit. A microcontroller contains one or more CPUs (processor cores) along with memory and programmable input/output peripherals. Program memory in the form of NOR flash, OTP ROM, or ferroelectric RAM is also often included on the chip, as well as a small amount of RAM. Microcontrollers are designed for embedded applications, in contrast to the microprocessors used in personal computers or other general-purpose applications consisting of various discrete chips.
In modern terminology, a microcontroller is similar to, but less sophisticated than, a system on a chip (SoC). A SoC may include a microcontroller as one of its components but usually integrates it with advanced peripherals like a graphics processing unit (GPU), a Wi-Fi module, or one or more coprocessors.
Microcontrollers are used in automatically controlled products and devices, such as automobile engine control systems, implantable medical devices, remote controls, office machines, appliances, power tools, toys, and other embedded systems. By reducing the size and cost compared to a design that uses a separate microprocessor, memory, and input/output devices, microcontrollers make digital control of more devices and processes practical. Mixed-signal microcontrollers are common, integrating analog components needed to control non-digital electronic systems. In the context of the Internet of Thi",Technology & Computing 
"Microprocessor
A microprocessor is a computer processor for which the data processing logic and control is included on a single integrated circuit (IC), or a small number of ICs. The microprocessor contains the arithmetic, logic, and control circuitry required to perform the functions of a computer's central processing unit (CPU). The IC is capable of interpreting and executing program instructions and performing arithmetic operations.[1] The microprocessor is a multipurpose, clock-driven, register-based, digital integrated circuit that accepts binary data as input, processes it according to instructions stored in its memory, and provides results (also in binary form) as output. Microprocessors contain both combinational logic and sequential digital logic, and operate on numbers and symbols represented in the binary number system.
The integration of a whole CPU onto a single or a few integrated circuits using Very-Large-Scale Integration (VLSI) greatly reduced the cost of processing power. Integrated circuit processors are produced in large numbers by highly automated metal–oxide–semiconductor (MOS) fabrication processes, resulting in a relatively low unit price. Single-chip processors increase reliability because there are fewer electrical connections that can fail. As microprocessor designs improve, the cost of manufacturing a chip (with smaller components built on a semiconductor chip the same size) generally stays the same, according to Rock's law.
Before microprocessors,",Technology & Computing 
"System on a chip
A system on a chip (SoC) is an integrated circuit that combines most or all key components of a computer or electronic system onto a single microchip.[1] Typically, an SoC includes a central processing unit (CPU) with memory, input/output, and data storage control functions, along with optional features like a graphics processing unit (GPU), Wi-Fi connectivity, and radio frequency processing. This high level of integration minimizes the need for separate, discrete components, thereby enhancing power efficiency and simplifying device design.
High-performance SoCs are often paired with dedicated memory, such as LPDDR, and flash storage chips, such as eUFS or eMMC, which may be stacked directly on top of the SoC in a package-on-package (PoP) configuration or placed nearby on the motherboard. Some SoCs also operate alongside specialized chips, such as cellular modems.[2]
Fundamentally, SoCs integrate one or more processor cores with critical peripherals. This comprehensive integration is conceptually similar to how a microcontroller is designed, but providing far greater computational power. This unified design delivers lower power consumption and a reduced semiconductor die area compared to traditional multi-chip architectures, though at the cost of reduced modularity and component replaceability.
SoCs are ubiquitous in mobile computing, where compact, energy-efficient designs are critical. They power smartphones, tablets, and smartwatches, and are increasingly ",Technology & Computing 
"RISC-V
RISC-V (pronounced ""risk-five""[4]: 1 ) is a free and open-source instruction set architecture (ISA) based on reduced instruction set computer (RISC) principles. Unlike proprietary ISAs such as x86 and ARM, RISC-V is described as ""free and open"" because its specifications are released under permissive open-source licenses and can be implemented without paying royalties.[5]
RISC-V was developed in 2010 at the University of California, Berkeley as the fifth generation of RISC processors created at the university since 1981.[6] In 2015, development and maintenance of the standard was transferred to RISC-V International, a non-profit organization based in Switzerland with more than 4,500 members as of 2025.[7]
As of 2025[update], RISC-V has become a popular architecture for microcontrollers and embedded systems, with development of higher-performance implementations targeting mobile, desktop, and server markets ongoing. The ISA is supported by several major Linux distributions, and companies such as SiFive, Andes Technology, Synopsys, Alibaba, and Raspberry Pi offer or have announced commercial systems on a chip (SoCs) that incorporate one or more RISC-V compatible CPU cores.[8]
History
[edit]The term RISC dates from about 1980.[9] Before then, there was some knowledge (see John Cocke) that simpler computers can be effective, but the design principles were not widely described. Simple, effective computers have always been of academic interest, and resulted in the RISC instr",Technology & Computing 
"PowerPC
PowerPC (with the backronym Performance Optimization With Enhanced RISC – Performance Computing, sometimes abbreviated as PPC) is a reduced instruction set computer (RISC) instruction set architecture (ISA) created by the 1991 Apple–IBM–Motorola alliance, known as AIM. PowerPC, as an evolving instruction set, has been named Power ISA since 2006, while the old name lives on as a trademark for some implementations of Power Architecture–based processors.
Originally intended for personal computers, the architecture is well known for being used by Apple's desktop and laptop lines from 1994 until 2006, and in several videogame consoles including Microsoft's Xbox 360, Sony's PlayStation 3, and Nintendo's GameCube, Wii, and Wii U. PowerPC was also used for the Curiosity and Perseverance rovers on Mars and a variety of satellites. It has since become a niche architecture for personal computers, particularly with AmigaOS 4 implementations, but remains popular for embedded systems.
PowerPC was the cornerstone of AIM's PReP and Common Hardware Reference Platform (CHRP) initiatives in the 1990s. It is largely based on the earlier IBM POWER architecture, and retains a high level of compatibility with it; the architectures have remained close enough that the same programs and operating systems will run on both if some care is taken in preparation; newer chips in the Power series use the Power ISA.
History
[edit]The history of RISC began with IBM's 801 research project, on which John",Technology & Computing 
"x86
x86 (also known as 80x86[1] or the 8086 family)[2] is a family of complex instruction set computer (CISC) instruction set architectures[a] initially developed by Intel, based on the 8086 microprocessor and its 8-bit-external-bus variant, the 8088. The 8086 was introduced in 1978 as a fully 16-bit extension of 8-bit Intel's 8080 microprocessor, with memory segmentation as a solution for addressing more memory than can be covered by a plain 16-bit address. The term ""x86"" came into being because the names of several successors to Intel's 8086 processor end in ""86"", including the 80186, 80286, 80386 and 80486. Colloquially, their names were ""186"", ""286"", ""386"" and ""486"".
The term is not synonymous with IBM PC compatibility, as this implies a multitude of other computer hardware. Embedded systems and general-purpose computers used x86 chips before the PC-compatible market started,[b] some of them before the IBM PC (1981) debut.
As of June 2022[update], most desktop and laptop computers sold are based on the x86 architecture family,[3] while mobile categories such as smartphones or tablets are dominated by ARM. At the high end, x86 continues to dominate computation-intensive workstation and cloud computing segments.[4]
-
The x86 architectures were based on the Intel 8086 microprocessor chip, initially released in 1978.
-
Intel Core i7, a modern x86-compatible, 64-bit multicore processor
-
AMD Athlon (early version), a technically different but fully compatible x86 implementatio",Technology & Computing 
"x86-64
x86-64 (also known as x64, x86_64, AMD64, and Intel 64)[note 1] is a 64-bit extension of the x86 instruction set. It was announced in 1999 and first available in the AMD Opteron family in 2003. It introduces two new operating modes: 64-bit mode and compatibility mode, along with a new four-level paging mechanism.
In 64-bit mode, x86-64 supports significantly larger amounts of virtual memory and physical memory compared to its 32-bit predecessors, allowing programs to utilize more memory for data storage. The architecture expands the number of general-purpose registers from 8 to 16, all fully general-purpose, and extends their width to 64 bits.
Floating-point arithmetic is supported through mandatory SSE2 instructions in 64-bit mode. While the older x87 FPU and MMX registers are still available, they are generally superseded by a set of sixteen 128-bit vector registers (XMM registers). Each of these vector registers can store one or two double-precision floating-point numbers, up to four single-precision floating-point numbers, or various integer formats.
In 64-bit mode, instructions are modified to support 64-bit operands and 64-bit addressing mode.
The x86-64 architecture defines a compatibility mode that allows 16-bit and 32-bit user applications to run unmodified alongside 64-bit applications, provided the 64-bit operating system supports them.[11][note 2] Since the full x86-32 instruction sets remain implemented in hardware without the need for emulation, these old",Technology & Computing 
"BIOS
In computing, BIOS (/ˈbaɪɒs, -oʊs/, BY-oss, -ohss; Basic Input/Output System, also known as the System BIOS, ROM BIOS, BIOS ROM or PC BIOS) is a type of firmware used to provide runtime services for operating systems and programs and to perform hardware initialization during the booting process (power-on startup).[1] The firmware comes pre-installed on the computer's motherboard.
The name originates from the Basic Input/Output System used in the CP/M operating system in 1975.[2][3] The BIOS firmware was originally proprietary to the IBM PC; it was reverse engineered by some companies (such as Phoenix Technologies) looking to create compatible systems. The interface of that original system serves as a de facto standard.
The BIOS in older PCs initializes and tests the system hardware components (power-on self-test or POST for short), and loads a boot loader from a mass storage device which then initializes a kernel. In the era of DOS, the BIOS provided BIOS interrupt calls for the keyboard, display, storage, and other input/output (I/O) devices that standardized an interface to application programs and the operating system. More recent operating systems do not use the BIOS interrupt calls after startup.[4]
Most BIOS implementations are specifically designed to work with a particular computer or motherboard model, by interfacing with various devices especially system chipset. Originally, BIOS firmware was stored in a ROM chip on the PC motherboard. In later computer systems",Technology & Computing 
"UEFI
Unified Extensible Firmware Interface (UEFI, /ˈjuːɪfaɪ/ as an acronym)[c] is a specification for the firmware architecture of a computing platform. When a computer is powered on, the UEFI implementation is typically the first that runs, before starting the operating system. Examples include AMI Aptio, Phoenix SecureCore, TianoCore EDK II, and InsydeH2O.
UEFI replaces the BIOS that was present in the boot ROM of all personal computers that are IBM PC compatible,[5][6] although it can provide backwards compatibility with the BIOS using CSM booting. Unlike its predecessor, BIOS, which is a de facto standard originally created by IBM as proprietary software, UEFI is an open standard maintained by an industry consortium. Like BIOS, most UEFI implementations are proprietary.
Intel developed the original Extensible Firmware Interface (EFI) specification. The last Intel version of EFI was 1.10 released in 2005. Subsequent versions have been developed as UEFI by the UEFI Forum.
UEFI is independent of platform and programming language, but C is used for the reference implementation TianoCore EDKII.
History
[edit]The original motivation for EFI came during early development of the first Intel–HP Itanium systems in the mid-1990s. BIOS limitations (such as 16-bit real mode, 1 MB addressable memory space,[7] assembly language programming, and PC AT hardware) had become too restrictive for the larger server platforms Itanium was targeting.[8] The effort to address these concerns began ",Technology & Computing 
"Device driver
In the context of an operating system, a device driver is a computer program that operates or controls a particular type of device that is attached to a computer or automaton.[1] A driver provides a software interface to hardware devices, enabling operating systems and other computer programs to access hardware functions without needing to know precise details about the hardware being used.
A driver communicates with the device through the computer bus or communications subsystem to which the hardware connects. When a calling program invokes a routine in the driver, the driver issues commands to the device (drives it). Once the device sends data back to the driver, the driver may invoke routines in the original calling program.
Drivers are hardware dependent and operating-system-specific. They usually provide the interrupt handling required for any necessary asynchronous time-dependent hardware interface.[2]
Purpose
[edit]The main purpose of device drivers is to provide abstraction by acting as a translator between a hardware device and the applications or operating systems that use it.[1] Programmers can write higher-level application code independently of whatever specific hardware the end-user is using. For example, a high-level application for interacting with a serial port may simply have two functions for ""send data"" and ""receive data"". At a lower level, a device driver implementing these functions would communicate to the particular serial port controller",Technology & Computing 
"File system
In computing, a file system or filesystem (often abbreviated to FS or fs) governs file organization and access. A local file system is a capability of an operating system that services the applications running on the same computer.[1][2] A distributed file system is a protocol that provides file access between networked computers.
A file system provides a data storage service that allows applications to share mass storage. Without a file system, applications could access the storage in incompatible ways that lead to resource contention, data corruption and data loss.
There are many file system designs and implementations – with various structure and features and various resulting characteristics such as speed, flexibility, security, size and more.
File systems have been developed for many types of storage devices, including hard disk drives (HDDs), solid-state drives (SSDs), magnetic tapes and optical discs.[3]
A portion of the computer main memory can be set up as a RAM disk that serves as a storage device for a file system. File systems such as tmpfs can store files in virtual memory.
A virtual file system provides access to files that are either computed on request, called virtual files (see procfs and sysfs), or are mapping into another, backing storage.
Etymology
[edit]From c. 1900 and before the advent of computers the terms file system, filing system and system for filing were used to describe methods of organizing, storing and retrieving paper documents.[4",Technology & Computing 
"NTFS
NT File System (NTFS) (commonly called New Technology File System) is a proprietary journaling file system developed by Microsoft in the 1990s.[10][11][2]
It was developed to overcome scalability, security and other limitations with FAT.[12] NTFS adds several features that FAT and HPFS lack, including: access control lists (ACLs); filesystem encryption; transparent compression; sparse files; file system journaling and volume shadow copy, a feature that allows backups of a system while in use.
Starting with Windows NT 3.1, it is the default file system of the Windows NT family superseding the File Allocation Table (FAT) file system.[13] NTFS read/write support is available on Linux and BSD using NTFS3 in Linux and NTFS-3G in BSD.[14][15]
NTFS uses several files hidden from the user to store metadata about other files stored on the drive which can help improve speed and performance when reading data.[1]
NTFS was slated to be replaced by WinFS, one of the anchor features of the Longhorn platform, however WinFS was cancelled after Microsoft was unable to resolve performance problems with the filesystem.
History
[edit]In the mid-1980s, Microsoft and IBM formed a joint project to create the next generation of graphical operating system; the result was OS/2 and HPFS. Because Microsoft disagreed with IBM on many important issues, they eventually separated; OS/2 remained an IBM project and Microsoft worked to develop Windows NT and NTFS.
The HPFS file system for OS/2 contained se",Technology & Computing 
"File Allocation Table
File Allocation Table (FAT) is a file system developed for personal computers and was the default file system for the MS-DOS and Windows 9x operating systems.[3] Originally developed in 1977 for use on floppy disks, it was adapted for use on hard disks and other devices. The increase in disk drive capacity over time drove modifications to the design that resulted in versions: FAT12, FAT16, FAT32, and exFAT. FAT was replaced with NTFS as the default file system on Microsoft operating systems starting with Windows XP.[4] Nevertheless, FAT continues to be commonly used on relatively small capacity solid-state storage technologies such as SD card, MultiMediaCard (MMC) and eMMC because of its compatibility and ease of implementation.[5]
Uses
[edit]
Historical
[edit]FAT was used on hard disks throughout the DOS and Windows 9x eras. Microsoft introduced NTFS with the Windows NT platform in 1993, but FAT remained the standard for the home user until the introduction of Windows XP in 2001. Windows Me was the final version of Windows to use FAT as its default file system.
For floppy disks, FAT has been standardized as ECMA-107[6] and ISO/IEC 9293:1994[7] (superseding ISO 9293:1987[8]). These standards cover FAT12 and FAT16 with only short 8.3 filename support; long filenames with VFAT were partially patented.[9] While FAT12 is used on floppy disks, FAT16 and FAT32 are typically found on the larger media.
Modern
[edit]FAT is used internally for the EFI system parti",Technology & Computing 
"ext4
ext4 (fourth extended filesystem) is a journaling file system for Linux, developed as the successor to ext3.
ext4 was initially a series of backward-compatible extensions to ext3, many of them originally developed by Cluster File Systems for the Lustre file system between 2003 and 2006, meant to extend storage limits and add other performance improvements.[4] However, other Linux kernel developers opposed accepting extensions to ext3 for stability reasons,[5] and proposed to fork the source code of ext3, rename it as ext4, and perform all the development there, without affecting existing ext3 users. This proposal was accepted, and on 28 June 2006, Theodore Ts'o, the ext3 maintainer, announced the new plan of development for ext4.[6]
A preliminary development version of ext4 was included in version 2.6.19[7] of the Linux kernel. On 11 October 2008, the patches that mark ext4 as stable code were merged in the Linux 2.6.28 source code repositories,[8] denoting the end of the development phase and recommending ext4 adoption. Kernel 2.6.28, containing the ext4 filesystem, was finally released on 25 December 2008.[9] On 15 January 2010, Google announced that it would upgrade its storage infrastructure from ext2 to ext4.[10] On 14 December 2010, Google also announced it would use ext4, instead of YAFFS, on Android 2.3.[11]
Adoption
[edit]ext4 is the default file system for many Linux distributions including Debian and Ubuntu.[12]
Features
[edit]- Large file system
- The ext4 fi",Technology & Computing 
"Btrfs
Btrfs (pronounced as ""better F S"",[9] ""butter F S"",[13][14] ""b-tree F S"",[14] or ""B.T.R.F.S."") is a computer storage format that combines a file system based on the copy-on-write (COW) principle with a logical volume manager (distinct from Linux's LVM), developed together. It was created by Chris Mason in 2007[15] for use in Linux, and since November 2013, the file system's on-disk format has been declared stable in the Linux kernel.[16]
Btrfs is intended to address the lack of pooling, snapshots, integrity checking, data scrubbing, and integral multi-device spanning in Linux file systems.[9] Mason, the principal Btrfs author, stated that its goal was ""to let [Linux] scale for the storage that will be available. Scaling is not just about addressing the storage but also means being able to administer and to manage it with a clean interface that lets people see what's being used and makes it more reliable"".[17]
History
[edit]The core data structure of Btrfs—the copy-on-write B-tree—was originally proposed by IBM researcher Ohad Rodeh at a USENIX conference in 2007.[18] Chris Mason, an engineer working on ReiserFS for SUSE at the time, joined Oracle later that year and began work on a new file system based on B-trees.[19]
In 2008, the principal developer of the ext3 and ext4 file systems, Theodore Ts'o, stated that although ext4 has improved features, it is not a major advance; it uses old technology and is a stop-gap. Ts'o said that Btrfs is the better direction because """,Technology & Computing 
"XFS
XFS is a high-performance 64-bit journaling file system created by Silicon Graphics, Inc (SGI) in 1993.[7] It was the default file system in SGI's IRIX operating system starting with its version 5.3. XFS was ported to the Linux kernel in 2001; as of June 2014, XFS is supported by most Linux distributions; Red Hat Enterprise Linux uses it as its default file system.
XFS excels in the execution of parallel input/output (I/O) operations due to its design, which is based on allocation groups (a type of subdivision of the physical volumes in which XFS is used- also shortened to AGs). Because of this, XFS enables extreme scalability of I/O threads, file system bandwidth, and size of files and of the file system itself when spanning multiple physical storage devices. XFS ensures the consistency of data by employing metadata journaling and supporting write barriers. Space allocation is performed via extents with data structures stored in B+ trees, improving the overall performance of the file system, especially when handling large files. Delayed allocation assists in the prevention of file system fragmentation; online defragmentation is also supported.
History
[edit]First generation XFS
[edit]Silicon Graphics began development of XFS[8] (""X"" was meant to be filled in later but never was) in 1993 for its UNIX System V based IRIX operating system. The file system was released under the GNU General Public License (GPL) in May 1999.[9]
Second generation XFS
[edit]A team led by Steve ",Technology & Computing 
"ZFS
ZFS (previously Zettabyte File System) is a file system with volume management capabilities. It began as part of the Sun Microsystems Solaris operating system in 2001. Large parts of Solaris, including ZFS, were published under an open source license as OpenSolaris for around 5 years from 2005 before being placed under a closed source license when Oracle Corporation acquired Sun in 2009–2010. During 2005 to 2010, the open source version of ZFS was ported to Linux, Mac OS X (continued as MacZFS) and FreeBSD. In 2010, the illumos project forked a recent version of OpenSolaris, including ZFS, to continue its development as an open source project. In 2013, OpenZFS was founded to coordinate the development of open source ZFS.[3][4][5] OpenZFS maintains and manages the core ZFS code, while organizations using ZFS maintain the specific code and validation processes required for ZFS to integrate within their systems. OpenZFS is widely used in Unix-like systems.[6][7][8]
Overview
[edit]The management of stored data generally involves two aspects: the physical volume management of one or more block storage devices (such as hard drives and SD cards), including their organization into logical block devices as VDEVs (ZFS Virtual Device)[9] as seen by the operating system (often involving a volume manager, RAID controller, array manager, or suitable device driver); and the management of data and files that are stored on these logical block devices (a file system or other data storage).",Technology & Computing 
"Hierarchical storage management
Hierarchical storage management (HSM), also known as tiered storage,[1] is a data storage and data management technique that automatically moves data between high-cost and low-cost storage media. HSM systems exist because high-speed storage devices, such as solid-state drive arrays, are more expensive (per byte stored) than slower devices, such as hard disk drives, optical discs and magnetic tape drives. While it would be ideal to have all data available on high-speed devices all the time, this is prohibitively expensive for many organizations. Instead, HSM systems store the bulk of the enterprise's data on slower devices, and then copy data to faster disk drives when needed. The HSM system monitors the way data is used and makes best guesses as to which data can safely be moved to slower devices and which data should stay on the fast devices.
HSM may also be used where more robust storage is available for long-term archiving, but this is slow to access. This may be as simple as an off-site backup, for protection against a building fire.
HSM is a long-established concept, dating back to the beginnings of commercial data processing. The techniques used though have changed significantly as new technology becomes available, for both storage and for long-distance communication of large data sets. The scale of measures such as 'size' and 'access time' have changed dramatically. Despite this, many of the underlying concepts keep returning to favour y",Technology & Computing 
"RAID
RAID (/reɪd/; redundant array of inexpensive disks or redundant array of independent disks)[1][2] is a data storage virtualization technology that combines multiple physical data storage components into one or more logical units for the purposes of data redundancy, performance improvement, or both. This is in contrast to the previous concept of highly reliable mainframe disk drives known as single large expensive disk (SLED).[1][3]
Data is distributed across the drives in one of several ways, referred to as RAID levels, depending on the required level of redundancy and performance. The different schemes, or data distribution layouts, are named by the word ""RAID"" followed by a number, for example RAID 0 or RAID 1. Each scheme, or RAID level, provides a different balance among the key goals: reliability, availability, performance, and capacity. RAID levels greater than RAID 0 provide protection against unrecoverable sector read errors, as well as against failures of whole physical drives.
History
[edit]The term ""RAID"" was invented by David Patterson, Garth Gibson, and Randy Katz at the University of California, Berkeley in 1987. In their June 1988 paper ""A Case for Redundant Arrays of Inexpensive Disks (RAID)"", presented at the SIGMOD Conference, they argued that the top-performing mainframe disk drives of the time could be beaten on performance by an array of the inexpensive drives that had been developed for the growing personal computer market. Although failures would r",Technology & Computing 
"Protocol stack
The protocol stack or network stack is an implementation of a computer networking protocol suite or protocol family. Some of these terms are used interchangeably but strictly speaking, the suite is the definition of the communication protocols, and the stack is the software implementation of them.[1]
Individual protocols within a suite are often designed with a single purpose in mind. This modularization simplifies design and evaluation. Because each protocol module usually communicates with two others, they are commonly imagined as layers in a stack of protocols. The lowest protocol always deals with low-level interaction with the communications hardware. Each higher layer adds additional capabilities. User applications usually deal only with the topmost layers.[2]
General protocol suite description
[edit]T ~ ~ ~ T [A] [B]_____[C]
Imagine three computers: A, B, and C. A and B both have radio equipment and can communicate via the airwaves using a suitable network protocol (such as IEEE 802.11). B and C are connected via a cable, using it to exchange data (again, with the help of a protocol, for example Point-to-Point Protocol). However, neither of these two protocols will be able to transport information from A to C, because these computers are conceptually on different networks. An inter-network protocol is required to connect them.
One could combine the two protocols to form a powerful third, mastering both cable and wireless transmission, but a different sup",Technology & Computing 
"Computer network programming
Computer network programming involves writing computer programs that enable processes to communicate with each other across a computer network.[1]
Connection-oriented and connectionless communications
[edit]Very generally, most of communications can be divided into connection-oriented, and connectionless. Whether a communication is connection-oriented or connectionless, is defined by the communication protocol, and not by application programming interface (API). Examples of the connection-oriented protocols include Transmission Control Protocol (TCP) and Sequenced Packet Exchange (SPX), and examples of connectionless protocols include User Datagram Protocol (UDP), ""raw IP"", and Internetwork Packet Exchange (IPX).
Clients and servers
[edit]For connection-oriented communications, communication parties usually have different roles. One party is usually waiting for incoming connections; this party is usually referred to as ""server"". Another party is the one which initiates connection; this party is usually referred to as ""client"".
For connectionless communications, one party (""server"") is usually waiting for an incoming packet, and another party (""client"") is usually understood as the one which sends an unsolicited packet to ""server"".
Popular protocols and APIs
[edit]Network programming traditionally covers different layers of OSI/ISO model (most of application-level programming belongs to L4 and up). The table below contains some examples of popular ",Technology & Computing 
"Winsock
In computing, the Windows Sockets API (WSA), later shortened to Winsock, is an application programming interface (API) that defines how Windows network application software should access network services, especially TCP/IP. It defines a standard interface between a Windows TCP/IP client application (such as an FTP client or a web browser) and the underlying TCP/IP protocol stack. The nomenclature is based on the Berkeley sockets API used in BSD for communications between programs.
Background
[edit]Early Microsoft operating systems, both MS-DOS and Microsoft Windows, offered limited networking capability, chiefly based on NetBIOS. In particular, Microsoft did not offer support for the TCP/IP protocol stack at that time. A number of university groups and commercial vendors, including the PC/IP group at MIT, FTP Software, Sun Microsystems, Ungermann-Bass, and Excelan, introduced TCP/IP products for MS-DOS, often as part of a hardware/software bundle. When Windows 2.0 was released, these vendors were joined by others such as Distinct and NetManage in offering TCP/IP for Windows.
The drawback faced by all of these vendors was that each of them used their own API (Application Programming Interface). Without a single standard programming model, it was difficult to persuade independent software developers to create networking applications which would work with any vendor's underlying TCP/IP implementation. Add to this the fact that end users were wary of getting locked into a",Technology & Computing 
"Berkeley sockets
A Berkeley (BSD) socket is an application programming interface (API) for Internet domain sockets and Unix domain sockets, used for inter-process communication (IPC). It is commonly implemented as a library of linkable modules. It originated with the 4.2BSD Unix operating system, which was released in 1983.
A socket is an abstract representation (handle) for the local endpoint of a network communication path. The Berkeley sockets API represents it as a file descriptor in the Unix philosophy that provides a common interface for input and output to streams of data.
Berkeley sockets evolved with little modification from a de facto standard into a component of the POSIX specification. The term POSIX sockets is essentially synonymous with Berkeley sockets, but they are also known as BSD sockets, acknowledging the first implementation in the Berkeley Software Distribution.
History and implementations
[edit]Berkeley sockets originated with the 4.2BSD Unix operating system, released in 1983, as a programming interface. Not until 1989, however, could the University of California, Berkeley release versions of the operating system and networking library free from the licensing constraints of AT&T Corporation's proprietary Unix.
All modern operating systems implement a version of the Berkeley socket interface. It became the standard interface for applications running in the Internet. Even the Winsock implementation for MS Windows, created by unaffiliated developers, clos",Technology & Computing 
"Zero-copy
In computer science, zero-copy refers to techniques that enable data transfer between memory spaces without requiring the CPU to copy the data. By avoiding redundant copying, zero-copy methods minimize CPU usage and memory bandwidth, leading to substantial performance gains. This is crucial for applications demanding high data throughput, such as network communication, file I/O, and multimedia processing.[1][2][3][4]
Principle
[edit]Zero-copy programming techniques can be used when exchanging data within a user space process (i.e. between two or more threads, etc.) and/or between two or more processes (see also producer–consumer problem) and/or when data has to be accessed / copied / moved inside kernel space or between a user space process and kernel space portions of operating systems (OS).
Usually when a user space process has to execute system operations like reading or writing data from/to a device (i.e. a disk, a NIC, etc.) through their high level software interfaces or like moving data from one device to another, etc., it has to perform one or more system calls that are then executed in kernel space by the operating system.
If data has to be copied or moved from source to destination and both are located inside kernel space (i.e. two files, a file and a network card, etc.) then unnecessary data copies, from kernel space to user space and from user space to kernel space, can be avoided by using special (zero-copy) system calls, usually available in most recen",Technology & Computing 
"Memory management
Memory management (also dynamic memory management, dynamic storage allocation, or dynamic memory allocation) is a form of resource management applied to computer memory. The essential requirement of memory management is to provide ways to dynamically allocate portions of memory to programs at their request, and free it for reuse when no longer needed. This is critical to any advanced computer system where more than a single process might be underway at any time.[1]
Several methods have been devised that increase the effectiveness of memory management. Virtual memory systems separate the memory addresses used by a process from actual physical addresses, allowing separation of processes and increasing the size of the virtual address space beyond the available amount of RAM using paging or swapping to secondary storage. The quality of the virtual memory manager can have an extensive effect on overall system performance. The system allows a computer to appear as if it may have more memory available than physically present, thereby allowing multiple processes to share it.
In some operating systems, e.g. Burroughs/Unisys MCP,[2] and OS/360 and successors,[3] memory is managed by the operating system.[note 1] In other operating systems, e.g. Unix-like operating systems, memory is managed at the application level.
Memory management within an address space is generally categorized as either manual memory management or automatic memory management.
Manual memory manage",Technology & Computing 
"Virtual memory
In computing, virtual memory, or virtual storage,[b] is a memory management technique that provides an ""idealized abstraction of the storage resources that are actually available on a given machine""[3] which ""creates the illusion to users of a very large (main) memory"".[4]
The computer's operating system, using a combination of hardware and software, maps memory addresses used by a program, called virtual addresses, into physical addresses in computer memory. Main storage, as seen by a process or task, appears as a contiguous address space or collection of contiguous segments. The operating system manages virtual address spaces and the assignment of real memory to virtual memory.[5] Address translation hardware in the CPU, often referred to as a memory management unit (MMU), automatically translates virtual addresses to physical addresses. Software within the operating system may extend these capabilities, utilizing, e.g., disk storage, to provide a virtual address space that can exceed the capacity of real memory and thus reference more memory than is physically present in the computer.
The primary benefits of virtual memory include freeing applications from having to manage a shared memory space, ability to share memory used by libraries between processes, increased security due to memory isolation, and being able to conceptually use more memory than might be physically available, using the technique of paging or segmentation.
Properties
[edit]Virtual memory ",Technology & Computing 
"Memory paging
In computer operating systems, memory paging is a memory management scheme that allows the physical memory used by a program to be non-contiguous.[1] This also helps avoid the problem of memory fragmentation and requiring compaction to reduce fragmentation.
Paging is often combined with the related technique of allocating and freeing page frames and storing pages on and retrieving them from secondary storage[a] in order to allow the aggregate size of the address spaces to exceed the physical memory of the system.[2] For historical reasons, this technique is sometimes referred to as swapping.
When combined with virtual memory, it is known as paged virtual memory. In this scheme, the operating system retrieves data from secondary storage in blocks of the same size (pages). Paging is an important part of virtual memory implementations in modern operating systems, using secondary storage to let programs exceed the size of available physical memory.
Hardware support is necessary for efficient translation of logical addresses to physical addresses. As such, paged memory functionality is usually hardwired into a CPU through its Memory Management Unit (MMU) or Memory Protection Unit (MPU), and separately enabled by privileged system code in the operating system's kernel. In CPUs implementing the x86 instruction set architecture (ISA) for instance, the memory paging is enabled via the CR0 control register.
History
[edit]In the 1960s, swapping was an early virtual memory ",Technology & Computing 
"Segment
Appearance
(Redirected from Segmentation)
Segment, segmentation, segmented, or segmental may refer to:
Biology
[edit]- Segmentation (biology), the division of body plans into a series of repetitive segments
- Internodal segment, the portion of a nerve fiber between two Nodes of Ranvier
- Segment, in fruit anatomy, a section of a citrus fruit
- Parts of a genome, especially in virology
Computing and communications
[edit]- Episode§Segment (radio and television), sub-unit of an episode of radio or television or podcast
- Memory segmentation, the division of computer memory into segments
- Image segmentation, the process of partitioning a digital image into multiple segments
- Time-series segmentation, the process of partitioning a time-series into a sequence of discrete segments in order to reveal the underlying properties of its source
- Network segmentation, splitting a computer network into subnetworks
- Packet segmentation, the process of dividing a data packet into smaller units
- TCP segmentation, the process of dividing a data stream into segments for transmission
- Segment architecture, a detailed, formal description of areas within an enterprise
Geometry
[edit]- Line segment, part of a line bounded by two end points
- Circular segment, the region of a circle cut off from the rest by a secant or chord
- Spherical segment, the solid defined by cutting a sphere with a pair of parallel planes
- Arc (geometry), a closed segment of a differentiable curve
Linguistics
[",Technology & Computing 
"Reference counting
In computer science, reference counting is a programming technique of storing the number of references, pointers, or handles to a resource, such as an object, a block of memory, disk space, and others.
In garbage collection algorithms, reference counts may be used to deallocate objects that are no longer needed.
Advantages and disadvantages
[edit]The main advantage of the reference counting over tracing garbage collection is that objects are reclaimed as soon as they can no longer be referenced, and in an incremental fashion, without long pauses for collection cycles and with clearly defined lifetime of every object. In real-time applications or systems with limited memory, this is important to maintain responsiveness. Reference counting is also among the simplest forms of memory management to implement. It also allows for effective management of non-memory resources such as operating system objects, which are often much scarcer than memory (tracing garbage collection systems use finalizers for this,[citation needed] but the delayed reclamation may cause problems). Weighted reference counts are a good solution for garbage collecting a distributed system.
Tracing garbage collection cycles are triggered too often if the set of live objects fills most of the available memory;[citation needed] it requires extra space to be efficient.[citation needed] Reference counting performance does not deteriorate as the total amount of free space decreases.[2]
Reference co",Technology & Computing 
"Tracing garbage collection
In computer programming, tracing garbage collection is a form of automatic memory management that consists of determining which objects should be deallocated (""garbage collected"") by tracing which objects are reachable by a chain of references from certain ""root"" objects, and considering the rest as ""garbage"" and collecting them. Tracing is the most common type of garbage collection – so much so that ""garbage collection"" often refers to the tracing method, rather than others such as reference counting – and there are a large number of algorithms used in implementation.
Reachability of an object
[edit][1]Informally, an object is reachable if it is referenced by at least one variable in the program, either directly or through references from other reachable objects. More precisely, objects can be reachable in only two ways:
- A distinguished set of roots: objects that are assumed to be reachable. Typically, these include all the objects referenced from anywhere in the call stack (that is, all local variables and parameters in the functions currently being invoked), and any global variables.
- Anything referenced from a reachable object is itself reachable; more formally, reachability is a transitive closure.
The reachability definition of ""garbage"" is not optimal, insofar as the last time a program uses an object could be long before that object falls out of the environment scope. A distinction is sometimes drawn between syntactic garbage, those objec",Technology & Computing 
"Garbage collection (computer science)
In computer science, garbage collection (GC) is a form of automatic memory management.[2] The garbage collector attempts to reclaim memory that was allocated by the program, but is no longer referenced; such memory is called garbage. Garbage collection was invented by American computer scientist John McCarthy around 1959 to simplify manual memory management in Lisp.[3]
Garbage collection relieves the programmer from doing manual memory management, where the programmer specifies what objects to de-allocate and return to the memory system and when to do so.[2] Other, similar techniques include stack allocation, region inference, and memory ownership, and combinations thereof. Garbage collection may take a significant proportion of a program's total processing time, and affect performance as a result.
Resources other than memory, such as network sockets, database handles, windows, file descriptors, and device descriptors, are not typically handled by garbage collection, but rather by other methods (e.g. destructors). Some such methods de-allocate memory also.
Overview
[edit]Many programming languages require garbage collection, either as part of the language specification (e.g., RPL, Java, C#, D,[4] Go, and most scripting languages) or effectively for practical implementation (e.g., formal languages like lambda calculus).[5] These are said to be garbage-collected languages. Other languages, such as C and C++, were designed for use with manua",Technology & Computing 
"Tracing garbage collection
In computer programming, tracing garbage collection is a form of automatic memory management that consists of determining which objects should be deallocated (""garbage collected"") by tracing which objects are reachable by a chain of references from certain ""root"" objects, and considering the rest as ""garbage"" and collecting them. Tracing is the most common type of garbage collection – so much so that ""garbage collection"" often refers to the tracing method, rather than others such as reference counting – and there are a large number of algorithms used in implementation.
Reachability of an object
[edit][1]Informally, an object is reachable if it is referenced by at least one variable in the program, either directly or through references from other reachable objects. More precisely, objects can be reachable in only two ways:
- A distinguished set of roots: objects that are assumed to be reachable. Typically, these include all the objects referenced from anywhere in the call stack (that is, all local variables and parameters in the functions currently being invoked), and any global variables.
- Anything referenced from a reachable object is itself reachable; more formally, reachability is a transitive closure.
The reachability definition of ""garbage"" is not optimal, insofar as the last time a program uses an object could be long before that object falls out of the environment scope. A distinction is sometimes drawn between syntactic garbage, those objec",Technology & Computing 
"Actor model
The actor model in computer science is a mathematical model of concurrent computation that treats an actor as the basic building block of concurrent computation. In response to a message it receives, an actor can: make local decisions, create more actors, send more messages, and determine how to respond to the next message received. Actors may modify their own private state, but can only affect each other indirectly through messaging (removing the need for lock-based synchronization).
The actor model originated in 1973.[1] It has been used both as a framework for a theoretical understanding of computation and as the theoretical basis for several practical implementations of concurrent systems. The relationship of the model to other work is discussed in actor model and process calculi.
History
[edit]According to Carl Hewitt, unlike previous models of computation, the actor model was inspired by physics, including general relativity and quantum mechanics.[citation needed] It was also influenced by the programming languages Lisp, Simula, early versions of Smalltalk, capability-based systems, and packet switching.
Its development was ""motivated by the prospect of highly parallel computing machines consisting of dozens, hundreds, or even thousands of independent microprocessors, each with its own local memory and communications processor, communicating via a high-performance communications network.""[2] Since that time, the advent of massive concurrency through multi-co",Technology & Computing 
"Lock (computer science)
In computer science, a lock or mutex (from mutual exclusion) is a synchronization primitive that prevents state from being modified or accessed by multiple threads of execution at once. Locks enforce mutual exclusion concurrency control policies, and with a variety of possible methods there exist multiple unique implementations for different applications.
Types
[edit]Generally, locks are advisory locks, where each thread cooperates by acquiring the lock before accessing the corresponding data. Some systems also implement mandatory locks, where attempting unauthorized access to a locked resource will force an exception in the entity attempting to make the access.
The simplest type of lock is a binary semaphore. It provides exclusive access to the locked data. Other schemes also provide shared access for reading data. Other widely implemented access modes are exclusive, intend-to-exclude and intend-to-upgrade.
Another way to classify locks is by what happens when the lock strategy prevents the progress of a thread. Most locking designs block the execution of the thread requesting the lock until it is allowed to access the locked resource. With a spinlock, the thread simply waits (""spins"") until the lock becomes available. This is efficient if threads are blocked for a short time, because it avoids the overhead of operating system process rescheduling. It is inefficient if the lock is held for a long time, or if the progress of the thread that is holding ",Technology & Computing 
"Transactional memory
In computer science and engineering, transactional memory attempts to simplify concurrent programming by allowing a group of load and store instructions to execute in an atomic way. It is a concurrency control mechanism analogous to database transactions for controlling access to shared memory in concurrent computing. Transactional memory systems provide high-level abstraction as an alternative to low-level thread synchronization. This abstraction allows for coordination between concurrent reads and writes of shared data in parallel systems.[1]
Motivation
[edit]In concurrent programming, synchronization is required when parallel threads attempt to access a shared resource. Low-level thread synchronization constructs such as locks are pessimistic and prohibit threads that are outside a critical section from running the code protected by the critical section. The process of applying and releasing locks often functions as an additional overhead in workloads with little conflict among threads. Transactional memory provides optimistic concurrency control by allowing threads to run in parallel with minimal interference.[2] The goal of transactional memory systems is to transparently support regions of code marked as transactions by enforcing atomicity, consistency and isolation.
A transaction is a collection of operations that can execute and commit changes as long as a conflict is not present. When a conflict is detected, a transaction will revert to its initi",Technology & Computing 
"Jump to content
Main menu
Main menu
move to sidebar
hide
Navigation
Main page
Contents
Current events
Random article
About Wikipedia
Contact us
Contribute
Help
Learn to edit
Community portal
Recent changes
Upload file
Special pages
Search
Search
Appearance
Donate
Create account
Log in
Personal tools
Donate
Create account
Log in
Pages for logged out editors
learn more
Contributions
Talk
Fork–join
Add languages
Add links
Article
Talk
English
Read
Edit
View history
Tools
Tools
move to sidebar
hide
Actions
Read
Edit
View history
General
What links here
Related changes
Upload file
Permanent link
Page information
Cite this page
Get shortened URL
Download QR code
Print/export
Download as PDF
Printable version
In other projects
Wikidata item
Appearance
move to sidebar
hide
From Wikipedia, the free encyclopedia
(Redirected from
Fork-join
)
Fork–join
may refer to:
Fork–join model
, a programming style in
parallel computing
Fork–join queue
, in probability theory
Topics referred to by the same term
This
disambiguation
page lists articles associated with the title
Fork–join
.
If an
internal link
led you here, you may wish to change the link to point directly to the intended article.
Category
:
Disambiguation pages
Hidden categories:
Short description is different from Wikidata
All article disambiguation pages
All disambiguation pages
Search
Search
Fork–join
Add languages
Add topic",Technology & Computing 
"MapReduce
MapReduce is a programming model and an associated implementation for processing and generating big data sets with a parallel and distributed algorithm on a cluster.[1][2][3]
A MapReduce program is composed of a map procedure, which performs filtering and sorting (such as sorting students by first name into queues, one queue for each name), and a reduce method, which performs a summary operation (such as counting the number of students in each queue, yielding name frequencies). The ""MapReduce System"" (also called ""infrastructure"" or ""framework"") orchestrates the processing by marshalling the distributed servers, running the various tasks in parallel, managing all communications and data transfers between the various parts of the system, and providing for redundancy and fault tolerance.
The model is a specialization of the split-apply-combine strategy for data analysis.[4] It is inspired by the map and reduce functions commonly used in functional programming,[5] although their purpose in the MapReduce framework is not the same as in their original forms.[6] The key contributions of the MapReduce framework are not the actual map and reduce functions (which, for example, resemble the 1995 Message Passing Interface standard's[7] reduce[8] and scatter[9] operations), but the scalability and fault-tolerance achieved for a variety of applications due to parallelization. As such, a single-threaded implementation of MapReduce is usually not faster than a traditional (non-Map",Technology & Computing 
"Bulk synchronous parallel
The bulk synchronous parallel (BSP) abstract computer is a bridging model for designing parallel algorithms. It is similar to the parallel random access machine (PRAM) model, but unlike PRAM, BSP does not take communication and synchronization for granted. In fact, quantifying the requisite synchronization and communication is an important part of analyzing a BSP algorithm.
History
[edit]The BSP model was developed by Leslie Valiant of Harvard University during the 1980s. The definitive article was published in 1990.[1]
Between 1990 and 1992, Leslie Valiant and Bill McColl of Oxford University worked on ideas for a distributed memory BSP programming model, in Princeton and at Harvard. Between 1992 and 1997, McColl led a large research team at Oxford that developed various BSP programming libraries, languages and tools, and also numerous massively parallel BSP algorithms, including many early examples of high-performance communication-avoiding parallel algorithms [2] and recursive ""immortal"" parallel algorithms that achieve the best possible performance and optimal parametric tradeoffs.[3]
With interest and momentum growing, McColl then led a group from Oxford, Harvard, Florida, Princeton, Bell Labs, Columbia and Utrecht that developed and published the BSPlib Standard for BSP programming in 1996.[4]
Valiant developed an extension to the BSP model in the 2000s, leading to the publication of the Multi-BSP model in 2011.[5]
In 2017, McColl developed a m",Technology & Computing 
"OpenMP
OpenMP is an application programming interface (API) that supports multi-platform shared-memory multiprocessing programming in C, C++, and Fortran,[3] on many platforms, instruction-set architectures and operating systems, including Solaris, AIX, FreeBSD, HP-UX, Linux, macOS, Windows and OpenHarmony. It consists of a set of compiler directives, library routines, and environment variables that influence run-time behavior.[2][4][5][6]
OpenMP is managed by the nonprofit technology consortium OpenMP Architecture Review Board (or OpenMP ARB), jointly defined by a broad swath of leading computer hardware and software vendors, including Arm, AMD, IBM, Intel, Cray, HP, Fujitsu, Nvidia, NEC, Red Hat, Texas Instruments, and Oracle Corporation.[1]
OpenMP uses a portable, scalable model that gives programmers a simple and flexible interface for developing parallel applications for platforms ranging from the standard desktop computer to the supercomputer.
An application built with the hybrid model of parallel programming can run on a computer cluster using both OpenMP and Message Passing Interface (MPI), such that OpenMP is used for parallelism within a (multi-core) node while MPI is used for parallelism between nodes. There have also been efforts to run OpenMP on software distributed shared memory systems,[7] to translate OpenMP into MPI[8][9] and to extend OpenMP for non-shared memory systems.[10]
Design
[edit]OpenMP is an implementation of multithreading, a method of parallelizi",Technology & Computing 
"CUDA
In computing, CUDA (Compute Unified Device Architecture) is a proprietary[2] parallel computing platform and application programming interface (API) that allows software to use certain types of graphics processing units (GPUs) for accelerated general-purpose processing, an approach called general-purpose computing on GPUs. CUDA was created by Nvidia in 2006.[3] When it was first introduced, the name was an acronym for Compute Unified Device Architecture,[4] but Nvidia later dropped the common use of the acronym and now rarely expands it.[5]
CUDA is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements for the execution of compute kernels.[6] In addition to drivers and runtime kernels, the CUDA platform includes compilers, libraries and developer tools to help programmers accelerate their applications.
CUDA is designed to work with programming languages such as C, C++, Fortran, Python and Julia. This accessibility makes it easier for specialists in parallel programming to use GPU resources, in contrast to prior APIs like Direct3D and OpenGL, which require advanced skills in graphics programming.[7] CUDA-powered GPUs also support programming frameworks such as OpenMP, OpenACC and OpenCL.[8][6]
Background
[edit]The graphics processing unit (GPU), as a specialized computer processor, addresses the demands of real-time high-resolution 3D graphics compute-intensive tasks. By 2012, GPUs had evolved into highly paralle",Technology & Computing 
"OpenCL
OpenCL (Open Computing Language) is a framework for writing programs that execute across heterogeneous platforms consisting of central processing units (CPUs), graphics processing units (GPUs), digital signal processors (DSPs), field-programmable gate arrays (FPGAs) and other processors or hardware accelerators. OpenCL specifies a programming language (based on C99) for programming these devices and application programming interfaces (APIs) to control the platform and execute programs on the compute devices. OpenCL provides a standard interface for parallel computing using task- and data-based parallelism.
OpenCL is an open standard maintained by the Khronos Group, a non-profit, open standards organisation. Conformant implementations (passed the Conformance Test Suite) are available from a range of companies including AMD, Arm, Cadence, Google, Imagination, Intel, Nvidia, Qualcomm, Samsung, SPI and Verisilicon.[8][9]
Overview
[edit]OpenCL views a computing system as consisting of a number of compute devices, which might be central processing units (CPUs) or ""accelerators"" such as graphics processing units (GPUs), attached to a host processor (a CPU). It defines a C-like language for writing programs. Functions executed on an OpenCL device are called ""kernels"".[10]: 17 A single compute device typically consists of several compute units, which in turn comprise multiple processing elements (PEs). A single kernel execution can run on all or many of the PEs in parallel. How",Technology & Computing 
"Vulkan
Vulkan is a cross-platform API and open standard for 3D graphics and computing.[20][21][22] It was intended to address the shortcomings of OpenGL, and allow developers more control over the GPU. It is designed to support a wide variety of GPUs, CPUs and operating systems, and it is also designed to work with modern multi-core CPUs.
Microsoft supports Vulkan 1.2 (and more) on Windows 10 and 11, with a downloadable compatibility pack.[23]
Overview
[edit]Vulkan targets high-performance real-time 3D-graphics applications, such as video games and interactive media, and highly parallelized computing. Vulkan is intended to offer higher performance and more efficient CPU and GPU usage compared to the older OpenGL and Direct3D 11 APIs. It does so by providing a considerably lower-level API for the application than the older APIs, that more closely resembles how modern GPUs work.
Vulkan is comparable to Apple's Metal API and Microsoft's Direct3D 12. In addition to its lower CPU usage, Vulkan is designed to allow developers to better distribute work among multiple CPU cores.[24]
Vulkan was first announced by the non-profit Khronos Group at GDC 2015.[17][25][26] The Vulkan API was initially referred to as the ""next generation OpenGL initiative"", or ""OpenGL next""[27] by Khronos, but use of those names was discontinued when ""Vulkan"" was announced.[28]
Vulkan is derived from and built upon components of AMD's Mantle API, which was donated by AMD to Khronos with the intent of giving K",Technology & Computing 
"DirectX
Microsoft DirectX is a collection of application programming interfaces (APIs) for handling tasks related to multimedia, especially game programming and video, on Microsoft platforms. Originally, the names of these APIs all began with ""Direct"", such as Direct3D, DirectDraw, DirectMusic, DirectPlay, DirectSound, and so forth. The name DirectX was coined as a shorthand term for all of these APIs (the X standing in for the particular API names) and soon became the name of the collection. When Microsoft later set out to develop a gaming console, the X was used as the basis of the name Xbox to indicate that the console was based on DirectX technology.[3] The X initial has been carried forward in the naming of APIs designed for the Xbox such as XInput and the Cross-platform Audio Creation Tool (XACT), while the DirectX pattern has been continued for Windows APIs such as Direct2D and DirectWrite.
Direct3D (the 3D graphics API within DirectX) is widely used in the development of video games for Microsoft Windows and the Xbox line of consoles. Direct3D is also used by other software applications for visualization and graphics tasks such as CAD/CAM engineering. As Direct3D is the most widely publicized component of DirectX, it is common to see the names ""DirectX"" and ""Direct3D"" used interchangeably.
The DirectX software development kit (SDK) consists of runtime libraries in redistributable binary form, along with accompanying documentation and headers for use in coding. Origina",Technology & Computing 
"Graphics pipeline
The computer graphics pipeline, also known as the rendering pipeline, or graphics pipeline, is a framework within computer graphics that outlines the necessary procedures for transforming a three-dimensional (3D) scene into a two-dimensional (2D) representation on a screen.[1] Once a 3D model is generated, the graphics pipeline converts the model into a visually perceivable format on the computer display.[2] Due to the dependence on specific software, hardware configurations, and desired display attributes, a universally applicable graphics pipeline does not exist. Nevertheless, graphics application programming interfaces (APIs), such as Direct3D, OpenGL and Vulkan were developed to standardize common procedures and oversee the graphics pipeline of a given hardware accelerator. These APIs provide an abstraction layer over the underlying hardware, relieving programmers from the need to write code explicitly targeting various graphics hardware accelerators like AMD, Intel, Nvidia, and others.
The model of the graphics pipeline is usually used in real-time rendering. Often, most of the pipeline steps are implemented in hardware, which allows for special optimizations. The term ""pipeline"" is used in a similar sense for the pipeline in processors: the individual steps of the pipeline run in parallel as long as any given step has what it needs.
Concept
[edit]The 3D pipeline usually refers to the most common form of computer 3-Dimensional rendering called 3D polygo",Technology & Computing 
"Rasterisation
In computer graphics, rasterisation (British English) or rasterization (American English) is the task of taking an image described in a vector graphics format (shapes) and converting it into a raster image (a series of pixels, dots or lines, which, when displayed together, create the image which was represented via shapes).[1][2] The rasterized image may then be displayed on a computer display, video display or printer, or stored in a bitmap file format. Rasterization may refer to the technique of drawing 3D models, or to the conversion of 2D rendering primitives, such as polygons and line segments, into a rasterized format.
Etymology
[edit]The term ""rasterisation"" comes from German Raster 'grid, pattern, schema' and Latin rāstrum 'scraper, rake'.[3][4]
2D images
[edit]Line primitives
[edit]Bresenham's line algorithm is an example of an algorithm used to rasterize lines.
Circle primitives
[edit]Algorithms such as the midpoint circle algorithm are used to render circles onto a pixelated canvas.
3D images
[edit]Rasterization is one of the typical techniques of rendering 3D models. Compared with other rendering techniques such as ray tracing, rasterization is extremely fast and therefore used in most realtime 3D engines. However, rasterization is simply the process of computing the mapping from scene geometry to pixels and does not prescribe a particular way to compute the color of those pixels. The specific color of each pixel is assigned by a pixel shader (which ",Technology & Computing 
"OpenGL Shading Language
OpenGL Shading Language (GLSL) is a high-level shading language with a syntax based on the C programming language. It was created by the OpenGL ARB (OpenGL Architecture Review Board) to give developers more direct control of the graphics pipeline without having to use ARB assembly language or hardware-specific languages.
Background
[edit]With advances in graphics cards, new features have been added to allow for increased flexibility in the rendering pipeline at the vertex and fragment level. Programmability at this level is achieved with the use of fragment and vertex shaders.
Originally, this functionality was achieved by writing shaders in ARB assembly language – a complex and unintuitive task. The OpenGL ARB created the OpenGL Shading Language to provide a more intuitive method for programming the graphics processing unit while maintaining the open standards advantage that has driven OpenGL throughout its history.
Originally introduced as an extension to OpenGL 1.4, GLSL was formally included into the OpenGL 2.0 core in 2004 by the OpenGL ARB. It was the first major revision to OpenGL since the creation of OpenGL 1.0 in 1992.
Some benefits of using GLSL are:
- Cross-platform compatibility on multiple operating systems, including Linux, macOS and Windows.
- The ability to write shaders that can be used on any hardware vendor's graphics card that supports the OpenGL Shading Language.
- Each hardware vendor includes the GLSL compiler in their driver, t",Technology & Computing 
"High-Level Shader Language
The High-Level Shader Language[1] or High-Level Shading Language[2] (HLSL) is a proprietary shading language developed by Microsoft for the Direct3D 9 API to augment the shader assembly language, and went on to become the required shading language for the unified shader model of Direct3D 10 and higher.
HLSL is analogous to the GLSL shading language used with the OpenGL standard. It is very similar to the Nvidia Cg shading language, as it was developed alongside it. Early versions of the two languages were considered identical, only marketed differently.[3] HLSL shaders can enable profound speed and detail increases as well as many special effects in both 2D and 3D computer graphics.[citation needed]
HLSL programs come in six forms: pixel shaders (fragment in GLSL), vertex shaders, geometry shaders, compute shaders, tessellation shaders (Hull and Domain shaders), and ray tracing shaders (Ray Generation Shaders, Intersection Shaders, Any Hit/Closest Hit/Miss Shaders). A vertex shader is executed for each vertex that is submitted by the application, and is primarily responsible for transforming the vertex from object space to view space, generating texture coordinates, and calculating lighting coefficients such as the vertex's normal, tangent, and bitangent vectors. When a group of vertices (normally 3, to form a triangle) come through the vertex shader, their output position is interpolated to form pixels within its area; this process is known as rast",Technology & Computing 
"Standard Portable Intermediate Representation
Standard Portable Intermediate Representation (SPIR) is an intermediate language for parallel computing and graphics by Khronos Group. It is used in multiple execution environments, including the Vulkan graphics API and the OpenCL compute API, to represent a shader or kernel. It is also used as an interchange language for cross compilation.[1][2]
SPIR-V is a new version of SPIR which was introduced in 2015 by the Khronos Group, and has since replaced the original SPIR, which was introduced in 2012.
On September 19th 2024, Microsoft has announced plans to adopt SPIR-V as the Direct3D Interchange format in place of DXIL, beginning support from Shader Model 7 on.[3]
Purpose
[edit]The purposes of SPIR-V are to natively represent the primitives needed by compute and graphics; to separate high-level language from the interface to compute and graphics drivers; to be the distribution form, or distribute fully compiled binaries; to be a fully self-contained specification; and to support multiple APIs. It is also used as an intermediate target for cross-compilation tools.
For example, SPIR-V allows the Vulkan API to use any shading language, including GLSL and HLSL.[4][5] SPIR-V can be decompiled into several shading languages (GLSL, GLSL ES, MSL, HLSL) using SPIRV-Cross, so that these languages can be interconverted.[6] It also has paths to and/or from WebGPU, OpenCL, SYCL, C++, and Rust.
In target platforms, ingesting SPIR-V removes the n",Technology & Computing 
"Compute kernel
In computing, a compute kernel is a routine compiled for high throughput accelerators (such as graphics processing units (GPUs), digital signal processors (DSPs) or field-programmable gate arrays (FPGAs)), separate from but used by a main program (typically running on a central processing unit). They are sometimes called compute shaders, sharing execution units with vertex shaders and pixel shaders on GPUs, but are not limited to execution on one class of device, or graphics APIs.[1][2]
Description
[edit]Compute kernels roughly correspond to inner loops when implementing algorithms in traditional languages (except there is no implied sequential operation), or to code passed to internal iterators.
They may be specified by a separate programming language such as ""OpenCL C"" (managed by the OpenCL API), as ""compute shaders"" written in a shading language (managed by a graphics API such as OpenGL), or embedded directly in application code written in a high level language, as in the case of C++AMP. Microsoft support this as DirectCompute.
Vector processing
[edit]This programming paradigm maps well to vector processors: there is an assumption that each invocation of a kernel within a batch is independent, allowing for data parallel execution. However, atomic operations may sometimes be used for synchronization between elements (for interdependent work), in some scenarios. Individual invocations are given indices (in 1 or more dimensions) from which arbitrary addressing",Technology & Computing 
"Shader
In computer graphics, a shader is a computer program that calculates the appropriate levels of light, darkness, and color during the rendering of a 3D scene—a process known as shading. Shaders have evolved to perform a variety of specialized functions in computer graphics special effects and video post-processing, as well as general-purpose computing on graphics processing units.
Traditional shaders calculate rendering effects on graphics hardware with a high degree of flexibility. Most shaders are coded for (and run on) a graphics processing unit (GPU),[1] though this is not a strict requirement. Shading languages are used to program the GPU's rendering pipeline, which has mostly superseded the fixed-function pipeline of the past that only allowed for common geometry transforming and pixel-shading functions; with shaders, customized effects can be used. The position and color (hue, saturation, brightness, and contrast) of all pixels, vertices, and/or textures used to construct a final rendered image can be altered using algorithms defined in a shader, and can be modified by external variables or textures introduced by the computer program calling the shader.[citation needed]
Shaders are used widely in cinema post-processing, computer-generated imagery, and video games to produce a range of effects. Beyond simple lighting models, more complex uses of shaders include: altering the hue, saturation, brightness (HSL/HSV) or contrast of an image; producing blur, light bloom",Technology & Computing 
"Shader
In computer graphics, a shader is a computer program that calculates the appropriate levels of light, darkness, and color during the rendering of a 3D scene—a process known as shading. Shaders have evolved to perform a variety of specialized functions in computer graphics special effects and video post-processing, as well as general-purpose computing on graphics processing units.
Traditional shaders calculate rendering effects on graphics hardware with a high degree of flexibility. Most shaders are coded for (and run on) a graphics processing unit (GPU),[1] though this is not a strict requirement. Shading languages are used to program the GPU's rendering pipeline, which has mostly superseded the fixed-function pipeline of the past that only allowed for common geometry transforming and pixel-shading functions; with shaders, customized effects can be used. The position and color (hue, saturation, brightness, and contrast) of all pixels, vertices, and/or textures used to construct a final rendered image can be altered using algorithms defined in a shader, and can be modified by external variables or textures introduced by the computer program calling the shader.[citation needed]
Shaders are used widely in cinema post-processing, computer-generated imagery, and video games to produce a range of effects. Beyond simple lighting models, more complex uses of shaders include: altering the hue, saturation, brightness (HSL/HSV) or contrast of an image; producing blur, light bloom",Technology & Computing 
"Shader
In computer graphics, a shader is a computer program that calculates the appropriate levels of light, darkness, and color during the rendering of a 3D scene—a process known as shading. Shaders have evolved to perform a variety of specialized functions in computer graphics special effects and video post-processing, as well as general-purpose computing on graphics processing units.
Traditional shaders calculate rendering effects on graphics hardware with a high degree of flexibility. Most shaders are coded for (and run on) a graphics processing unit (GPU),[1] though this is not a strict requirement. Shading languages are used to program the GPU's rendering pipeline, which has mostly superseded the fixed-function pipeline of the past that only allowed for common geometry transforming and pixel-shading functions; with shaders, customized effects can be used. The position and color (hue, saturation, brightness, and contrast) of all pixels, vertices, and/or textures used to construct a final rendered image can be altered using algorithms defined in a shader, and can be modified by external variables or textures introduced by the computer program calling the shader.[citation needed]
Shaders are used widely in cinema post-processing, computer-generated imagery, and video games to produce a range of effects. Beyond simple lighting models, more complex uses of shaders include: altering the hue, saturation, brightness (HSL/HSV) or contrast of an image; producing blur, light bloom",Technology & Computing 
"Shader
In computer graphics, a shader is a computer program that calculates the appropriate levels of light, darkness, and color during the rendering of a 3D scene—a process known as shading. Shaders have evolved to perform a variety of specialized functions in computer graphics special effects and video post-processing, as well as general-purpose computing on graphics processing units.
Traditional shaders calculate rendering effects on graphics hardware with a high degree of flexibility. Most shaders are coded for (and run on) a graphics processing unit (GPU),[1] though this is not a strict requirement. Shading languages are used to program the GPU's rendering pipeline, which has mostly superseded the fixed-function pipeline of the past that only allowed for common geometry transforming and pixel-shading functions; with shaders, customized effects can be used. The position and color (hue, saturation, brightness, and contrast) of all pixels, vertices, and/or textures used to construct a final rendered image can be altered using algorithms defined in a shader, and can be modified by external variables or textures introduced by the computer program calling the shader.[citation needed]
Shaders are used widely in cinema post-processing, computer-generated imagery, and video games to produce a range of effects. Beyond simple lighting models, more complex uses of shaders include: altering the hue, saturation, brightness (HSL/HSV) or contrast of an image; producing blur, light bloom",Technology & Computing 
"Shader
In computer graphics, a shader is a computer program that calculates the appropriate levels of light, darkness, and color during the rendering of a 3D scene—a process known as shading. Shaders have evolved to perform a variety of specialized functions in computer graphics special effects and video post-processing, as well as general-purpose computing on graphics processing units.
Traditional shaders calculate rendering effects on graphics hardware with a high degree of flexibility. Most shaders are coded for (and run on) a graphics processing unit (GPU),[1] though this is not a strict requirement. Shading languages are used to program the GPU's rendering pipeline, which has mostly superseded the fixed-function pipeline of the past that only allowed for common geometry transforming and pixel-shading functions; with shaders, customized effects can be used. The position and color (hue, saturation, brightness, and contrast) of all pixels, vertices, and/or textures used to construct a final rendered image can be altered using algorithms defined in a shader, and can be modified by external variables or textures introduced by the computer program calling the shader.[citation needed]
Shaders are used widely in cinema post-processing, computer-generated imagery, and video games to produce a range of effects. Beyond simple lighting models, more complex uses of shaders include: altering the hue, saturation, brightness (HSL/HSV) or contrast of an image; producing blur, light bloom",Technology & Computing 
"Graphics processing unit
A graphics processing unit (GPU) is a specialized electronic circuit designed for digital image processing and to accelerate computer graphics, being present either as a discrete video card or embedded on motherboards, mobile phones, personal computers, workstations, and game consoles. GPUs were later found to be useful for non-graphic calculations involving embarrassingly parallel problems due to their parallel structure. The ability of GPUs to rapidly perform vast numbers of calculations has led to their adoption in diverse fields including artificial intelligence (AI) where they excel at handling data-intensive and computationally demanding tasks. Other non-graphical uses include the training of neural networks and cryptocurrency mining.
History
[edit]1970s
[edit]Arcade system boards have used specialized graphics circuits since the 1970s. In early video game hardware, RAM for frame buffers was expensive, so video chips composited data together as the display was being scanned out on the monitor.[1]
A specialized barrel shifter circuit helped the CPU animate the framebuffer graphics for various 1970s arcade video games from Midway and Taito, such as Gun Fight (1975), Sea Wolf (1976), and Space Invaders (1978).[2] The Namco Galaxian arcade system in 1979 used specialized graphics hardware that supported RGB color, multi-colored sprites, and tilemap backgrounds.[3] The Galaxian hardware was widely used during the golden age of arcade video games, by ",Technology & Computing 
"Knowledge distillation
In machine learning, knowledge distillation or model distillation is the process of transferring knowledge from a large model to a smaller one. While large models (such as very deep neural networks or ensembles of many models) have more knowledge capacity than small models, this capacity might not be fully utilized. It can be just as computationally expensive to evaluate a model even if it utilizes little of its knowledge capacity. Knowledge distillation transfers knowledge from a large model to a smaller one without loss of validity. As smaller models are less expensive to evaluate, they can be deployed on less powerful hardware (such as a mobile device).[1]
Model distillation is not to be confused with model compression, which describes methods to decrease the size of a large model itself, without training a new model. Model compression generally preserves the architecture and the nominal parameter count of the model, while decreasing the bits-per-parameter.
Knowledge distillation has been successfully used in several applications of machine learning such as object detection,[2] acoustic models,[3] and natural language processing.[4] Recently[when?], it has also been introduced to graph neural networks applicable to non-grid data.[5]
Methods
[edit]Knowledge transfer from a large model to a small one somehow needs to teach the latter without loss of validity. If both models are trained on the same data, the smaller model may have insufficient capacity ",Technology & Computing 
"Model compression
Model compression is a machine learning technique for reducing the size of trained models. Large models can achieve high accuracy, but often at the cost of significant resource requirements. Compression techniques aim to compress models without significant performance reduction. Smaller models require less storage space, and consume less memory and compute during inference.
Compressed models enable deployment on resource-constrained devices such as smartphones, embedded systems, edge computing devices, and consumer electronics computers. Efficient inference is also valuable for large corporations that serve large model inference over an API, allowing them to reduce computational costs and improve response times for users.
Model compression is not to be confused with knowledge distillation, in which a separate, smaller ""student"" model is trained to imitate the input-output behavior of a larger ""teacher"" model.
Techniques
[edit]Several techniques are employed for model compression.
Pruning
[edit]Pruning sparsifies a large model by setting some parameters to exactly zero. This effectively reduces the number of parameters. This allows the use of sparse matrix operations, which are faster than dense matrix operations.
Pruning criteria can be based on magnitudes of parameters, the statistical pattern of neural activations, Hessian values, etc.[1][2]
Quantization
[edit]Quantization reduces the numerical precision of weights and activations. For example, instead of ",Technology & Computing 
"Edge computing
Edge computing is a distributed computing model that brings computation and data storage closer to the sources of data. More broadly, it refers to any design that pushes computation physically closer to a user, so as to reduce the latency compared to when an application runs on a centralized data centre.[1]
The term began being used in the 1990s to describe content delivery networks—these were used to deliver website and video content from servers located near users.[2] In the early 2000s, these systems expanded their scope to hosting other applications,[3] leading to early edge computing services.[4] These services could do things like find dealers, manage shopping carts, gather real-time data, and place ads.
The Internet of Things (IoT), where devices are connected to the internet, is often linked with edge computing.[5]
Definition
[edit]Edge computing involves running computer programs that deliver quick responses close to where requests are made. Karim Arabi, during an IEEE DAC 2014 keynote[6] and later at an MIT MTL Seminar in 2015, described edge computing as computing that occurs outside the cloud, at the network's edge, particularly for applications needing immediate data processing.[7]
Edge computing is often equated with fog computing, particularly in smaller setups.[8] However, in larger deployments, such as smart cities, fog computing serves as a distinct layer between edge computing and cloud computing, with each layer having its own responsibiliti",Technology & Computing 
"Automated machine learning
Automated machine learning (AutoML) is the process of automating the tasks of applying machine learning to real-world problems. It is the combination of automation and ML.[1]
AutoML potentially includes every stage from beginning with a raw dataset to building a machine learning model ready for deployment. AutoML was proposed as an artificial intelligence-based solution to the growing challenge of applying machine learning.[2][3] The high degree of automation in AutoML aims to allow non-experts to make use of machine learning models and techniques without requiring them to become experts in machine learning. Automating the process of applying machine learning end-to-end additionally offers the advantages of producing simpler solutions, faster creation of those solutions, and models that often outperform hand-designed models.[4]
Common techniques used in AutoML include hyperparameter optimization, meta-learning and neural architecture search.
Comparison to the standard approach
[edit]In a typical machine learning application, practitioners have a set of input data points to be used for training. The raw data may not be in a form that all algorithms can be applied to. To make the data amenable for machine learning, an expert may have to apply appropriate data pre-processing, feature engineering, feature extraction, and feature selection methods. After these steps, practitioners must then perform algorithm selection and hyperparameter optimization to m",Technology & Computing 
"Table of Contents
.mk
file.hash
fileSNNfoo
start scriptList of Examples
Buildroot 2025.05 manual generated on 2025-06-09 20:23:58 UTC from git revision fcde5363aa
The Buildroot manual is written by the Buildroot developers. It is licensed under the GNU General Public License, version 2. Refer to the COPYING file in the Buildroot sources for the full text of this license.
Copyright © The Buildroot developers <buildroot@buildroot.org>
Buildroot is a tool that simplifies and automates the process of building a complete Linux system for an embedded system, using cross-compilation.
In order to achieve this, Buildroot is able to generate a cross-compilation toolchain, a root filesystem, a Linux kernel image and a bootloader for your target. Buildroot can be used for any combination of these options, independently (you can for example use an existing cross-compilation toolchain, and build only your root filesystem with Buildroot).
Buildroot is useful mainly for people working with embedded systems. Embedded systems often use processors that are not the regular x86 processors everyone is used to having in his PC. They can be PowerPC processors, MIPS processors, ARM processors, etc.
Buildroot supports numerous processors and their variants; it also comes with default configurations for several boards available off-the-shelf. Besides this, a number of third-party projects are based on, or develop their BSP [1] or SDK [2] on top of Buildroot.
Buildroot is designed to run on Linux system",Technology & Computing 
"CircuitJS1 - Interactive Circuit Simulator
Between 2016 and 2022 I was a major contributor to CircuitJS1, the interactive circuit simulator created and maintained by Paul Falstad. My main contribution was to update the application to cross-compile to JavaScript so it could run natively in the browser without needing a Java plug-in
I always found the simulator a great tool to visualize circuits and loved the interactive nature compared to normal SPICE implementations. However, I never really liked the requirement for a Java plug-in. I thought that the new generation of JavaScript interpreters would likely have sufficient performance to simulate circuits without a plug-in, so with Paul's permission I started work on modifying the code.
I modified the original Java to run in the Google Web Toolkit (GWT). Most of the user interface was rewritten but the technical parts of the simulation were almost untouched. The initial work took just over a month.
I subsequently did further updates, including adding sub-circuits and major improvements to the UI for scopes.
Thanks to the kind permission of Paul Falstad the code is published and maintained on GitHub under a GPLv2 license.
https://github.com/sharpie7/circuitjs1
Using CircuitJS1
When the simulator starts up you will see an animated schematic of a simple LRC circuit. The green colour indicates positive voltage. The grey colour indicates ground. A red colour indicates negative voltage. The moving yellow dots indicate current.
To turn",Technology & Computing 
"A (very) belated follow up to Getting Started with Microformats 2, covering the basics of consuming and using microformats 2 data. Originally posted on waterpigs.co.uk.
More and more people are using microformats 2 to mark up profiles, posts, events and other data on their personal sites, enabling developers to build applications which use this data in useful and interesting ways. Whether you want to add basic support for webmention comments to your personal site, or have ambitious plans for a structured-data-aware-social-graph-search-engine-super-feed-reader, you’re going to need a solid grasp of how to parse and handle microformats 2 data.
Choose a Parser
To turn a web page containing data marked up with microformats 2 (or classic microformats, if supported) into a canonical MF2 JSON data structure, you’ll need a parser.
At the time of writing, there are actively supported microformats 2 parsers available for the following programming languages:
Parsers for various other languages exist, but might not be actively supported or support recent changes to the parsing specification.
There are also various websites which you can use to experiment with microformats markup without having to download a library and write any code:
- My own live-updating php-mf2 sandbox
- The various parser comparison tools hosted on microformats.io
- Aaron Parecki’s pin13.net microformats parser for parsing either URLs or HTML fragments
If there’s not currently a parser available for your language of",Technology & Computing 
"microformats
What are microformats?
microformats are the simplest way to openly publish contacts, events, reviews, recipes, and other structured information on the web.
microformats.org maintains the official registry of HTML rel values.
Check out microformats2 for current work.
the microformats principles
- solve a specific problem
- start simple
- humans first, machines second
- dry
- reuse
- modularity / embeddability
quotes
See testimonials and quotes relating to the principles.
current microformats
See the main page for a list of current microformats specifications, drafts, and discussions.
How microformats started
What are microformats started with the following in 2005:
microformats are
- a way of thinking about data
- design principles for formats
- adapted to current behaviors and usage patterns (""Pave the cow paths."" - Adam Rifkin)
- highly correlated with semantic XHTML, AKA the real world semantics, AKA lowercase semantic web, AKA lossless XHTML
- described by Tantek's recent presentation at SXSW: The Elements of Meaningful XHTML
- a set of simple open data format standards that a diverse community of individuals and organizations are actively developing and implementing for more/better structured blogging and web microcontent publishing in general.
- ""An evolutionary revolution"" - Ryan King
- all the above.
microformats are not
- a new language
- infinitely extensible and open-ended
- an attempt to get everyone to change their behavior and rewrite their tools
- a",Technology & Computing 
"Version 0.4.0-beta.6
MQTT Explorer is a comprehensive MQTT client that provides a structured overview of your MQTT topics and makes working with devices/services on your broker dead-simple.
Features
- Visualize topics and topic activity
- Delete retained topics
- Search/filter topics
- Delete topics recursively
- Diff view of current and previous received messages
- Publish topics
- Plot numeric topics
- Retain a history of each topic
- Dark/Light Themes
- … See Changelog to see all features
The hierarchical view makes this tool so easy to use and differentiates the MQTT Explorer from other great MQTT clients like MQTTLens, MQTTBox and MQTT.fx.
This MQTT Client strives to be a MQTT swiss-army-knife, the perfect tool to integrate new services and IoT devices on your network.
Download
Developing this tool takes a lot of effort, sweat and time, please consider rating the App on the Windows or Mac app store .
If you feel like a feature is missing or you found a bug, please leave me a comment / issue and I’ll see what I can do.
Video
Performance
This MQTT Client is optimized to handle thousands of topics and at hundreds of thousands messages per minute.
Custom subscriptions can limit the amount of messages MQTT Explorer needs to process, subscriptions can be managed in the advanced connection settings.
In very large productive environments brokers may handle an extreme load of topics, subscribing with a wildcard topic is in this scenario not advised.
IoT Applications
List of usefu",Technology & Computing 
"Thursday, July 3, 2025
Live Chat with Me on Saturday, July 5th!
Monday, June 16, 2025
Too Much Horror Fiction Updates...
Hola amigos, long time since I rapped at ya! Got some horror (all good) news you can use...
I've written two introductions for two new horror anthologies: one was published at the end of 2024, The Rack: Stories Inspired by Vintage Horror Paperbacks, edited by Stoker Award-winning author Tom Deady, from Greymore Publishing; order here. Also, the brand-new Claw Machine, compiled by an old East Coast pal of mine who now also resides in Portland. You can order it from Little Key Press here. Both feature horror/science fiction/speculative lit stories that I think will appeal to TMHF and Paperbacks from Hell fans. It was definitely an honor to have been asked to write for these books!
Last but certainly not least: Grady Hendrix and I, along with Valancourt Books, have decided to wrap up the Paperbacks from Hell reprint series with three more titles, thus ending the line with an even two dozen works. But the titles have not been finalized yet! We're discussing a few books, but as you know, tracking down publication rights, and then convincing people to have their books republished, is tricky business; the stars have to align just so.
The moving parts are: books we all three like; the book is entirely out of print (no ebook/audiobook either); the original paperback is somewhat rare/expensive in the secondhand market; the author/estate is willing to have the book re",art_culture
"Convolutional-Pooling Neural Network (CNN/ConvNet) Model
A Convolutional-Pooling Neural Network (CNN/ConvNet) Model is a multi-layer feed-forward neural network that includes convolutional layers and pooling layers.
- AKA: Shift Invariant NNet, Space Invariant Artificial NNet (SIANN).
- Context:
- It can (typically) include Convolutional Layers and Pooling Layers.
- It can be represented by a CNN Architecture.
- It can be trained by a CNN Training System (that implements a CNN training algorithm to solve a CNN training task).
- It can (often) include Normalization Layers and Fully-Connected Layers;
- It can range from being a Shallow CNN to being a Deep CNN.
- …
- Example(s):
- a Temporal Convolutional Network,
- a Convolutional Deep Belief Network (CDBN),
- a Convolutional Neural Network with Attention Mechanism,
- a Deep Convolutional Neural Network (DCN),
- a Convolutional Network for Reinforcement Learning,
- a CNN Encoder-Decoder Neural Network,
- a Deep Convolutional Neural Netowrk such as: VGG Net, AlexNet, and GooLeNet,
- an Inception Architecture.
- …
- Counter-Example(s):
- See: Visual Field, Image Recognition, Vanishing Gradient Problem, Bidirectional LSTM-CNN.
References
2022
- (Liu, Mao et al., 2022) ⇒ Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, and Saining Xie. (2022). “A ConvNet for the 2020s.”
- QUOTE: ... The ""Roaring 20s"" of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly supersede",Technology & Computing 
"PATRICIA MILLER Theatre. Live Arts. Film. Education
http://www.pollinatorarts.org
Patricia Miller is based in London/San Francisco. Patricia brings a diversity of experience and training to theatre directing, teaching and acting. She is interested in the dynamic between text work and physical theatre techniques. She works in many genres raging from classics to new play development, modern works and live arts genres (performance, circus, ritual and opera). Her work has been seen all over the UK, including Edinburgh premieres, Europe and California. Winner of Theatre Bay Area’s Titan Award. Currently teaching DIRECTING and PLAY CREATION at BERKELEY REP SCHOOL OF THEATRE.
Master of Fine Arts Master of Arts, A.B.D. Batchelor of Arts Certificate Program
Theatre Directing
Directing for Theatre and Media Studies Drama, English and American Studies Film Production and Broadcasting
EDUCATION and AFFILIATIONS
University of California, Davis, CA Hull University UK
Manchester University, UK
City College, San Francisco
INFLUENCES AND ADDITIONAL TRAINING
Text based, traditional theatre
Voice and Text: Cicely Berry; Fitzmaurice technique Melanie Julian: Linklater/ Neil Worden
Text and Dramaturgy : Peter Lichtenfels; Sarah Pia Anderson; Lynette Hunter; David Mayer. Stanislavski technique: Bella Merlin; Bess Jones and Mollie Hudson Studio School London Playwriting: Phillip Kan Gotanda, Liz Duffy Adams, Marcus Gardley.
Design: John Iacovelli; Thomas Munn; Maggie Morgan
Physical Theatre and Cre",art_culture
"Introduction to Evolutionary Biology
Version 2
Copyright © 1996-1997 by
Chris Colby
[Last Update: January 7, 1996]
volution is the cornerstone of modern biology. It unites all the fields of biology under one theoretical umbrella. It is not a difficult concept, but very few people -- the majority of biologists included -- have a satisfactory grasp of it. One common mistake is believing that species can be arranged on an evolutionary ladder from bacteria through ""lower"" animals, to ""higher"" animals and, finally, up to man. Mistakes permeate popular science expositions of evolutionary biology. Mistakes even filter into biology journals and texts. For example, Lodish, et. al., in their cell biology text, proclaim, ""It was Charles Darwin's great insight that organisms are all related in a great chain of being..."" In fact, the idea of a great chain of being, which traces to Linnaeus, was overturned by Darwin's idea of common descent.
Misunderstandings about evolution are damaging to the study of evolution and biology as a whole. People who have a general interest in science are likely to dismiss evolution as a soft science after absorbing the pop science nonsense that abounds. The impression of it being a soft science is reinforced when biologists in unrelated fields speculate publicly about evolution.
This is a brief introduction to evolutionary biology. I attempt to explain basics of the theory of evolution and correct many of the misconceptions.
Evolution is a change in the gene",Science & Research 
"Immersive Art Installations: The Art Experience
The Uptown Art Fair team is excited to introduce a captivating new initiative: “The ART Experience: Uptown Minneapolis.” This vibrant event series will showcase immersive art installations that engage the community, along with an ART CONTEST—all hosted at Seven Points Uptown, located at the intersection of Hennepin Ave. and Lake Street.
The ART Experience aims to nurture community involvement and inspire creativity by fostering an open and participatory environment for art lovers. This initiative encourages interaction and dialogue between artists and visitors.
ART INSTALLATIONS ARTISTS & INFORMATION:",art_culture
"POS Tagging (State of the art)
Test collections
- Performance measure: per token accuracy. (The convention is for this to be measured on all tokens, including punctuation tokens and other unambiguous tokens.)
- English
- Penn Treebank Wall Street Journal (WSJ) release 3 (LDC99T42). The splits of data for this task were not standardized early on (unlike for parsing) and early work uses various data splits defined by counts of tokens or by sections. Most work from 2002 on adopts the following data splits, introduced by Collins (2002):
- Training data: sections 0-18
- Development test data: sections 19-21
- Testing data: sections 22-24
- Penn Treebank Wall Street Journal (WSJ) release 3 (LDC99T42). The splits of data for this task were not standardized early on (unlike for parsing) and early work uses various data splits defined by counts of tokens or by sections. Most work from 2002 on adopts the following data splits, introduced by Collins (2002):
- French
- French TreeBank (FTB, Abeillé et al; 2003) Le Monde, December 2007 version, 28-tag tagset (CC tagset, Crabbé and Candito, 2008). Classical data split (10-10-80):
- Training data: sentences 2471 to 12351
- Development test data: sentences 1236 to 2470
- Testing data: sentences 1 to 1235
- French TreeBank (FTB, Abeillé et al; 2003) Le Monde, December 2007 version, 28-tag tagset (CC tagset, Crabbé and Candito, 2008). Classical data split (10-10-80):
Tables of results
WSJ
(*) TnT: Accuracy is as reported by Giménez and Márquez",Technology & Computing 
"Acting in Style fashion chats with red carpet celebs and others in the fashion, costuming, and entertainment industries.
ActorsE Chat (Actors Entertainment on IMDb) streams LIVE - Search for past entertainment industry guests. ActorsE : 10th Season, over 1,500 episodes and 6,948,752+ viewers!
G-d in Hollywood highlights entertainment professionals making a positive difference.
Cute, silly, and unexpected film shorts created by John Michael Ferrari. Rules: one take and actors don't usually know what's coming.
Models, Photographers, Designers, and hair and make-up artists show and tell about the world of modeling and photography.
Learn and share with John Michael Ferrari how to get motivated personally and financially.
Foodie guests on food, recipes, restaurants, trends, products, cookbooks, life stories, insights!
Take a peek into happening ... off the mainstream ... music & musical talent.
Catch funny and uplifting comedian, producer, and author Stevie D. rock the double-wide with his guests.
Interviews, Carpets, B-roll of the real of Hollywood w/ host Eric ""EZ"" Zuley. The EZ Show is featured in EZWAY MAGAZINE, Posted on ACTORSREPORTER.COM, WTVNETWORKS.COM, THEEZSHOW.COM, ACTORSE.COM & viewers can download The Eric Zuley App (for Apple and Android Users) and watch The EZ Show live or archived episode.
Join passionate theatre critics sharing their insightful views and reviews of small theatre performances in and around Los Angeles.
Enjoy following Danika Quinn and the Actors E",art_culture
"Learning Self-Attention with Neural Networks
By Team Acumentica
Self-attention, a mechanism within the field of neural networks, has revolutionized the way models handle and process data. It allows models to dynamically weigh the importance of different parts of the input data, thereby improving their ability to learn and make predictions. This capability is particularly powerful in tasks that involve sequences, such as natural language processing (NLP) and time series analysis. In this article, we’ll delve into the concept of self-attention, explore how it is implemented in neural networks, and discuss its advantages and applications.
What is Self-Attention?
Self-attention is a mechanism that allows an output to be computed as a weighted sum of the inputs, where the weights are determined by a function of the inputs themselves. Essentially, it enables a model to focus on the most relevant parts of the input for performing a specific task. This is akin to the way humans pay more attention to certain aspects of a scene or conversation depending on the context.
The Mechanism of Self-Attention
Self-attention can be described as a mapping of a query and a set of key-value pairs to an output. The output is computed as a weighted sum of the values, where the weight assigned to each value is determined by a compatibility function of the query with the corresponding key.
Here’s a step-by-step breakdown of how self-attention works:
- Input Representation: Each input element (e.g., a w",Technology & Computing 
"What is Z-Wave?
Similar to Wi-Fi, Z-Wave ( Zwave ) is a wireless communication technology facilitating seamless interaction among all Aeotec’s devices and extending connectivity to other approved devices, regardless of the manufacturer. This communication is not only reliable but also interference-free, energy-efficient, and, above all, secure.
At Aeotec, our focus is on empowering you to shape the home of tomorrow, today, using cutting-edge technology tailored for home automation. We prioritize reliable, proven, and standardized solutions. one such technology we specialize in is Z-Wave.
Explore more about Aeotec’s diverse home automation products and discover the different ranges we offer. Shape your smart home with technology that redefines reliability and standardization.
Z-Wave features
Low Power
Mesh Networking
Interference free
Security
Wireless
Expandable
Easy to use
Cross compatible
Smart Start (Z-Wave)
SmartStart, present in chosen Z-Wave devices of the 500 series and all those utilizing 700 and 800 series technology, streamlines the setup process. Users can effortlessly connect their devices to the Zwave gateway by scanning a QR code with a SmartStart-enabled app. This feature caters to professional system integrators, enabling device connection before powering on, as well as DIY installations, where users can easily set up these devices by scanning a QR code. SmartStart substantially diminishes the time and effort needed for a comprehensive automation system instal",Technology & Computing 
"Download Articulate Storyline 3 free latest full version direct download link one-click standalone offline installer for Windows 32-bit and 64-bit. Articulate Storyline 2020 v3.11 is a powerful application for e-learning and authoring that can create different types of tutorials and other learning presentations.
Articulate Storyline 3 Overview
Articulate Storyline is a leading and industry-standard e-learning authoring tool designed to empower instructional designers and educators in creating engaging and interactive e-learning content. This powerful software provides users with a range of features and capabilities for developing compelling and effective online courses.
One of the standout features of Articulate Storyline is its ability to facilitate the creation of interactive and multimedia-rich e-learning modules. Users can incorporate various elements such as text, images, videos, quizzes, simulations, and interactive scenarios to engage learners effectively.
The software boasts a user-friendly and intuitive interface that simplifies the process of designing e-learning content. Even those with limited technical expertise can navigate and utilize the application efficiently.
Articulate Storyline offers flexibility in content creation. Users have the freedom to create custom navigation paths, branching scenarios, and adaptive content to cater to different learning styles and needs.
Another strength of this tool is its support for responsive design, ensuring that e-learning ",Technology & Computing 
"AV1 Features
ROYALTY-FREE
Interoperable and open
UBIQUITOUS
Scales to any modern device at any bandwith
FLEXIBLE
For use in both commercial and non-commercial content, including user-generated content
30% BETTER COMPRESSION *
Uses less data while delivering 4k UHD video and beyond when compared to alternatives
OPTIMIZED
Developed for the internet and related applications and services-from browsers and streaming to videoconferencing services
LOW FOOTPRINT
Designed with a low computational footprint and optimized for hardware
CONSISTENT, HIGHEST-QUALITY REAL-TIME VIDEO
Bringing features like 4k UHD, HDR, and WCG to real-time video
- Source AV1 Test Results, BitMovin, “Multi-Codec DASH Dataset: An Evaluation of AV1, AVC, HEVC, and VP9.”",Technology & Computing 
"Table of Contents
A lot of Machine Learning problems consist of hundreds to thousands of features. Having such a large number of features poses certain problems.
This problem is also sometimes known as The Curse of Dimensionality and Dimensionality Reduction or Dimension reduction is the process of reducing the number of random variables under consideration by obtaining a set of principal variables.
In other words, the goal is to take something that is very high dimensional and get it down to something that is easier to work with, without losing much of the information.
Why Dimensionality Reduction?
- We are living in a time where the connections between the different devices have increased because they have more sensors and measuring technologies that control some actions. That makes the features we should analyze bigger every time and more unintelligible.
- These techniques help us to reduce the quantity of relevant information that we should save so they reduce a lot the storage costs.
- Large dimensions are difficult to train on, it needs more computational power and time.
- In most datasets we find a high quantity or repeated data, columns that have just one value or which variance is so small that are not able to give the needed information for the model learning. The reduction of dimensionality helps us to filter this unnecessary information.
- One of the most important things is the human eye. We do not have the same capabilities as a machine so it’s necessary to adap",Technology & Computing 
"Optimizers: SGD, Adam, and RMSprop
(Gradient-Based Learning)Stochastic Gradient Descent (SGD) updates model weights using the gradient of the loss function scaled by a fixed learning rate. Pros: Simple, interpretable, and useful for convex problems. Cons: Requires manual tuning and struggles with complex loss landscapes.
Adam combines momentum (tracking moving averages of gradients) and adaptive learning rates per parameter. Why use it: Automatically adjusts learning rates, excels with sparse gradients (e.g., NLP tasks), and converges faster than SGD in many cases.
RMSprop adapts learning rates by dividing gradients by a moving average of their magnitudes. Ideal for: Non-stationary objectives (e.g., recurrent networks) or when gradients vary widely in magnitude.
javascript// Example: Implementing optimizers in TensorFlow.js
import * as tf from '@tensorflow/tfjs';
// Create a simple sequential model
const model = tf.sequential({
layers: [tf.layers.dense({ units: 1, inputShape: [10] })]
});
// SGD with learning rate 0.01
const sgdOpt = tf.train.sgd(0.01);
// Adam with default parameters (lr=0.001, beta1=0.9, beta2=0.999)
const adamOpt = tf.train.adam();
// RMSprop with learning rate 0.001 and decay rate 0.9
const rmsOpt = tf.train.rmsprop(0.001, 0.9);
// Compile the model with Adam optimizer
model.compile({ optimizer: adamOpt, loss: 'meanSquaredError' });
Code notes:
- Learning rates are explicit in SGD/RMSprop but use defaults in Adam for simplicity.
- Beta parameters in Adam ",Technology & Computing 
"AWS News Blog
Amazon Lex – Build Conversational Voice & Text Interfaces
While computers that talk are great, computers that listen and respond are even better! If you have used an Amazon Echo, you know how simple, useful, and powerful the Alexa-powered interaction model can be.
Today we are making the same deep learning technologies (ASR – Automatic Speech Recognition NLU – Natural Language Understanding) that power Amazon Alexa available to you for use in your own conversational applications. You can use Amazon Lex to build chatbots and other types of web & mobile applications that support engaging, lifelike interactions. Your bots can provide information, power your application, streamline work activities, or provide a control mechanism for robots, drones, and toys.
Amazon Lex is designed to let you get going quickly. You start out by designing your conversation in the Lex Console, providing Lex with some sample phrases that are used to build a natural language model. Then you publish your Amazon Lex bot and let it process text or voice conversations with your users. Amazon Lex is a fully-managed service so you don’t need to spend time setting up, managing, or scaling any infrastructure.
Your chatbot can connect with Facebook Messenger today; Slack and Twilio integration is in the works as well. On the AWS side, it works with AWS Lambda, AWS Mobile Hub, and Amazon CloudWatch. Your code can make use of Amazon DynamoDB, Amazon Cognito, and other services.
Amazon Lex lets you ",Technology & Computing 
"Amazon Lex - AI Chat Builder
Add sophisticated, natural language, AI-powered chatbots to new and existing applications.
What is Amazon Lex?
Powered by the same technology as Alexa, Amazon Lex is an AI chat builder that allows users to interact with any application using natural language voice or chat. Use Amazon Lex to build and deploy conversational AI interfaces for any application. Integrating AI chat into existing business processes and use cases gives users more flexibility and support to get work done in ways that are natural to your users. AI chat experiences in customer-facing applications enhance customer satisfaction.
Benefits of Amazon Lex
How text and voice AI chat transforms business processes
Use cases
FAQs
Did you find what you were looking for today?
Let us know so we can improve the quality of the content on our pages.",Technology & Computing 
"Amazon Lex
Amazon Lex is a service for building conversational interfaces using voice and text. Powered by the same conversational engine as Alexa, Amazon Lex provides high quality speech recognition and language understanding capabilities, enabling addition of sophisticated, natural language ‘chatbots’ to new and existing applications. Amazon Lex reduces multi-platform development effort, allowing you to easily publish your speech or text chatbots to mobile devices and multiple chat services, like Facebook Messenger, Slack, Kik, or Twilio SMS. Native interoperability with AWS Lambda and Amazon CloudWatch and easy integration with many other services on the AWS platform including Amazon Cognito, and Amazon DynamoDB makes bot development effortless.
To start using Amazon Lex, simply sign into the AWS Management Console and navigate to “Lex” under the “Artificial Intelligence” category. You must have an Amazon Web Services account to start using Amazon Lex. If you do not already have one, you will be prompted to create one during the sign-up process. Please refer to the Amazon Lex V2 Getting Started Guide for more information.
The most common use-cases include:
Self-service voice assistants and chatbots – build a call center bot
Informational bot – build an automated customer support agent or bot that answers questions
Application/Transactional bot – build a stand-alone pizza ordering agent or a travel bot
Enterprise Productivity bot – build custom bots to connect to enterprise",Technology & Computing 
"Amazon Lex is a service for building conversational interfaces into any application using voice and text. With Amazon Lex, you pay only for what you use. There is no upfront commitment or minimum fee. Amazon Lex bots are designed for a request and response interaction or a continuous streaming conversation. With the request and response interaction, each user input (voice or text) is processed as a separate API call. In a streaming conversation, all user inputs across multiple turns are processed in one streaming API call. Pricing for Amazon Lex is based upon these two interaction models.
With streaming conversation, the bot continuously listens and can be designed to respond proactively. For example, you can configure the bot to keep a conversation going when the user needs more time to respond by sending periodic messages such as “Take your time. Let me know once you are ready.” The request and response model is a different user experience where a user input is required as an initiator.
You can try Amazon Lex for free. From the date you get started with Amazon Lex, you can process up to 10,000 text requests and 5,000 speech requests or speech intervals per month for free for the first year. You can also use Automated chatbot designer for two hours of training time per month for first two months.
Request and response interaction pricing
Speech request: Each speech input from the user is counted as a speech request.
Text request: Each text input from the user is counted as a ",Technology & Computing 
"What Is a Document Database?
A document database is a type of NoSQL database that can be used to store and query data as JSON-like documents. JavaScript Object Notation (JSON) is an open data interchange format that is both human and machine-readable. Developers can use JSON documents in their code and save them directly into the document database. The flexible, semi-structured, and hierarchical nature of documents and document databases allows them to evolve with applications’ needs.
What are the advantages of document databases
Document databases enable flexible indexing, powerful ad hoc queries, and analytics over collections of documents. Read more about the benefits below.
Ease of development
JSON documents map to objects—a common data type in most programming languages. When building applications, developers can flexibly create and update documents directly from the code. This means they spend less time creating data models beforehand. Therefore, application development is more rapid and efficient.
Flexible schema
A document-oriented database allows you to create multiple documents with different fields within the same collection. This can be handy when storing unstructured data like emails or social media posts. However, some document databases offer schema validation, so you can impose some restrictions on the structure.
Performance at scale
Document databases offer built-in distribution capabilities. You can scale them horizontally across multiple servers without imp",Technology & Computing 
"What is a Data Mesh?
A data mesh is an architectural framework that solves advanced data security challenges through distributed, decentralized ownership. Organizations have multiple data sources from different lines of business that must be integrated for analytics. A data mesh architecture effectively unites the disparate data sources and links them together through centrally managed data sharing and governance guidelines. Business functions can maintain control over how shared data is accessed, who accesses it, and in what formats it’s accessed. A data mesh adds complexities to architecture but also brings efficiency by improving data access, security, and scalability.
What challenges does a data mesh solve?
Even though organizations have access to ever-increasing data volume, they have to sort, filter, process, and analyze the data to derive practical benefits. Organizations often utilize a central team of engineers and scientists for managing data. The team uses a centralized data platform for the following purposes:
- Ingest the data from all the different business units (or business domains).
- Transform the data into a consistent, trustworthy, and useful format. For example, the team could make sure all dates in the system are in a common format or summarize daily reports.
- Prepare the data for data consumers, like by generating reports for humans or preparing XML files for applications. Read about XML »
As data volume increases, organizations face increasing costs t",Technology & Computing 
"We’re back with another global cinema spotlight! This time we’re heading to Denmark with Dogme 95. This movement radically redefined cinema with a back-to-basics philosophy. Its stripped-down style and commitment to naturalism made for some of the most memorable films in recent Danish history. The Dogme 95 Collective was founded by directors Lars von Trier and Thomas Vinterberg in 1995 and disbanded in 2005. “Dogme” is the Danish word for dogma, and “95” refers to the year of creation.
Background
The movement was an attempt to create a niche of film free of Hollywood-esque technological gimmicks like special effects. Vinterberg and von Trier aimed to return to the basic ethos of filmmaking; story, theme, and acting. Essentially, it was a return to the pure foundation of film without the excess flab it often comes with. Hence the creation of a dogme (dogma) of strict rules for filmmakers.
The theory was introduced to the public at Le cinéma vers son deuxième siècle in Paris in March 1995. This was a conference celebrating 20th Century film. Lars von Trier was one of the directors invited to speak at this event. Before his speech, pamphlets that described the new Dogme 95 movement were distributed to the audience of filmmakers. The pamphlets were a manifesto co-written by Vinterberg and von Trier. They included a list of rules called “Vows of Chastity” that directors had to adhere to.
The rules included requirements that shooting must be done on location, no props can be brough",art_culture
"AV1
The next generation video codec that can deliver stunning 4K video over connections that are limited to SD with older codecs
What is the AV1 codec?
AV1 is an open, royalty-free, next-generation video coding format from the Alliance for Open Media. It was designed to succeed Google’s VP9 and compete with H.265/HEVC. AV1 can provide 30% bandwidth savings compared to VP9 and HEVC and drastically improves visual quality at equivalent bitrates.
- Interoperable and open
- Designed with a low computational footprint and optimized for hardware
- Capable of consistent, highest-quality, real-time video delivery
- Optimized for the Internet
- Scalable to any modern device at any bandwidth
- Flexible for both commercial and non-commercial content, including user-generated content
AV1 Datasheet
How efficient is AV1? From its inception, Bitmovin has been testing and benchmarking the efficiency and quality results from different AV1 techniques and implementations, while developing new patent-pending methods for maximizing speed and performance.
Download our datasheet to view the results of our tests, implementations, and the types of presets that we recommend when applying AV1.
How much can AV1 lower your total cost of ownership?
While AV1 encoding is more complex and requires more processing power than other codecs, it provides much higher compression efficiency, which can drastically reduce your storage and CDN costs. The actual break-even and savings point will vary based on your ind",Technology & Computing 
"Today, v2 of Pwned Passwords was released as part of the Have I Been Pwned service offered by Troy Hunt. Containing over half a billion real world leaked passwords, this database provides a vital tool for correcting the course of how the industry combats modern threats against password security.
I have written about how we need to rethink password security and Pwned Passwords v2 in the following post: How Developers Got Password Security So Wrong. Instead, in this post I want to discuss one of the technical contributions Cloudflare has made towards protecting user information when using this tool.
Cloudflare continues to support Pwned Passwords by providing CDN and security functionality such that the data can easily be made available for download in raw form to organisations to protect their customers. Further, as part of the second iteration of this project, I have also worked with Troy on designing and implementing API endpoints that support anonymised range queries to function as an additional layer of security for those consuming the API, that is visible to the client.
This contribution allows for Pwned Passwords clients to use range queries to search for breached passwords, without having to disclose a complete unsalted password hash to the service.
Getting Password Security Right
Over time, the industry has realised that complex password composition rules (such as requiring a minimum number of special characters) have done little to improve user behaviour in making str",Technology & Computing 
"Note: this post was originally written in June 2016. It is now very outdated. Please see this guide to fine-tuning for an up-to-date alternative, or check out chapter 8 of my book ""Deep Learning with Python (2nd edition)"".
In this tutorial, we will present a few simple yet effective methods that you can use to build a powerful image classifier, using only very few training examples --just a few hundred or thousand pictures from each class you want to be able to recognize.
We will go over the following options:
- training a small network from scratch (as a baseline)
- using the bottleneck features of a pre-trained network
- fine-tuning the top layers of a pre-trained network
This will lead us to cover the following Keras features:
fit_generator
for training Keras a model using Python data generatorsImageDataGenerator
for real-time data augmentation- layer freezing and model fine-tuning
- ...and more.
Our setup: only 2000 training examples (1000 per class)
We will start from the following setup:
- a machine with Keras, SciPy, PIL installed. If you have a NVIDIA GPU that you can use (and cuDNN installed), that's great, but since we are working with few images that isn't strictly necessary.
- a training data directory and validation data directory containing one subdirectory per image class, filled with .png or .jpg images:
data/
train/
dogs/
dog001.jpg
dog002.jpg
...
cats/
cat001.jpg
cat002.jpg
...
validation/
dogs/
dog001.jpg
dog002.jpg
...
cats/
cat001.jpg
cat002.jpg
...
To ac",Technology & Computing 
"To successfully use PowerPoint for rapid elearning, you need to do two things:
- Rethink how you use PowerPoint. Most people approach it from a linear presentation mindset, building slides the same way they would for face-to-face presentations. That just doesn’t work for elearning.
- Learn to use PowerPoint’s features. Once you scratch the surface of the tools available in PowerPoint, you’ll see it’s more than adequate for building great elearning. In many ways it’s the ideal choice because it offers a blend of speed, ease-of-use, and cost savings.
The following posts explore lots of practical, hands-on tips and tricks for using PowerPoint to create elearning. Use them and you’ll see how effective PowerPoint is to build good elearning courses.
What You Need to Know About PowerPoint & E-Learning
This series discusses key concepts and provides excellent examples of how to use PowerPoint for your elearning courses.
- What Everybody Ought To Know About Using PowerPoint for E-Learning
- 5 Essential Rapid E-Learning Tips
- Why Dissecting an E-Learning Course Will Improve Your Skills
- How to Convert Your PowerPoint Presentation into an Elearning Course
- Change Your Presentation Template to an E-Learning Template
- Here Are Some Time Saving Tips for Your Next Software Demo
Tips & Tricks to Improve Your PowerPoint Skills
Here’s a series of posts that will give you all of the basic production techniques that you need to be successful. The trick is to practice the techniques so that y",Technology & Computing 
"Rapid elearning can mean many things. For some it means easy tools that let you
build elearning courses without special programming skills. For others, it means being empowered to quickly share your expertise with others. Ultimately, it’s usually about getting the right information to people at the right time while operating at the speed of business.
Rapid E-Learning 101
If you’re just getting started with elearning, this series brings you up-to-speed. You’ll learn the basics of rapid elearning and how best to get your project off the ground.
- So You Want To Be An E-Learning Hero?
- 5 Ways To Jump Start Your Next E-Learning Project.
- What Everyone Ought To Know About Designing An E-Learning Course.
- Build A Simple E-Learning Project Plan.
- How To Get The Most Out Of Your Subject Matter Expert.
- Understanding Multimedia For Rapid E-Learning Design.
- I Just Finished My Rapid E-Learning Course. Now, What Do I Do?
-
Here’s Why Rapid E-Learning is So Darn Cool (and Just Might Change the World)
How to Get Started with E-Learning
I get a lot of emails asking how to get started with elearning. Subscribing to this blog is a good start. But I do have a few more suggestions. There are three core areas you should focus on: instructional design, visual design, and performance consulting. These areas will help build effective courses that look good. And you’ll know how to build the right type of course.
But the real tip is to practice what you’re learning, even if it’s simple in the ",Technology & Computing 
"Table of Contents
.mk
file.hash
fileSNNfoo
start scriptList of Examples
Buildroot 2025.05 manual generated on 2025-06-09 20:23:58 UTC from git revision fcde5363aa
The Buildroot manual is written by the Buildroot developers. It is licensed under the GNU General Public License, version 2. Refer to the COPYING file in the Buildroot sources for the full text of this license.
Copyright © The Buildroot developers <buildroot@buildroot.org>
Buildroot is a tool that simplifies and automates the process of building a complete Linux system for an embedded system, using cross-compilation.
In order to achieve this, Buildroot is able to generate a cross-compilation toolchain, a root filesystem, a Linux kernel image and a bootloader for your target. Buildroot can be used for any combination of these options, independently (you can for example use an existing cross-compilation toolchain, and build only your root filesystem with Buildroot).
Buildroot is useful mainly for people working with embedded systems. Embedded systems often use processors that are not the regular x86 processors everyone is used to having in his PC. They can be PowerPC processors, MIPS processors, ARM processors, etc.
Buildroot supports numerous processors and their variants; it also comes with default configurations for several boards available off-the-shelf. Besides this, a number of third-party projects are based on, or develop their BSP [1] or SDK [2] on top of Buildroot.
Buildroot is designed to run on Linux system",Technology & Computing 
"Privacy-Friendly Analytics for Your WordPress Site
Get understandable data without compromising user privacy
- Real-time, comprehensive insights with a user-friendly interface
- Fully compliant with GDPR and other privacy regulations
- Quick and easy set-up process, ready in seconds
No third-party tracking — just clear insights.
Burst is Part of the Team Updraft Family, known for:
What our WordPress users are saying
4.9 out of 5 stars out of 146+ reviews
@marxgal“Excellent plug-in. I had Google Analytics, I installed Burst stats and it gives me the stats I need without all the overhead. My pagespeed score improved too!”
@naturalextractor“A client installed Burst analytics on a site and after looking at it can state I will be using this on clients sites moving forward, due to its ease of use and been able to see all the things I need in one dash. ”
@karsten007“Fast as lightning support and very helpful. Great plugin for reasonable price.”
Frequently Asked Questions
What is Burst Statistics?
Burst is a privacy-friendly analytics plugin for WordPress. It helps you track your website traffic without collecting personal data — so you stay in control.
It’s simple, lightweight, and runs entirely on your own server. No third-party tracking, no complicated setup, and no data leaving your site.
What’s the difference between Burst Free and Burst Pro?
Burst Free gives you clean, essential analytics — perfect for bloggers and small site owners.
Burst Pro adds advanced tools for webshops a",Technology & Computing 
"Cross-Site Request Forgery Prevention Cheat Sheet¶
Introduction¶
A Cross-Site Request Forgery (CSRF) attack occurs when a malicious web site, email, blog, instant message, or program tricks an authenticated user's web browser into performing an unwanted action on a trusted site. If a target user is authenticated to the site, unprotected target sites cannot distinguish between legitimate authorized requests and forged authenticated requests.
Since browser requests automatically include all cookies including session cookies, this attack works unless proper authorization is used, which means that the target site's challenge-response mechanism does not verify the identity and authority of the requester. In effect, CSRF attacks make a target system perform attacker-specified functions via the victim's browser without the victim's knowledge (normally until after the unauthorized actions have been committed).
However, successful CSRF attacks can only exploit the capabilities exposed by the vulnerable application and the user's privileges. Depending on the user's credentials, the attacker can transfer funds, change a password, make an unauthorized purchase, elevate privileges for a target account, or take any action that the user is permitted to do.
In short, the following principles should be followed to defend against CSRF:
IMPORTANT: Remember that Cross-Site Scripting (XSS) can defeat all CSRF mitigation techniques! While Cross-Site Scripting (XSS) vulnerabilities can bypass CSRF ",Technology & Computing 
"french new wave
est. 1955 – late 1960s
The French New Wave or La Nouvelle Vague, is one of the most iconic and influential film movements in the history of cinema. Emerging in the late 1950s and flourishing throughout the 1960s, it transformed the cinema not only in France but also worldwide, which marked cultural and intellectual transformation of the film as a medium.
Published by: CinemaWaves Team | Filed Under: Film Movements
Beginnings of the French New Wave
The origins of the French New Wave can be traced to the post-World War II period in France, when the country was undergoing a major cultural and social transformation. After years of Nazi occupation, French cinema had stagnated, relying on formulaic, studio-driven productions.
However, with the liberation of France, a new generation of young cinephiles emerged, many of whom were critics for the influential film journal Cahiers du Cinéma. These aspiring filmmakers, including Jean-Luc Godard, Francois Truffaut, and Claude Chabrol, were passionate about cinema and critical of the conventional French filmmaking practices of the time, which they saw as uninspired and detached from real life. This dissatisfaction laid the foundation of the French New Wave movement.
In the 1950s, French New Wave pioneers found inspiration in the films of Italian Neorealism, American cinema, and the writings of film theorists such as Andre Bazin, who championed the idea of “auteur theory.” This theory proposed that directors should have crea",art_culture
"High-performance GPUs on Google Cloud for machine learning, scientific computing, and generative AI.
Speed up compute jobs like generative AI, 3D visualization, and HPC
A wide selection of GPUs to match a range of performance and price points
Flexible pricing and machine customizations to optimize for your workload
Key features
NVIDIA GB200, B200, H200, H100, L4, P100, P4, T4, V100, and A100 GPUs provide a range of compute options to cover your workloads for a broad set of cost and performance needs.
Optimally balance the processor, memory, high performance disk, and up to 8 GPUs per instance for your individual workload. All with the per-second billing, so you only pay only for what you need while you are using it.
Run GPU workloads on Google Cloud where you have access to industry-leading storage, networking, and data analytics technologies.
What's new
Sign up for Google Cloud newsletters to receive product updates, event information, special offers, and more.
Documentation
Pricing
For information about GPU pricing for the different GPU types and regions that are available on Compute Engine, refer to the GPU pricing document.
Start building on Google Cloud with $300 in free credits and 20+ always free products.",Technology & Computing 
"Introduction to Cloud TPU
Tensor Processing Units (TPUs) are Google's custom-developed, application-specific integrated circuits (ASICs) used to accelerate machine learning workloads. For more information about TPU hardware, see TPU architecture. Cloud TPU is a web service that makes TPUs available as scalable computing resources on Google Cloud.
TPUs train your models more efficiently using hardware designed for performing large matrix operations often found in machine learning algorithms. TPUs have on-chip high-bandwidth memory (HBM) letting you use larger models and batch sizes. TPUs can be connected in groups called slices that scale up your workloads with little to no code changes.
Code that runs on TPUs must be compiled by the accelerator linear algebra (XLA) compiler. XLA is a just-in-time compiler that takes the graph emitted by an ML framework application and compiles the linear algebra, loss, and gradient components of the graph into TPU machine code. The rest of the program runs on the TPU host machine. The XLA compiler is part of the TPU VM image that runs on a TPU host machine.
For more information about Tensor Processing Units, see How to think about TPUs.
When to use TPUs
Cloud TPUs are optimized for specific workloads. In some situations, you might want to use GPUs or CPUs on Compute Engine instances to run your machine learning workloads. In general, you can decide what hardware is best for your workload based on the guidelines that follow.
CPUs
- Quick proto",Technology & Computing 
"9 Homework 10
This assignment is due Thursday, 3/20 by MIDNIGHT
What to Download:
Submit your completed file to the HW10 assignment on Gradescope.
9.1 Message Passing Concurrency
In this HW, you will design a program with three processes, ""a"", ""b"", and ""c"".
The program will start by having process ""a"" send a message ""hello"" to process ""b"".
Whenever process ""b"" receives message ""hello"" from process ""a"", it should send message ""hello"" to process ""c"".
Whenever process ""c"" receives message ""hello"" from process ""b"", it should send message ""got it"" to process ""a"", unless it has already received 4 ""hello"" messages from process ""b"", in which case it should do nothing.
Whenever process ""a"" receives message ""got it"" from process ""c"", it should send message ""hello"" to process ""b"".
9.2 Problem 1
Processes update their own state in response to messages so when designing concurrent programs, the first task is to think about the state of each process. In this problem, your task is to define the state for process ""a"".
9.3 Problem 2
Next, define handlers for the ""a"" process: the handler that is called once at the beginning of the program, to initialize the processes, and the handler that is called every time process ""a"" receives a message. Write tests for both.
9.4 Problem 3
Now, repeat Problem 1 with process ""b"":
9.5 Problem 4
And, repeat Problem 2 with process ""b"":
9.6 Problem 5
Now, repeat Problem 1 with process ""c"":
9.7 Problem 6
And, repeat Problem 2 with process ""c"":
9.8 Problem 7
Now t",Technology & Computing 
"Table of Contents:
- Architecture Overview
- ConvNet Layers
- ConvNet Architectures
- Layer Patterns
- Layer Sizing Patterns
- Case Studies (LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet)
- Computational Considerations
- Additional References
Convolutional Neural Networks (CNNs / ConvNets)
Convolutional Neural Networks are very similar to ordinary Neural Networks from the previous chapter: they are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer and all the tips/tricks we developed for learning regular Neural Networks still apply.
So what changes? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.
Architecture Overview
Recall: Regular Neural Nets. As we saw in the previous chapter, Neural Networks receive an input (a single vector), and transform it through a series of hidden layers. Each hidden layer is made up of a set of neurons, where each neuron is fully connected to all neurons in the previous layer, and where neu",Technology & Computing 
"Keywords: data anonymity, data privacy, re-identification, data fusion, privacy
Citation:
Abstract
Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k-anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, m-Argus and k-Similar provide guarantees of privacy protection.
L. Sweeney. k-anonymity: a model for protecting privacy.
International Journal on Uncertainty, Fuzziness and Knowledge-based Systems, 10 (5), 2002; 557-570.
Paper: 14 pages in PS or PDF.
Related Links",Technology & Computing 
"Keywords: data anonymity, data privacy, re-identification, data fusion, privacy
Citation:
Abstract
Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k-anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, m-Argus and k-Similar provide guarantees of privacy protection.
L. Sweeney. k-anonymity: a model for protecting privacy.
International Journal on Uncertainty, Fuzziness and Knowledge-based Systems, 10 (5), 2002; 557-570.
Paper: 14 pages in PS or PDF.
Related Links
Related Publications",Technology & Computing 
"Understanding Gradient Clipping in Deep Learning
Gradient clipping is a technique used during the training of deep neural networks to prevent the exploding gradient problem. This problem occurs when the gradients of the network's loss with respect to the weights become excessively large. As a result, the weight updates may be too large, causing the network to diverge and the loss function to become unstable. By clipping the gradients, we ensure that their magnitude does not exceed a specified threshold, thus maintaining stability in the training process.
Why Gradient Clipping is Necessary
In deep learning, the backpropagation algorithm is used to calculate the gradients, which are then employed to update the weights of the network. Ideally, these updates are small and controlled, nudging the network towards better performance. However, in deep networks or recurrent neural networks (RNNs), gradients can accumulate during backpropagation and grow exponentially large due to the multiplicative effect through layers. This can lead to very large updates to the weights, causing the loss to oscillate or diverge, rather than converge to a minimum.
Gradient clipping mitigates this risk by imposing a cap on the gradients, ensuring that the training remains stable and that the network continues to learn effectively.
How Gradient Clipping Works
Gradient clipping involves setting a threshold value, and then scaling down the gradients if their norm exceeds this threshold. There are two comm",Technology & Computing 
"DirectX Developer Blog
The latest news on Microsoft's Graphics and Display technology
Latest posts
DirectStorage 1.3 is now available
Today we’re releasing DirectStorage 1.3, this update includes a new API and several refinements based on developer feedback. The package is now available for download via NuGet. Read on to learn about what’s new with DirectStorage 1.3. EnqueueRequests – Enhanced I/O Scheduling DirectStorage 1.3 adds a new API called EnqueueRequests. This API gives developers more flexibility and control over how data requests are issued and synchronized with graphics work. EnqueueRequests allows developers to batch multiple requests in a single call and synchronize them using a D3D12 fence to better coordinate DirectStorage wit...
D3D12 Cooperative Vector
Welcome to the preview release for Cooperative Vector support in D3D12. This exposes powerful new hardware acceleration for vector and matrix operations, enabling developers to efficiently drive neural rendering techniques directly from individual shader threads in real-time graphics pipelines. In research and in industry, machine learning based approaches have made their way to mainstream, replacing/augmenting traditional techniques. In graphics, neural network based rendering methods are gaining popularity over traditional methods of image reconstruction, texture compression, material shading etc. Simul...
D3D12 Opacity Micromaps
DirectX Raytracing (DXR) now supports Opacity Micromaps (OMMs), enabling hardwa",Technology & Computing 
"It is time for DirectX to evolve once again.
From the team that has brought PC and Console gamers the latest in graphics innovation for nearly 25 years, we are beyond pleased to bring gamers DirectX 12 Ultimate, the culmination of the best graphics technology we’ve ever introduced in an unprecedented alignment between PC and Xbox Series X.
When gamers purchase PC graphics hardware with the DX12 Ultimate logo or an Xbox Series X, they can do so with the confidence that their hardware is guaranteed to support ALL next generation graphics hardware features, including DirectX Raytracing, Variable Rate Shading, Mesh Shaders and Sampler Feedback. This mark of quality ensures stellar “future-proof” feature support for next generation games!
Ultimate Graphics Innovation
Microsoft’s Game Stack exists to bring developers the tools they need to create bold, immersive game experiences, and DX12 Ultimate is the ideal tool to amplify gaming graphics. DX12 Ultimate is the result of continual investment in the DirectX 12 platform made over the last five years to ensure that Xbox and Windows 10 remain at the very pinnacle of graphics technology. To further empower game developers to create games with stunning visuals, we enhanced features that are already beginning to transform gaming such as DirectX Raytracing and Variable Rate Shading, and have added new major features such as Mesh Shaders and Sampler Feedback.
Together, these features represent many years of innovation from Microsoft and o",Technology & Computing 
"DirectX is coming to the Windows Subsystem for Linux
At //build 2020 we announced that GPU hardware acceleration is coming to the Windows Subsystem for Linux 2 (WSL 2).
What is WSL? WSL is an environment in which users can run their Linux applications from the comfort of their Windows PC. If you are a developer working on containerized workload that will be deployed in the cloud inside of Linux containers, you can develop and test these workloads locally on your Windows PC using the same native Linux tools you are accustomed to. In response to popular demand, these Linux applications and tools can now benefit from GPU acceleration.
The purpose of this blog is to give you a glimpse of how this support is achieved and how the various pieces fit together.
GPU Virtualization
Over the last few Windows releases, we have been busy developing client GPU virtualization technology. This technology is integrated into WDDM (Windows Display Driver Model) and all WDDMv2.5 or later drivers have native support for GPU virtualization. This technology is referred to as WDDM GPU Paravirtualization, or GPU-PV for short. GPU-PV is now a foundational part of Windows and is used in scenarios like Windows Defender Application Guard, the Windows Sandbox or the Hololens 2 emulator. Today this technology is limited to Windows guests, i.e. Windows running inside of a VM or container.
To bring support for GPU acceleration to WSL 2, WDDMv2.9 will expand the reach of GPU-PV to Linux guests. This is achieve",Technology & Computing 
"After months of development and refinement in collaboration with hardware vendors and software developers, we are pleased to announce the availability of Shader Model 6.6! Shader Model 6.6 empowers shader authors with new tools for greater flexibility to make existing shaders faster
and more versatile as well as to devise all new techniques.
To give Shader Model 6.6 a try, developers will need a few tools. To compile shaders using Shader Model 6.6, you need the latest DirectX Shader Compiler release. To run those compiled shaders, you’ll need the DirectX 12 Agility SDK and the corresponding graphics driver.
New Atomic Operations
Shader Model 6.6 introduces 64-bit integer and limited bitwise floating-point atomic operations by overloading the Interlocked* functions and methods used on group shared memory, raw buffer, and typed (RWBuffer/RWTexture) resources.
See the Shader Model 6.6 Atomic Operations specification for more details.
Dynamic Resources
Shader Model 6.6 introduces the ability to create resources from descriptors by directly indexing into the CBV_SRV_UAV (resource view) heap or the Sampler heap. No root signature descriptor table mapping is required for this resource creation method, but new global root signature flags are used to indicate the use of each heap from the shader.
A short example:
Texture2D<float4> myTexture = ResourceDescriptorHeap[texIdx];
float4 result = myTexture.Sample(SamplerDescriptorHeap[sampIdx], coord);
Helper Lane Detection
IsHelperLane() is",Technology & Computing 
"Microsoft and its partners are happy to announce the development of Shader Model 6.6, the latest advancement in HLSL capability.
Shader Model 6.6 will grant shader developers increased flexibility to enhance and expand existing rendering approaches and devise all new ones. New features include expanded atomic operations, dynamic resource binding, derivatives and samples in compute shaders, packed 8-bit computations, and wave size.
Feature Details
64-bit Integer Atomic Operations
Shader Model 6.6 will introduce the ability to perform atomic arithmetic, bitwise, and exchange/store operations on 64-bit values.
All the following atomic intrinsic functions and methods will take 64-bit values when used on RWByteAddressBuffer and RWStructuredBuffer types in all shader stages:
void InterlockedAdd(inout BufType dest, int64_t value, out int64_t orig); void InterlockedAnd(inout BufType dest, int64_t value, out int64_t orig); void InterlockedOr(inout BufType dest, int64_t value, out int64_t orig); void InterlockedXor(inout BufType dest, int64_t value, out int64_t orig); void InterlockedMin(inout BufType dest, int64_t value, out int64_t orig); void InterlockedMax(inout BufType dest, int64_t value, out int64_t orig); void InterlockedExchange(inout BufType dest, int64_t value, out int64_t orig); void InterlockedCompareStore(inout BufType dest, int64_t cmpval, int64_t value); void InterlockedCompareExchange(inout BufType dest, int64_t cmpval, int64_t value, out int64_t orig);
Where RWByteAdd",Technology & Computing 
"CUDA Toolkit
The NVIDIA® CUDA® Toolkit provides a development environment for creating high-performance, GPU-accelerated applications. With it, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms, and supercomputers. The toolkit includes GPU-accelerated libraries, debugging and optimization tools, a C/C++ compiler, and a runtime library.
The Features of CUDA 12
Built-In Capabilities for Easy Scaling
Using built-in capabilities for distributing computations across multi-GPU configurations, you can develop applications that scale from single-GPU workstations to cloud installations with thousands of GPUs.
Learn More
New Release, New Benefits
CUDA 12 introduces support for the NVIDIA Hopper™ and Ada Lovelace architectures, Arm® server processors, lazy module and kernel loading, revamped dynamic parallelism APIs, enhancements to the CUDA graphs API, performance-optimized libraries, and new developer tool capabilities.
Learn More
Support for Hopper
Support for the Hopper architecture includes next-generation Tensor Cores and Transformer Engine, the high-speed NVIDIA NVLink® Switch, mixed-precision modes, second-generation Multi-Instance GPU (MIG), advanced memory management, and standard C++/Fortran/Python parallel language constructs.
Learn More
Tutorials
CUDA Developer Tools is a series of tutorial videos designed to get you started using NVIDIA Nsight™ tools for CUDA dev",Technology & Computing 
"CUDA Zone
CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.
In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python, Julia and MATLAB and express parallelism through extensions in the form of a few basic keywords.
The CUDA Toolkit from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.
Download Now
Applications Developed with CUDA
Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.
CUDA for all NVIDIA GPU Families
CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations.
Desktop Developer
Data Center Solutions
Embedded Applications
GPU-Accelerate Cloud
The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapid",Technology & Computing 
"Convolutional Neural Network (CNN)
A Convolutional Neural Network is a class of artificial neural network that uses convolutional layers to filter inputs for useful information. The convolution operation involves combining input data (feature map) with a convolution kernel (filter) to form a transformed feature map. The filters in the convolutional layers (conv layers) are modified based on learned parameters to extract the most useful information for a specific task. Convolutional networks adjust automatically to find the best feature based on the task. The CNN would filter information about the shape of an object when confronted with a general object recognition task but would extract the color of the bird when faced with a bird recognition task. This is based on the CNN’s understanding that different classes of objects have different shapes but that different types of birds are more likely to differ in color than in shape.
Applications of Convolutional Neural Networks include various image (image recognition, image classification, video labeling, text analysis) and speech (speech recognition, natural language processing, text classification) processing systems, along with state-of-the-art AI systems such as robots,virtual assistants, and self-driving cars.
Components of a Convolutional Neural Network
Convolutional networks are composed of an input layer, an output layer, and one or more hidden layers. A convolutional network is different than a regular neural network in th",Technology & Computing 
"My first encounter with Dogme 95 was when MarBelle took me to see von Trier’s The Idiots. I hated it! It’s not that I was offended by it or anything like that, I just thought that it was bloody stupid. And shit. In fact I only really became aware of the Dogme 95 movement when I had to research it last year. As The Idiots was the second Dogme film to be made by one of the movement’s founders, this meant that I had to sit through it again. And guess what? I still hated it.
I did however discover Kristian Levring’s The King is Alive (#4), which is absolutely fantastic, and had the pleasure of re-watching perhaps one of the strangest films of all time (which is just the way I like ’em), Harmony Korine’s Julien Donkey-Boy (#6).
Last year I set myself a task to try and watch all of the Dogme 95 films. I enjoy the fact that these films have to adhere to ten rules, otherwise known as The Vow of Chastity, and that if any of these are broken the director of the film has to confess that this is the case. My favourite of these has to be the confession of Julien Donkey-Boy in which Korine states that Chloe Sevigny’s pregnant belly was not really pregnant, despite his attempts. There are currently 117 Dogme films registered from around the world and I haven’t done as well as I would have liked with getting through them. Before June 2002 the Dogmesecretariat was responsible for registering all new Dogme films. Now you can register your film and activate your Dogme certificate online, just a",art_culture
"You're reading the documentation for a development version. For the latest released version, please have a look at Kilted.
ROS 2 Documentation
The Robot Operating System (ROS) is a set of software libraries and tools for building robot applications. From drivers and state-of-the-art algorithms to powerful developer tools, ROS has the open source tools you need for your next robotics project.
Since ROS was started in 2007, a lot has changed in the robotics and ROS community. The goal of the ROS 2 project is to adapt to these changes, leveraging what is great about ROS 1 and improving what isn’t.
Are you looking for documentation for a particular ROS package like MoveIt, image_proc, or octomap? Please see ROS Index or check out this index of per-package documentation.
This site contains the documentation for ROS 2. If you are looking for ROS 1 documentation, check out the ROS wiki.
If you use ROS 2 in your work, please see Citations to cite ROS 2.
Getting started
-
Instructions to set up ROS 2 for the first time
-
The best place to start for new users!
Hands-on sample projects that help you build a progression of necessary skills
-
Quick answers to your “How do I…?” questions without working through the Tutorials
-
High-level explanations of core ROS 2 concepts covered in the Tutorials
-
Answers to your questions or a forum to start a discussion
The ROS 2 project
If you’re interested in the advancement of the ROS 2 project:
-
Best practices and methodology for contributing to R",Technology & Computing 
"Educational Data Mining is an emerging discipline, concerned with developing methods for exploring the unique and increasingly large-scale data that come from educational settings and using those methods to better understand students, and the settings which they learn in.
Whether educational data is taken from students’ use of interactive learning environments, computer-supported collaborative learning, or administrative data from schools and universities, it often has multiple levels of meaningful hierarchy, which often need to be determined by properties of the data itself, rather than in advance. Issues of time, sequence, and context also play important roles in the study of educational data.
The International Educational Data Mining Society’s aim is to support collaboration and scientific development in this new discipline, through the organization of the EDM conference series, the Journal of Educational Data Mining, and mailing lists, as well as the development of community resources, to support the sharing of data and techniques.
Not yet an IEDMS member?
Join or renew nowThe latest issue of the Journal of Educational Data Mining (JEDM), Vol. 15 No. 3 (2023) is now available here. This issue includes, for the first time, articles published in both PDF and HTML formats. Future issues of JEDM will continue including accessible versions of all articles. Contributions to the paper format conversion project are welcome.
The latest issue of the Journal of Educational Data Mini",Technology & Computing 
"Home
About the Conference
Educational Data Mining is a leading international forum for high-quality research that mines data sets to answer educational research questions that shed light on the learning process. These data sets may originate from a variety of learning contexts, including learning management systems, interactive learning environments, intelligent tutoring systems, educational games, and data-rich learning activities. Educational data mining considers a wide variety of types of data, including but not limited to raw log files, student-produced artifacts, discourse, multimodal streams such as eye-tracking, and other sensor data. The overarching goal of the Educational Data Mining research community is to better support learners by developing data-driven understandings of the learning process in a wide variety of contexts and for diverse learners.
Topics of interest
Topics of interest to the conference include, but are not limited to.
- Deriving representations of domain knowledge from data.
- Detecting and addressing students’ affective and emotional states.
- Informing data mining research with educational theory.
- Contributing to theories of learning through data mining.
- Data mining to understand how learners interact with emerging genres of pedagogical environments such as educational games, MOOCs, and exploratory learning environments.
- Analyzing multimodal and sensor data.
- Using data mining methods to provide support for teachers, parents and policy m",Technology & Computing 
"Home
Educational Data Mining in Open-Ended Domains
Educational Data Mining is a leading international forum for high-quality research that mines data sets to answer educational research questions that shed light on the learning process. These data sets may originate from a variety of learning contexts, including learning management systems, interactive learning environments, intelligent tutoring systems, educational games, and data-rich learning activities. Educational data mining considers a wide variety of types of data, including but not limited to raw log files, student-produced artifacts, discourse, multimodal streams such as eye-tracking, and other sensor data. The overarching goal of the Educational Data Mining research community is to better support learners by developing data-driven understandings of the learning process in a wide variety of contexts and for diverse learners.
The theme of this year’s conference is EDM in Open-Ended Domains. As EDM has matured it has increasingly been applied to open-ended and ill-defined tasks such as writing, design, and collaborative problem-solving. And it has been used in new informal contexts where student actions are at best semi-structured. For this 12th iteration of the conference, we specifically welcome research in these new areas.
Topics of interest
Topics of interest to the conference include but are not limited to.
- Modeling student and group interaction for guidance and collaborative problem-solving.
- Deriving represe",Technology & Computing 
"Home
Due to the global health emergency caused by the Coronavirus
pandemic, EDM2020 will take place as a Fully Virtual Conference
Improving Learning Outcomes for All Learners
Educational Data Mining is a leading international forum for high-quality research that mines datasets to answer educational research questions, including exploring how people learn and how they teach. These data may originate from a variety of learning contexts, including learning and information management systems, interactive learning environments, intelligent tutoring systems, educational games, and data-rich learning activities. Educational data mining considers a wide variety of types of data, including but not limited to raw log files, student-produced artifacts, discourse, multimodal streams such as eye-tracking and other sensor data, and additional databases of student information. The overarching goal of the Educational Data Mining research community is to support learners and teachers more effectively, by developing data-driven understandings of the learning and teaching processes in a wide variety of contexts and for diverse learners.
The theme of this year’s conference is “Improving Learning Outcomes for All Learners”. The theme comprises two parts: (1) Identifying actionable learning or teaching strategies that can be used to improve learning outcomes. (2) Using EDM to promoting more equitable learning across diverse groups of learners. For this 13th iteration of the conference we specifica",Technology & Computing 
"Harnessing Large Language Models for Teaching and Learning: Challenges, Opportunities, and Future Directions
Edited by: Zhengdao Li, Aniello Castiglione, Moncef Gabbouj, Xiaofeng Chen
Submission deadline: 19 December 2025
Learning analytics and AI support for learning design and educational decision-making
Edited by: Bart Rienties, Blazenka Divjak, Nancy Law
Submission deadline: 31 August 2025",Technology & Computing 
"2025 Learning System Top Picks
Who is leading the pack? Who is setting themselves apart here in the mid-year? Are they an LMS? LMS/LXP? Talent
The Truth and Realities of E-Learning
Who is leading the pack? Who is setting themselves apart here in the mid-year? Are they an LMS? LMS/LXP? Talent
When I considered identifying the most significant impacts of online learning over the last 25 years, I realized it wasn’t
Skills are being limited to ratings, content and perceptions. AI adds a twist, but validation is lacking – and knowing doesn’t mean actually knowing.
AI functionality in LMS, LXP, TDP, and other learning systems is rapidly increasing. Some are the same, some aren’t.
The top 10 Learning Systems for 2024
“Vision 2025 by Craig Weiss” outlines a futuristic perspective on learning systems and their integration with artificial intelligence (AI).
Content. Courses. One in the same. Importance is a must and a need. It is more than a commodity; it is the fuel that drives online learning.
Where were you? I’m sure you heard this phrase where someone said, “Where were you when ABC happened?” “What was
Plan on buying an ERP learning system? Believe Workday Learning, SuccessFactors from SAP or Oracle Learn are better than other systems? Think the integration is easier? Think again.
My name is Craig, and I’m working in a job that requires me to learn about Microsoft Word because I’ll
Too many people are seeing the huge benefits of AI, ignoring the dark side, an increase in hallucinat",Technology & Computing 
"As technologies advance, organisations are faced with a humongous load of data and struggle to use it effectively and still keep up with rapidly changing regulations.
According to Secureframe, in 2023 60% of executives revealed that their organisation invested more time and resources in complying with laws and regulations.
To manage such complexities from data analysis to data management and compliance, the concept of data fabric appeared – a framework that strives to simplify data for best use cases.
This article tells you everything you need to know about data fabric, what it is, its architecture, features and use cases.
What is Data Fabric?
Data fabric can be defined as a framework that connects vast amounts of data from different sources on a single platform and manages them efficiently. It offers a sustainable solution to organisations that are seeking a unified architecture to manage their data seamlessly on their cloud environments while still connecting to data pipelines on a single platform.
A data fabric intends to democratize and automate data management by bridging the gap between data producers and consumers through a single framework. This framework applies necessary governance policies and allows organisations to access and use all their data at any time safely.
It cuts through complexities posed by distributed architectures and prepares it for analytics, AI, and machine learning applications. The complexities are simplified through unification, cleansing, and ",Technology & Computing 
"Exercise Physiology
Appearance
Exercise Physiology is the study of how the body responds and adapts to physical activity and exercise. It delves into the physiological processes that occur within our bodies when we engage in various forms of exercise, from a leisurely walk to ultramarathoner training, and everything in between. This WikiBook aims to give you a deeper scientific understanding of how the body reacts to exercise and functions in general. By understanding these mechanisms, we can optimize training programs, improve athletic performance, and enhance the overall health and well-being of individuals.
Table of contents
[edit | edit source]Here's the planned outline, which is unfinal:
- Introduction to Exercise Physiology
- 1.1 Fundamentals of Exercise Physiology
- 1.2 History and Milestones
- 1.3 Physiological Systems in Action
- Cardiovascular Physiology
- 2.1 Cardiovascular Adaptations to Exercise
- 2.2 Heart Function and Exercise
- 2.3 Blood Pressure Regulation
- 2.4 Oxygen Transport and Utilization
- Muscle Physiology
- 3.1 Skeletal Muscle Structure and Function
- 3.2 Muscle Contraction and Energy Metabolism
- 3.3 Muscular Adaptations to Training
- Respiratory Physiology
- 4.1 The Respiratory System and Exercise
- 4.2 Ventilation and Gas Exchange
- 4.3 Oxygen Transport in the Blood
- Nutrition and Exercise
- 5.1 Macronutrients and Micronutrients
- 5.2 Dietary Strategies for Performance
- 5.3 Hydration and Exercise
- Training Principles and Program Design
- 6.1 Pr",Health & Medicine 
"Java Programming
This book is an introduction to programming in Oracle’s Java™ programming language, a widely used programming language and software platform. This book serves as a comprehensive guide, complete with a series of tutorials to help users better understand the many ways one can program in Java. In its entirety, this book is meant to be both an introductory guide and a useful reference on Java and related technologies. As is the nature of this book, the content within the book is continuously being updated and revised. With every chapter within this book, the complexity of the context increases, building up on lessons learnt in the previous chapters. Beginners should therefore start from the beginning and proceed in a sequence throughout the material of the book.
If you are not familiar with object-oriented programming, you should first read the book Object Oriented Programming. Other special purpose books such as Jakarta EE enterprise programming, Java Persistence, or Java Swing programming, with more details, would complement this book nicely.
Contents
- About this book
- History of Java
- Overview of the Java programming language
- The Java platform (JRE & JDK)
- Installing Java on Your Computer
- Compiling programs
- Running Java programs
- Understanding a Java program
- Java IDEs
- Statements
- Conditional blocks
- Loop blocks
- Boolean expressions
- Variables
- Primitive Types
- Arithmetic expressions
- Literals
- Methods
- String
- Objects
- Packages
- Arra",Technology & Computing 
"Art Deco
Art Deco, short for the French Arts décoratifs (lit. 'Decorative Arts'),[1] is a style of visual arts, architecture, and product design that first appeared in Paris in the 1910s just before World War I[2] and flourished in the United States, Mexico[3] and Europe during the 1920s to early 1930s, through styling and design of the exterior and interior of anything from large structures to small objects, including clothing, fashion, and jewelry. Art Deco has influenced buildings from skyscrapers to cinemas, bridges, ocean liners, trains, cars, trucks, buses, furniture, and everyday objects, including radios and vacuum cleaners.[4]
The name Art Deco came into use after the 1925 Exposition internationale des arts décoratifs et industriels modernes (International Exhibition of Modern Decorative and Industrial Arts) held in Paris.[5] It has its origin in the bold geometric forms of the Vienna Secession and Cubism. From the outset, Art Deco was influenced by the bright colors of Fauvism and the Ballets Russes, and the exoticized styles of art from China, Japan, India, Persia, ancient Egypt, and Maya. In its time, Art Deco was tagged with other names such as style moderne, Moderne, modernistic, or style contemporain, and it was not recognized as a distinct and homogeneous style.[6]
During its heyday, Art Deco represented luxury, glamour, exuberance, and faith in social and technological progress. The movement featured rare and expensive materials such as ebony and ivory, and e",art_culture
"Audio signal processing
Audio signal processing is a subfield of signal processing that is concerned with the electronic manipulation of audio signals. Audio signals are electronic representations of sound waves—longitudinal waves which travel through air, consisting of compressions and rarefactions. The energy contained in audio signals or sound power level is typically measured in decibels. As audio signals may be represented in either digital or analog format, processing may occur in either domain. Analog processors operate directly on the electrical signal, while digital processors operate mathematically on its digital representation.
History
[edit]The motivation for audio signal processing began at the beginning of the 20th century with inventions like the telephone, phonograph, and radio that allowed for the transmission and storage of audio signals. Audio processing was necessary for early radio broadcasting, as there were many problems with studio-to-transmitter links.[1] The theory of signal processing and its application to audio was largely developed at Bell Labs in the mid 20th century. Claude Shannon and Harry Nyquist's early work on communication theory, sampling theory and pulse-code modulation (PCM) laid the foundations for the field. In 1957, Max Mathews became the first person to synthesize audio from a computer, giving birth to computer music.
Major developments in digital audio coding and audio data compression include differential pulse-code modulation (D",Technology & Computing 
"Bank
A bank is a financial institution that accepts deposits from the public and creates a demand deposit while simultaneously making loans.[1] Lending activities can be directly performed by the bank or indirectly through capital markets.[2]
As banks play an important role in financial stability and the economy of a country, most jurisdictions exercise a high degree of regulation over banks. Most countries have institutionalized a system known as fractional-reserve banking, under which banks hold liquid assets equal to only a portion of their current liabilities.[3] In addition to other regulations intended to ensure liquidity, banks are generally subject to minimum capital requirements based on an international set of capital standards, the Basel Accords.[4]
Banking in its modern sense evolved in the fourteenth century in the prosperous cities of Renaissance Italy but, in many ways, functioned as a continuation of ideas and concepts of credit and lending that had their roots in the ancient world. In the history of banking, a number of banking dynasties – notably, the Medicis, the Pazzi, the Fuggers, the Welsers, the Berenbergs, and the Rothschilds – have played a central role over many centuries. The oldest existing retail bank is Banca Monte dei Paschi di Siena (founded in 1472), while the oldest existing merchant bank is Berenberg Bank (founded in 1590).
History
[edit]Banking as an archaic activity (or quasi-banking[5][6]) is thought to have begun as early as the end of t",economics_finance
"Botany
Botany, also called plant science, is the branch of natural science and biology studying plants, especially their anatomy, taxonomy, and ecology.[1] A botanist or plant scientist is a scientist who specialises in this field. ""Plant"" and ""botany"" may be defined more narrowly to include only land plants and their study, which is also known as phytology. Phytologists or botanists (in the strict sense) study approximately 410,000 species of land plants, including some 391,000 species of vascular plants (of which approximately 369,000 are flowering plants)[2] and approximately 20,000 bryophytes.[3]
Botany originated as prehistoric herbalism to identify and later cultivate plants that were edible, poisonous, and medicinal, making it one of the first endeavours of human investigation.[citation needed] Medieval physic gardens, often attached to monasteries, contained plants possibly having medicinal benefit. They were forerunners of the first botanical gardens attached to universities, founded from the 1540s onwards. One of the earliest was the Padua botanical garden. These gardens facilitated the academic study of plants. Efforts to catalogue and describe their collections were the beginnings of plant taxonomy and led in 1753 to the binomial system of nomenclature of Carl Linnaeus that remains in use to this day for the naming of all biological species.
In the 19th and 20th centuries, new techniques were developed for the study of plants, including methods of optical microsco",Science & Research 
"Budget
A budget is a calculation plan, usually but not always financial, for a defined period, often one year or a month. A budget may include anticipated sales volumes and revenues, resource quantities including time, costs and expenses, environmental impacts such as greenhouse gas emissions, other impacts, assets, liabilities and cash flows. Companies, governments, families, and other organizations use budgets to express strategic plans of activities in measurable terms.[1]
Preparing a budget allows companies, authorities, private entities or families to establish priorities and evaluate the achievement of their objectives. To achieve these goals it may be necessary to incur a deficit (expenses exceed income) or, on the contrary, it may be possible to save, in which case the budget will present a surplus (income exceed expenses).
In the field of commerce, a budget is also a financial document or report that details the cost that a service will have if performed. Whoever makes the budget must adhere to it and cannot change it if the client accepts the service.
A budget expresses intended expenditures along with proposals for how to meet them with resources. A budget may express a surplus, providing resources for use at a future time, or a deficit[disambiguation needed] in which expenditures exceed income or other resources.
Government
[edit]The budget of a government is a summary or plan of the anticipated resources (often but not always from taxes) and expenditures of that ",economics_finance
"Category:American psychological thriller films
Appearance
Subcategories
This category has the following 2 subcategories, out of 2 total.
E
- The Exorcist films (6 P)
S
- Saw (franchise) films (11 P)
Pages in category ""American psychological thriller films""
The following 200 pages are in this category, out of approximately 645 total. This list may not reflect recent changes.
(previous page) (next page)0–9
A
- Abandon (film)
- Abandoned (2010 film)
- Acrimony (film)
- The Afflicted (film)
- After.Life
- Airtight (film)
- Alice, Darling
- Alice, Sweet Alice
- All I See Is You (film)
- Alone with Her
- The Altruist
- Always Shine
- American Crime (film)
- American Psycho (film)
- The Amusement Park
- Amy Makes Three
- Anamorph (film)
- Apartment 7A
- Apt Pupil (film)
- Arrival (film)
- As Good as Dead (1995 film)
- Asylum Blackout
- Awake (2007 film)
B
- Baby Ruby
- Bad Company (1995 film)
- Bad Day on the Block
- The Bad Seed (1956 film)
- The Ballad of a Small Player (film)
- Barricade (2012 film)
- Basic Instinct
- Basic Instinct 2
- Before I Go to Sleep (film)
- The Belko Experiment
- Beyond (2012 film)
- Beyond the Reach
- The Binding (2016 film)
- Black Bear (film)
- Black Cadillac (film)
- Black Friday (1940 film)
- Black Mold (film)
- Black Swan (film)
- The Blackcoat's Daughter
- Blind Horizon
- Blink (1993 film)
- Blink Twice
- Blood Star
- Blue Desert (film)
- Blue Velvet (film)
- Body Double
- Body of Evidence (1993 film)
- Boot Camp (film)
- The Box (2009 film)
- Bra",art_culture
"Category:Corporate law
Appearance
Corporate law is a branch of law that examines the nature, creation and operation of legally incorporated businesses. For an overview, see the corporate law article.
Wikimedia Commons has media related to Corporate law.
Subcategories
This category has the following 9 subcategories, out of 9 total.
Pages in category ""Corporate law""
The following 129 pages are in this category, out of 129 total. This list may not reflect recent changes.
A
- Alternate director
- Alternative Investment Fund Managers Directive 2011
- Anti-corporate activism
- Antigua and Barbuda Financial Services Regulatory Commission
- Apparent authority
- Appraisal rights
- Articles of association
- Articles of incorporation
- Articles of organization
- Asset lock
- Associate company
- Audit committee
- Authorised capital
C
- Canada Cooperatives Act
- Capital impairment
- Certificate of incorporation
- Claim in bankruptcy
- Common stock dividend
- Companies Act 1993
- Companies and Allied Matters Act, 2020
- Companies Office
- Companies Ordinance 1984
- Company and Securities Law Journal
- Company Law of the People's Republic of China
- Company register
- List of official business registers
- Company registration in Ghana
- Comply or explain
- Constitution (corporate)
- Constitutional documents
- Corporate dissolution
- Corporate governance
- Proxy firm
- Corporate haven
- Corporate Insolvency and Governance Act 2020
- Corporate opportunity
- Corporate structure
- Corporation
-",economics_finance
"Cell (biology)
The cell is the basic structural and functional unit of all forms of life. Every cell consists of cytoplasm enclosed within a membrane; many cells contain organelles, each with a specific function. The term comes from the Latin word cellula meaning 'small room'. Most cells are only visible under a microscope. Cells emerged on Earth about 4 billion years ago. All cells are capable of replication, protein synthesis, and motility.
Cells are broadly categorized into two types: eukaryotic cells, which possess a nucleus, and prokaryotic cells, which lack a nucleus but have a nucleoid region. Prokaryotes are single-celled organisms such as bacteria, whereas eukaryotes can be either single-celled, such as amoebae, or multicellular, such as some algae, plants, animals, and fungi. Eukaryotic cells contain organelles including mitochondria, which provide energy for cell functions, chloroplasts, which in plants create sugars by photosynthesis, and ribosomes, which synthesise proteins.
Cells were discovered by Robert Hooke in 1665, who named them after their resemblance to cells inhabited by Christian monks in a monastery. Cell theory, developed in 1839 by Matthias Jakob Schleiden and Theodor Schwann, states that all organisms are composed of one or more cells, that cells are the fundamental unit of structure and function in all living organisms, and that all cells come from pre-existing cells.
Cell types
Cells are broadly categorized into two types: eukaryotic cells, which",Science & Research 
"Cellular evolutionary algorithm
A cellular evolutionary algorithm (cEA) is a kind of evolutionary algorithm (EA) in which individuals cannot mate arbitrarily, but every one interacts with its closer neighbors on which a basic EA is applied (selection, variation, replacement).
The cellular model simulates natural evolution from the point of view of the individual, which encodes a tentative optimization, learning, or search problem solution. The essential idea of this model is to provide the EA population with a special structure defined as a connected graph, in which each vertex is an individual who communicates with his nearest neighbors. Particularly, individuals are conceptually set in a toroidal mesh, and are only allowed to recombine with close individuals. This leads to a kind of locality known as ""isolation by distance"". The set of potential mates of an individual is called its ""neighborhood"". It is known that, in this kind of algorithm, similar individuals tend to cluster creating niches, and these groups operate as if they were separate sub-populations (islands). There is no clear borderline between adjacent groups, and close niches could be easily colonized by competitive niches and potentially merge solution contents during the process. Simultaneously, farther niches can be affected more slowly.
Introduction
[edit]A cellular evolutionary algorithm (cEA) usually evolves a structured bidimensional grid of individuals, although other topologies are also possible. In th",Technology & Computing 
"Clinical pharmacology
Clinical pharmacology is ""that discipline that teaches, does research, frames policy, gives information and advice about the actions and proper uses of medicines in humans and implements that knowledge in clinical practice"".[1][2] Clinical pharmacology is inherently a translational discipline underpinned by the basic science of pharmacology, engaged in the experimental and observational study of the disposition and effects of drugs in humans, and committed to the translation of science into evidence-based therapeutics.[3] It has a broad scope, from the discovery of new target molecules to the effects of drug usage in whole populations.[4] The main aim of clinical pharmacology is to generate data for optimum use of drugs and the practice of 'evidence-based medicine'.
Clinical pharmacologists have medical and scientific training that enables them to evaluate evidence and produce new data through well-designed studies. Clinical pharmacologists must have access to enough patients for clinical care, teaching and education, and research. Their responsibilities to patients include, but are not limited to, detecting and analysing adverse drug effects and reactions, therapeutics, and toxicology including reproductive toxicology, perioperative drug management, and psychopharmacology.
Modern clinical pharmacologists are also trained in data analysis skills. Their approaches to analyse data can include modelling and simulation techniques (e.g. population analysis, n",Health & Medicine 
"Cobot
A cobot, or collaborative robot, also known as a companion robot, is a robot intended for direct human-robot interaction within a shared space, or where humans and robots are in close proximity. Cobot applications contrast with traditional industrial robot applications in which robots are isolated from human contact or the humans are protected by robotic tech vests.[1][2] Cobot safety may rely on lightweight construction materials, rounded edges, and inherent limitation of speed and force, or on sensors and software that ensure safe behavior.[3][4]
Uses
[edit]The International Federation of Robotics (IFR),[5] a global industry association of robot manufacturers and national robot associations, recognizes two main groups of robots: industrial robots used in automation and service robots for domestic and professional use. Service robots could be considered to be cobots as they are intended to work alongside humans. Industrial robots have traditionally worked separately from humans behind fences or other protective barriers, but cobots remove that separation.
As COBOTS operates safely and efficiently in a shared environment with humans, their versatility allows them to support a wide range of tasks in different settings, and their applications have also expanded rapidly in both public and industrial fields.[6] Cobots can have many uses, from information robots in public spaces (an example of service robots),[7] logistics robots that transport materials within a building,[8",Technology & Computing 
"Computer cluster
A computer cluster is a set of computers that work together so that they can be viewed as a single system. Unlike grid computers, computer clusters have each node set to perform the same task, controlled and scheduled by software. The newest manifestation of cluster computing is cloud computing.
The components of a cluster are usually connected to each other through fast local area networks, with each node (computer used as a server) running its own instance of an operating system. In most circumstances, all of the nodes use the same hardware[1][better source needed] and the same operating system, although in some setups (e.g. using Open Source Cluster Application Resources (OSCAR)), different operating systems can be used on each computer, or different hardware.[2]
Clusters are usually deployed to improve performance and availability over that of a single computer, while typically being much more cost-effective than single computers of comparable speed or availability.[3]
Computer clusters emerged as a result of the convergence of a number of computing trends including the availability of low-cost microprocessors, high-speed networks, and software for high-performance distributed computing.[citation needed] They have a wide range of applicability and deployment, ranging from small business clusters with a handful of nodes to some of the fastest supercomputers in the world such as IBM's Sequoia.[4] Prior to the advent of clusters, single-unit fault tolerant m",Technology & Computing 
"Computer forensics
Computer forensics (also known as computer forensic science)[1] is a branch of digital forensic science pertaining to evidence found in computers and digital storage media. The goal of computer forensics is to examine digital media in a forensically sound manner with the aim of identifying, preserving, recovering, analyzing, and presenting facts and opinions about the digital information.
Although it is most often associated with the investigation of a wide variety of computer crime, computer forensics may also be used in civil proceedings. The discipline involves similar techniques and principles to data recovery, but with additional guidelines and practices designed to create a legal audit trail.
Evidence from computer forensics investigations is usually subjected to the same guidelines and practices as other digital evidence. It has been used in a number of high-profile cases and is accepted as reliable within U.S. and European court systems.
Overview
[edit]In the early 1980s, personal computers became more accessible to consumers, leading to their increased use in criminal activity (for example, to help commit fraud). At the same time, several new ""computer crimes"" were recognized (such as cracking). The discipline of computer forensics emerged during this time as a method to recover and investigate digital evidence for use in court. Since then, computer crime and computer-related crime has grown, with the FBI reporting a suspected 791,790 internet crim",Technology & Computing 
"Computer stereo vision
Computer stereo vision is the extraction of 3D information from digital images, such as those obtained by a CCD camera. By comparing information about a scene from two vantage points, 3D information can be extracted by examining the relative positions of objects in the two panels. This is similar to the biological process of stereopsis.
Outline
[edit]In traditional stereo vision, two cameras, displaced horizontally from one another, are used to obtain two differing views on a scene, in a manner similar to human binocular vision. By comparing these two images, the relative depth information can be obtained in the form of a disparity map, which encodes the difference in horizontal coordinates of corresponding image points. The values in this disparity map are inversely proportional to the scene depth at the corresponding pixel location.
For a human to compare the two images, they must be superimposed in a stereoscopic device, with the image from the right camera being shown to the observer's right eye and from the left one to the left eye.
In a computer vision system, several pre-processing steps are required.[1]
- The image must first be undistorted, such that barrel distortion and tangential distortion are removed. This ensures that the observed image matches the projection of an ideal pinhole camera.
- The image must be projected back to a common plane to allow comparison of the image pairs, known as image rectification.
- An information measure which ",Technology & Computing 
"Concert band
A concert band, also called a wind band, wind ensemble, wind symphony, wind orchestra, symphonic band, the symphonic winds, or symphonic wind ensemble,[1] is a performing ensemble consisting of members of the woodwind, brass, and percussion families of instruments,[2] and occasionally including the piano, double bass, and harp. On rare occasions, additional, non-traditional instruments may be added to such ensembles such as synthesizer, electric guitar, and bass guitar.[3]
Concert band music generally includes original wind compositions, concert marches, transcriptions of orchestral arrangements, light music, and popular music. Though the concert band does have similar instrumentation to the marching band, a marching band's main purpose is to perform while marching. In contrast, a concert band usually performs as a stationary ensemble[citation needed], though European ensembles often do both.
Origins
[edit]The origins of concert band can be traced back to the French Revolution, in which large bands would often gather for patriotic festivals and celebrations. These bands would play popular music that would immediately captivate the public's attention. Throughout the French Revolution, however, serious composers were often not interested in composing music for bands; this was due in large part to the instrumentation. Concert bands were (and still are) not standardized in their required type and number of instruments, making it nearly impossible to write the correct",art_culture
"Cross-site request forgery
Cross-site request forgery, also known as one-click attack or session riding and abbreviated as CSRF (sometimes pronounced sea-surf[1]) or XSRF, is a type of malicious exploit of a website or web application where unauthorized commands are submitted from a user that the web application trusts.[2] There are many ways in which a malicious website can transmit such commands; specially-crafted image tags, hidden forms, and JavaScript fetch or XMLHttpRequests, for example, can all work without the user's interaction or even knowledge. Unlike cross-site scripting (XSS), which exploits the trust a user has for a particular site, CSRF exploits the trust that a site has in a user's browser.[3] In a CSRF attack, an innocent end user is tricked by an attacker into submitting a web request that they did not intend. This may cause actions to be performed on the website that can include inadvertent client or server data leakage, change of session state, or manipulation of an end user's account.
The term ""CSRF"" is also used as an abbreviation in defences against CSRF attacks, such as techniques that use header data, form data, or cookies, to test for and prevent such attacks.
Characteristics
[edit]In a CSRF attack, the attacker's goal is to cause an innocent victim to unknowingly submit a maliciously crafted web request to a website that the victim has privileged access to. This web request can be crafted to include URL parameters, cookies and other data that appe",Technology & Computing 
"Discrete wavelet transform
In numerical analysis and functional analysis, a discrete wavelet transform (DWT) is any wavelet transform for which the wavelets are discretely sampled. As with other wavelet transforms, a key advantage it has over Fourier transforms is temporal resolution: it captures both frequency and location information (location in time).
Definition
[edit]One level of the transform
[edit]The DWT of a signal is calculated by passing it through a series of filters. First the samples are passed through a low-pass filter with impulse response resulting in a convolution of the two:
The signal is also decomposed simultaneously using a high-pass filter . The outputs give the detail coefficients (from the high-pass filter) and approximation coefficients (from the low-pass). It is important that the two filters are related to each other and they are known as a quadrature mirror filter.
However, since half the frequencies of the signal have now been removed, half the samples can be discarded according to Nyquist's rule. The filter output of the low-pass filter in the diagram above is then subsampled by 2 and further processed by passing it again through a new low-pass filter and a high- pass filter with half the cut-off frequency of the previous one, i.e.:
This decomposition has halved the time resolution since only half of each filter output characterises the signal. However, each output has half the frequency band of the input, so the frequency resolution has been do",Technology & Computing 
"Document-oriented database
A document-oriented database, or document store, is a computer program and data storage system designed for storing, retrieving and managing document-oriented information, also known as semi-structured data.[1]
Document-oriented databases are one of the main categories of NoSQL databases, and the popularity of the term ""document-oriented database"" has grown[2] with the use of the term NoSQL itself. XML databases are a subclass of document-oriented databases that are optimized to work with XML documents. Graph databases are similar, but add another layer, the relationship, which allows them to link documents for rapid traversal.
Document-oriented databases are inherently a subclass of the key-value store, another NoSQL database concept. The difference[contradictory] lies in the way the data is processed; in a key-value store, the data is considered to be inherently opaque to the database, whereas a document-oriented system relies on internal structure in the document in order to extract metadata that the database engine uses for further optimization. Although the difference is often negligible due to tools in the systems,[a] conceptually the document-store is designed to offer a richer experience with modern programming techniques.
Document databases[b] contrast strongly with the traditional relational database (RDB). Relational databases generally store data in separate tables that are defined by the programmer, and a single object may be spread acr",Technology & Computing 
"E-learning (theory)
E-learning theory describes the cognitive science principles of effective multimedia learning using electronic educational technology.
Applications of Multimedia Principles in Digital Learning
[edit]In recent applications, digital learning platforms have leveraged multimedia instructional design principles to facilitate effective online learning. A prime example includes e-learning platforms that offer users a balanced combination of visual and textual content, segmenting information and enabling user-paced learning. This approach is particularly advantageous in virtual learning environments (VLEs), where well-designed multimedia tools can replicate or even enhance traditional classroom dynamics by incorporating interactive elements, such as quizzes and visual aids, to manage cognitive load and reinforce learning.[1] Further research continues to explore the optimal integration of these principles across diverse e-learning contexts to ensure accessibility and engagement for learners of all backgrounds and experience levels.[2]
Learning theories
[edit]Good pedagogical practice has a theory of learning at its core. However, no single best-practice e-learning standard has emerged. This may be unlikely given the range of learning and teaching styles, the potential ways technology can be implemented, and how educational technology itself is changing.[3] Various pedagogical approaches or learning theories may be considered in designing and interacting with e-lea",Technology & Computing 
"Electronic circuit simulation
Electronic circuit simulation uses mathematical models to replicate the behavior of an actual electronic device or circuit. Simulation software allows for the modeling of circuit operation and is an invaluable analysis tool. Due to its highly accurate modeling capability, many colleges and universities use this type of software for the teaching of electronics technician and electronics engineering programs. Electronics simulation software engages its users by integrating them into the learning experience. These kinds of interactions actively engage learners to analyze, synthesize, organize, and evaluate content and result in learners constructing their own knowledge.[1]
Simulating a circuit’s behavior before actually building it can greatly improve design efficiency by making faulty designs known as such, and providing insight into the behavior of electronic circuit designs. In particular, for integrated circuits, the tooling (photomasks) is expensive, breadboards are impractical, and probing the behavior of internal signals is extremely difficult. Therefore, almost all IC design relies heavily on simulation. The most well known analog simulator is SPICE. Probably the best known digital simulators are those based on Verilog and VHDL.
Some electronics simulators integrate a schematic editor, a simulation engine, and an on-screen waveform display (see Figure 1), allowing designers to rapidly modify a simulated circuit and see what effect the change",Technology & Computing 
"Evolutionary computation
Evolutionary computation from computer science is a family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing studying these algorithms. In technical terms, they are a family of population-based trial and error problem solvers with a metaheuristic or stochastic optimization character.
In evolutionary computation, an initial set of candidate solutions is generated and iteratively updated. Each new generation is produced by stochastically removing less desired solutions, and introducing small random changes as well as, depending on the method, mixing parental information. In biological terminology, a population of solutions is subjected to natural selection (or artificial selection), mutation and possibly recombination. As a result, the population will gradually evolve to increase in fitness, in this case the chosen fitness function of the algorithm.
Evolutionary computation techniques can produce highly optimized solutions in a wide range of problem settings, making them popular in computer science. Many variants and extensions exist, suited to more specific families of problems and data structures. Evolutionary computation is also sometimes used in evolutionary biology as an in silico experimental procedure to study common aspects of general evolutionary processes.
History
[edit]The concept of mimicking evolutionary processes to solve problems originates before the adv",Technology & Computing 
"Filter (signal processing)
In signal processing, a filter is a device or process that removes some unwanted components or features from a signal. Filtering is a class of signal processing, the defining feature of filters being the complete or partial suppression of some aspect of the signal. Most often, this means removing some frequencies or frequency bands. However, filters do not exclusively act in the frequency domain; especially in the field of image processing many other targets for filtering exist. Correlations can be removed for certain frequency components and not for others without having to act in the frequency domain. Filters are widely used in electronics and telecommunication, in radio, television, audio recording, radar, control systems, music synthesis, image processing, computer graphics, and structural dynamics.
There are many different bases of classifying filters and these overlap in many different ways; there is no simple hierarchical classification. Filters may be:
- non-linear or linear
- time-variant or time-invariant, also known as shift invariance. If the filter operates in a spatial domain then the characterization is space invariance.
- causal or non-causal: A filter is non-causal if its present output depends on future input. Filters processing time-domain signals in real time must be causal, but not filters acting on spatial domain signals or deferred-time processing of time-domain signals.
- analog or digital
- discrete-time (sampled) or continu",Technology & Computing 
"First-order logic
First-order logic, also called predicate logic, predicate calculus, or quantificational logic, is a collection of formal systems used in mathematics, philosophy, linguistics, and computer science. First-order logic uses quantified variables over non-logical objects, and allows the use of sentences that contain variables. Rather than propositions such as ""all humans are mortal"", in first-order logic one can have expressions in the form ""for all x, if x is a human, then x is mortal"", where ""for all x"" is a quantifier, x is a variable, and ""... is a human"" and ""... is mortal"" are predicates.[1] This distinguishes it from propositional logic, which does not use quantifiers or relations;[2]: 161 in this sense, propositional logic is the foundation of first-order logic.
A theory about a topic, such as set theory, a theory for groups,[3] or a formal theory of arithmetic, is usually a first-order logic together with a specified domain of discourse (over which the quantified variables range), finitely many functions from that domain to itself, finitely many predicates defined on that domain, and a set of axioms believed to hold about them. ""Theory"" is sometimes understood in a more formal sense as just a set of sentences in first-order logic.
The term ""first-order"" distinguishes first-order logic from higher-order logic, in which there are predicates having predicates or functions as arguments, or in which quantification over predicates, functions, or both, are permi",Philosophy & Religion 
"Fiscal policy of the United States
Fiscal policy is any changes the government makes to the national budget to influence a nation's economy.[1] ""An essential purpose of this Financial Report is to help American citizens understand the current fiscal policy and the importance and magnitude of policy reforms essential to make it sustainable. A sustainable fiscal policy is explained as the debt held by the public to Gross Domestic Product which is either stable or declining over the long term"" (Bureau of the fiscal service). The approach to economic policy in the United States was rather laissez-faire until the Great Depression. The government tried to stay away from economic matters as much as possible and hoped that a balanced budget would be maintained.[2] Prior to the Great Depression, the economy did have economic downturns and some were quite severe. However, the economy tended to self-correct so the laissez faire approach to the economy tended to work.
President Franklin D. Roosevelt first instituted fiscal policies in the United States in The New Deal. The first experiments did not prove to be very effective, but that was in part because the Great Depression had already lowered the expectations of business so drastically.[3]
History
[edit]The Great Depression
[edit]The Great Depression struck countries in the late 1920s and continued throughout the entire 1930's. It affected some countries more than others, and the effects in the US were detrimental. In 1933, 25 percent ",economics_finance
"Formal semantics (natural language)
Formal semantics is the scientific study of linguistic meaning through formal tools from logic and mathematics. It is an interdisciplinary field, sometimes regarded as a subfield of both linguistics and philosophy of language. Formal semanticists rely on diverse methods to analyze natural language. Many examine the meaning of a sentence by studying the circumstances in which it would be true. They describe these circumstances using abstract mathematical models to represent entities and their features. The principle of compositionality helps them link the meaning of expressions to abstract objects in these models. This principle asserts that the meaning of a compound expression is determined by the meanings of its parts.
Propositional and predicate logic are formal systems used to analyze the semantic structure of sentences. They introduce concepts like singular terms, predicates, quantifiers, and logical connectives to represent the logical form of natural language expressions. Type theory is another approach utilized to describe sentences as nested functions with precisely defined input and output types. Various theoretical frameworks build on these systems. Possible world semantics and situation semantics evaluate truth across different hypothetical scenarios. Dynamic semantics analyzes the meaning of a sentence as the information contribution it makes.
Using these and similar theoretical tools, formal semanticists investigate a wide rang",Philosophy & Religion 
"Garbage collection (computer science)
In computer science, garbage collection (GC) is a form of automatic memory management.[2] The garbage collector attempts to reclaim memory that was allocated by the program, but is no longer referenced; such memory is called garbage. Garbage collection was invented by American computer scientist John McCarthy around 1959 to simplify manual memory management in Lisp.[3]
Garbage collection relieves the programmer from doing manual memory management, where the programmer specifies what objects to de-allocate and return to the memory system and when to do so.[2] Other, similar techniques include stack allocation, region inference, and memory ownership, and combinations thereof. Garbage collection may take a significant proportion of a program's total processing time, and affect performance as a result.
Resources other than memory, such as network sockets, database handles, windows, file descriptors, and device descriptors, are not typically handled by garbage collection, but rather by other methods (e.g. destructors). Some such methods de-allocate memory also.
Overview
[edit]Many programming languages require garbage collection, either as part of the language specification (e.g., RPL, Java, C#, D,[4] Go, and most scripting languages) or effectively for practical implementation (e.g., formal languages like lambda calculus).[5] These are said to be garbage-collected languages. Other languages, such as C and C++, were designed for use with manua",Technology & Computing 
"Glossary of machine vision
Appearance
The following are common definitions related to the machine vision field.
General related fields
0-9
[edit]- 1394. FireWire is Apple Inc.'s brand name for the IEEE 1394 interface. It is also known as i.Link (Sony's name) or IEEE 1394 (although the 1394 standard also defines a backplane interface). It is a personal computer (and digital audio/digital video) serial bus interface standard, offering high-speed communications and isochronous real-time data services.
- 1D. One-dimensional.
- 2D computer graphics. The computer-based generation of digital images—mostly from two-dimensional models (such as 2D geometric models, text, and digital images) and by techniques specific to them.
- 3D computer graphics. 3D computer graphics are different from 2D computer graphics in that a three-dimensional representation of geometric data is stored in the computer for the purposes of performing calculations and rendering 2D images. Such images may be for later display or for real-time viewing. Despite these differences, 3D computer graphics rely on many of the same algorithms as 2D computer vector graphics in the wire frame model and 2D computer raster graphics in the final rendered display. In computer graphics software, the distinction between 2D and 3D is occasionally blurred; 2D applications may use 3D techniques to achieve effects such as lighting, and primarily 3D may use 2D rendering techniques.
- 3D scanner. This is a device that analyzes a real-w",Technology & Computing 
"Government budget
A government budget is a projection of the government's revenues and expenditure for a particular period, often referred to as a financial or fiscal year, which may or may not correspond with the calendar year. Government revenues mostly include taxes (e.g. inheritance tax, income tax, corporation tax, import taxes) while expenditures consist of government spending (e.g. healthcare, education, defense, infrastructure, social benefits). A government budget is prepared by the Central government or other political entity. In most parliamentary systems, the budget is presented to the legislature and often requires approval of the legislature. The government implements economic policy through this budget and realizes its program priorities. Once the budget is approved, the use of funds from individual chapters is in the hands of government ministries and other institutions. Revenues of the state budget consist mainly of taxes, customs duties, fees, and other revenues. State budget expenditures cover the activities of the state, which are either given by law or the constitution. The budget in itself does not appropriate funds for government programs, hence the need for additional legislative measures.[1]
History
[edit]Credible budgets, which are defined as statutory fixed term (generally one year) budgets auditable by parliament, were first introduced in the Netherlands in 1572, England in 1689, France in 1830, Denmark, Piedmont, and Prussia in 1848, Portugal in 1",economics_finance
"Graphics processing unit
A graphics processing unit (GPU) is a specialized electronic circuit designed for digital image processing and to accelerate computer graphics, being present either as a discrete video card or embedded on motherboards, mobile phones, personal computers, workstations, and game consoles. GPUs were later found to be useful for non-graphic calculations involving embarrassingly parallel problems due to their parallel structure. The ability of GPUs to rapidly perform vast numbers of calculations has led to their adoption in diverse fields including artificial intelligence (AI) where they excel at handling data-intensive and computationally demanding tasks. Other non-graphical uses include the training of neural networks and cryptocurrency mining.
History
[edit]1970s
[edit]Arcade system boards have used specialized graphics circuits since the 1970s. In early video game hardware, RAM for frame buffers was expensive, so video chips composited data together as the display was being scanned out on the monitor.[1]
A specialized barrel shifter circuit helped the CPU animate the framebuffer graphics for various 1970s arcade video games from Midway and Taito, such as Gun Fight (1975), Sea Wolf (1976), and Space Invaders (1978).[2] The Namco Galaxian arcade system in 1979 used specialized graphics hardware that supported RGB color, multi-colored sprites, and tilemap backgrounds.[3] The Galaxian hardware was widely used during the golden age of arcade video games, by ",Technology & Computing 
"Haptic technology
Haptic technology (also kinaesthetic communication or 3D touch)[1][2] is technology that can create an experience of touch by applying forces, vibrations, or motions to the user.[3] These technologies can be used to create virtual objects in a computer simulation, to control virtual objects, and to enhance remote control of machines and devices (telerobotics). Haptic devices may incorporate tactile sensors that measure forces exerted by the user on the interface. The word haptic, from the Ancient Greek: ἁπτικός (haptikos), means ""tactile, pertaining to the sense of touch"". Simple haptic devices are common in the form of game controllers, joysticks, and steering wheels.
Haptic technology facilitates investigation of how the human sense of touch works by allowing the creation of controlled haptic virtual objects. Vibrations and other tactile cues have also become an integral part of mobile user experience and interface design.[4] Most researchers distinguish three sensory systems related to sense of touch in humans: cutaneous, kinaesthetic and haptic.[5][6][7] All perceptions mediated by cutaneous and kinaesthetic sensibility are referred to as tactual perception. The sense of touch may be classified as passive and active,[8] and the term ""haptic"" is often associated with active touch to communicate or recognize objects.[9]
History
[edit]One of the earliest applications of haptic technology was in large aircraft that use servomechanism systems to operate contr",Technology & Computing 
"Hierarchical navigable small world
The Hierarchical navigable small world (HNSW) algorithm is a graph-based approximate nearest neighbor search technique used in many vector databases.[1] Nearest neighbor search without an index involves computing the distance from the query to each point in the database, which for large datasets is computationally prohibitive. For high-dimensional data, tree-based exact vector search techniques such as the k-d tree and R-tree do not perform well enough because of the curse of dimensionality. To remedy this, approximate k-nearest neighbor searches have been proposed, such as locality-sensitive hashing (LSH) and product quantization (PQ) that trade performance for accuracy.[1] The HNSW graph offers an approximate k-nearest neighbor search which scales logarithmically even in high-dimensional data.
It is an extension of the earlier work on navigable small world graphs presented at the Similarity Search and Applications (SISAP) conference in 2012 with an additional hierarchical navigation to find entry points to the main graph faster.[2] HNSW-based libraries are among the best performers in the approximate nearest neighbors benchmark.[3][4]
A related technique is IVFFlat.[5]
Use in vector databases
[edit]HNSW is a key method for approximate nearest neighbor search in high-dimensional vector databases, for example in the context of embeddings from neural networks in large language models. Databases that use HNSW as search index include:
- Apache ",Technology & Computing 
"Hindi cinema
Hindi cinema, popularly known as Bollywood and formerly as Bombay cinema,[1] is primarily produced in Mumbai. The popular term Bollywood is a portmanteau of ""Bombay"" (former name of Mumbai) and ""Hollywood"". The industry, producing films in the Hindi language, is a part of the larger Indian cinema industry, which also includes South Indian cinema and other smaller film industries.[2][3][4] The term 'Bollywood', often mistakenly used to refer to Indian cinema as a whole, only refers to Hindi-language films, with Indian cinema being an umbrella term that includes all the film industries in the country, each offering films in diverse languages and styles.
In 2017, Indian cinema produced 1,986 feature films, of which the largest number, 364, have been in Hindi.[2] In 2022, Hindi cinema represented 33% of box office revenue, followed by Telugu and Tamil representing 20% and 16% respectively.[5] Mumbai is one of the largest centres for film production in the world.[6][7][8] Hindi films sold an estimated 341 million tickets in India in 2019.[9][10] Earlier Hindi films tended to use vernacular Hindustani, mutually intelligible by speakers of either Hindi or Urdu, while modern Hindi productions increasingly incorporate elements of Hinglish.[11]
The most popular commercial genre in Hindi cinema since the 1970s has been the masala film, which freely mixes different genres including action, comedy, romance, drama and melodrama along with musical numbers.[12][13] Masala films ",art_culture
"Hindi film music
Hindi film songs, more formally known as Hindi Geet or Filmi songs and informally known as Bollywood music, are songs featured in Hindi films. Derived from the song-and-dance routines common in Indian films, Bollywood songs, along with dance, are a characteristic motif of Hindi cinema which gives it enduring popular appeal, cultural value and context.[1] Hindi film songs form a predominant component of Indian pop music, and derive their inspiration from both classical and modern sources.[1] Hindi film songs are now firmly embedded in North India's popular culture and routinely encountered in North India in marketplaces, shops, during bus and train journeys and numerous other situations.[2] Though Hindi films routinely contain many songs and some dance routines, they are not musicals in the Western theatrical sense; the music-song-dance aspect is an integral feature of the genre akin to plot, dialogue and other parameters.[1]: 2
The first song recorded in India by Gauhar Jaan in 1902 and the first Bollywood film Alam Ara (1931) were under Saregama, India's oldest music label currently owned by RP-Sanjiv Goenka Group.[3] Linguistically, Bollywood songs tend to use vernacular Hindustani, mutually intelligible to self-identified speakers of both Hindi and Urdu, while modern Bollywood songs also increasingly incorporate elements of Hinglish.[4] Urdu poetry has had a particularly strong impact on Bollywood songs, where the lyrics draw heavily from Urdu poetry and t",art_culture
"HTML5
HTML5 (Hypertext Markup Language 5) is a markup language used for structuring and presenting hypertext documents on the World Wide Web. It was the fifth and final[4] major HTML version that is now a retired World Wide Web Consortium (W3C) recommendation. The current specification is known as the HTML Living Standard. It is maintained by the Web Hypertext Application Technology Working Group (WHATWG), a consortium of the major browser vendors (Apple, Google, Mozilla, and Microsoft).
HTML5 was first released in a public-facing form on 22 January 2008,[2] with a major update and ""W3C Recommendation"" status in October 2014.[5][6] Its goals were to improve the language with support for the latest multimedia and other new features; to keep the language both easily readable by humans and consistently understood by computers and devices such as web browsers, parsers, etc., without XHTML's rigidity; and to remain backward-compatible with older software. HTML5 is intended to subsume not only HTML 4 but also XHTML1 and even the DOM Level 2 HTML itself.[7]
HTML5 includes detailed processing models to encourage more interoperable implementations; it extends, improves, and rationalizes the markup available for documents and introduces markup and application programming interfaces (APIs) for complex web applications.[8] For the same reasons, HTML5 is also a candidate for cross-platform mobile applications because it includes features designed with low-powered devices in mind.
Many new",Technology & Computing 
"International Finance Corporation
The International Finance Corporation (IFC) is an international financial institution headquartered in Washington, D.C. and a member of the World Bank Group that offers investment, advisory, and asset-management services to encourage private-sector development in less developed countries.
It was established in 1956, as the private-sector arm of the World Bank Group, to advance economic development by investing in for-profit and commercial projects for poverty reduction and promoting development.[2][3][4] The IFC's stated aim is to create opportunities for people to escape poverty and achieve better living standards by mobilizing financial resources for private enterprise.
It offers an array of debt and equity financing services, helps companies face their risk exposures while refraining from participating in a management capacity and advices to companies on making decisions, evaluating their impact on the environment and society, and being responsible.
The corporation is assessed by an independent evaluator each year. The IFC is in good financial standing and received the highest ratings from two independent credit rating agencies in 2018.[5]
History
[edit]The World Bank and International Monetary Fund were designed by delegates at the Bretton Woods conference in 1944. The World Bank, then consisting of only the International Bank for Reconstruction and Development, became operational in 1946. Robert L. Garner joined the World Bank in 1947 as",economics_finance
"Investment strategy
In finance, an investment strategy is a set of rules, behaviors or procedures, designed to guide an investor's selection of an investment portfolio. Individuals have different profit objectives, and their individual skills make different tactics and strategies appropriate.[1] Some choices involve a tradeoff between risk and return. Most investors fall somewhere in between, accepting some risk for the expectation of higher returns.
In the field of economics, this decision is driven by finding the investment strategy that has the highest utility. Investors frequently pick investments to hedge themselves against inflation.[2] During periods of high inflation investments such as shares tend to perform less well in real terms.
The time horizon of investments also influences the strategy to be followed. Investments such as shares should be invested into with the time frame of a minimum of 5 years in mind. It is recommended in finance a minimum of 6 months to 12 months expenses in a rainy-day current account, giving instant access before investing in riskier investments than an instant access account. It is also recommended no more than 90% of your money in non-instant access shares. Unexpected expenses can happen. If someone does not have an income an income can be created by using share income funds.
Strategies
[edit]- No strategy: Investors who do not have a strategy have been called ""Sheep"".[3] Arbitrary choices modeled on throwing darts at a page (referencin",economics_finance
"Java (programming language)
Java is a high-level, general-purpose, memory-safe, object-oriented programming language. It is intended to let programmers write once, run anywhere (WORA),[18] meaning that compiled Java code can run on all platforms that support Java without the need to recompile.[19] Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of the underlying computer architecture. The syntax of Java is similar to C and C++, but has fewer low-level facilities than either of them. The Java runtime provides dynamic capabilities (such as reflection and runtime code modification) that are typically not available in traditional compiled languages.
Java gained popularity shortly after its release, and has been a popular programming language since then.[20] Java was the third most popular programming language in 2022[update] according to GitHub.[21] Although still widely popular, there has been a gradual decline in use of Java in recent years with other languages using JVM gaining popularity.[22]
Java was designed by James Gosling at Sun Microsystems. It was released in May 1995 as a core component of Sun's Java platform. The original and reference implementation Java compilers, virtual machines, and class libraries were released by Sun under proprietary licenses. As of May 2007, in compliance with the specifications of the Java Community Process, Sun had relicensed most of its Java technologies under the GPL-2.0-only",Technology & Computing 
"List of TCP and UDP port numbers
This is a list of TCP and UDP port numbers used by protocols for operation of network applications. The Transmission Control Protocol (TCP) and the User Datagram Protocol (UDP) only need one port for bidirectional traffic. TCP usually uses port numbers that match the services of the corresponding UDP implementations, if they exist, and vice versa.
The Internet Assigned Numbers Authority (IANA) is responsible for maintaining the official assignments of port numbers for specific uses,[1] However, many unofficial uses of both well-known and registered port numbers occur in practice. Similarly, many of the official assignments refer to protocols that were never or are no longer in common use. This article lists port numbers and their associated protocols that have experienced significant uptake.
Table legend
[edit]Well-known ports
[edit]The port numbers in the range from 0 to 1023 (0 to 210 − 1) are the well-known ports or system ports.[3] They are used by system processes that provide widely used types of network services. On Unix-like operating systems, a process must execute with superuser privileges to be able to bind a network socket to an IP address using one of the well-known ports.[5]
Registered ports
[edit]The range of port numbers from 1024 to 49151 (210 to 215 + 214 − 1) are the registered ports. They are assigned by IANA for specific service upon application by a requesting entity.[2] On most systems, registered ports can be used witho",Technology & Computing 
"Literary modernism
Modernist literature originated in the late 19th and early 20th centuries, and is characterised by a self-conscious separation from traditional ways of writing in both poetry and prose fiction writing. Modernism experimented with literary form and expression, as exemplified by Ezra Pound's maxim to ""Make it new"".[1] This literary movement was driven by a conscious desire to overturn traditional modes of representation and express the new sensibilities of the time.[2] The immense human costs of the First World War saw the prevailing assumptions about society reassessed,[3] and much modernist writing engages with the technological advances and societal changes of modernity moving into the 20th century. In Modernist Literature, Mary Ann Gillies notes that these literary themes share the ""centrality of a conscious break with the past"", one that ""emerges as a complex response across continents and disciplines to a changing world"".[4]
Modernism, Romanticism, Philosophy and Symbol
[edit]Literary modernism is often summed up in a line from W. B. Yeats: ""Things fall apart; the centre cannot hold"" (in 'The Second Coming').[5] Modernists often search for a metaphysical 'centre' but experience its collapse.[6] (Postmodernism, by way of contrast, celebrates that collapse, exposing the failure of metaphysics, such as Jacques Derrida's deconstruction of metaphysical claims.)[6]
Philosophically, the collapse of metaphysics can be traced back to the Scottish philosopher Dav",art_culture
"London Symphony Orchestra
The London Symphony Orchestra (or LSO) is a symphony orchestra based in London. Founded in 1904, it is London's oldest symphony orchestra. It was formed by a group of players who left The Queen's Hall Orchestra in order to form a new group based on co-operative principles.
Since 1982, the LSO has been based at the Barbican Centre. Among its programmes there have been large-scale festivals celebrating composers such as Berlioz, Mahler and Bernstein. The LSO claims to be the world's most recorded orchestra and has made gramophone recordings since 1912. It has played on more than 200 soundtrack recordings, including the Star Wars series.
Opening under the baton of the legendary Wagner conductor Hans Richter, the London Symphony Orchestra went on to perform with the likes of Arthur Nikisch, Sir Edward Elgar, Fritz Steinbach, Charles Villiers Stanford Sir Thomas Beecham and Edouard Colonne. Following a decline in standards, the orchestra underwent periods of eclipse in the 1930s and 1950. The profit-sharing principle was abandoned in the post-war era as a condition of receiving public subsidy for the first time. Many senior players. By the 1960s however, the LSO had recovered its leading position, playing under Pierre Monteux, André Previn, Claudio Abbado, Sir Colin Davis, and Valery Gergiev among others.
History
[edit]Introduction
[edit]At the turn of the twentieth century London did not have permanent salaried orchestras. The main music venues: Covent G",art_culture
"Medical research
Medical research (or biomedical research), also known as health research, refers to the process of using scientific methods with the aim to produce knowledge about human diseases, the prevention and treatment of illness, and the promotion of health.[1]
Medical research encompasses a wide array of research, extending from ""basic research"" (also called bench science or bench research),[2] – involving fundamental scientific principles that may apply to a preclinical understanding – to clinical research, which involves studies of people who may be subjects in clinical trials. Within this spectrum is applied research, or translational research, conducted to expand knowledge in the field of medicine.
Both clinical and preclinical research phases exist in the pharmaceutical industry's drug development pipelines, where the clinical phase is denoted by the term clinical trial. However, only part of the clinical or preclinical research is oriented towards a specific pharmaceutical purpose. The need for fundamental and mechanism-based understanding, diagnostics, medical devices, and non-pharmaceutical therapies means that pharmaceutical research is only a small part of medical research.
Most of the research in the field is pursued by biomedical scientists, but significant contributions are made by other type of biologists. Medical research on humans has to strictly follow the medical ethics sanctioned in the Declaration of Helsinki and the institutional review board whe",Health & Medicine 
"Message passing
In computer science, message passing is a technique for invoking behavior (i.e., running a program) on a computer. The invoking program sends a message to a process (which may be an actor or object) and relies on that process and its supporting infrastructure to then select and run some appropriate code. Message passing differs from conventional programming where a process, subroutine, or function is directly invoked by name. Message passing is key to some models of concurrency and object-oriented programming.
Message passing is ubiquitous in modern computer software.[citation needed] It is used as a way for the objects that make up a program to work with each other and as a means for objects and systems running on different computers (e.g., the Internet) to interact. Message passing may be implemented by various mechanisms, including channels.
Overview
[edit]Message passing is a technique for invoking behavior (i.e., running a program) on a computer. In contrast to the traditional technique of calling a program by name, message passing uses an object model to distinguish the general function from the specific implementations. The invoking program sends a message and relies on the object to select and execute the appropriate code. The justifications for using an intermediate layer essentially falls into two categories: encapsulation and distribution.
Encapsulation is the idea that software objects should be able to invoke services on other objects without know",Technology & Computing 
"Microservices
In software engineering, a microservice architecture is an architectural pattern that organizes an application into a collection of loosely coupled, fine-grained services that communicate through lightweight protocols. This pattern is characterized by the ability to develop and deploy services independently, improving modularity, scalability, and adaptability. However, it introduces additional complexity, particularly in managing distributed systems and inter-service communication, making the initial implementation more challenging compared to a monolithic architecture.[1]
Definition
[edit]There is no single, universally agreed-upon definition of microservices. However, they are generally characterized by a focus on modularity, with each service designed around a specific business capability. These services are loosely coupled, independently deployable, and often developed and scaled separately, enabling greater flexibility and agility in managing complex systems. Microservices architecture is closely associated with principles such as domain-driven design, decentralization of data and governance, and the flexibility to use different technologies for individual services to best meet their requirements. [2][3][4]
Usage
[edit]It is common for microservices architectures to be adopted for cloud-native applications, serverless computing, and applications using lightweight container deployment. According to Fowler, because of the large number (when compared to monoli",Technology & Computing 
"Mind
The mind is that which thinks, feels, perceives, imagines, remembers, and wills. It covers the totality of mental phenomena, including both conscious processes, through which an individual is aware of external and internal circumstances, and unconscious processes, which can influence an individual without intention or awareness. The mind plays a central role in most aspects of human life, but its exact nature is disputed. Some characterizations focus on internal aspects, saying that the mind transforms information and is not directly accessible to outside observers. Others stress its relation to outward conduct, understanding mental phenomena as dispositions to engage in observable behavior.
The mind–body problem is the challenge of explaining the relation between matter and mind. Traditionally, mind and matter were often thought of as distinct substances that could exist independently from one another. The dominant philosophical position since the 20th century has been physicalism, which says that everything is material, meaning that minds are certain aspects or features of some material objects. The evolutionary history of the mind is tied to the development of nervous systems, which led to the formation of brains. As brains became more complex, the number and capacity of mental functions increased with particular brain areas dedicated to specific mental functions. Individual human minds also develop over time as they learn from experience and pass through psychologica",Philosophy & Religion 
"Modern art
Modern art includes artistic work produced during the period extending roughly from the 1860s to the 1970s, and denotes the styles and philosophies of the art produced during that era.[1] The term is usually associated with art in which the traditions of the past have been thrown aside in a spirit of experimentation.[2] Modern artists experimented with new ways of seeing and with fresh ideas about the nature of materials and functions of art. A tendency away from the narrative, which was characteristic of the traditional arts, toward abstraction is characteristic of much modern art. More recent artistic production is often called contemporary art or Postmodern art.
Modern art begins with the post-impressionist painters like Vincent van Gogh, Paul Cézanne, Paul Gauguin, Georges Seurat and Henri de Toulouse-Lautrec. These artists were essential to modern art's development.[3] At the beginning of the 20th century Henri Matisse and several other young artists including the pre-cubists Georges Braque, André Derain, Raoul Dufy, Jean Metzinger and Maurice de Vlaminck revolutionized the Paris art world with ""wild,"" multi-colored, expressive landscapes and figure paintings that the critics called Fauvism.[4] Matisse's two versions of The Dance signified a key point in his career and the development of modern painting.[5] It reflected Matisse's incipient fascination with primitive art: the intense warm color of the figures against the cool blue-green background and the rhyth",art_culture
"Multinomial logistic regression
In statistics, multinomial logistic regression is a classification method that generalizes logistic regression to multiclass problems, i.e. with more than two possible discrete outcomes.[1] That is, it is a model that is used to predict the probabilities of the different possible outcomes of a categorically distributed dependent variable, given a set of independent variables (which may be real-valued, binary-valued, categorical-valued, etc.).
Multinomial logistic regression is known by a variety of other names, including polytomous LR,[2][3] multiclass LR, softmax regression, multinomial logit (mlogit), the maximum entropy (MaxEnt) classifier, and the conditional maximum entropy model.[4]
Background
[edit]Multinomial logistic regression is used when the dependent variable in question is nominal (equivalently categorical, meaning that it falls into any one of a set of categories that cannot be ordered in any meaningful way) and for which there are more than two categories. Some examples would be:
- Which major will a college student choose, given their grades, stated likes and dislikes, etc.?
- Which blood type does a person have, given the results of various diagnostic tests?
- In a hands-free mobile phone dialing application, which person's name was spoken, given various properties of the speech signal?
- Which candidate will a person vote for, given particular demographic characteristics?
- Which country will a firm locate an office in, given",Technology & Computing 
"Museum of Modern Art
The Museum of Modern Art (MoMA) is an art museum located in Midtown Manhattan, New York City, on 53rd Street between Fifth and Sixth Avenues. MoMA's collection spans the late 19th century to the present, and includes over 200,000 works of architecture and design, drawing, painting, sculpture, photography, prints, illustrated and artist's books, film, as well as electronic media.[2]
The institution was conceived in 1929 by Abby Aldrich Rockefeller, Lillie P. Bliss, and Mary Quinn Sullivan. Initially located in the Heckscher Building on Fifth Avenue, it opened just days after the Wall Street Crash. The museum was led by A. Conger Goodyear as president and Abby Rockefeller as treasurer, with Alfred H. Barr Jr. as its first director. Under Barr's leadership, the museum's collection rapidly expanded, beginning with an inaugural exhibition of works by European modernists. Despite financial challenges, including opposition from John D. Rockefeller Jr., the museum moved to several temporary locations in its early years, and John D. Rockefeller Jr. eventually donated the land for its permanent site. In 1939, the museum moved to its current location on West 53rd Street designed by architects Philip L. Goodwin and Edward Durell Stone. A new sculpture garden, designed by Barr and curator John McAndrew, also opened that year.
From the 1930s through the 1950s, MoMA became a host to several landmark exhibitions, including Barr's influential ""Cubism and Abstract Art"" in ",art_culture
"Named-entity recognition
Named-entity recognition (NER) (also known as (named) entity identification, entity chunking, and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names (PER), organizations (ORG), locations (LOC), geopolitical entities (GPE), vehicles (VEH), medical codes, time expressions, quantities, monetary values, percentages, etc.
Most research on NER/NEE systems has been structured as taking an unannotated block of text, such as transducing:
Jim bought 300 shares of Acme Corp. in 2006.
into an annotated block of text that highlights the names of entities:
[Jim]Person bought 300 shares of [Acme Corp.]Organization in [2006]Time.
In this example, a person name consisting of one token, a two-token company name and a temporal expression have been detected and classified.
Problem
[edit]Definition
[edit]In the expression named entity, the word named restricts the task to those entities for which one or many strings, such as words or phrases, stand (fairly) consistently for some referent. This is closely related to rigid designators, as defined by Kripke,[1][2] although in practice NER deals with many names and referents that are not philosophically ""rigid"". For instance, the automotive company created by Henry Ford in 1903 can be referred to as Ford or Ford Motor Company, although ""Ford"" can refer to many other entities as well (see Ford",Technology & Computing 
"Nonlinear dimensionality reduction
Nonlinear dimensionality reduction, also known as manifold learning, is any of various related techniques that aim to project high-dimensional data, potentially existing across non-linear manifolds which cannot be adequately captured by linear decomposition methods, onto lower-dimensional latent manifolds, with the goal of either visualizing the data in the low-dimensional space, or learning the mapping (either from the high-dimensional space to the low-dimensional embedding or vice versa) itself.[1][2] The techniques described below can be understood as generalizations of linear decomposition methods used for dimensionality reduction, such as singular value decomposition and principal component analysis.
Applications of NLDR
[edit]High dimensional data can be hard for machines to work with, requiring significant time and space for analysis. It also presents a challenge for humans, since it's hard to visualize or understand data in more than three dimensions. Reducing the dimensionality of a data set, while keep its essential features relatively intact, can make algorithms more efficient and allow analysts to visualize trends and patterns.
The reduced-dimensional representations of data are often referred to as ""intrinsic variables"". This description implies that these are the values from which the data was produced. For example, consider a dataset that contains images of a letter 'A', which has been scaled and rotated by varying amounts. Ea",Technology & Computing 
"Novel
A novel is an extended work of narrative fiction usually written in prose and published as a book.[1] The word derives from the Italian: novella for 'new', 'news', or 'short story (of something new)', itself from the Latin: novella, a singular noun use of the neuter plural of novellus, diminutive of novus, meaning 'new'.[2] According to Margaret Doody, the novel has ""a continuous and comprehensive history of about two thousand years"", with its origins in the Ancient Greek and Roman novel, Medieval Chivalric romance, and the tradition of the Italian Renaissance novella.[3] The ancient romance form was revived by Romanticism, in the historical romances of Walter Scott and the Gothic novel.[4] Some novelists, including Nathaniel Hawthorne,[5] Herman Melville,[6] Ann Radcliffe,[7] and John Cowper Powys,[8] preferred the term romance. Such romances should not be confused with the genre fiction romance novel, which focuses on romantic love. M. H. Abrams and Walter Scott have argued that a novel is a fiction narrative that displays a realistic depiction of the state of a society, like Harper Lee's To Kill a Mockingbird.[9][10] The romance, on the other hand, encompasses any fictitious narrative that emphasizes marvellous or uncommon incidents.[11][12][13] In reality, such works are nevertheless also commonly called novels, including Mary Shelley's Frankenstein[14] and J. R. R. Tolkien's The Lord of the Rings.[15]
The spread of printed books in China led to the appearance of th",art_culture
"Nyquist stability criterion
In control theory and stability theory, the Nyquist stability criterion or Strecker–Nyquist stability criterion, independently discovered by the German electrical engineer Felix Strecker at Siemens in 1930[1][2][3] and the Swedish-American electrical engineer Harry Nyquist at Bell Telephone Laboratories in 1932,[4] is a graphical technique for determining the stability of a linear dynamical system.
Because it only looks at the Nyquist plot of the open loop systems, it can be applied without explicitly computing the poles and zeros of either the closed-loop or open-loop system (although the number of each type of right-half-plane singularities must be known). As a result, it can be applied to systems defined by non-rational functions, such as systems with delays. In contrast to Bode plots, it can handle transfer functions with right half-plane singularities. In addition, there is a natural generalization to more complex systems with multiple inputs and multiple outputs, such as control systems for airplanes.
The Nyquist stability criterion is widely used in electronics and control system engineering, as well as other fields, for designing and analyzing systems with feedback. While Nyquist is one of the most general stability tests, it is still restricted to linear time-invariant (LTI) systems. Nevertheless, there are generalizations of the Nyquist criterion (and plot) for non-linear systems, such as the circle criterion and the scaled relative graph",Technology & Computing 
"Peace and conflict studies
Peace and conflict studies is a social science field that identifies and analyzes violent and nonviolent behaviors as well as the structural mechanisms attending conflicts (including social conflicts), to understand those processes which lead to a more desirable human condition.[1] A variation on this, peace studies, is an interdisciplinary effort aiming at the prevention, de-escalation, and solution of conflicts by peaceful means, based on achieving conflict resolution and dispute resolution at the international and domestic levels based on positive sum, rather than negative sum, solutions.
In contrast with strategic studies or war studies, which focus on traditionally realist objectives based on the state or individual unit level of analysis, peace and conflict studies often focuses on the structural violence, social or human levels of analysis.
Disciplines involved may include philosophy, political science, geography, economics, psychology, communication studies, sociology, international relations, history, anthropology, religious studies, gender studies, law, and development studies as well as a variety of others. Relevant sub-disciplines of such fields, such as peace economics, may also be regarded as belonging to peace and conflict studies. The study of peace is also known as irenology.[2]
Historical background
[edit]Peace and conflict studies is both a pedagogical activity, in which teachers transmit knowledge to students; and a research acti",history
"Philosophy of mind
Philosophy of mind is a branch of philosophy that deals with the nature of the mind and its relation to the body and the external world.
The mind–body problem is a paradigmatic issue in philosophy of mind, although a number of other issues are addressed, such as the hard problem of consciousness and the nature of particular mental states.[1][2][3] Aspects of the mind that are studied include mental events, mental functions, mental properties, consciousness and its neural correlates, the ontology of the mind, the nature of cognition and of thought, and the relationship of the mind to the body.
Dualism and monism are the two central schools of thought on the mind–body problem, although nuanced views have arisen that do not fit one or the other category neatly.
- Dualism finds its entry into Western philosophy thanks to René Descartes in the 17th century.[4] Substance dualists like Descartes argue that the mind is an independently existing substance, whereas property dualists maintain that the mind is a group of independent properties that emerge from and cannot be reduced to the brain, but that it is not a distinct substance.[5]
- Monism is the position that mind and body are ontologically indiscernible entities, not dependent substances. This view was espoused by the 17th-century rationalist Baruch Spinoza.[6] Physicalists argue that only entities postulated by physical theory exist, and that mental processes will eventually be explained in terms of these en",Philosophy & Religion 
"Piano concerto
A piano concerto, a type of concerto, is a solo composition in the classical music genre which is composed for piano accompanied by an orchestra or other large ensemble. Piano concertos are typically virtuosic showpieces which require an advanced level of technique. Piano concertos are typically written out in music notation, including sheet music for the pianist (which is typically memorized for a more virtuosic performance), orchestral parts, and a full score for the conductor.
The standard practice in the Baroque and Classical eras (together spanning from circa 1600 to circa 1800), was for the orchestra to provide subordinate accompaniment over which the piano plays solo parts. However, at the end of the classical era, the orchestra had an equal role to the pianist and frequently had “dialogue” or “conversation” between the two. When music students and music competition auditionees play piano concertos, the orchestra part may be performed in an orchestral reduction, a conversion of the orchestra parts into a part for an accompanist playing piano or pipe organ, as it is very expensive to hire a full orchestra. Keyboard concerti were common in the time of Johann Sebastian Bach in the Baroque music era, during the Classical period and during the Romantic music era (1800–1910). Keyboard concertos are also written by contemporary classical music composers. Twentieth- and 21st-century piano concertos may include experimental or unusual performance techniques. In t",art_culture
"Portal topics - (Random portal)
Haunting is sometimes used as a plot device in horror fiction and paranormal-based fiction. Legends about haunted houses have long appeared in literature. For example, the Arabian Nights tale of ""Ali the Cairene and the Haunted House in Baghdad"" revolves around a house haunted by djinns. The influence of the Arabian Nights on modern horror fiction is certainly discernible in some of the work of H. P. Lovecraft.
Achievements in horror fiction are recognized by numerous awards. The Horror Writer's Association presents the Bram Stoker Awards for Superior Achievement, named in honor of Bram Stoker, author of the seminal horror novel Dracula. The Australian Horror Writers Association presents annual Australian Shadows Awards. The International Horror Guild Award was presented annually to works of horror and dark fantasy from 1995 to 2008. Other important awards for horror literature are as subcategories included within general awards for fantasy and science fiction in such awards as the Aurealis Award.
Through his association with Dracula (in which he appeared with minimal makeup, using his natural, heavily accented voice), Lugosi found himself typecast as a horror villain in such movies as Murders in the Rue Morgue, The Raven, and Son of Frankenstein for Universal, and the independent White Zombie. His accent, while a part of his image, limited the roles he could play.
Lugosi did attempt to break type by auditioning for other roles. He lost out to ",art_culture
"Raster graphics
In computer graphics and digital photography, a raster graphic, raster image, or simply raster is a digital image made up of a rectangular grid of tiny colored (usually square) so-called pixels. Unlike vector graphics which use mathematical formulas to describe shapes and lines, raster images store the exact color of each pixel, making them ideal for photographs and images with complex colors and details. Raster images are characterized by their dimensions (width and height in pixels) and color depth (the number of bits per pixel).[1] They can be displayed on computer displays, printed on paper, or viewed on other media, and are stored in various image file formats.
The printing and prepress industries know raster graphics as contones (from ""continuous tones""). In contrast, line art is usually implemented as vector graphics in digital systems.[2]
Many raster manipulations map directly onto the mathematical formalisms of linear algebra, where mathematical objects of matrix structure are of central concern.
Raster or gridded data may be the result of a gridding procedure.
Etymology
[edit]The word ""raster"" has its origins in the Latin rastrum (a rake), which is derived from radere (to scrape). It originates from the raster scan of cathode-ray tube (CRT) video monitors, which draw the image line by line by magnetically or electrostatically steering a focused electron beam.[3] By association, it can also refer to a rectangular grid of pixels. The word rastrum is no",Technology & Computing 
"Raster graphics editor
A raster graphics editor (also called bitmap graphics editor) is a computer program that allows users to create and edit images interactively on the computer screen and save them in one of many raster graphics file formats (also known as bitmap images) such as JPEG, PNG, and GIF.
Comparison to vector graphic editors
[edit]Vector graphics editors are often contrasted with raster graphics editors, yet their capabilities complement each other. The technical difference between vector and raster editors stem from the difference between vector and raster images. Vector graphics are created mathematically, using geometric formulas. Each element is created and manipulated numerically; essentially using Cartesian coordinates for the placement of key points, and then a mathematical algorithm to connect the dots and define the colors.
Raster images include digital photos. A raster image is made up of rows and columns of dots, called pixels,[1][2] and is generally more photo-realistic. This is the standard form for digital cameras; whether it be a .raw file or .jpg file, the concept is the same. The image is represented pixel by pixel, like a microscopic jigsaw puzzle.
Vector editors tend to be better suited for graphic design, page layout, typography, logos, sharp-edged artistic illustrations, e.g., cartoons, clip art, complex geometric patterns, technical illustrations, diagramming and flowcharting.
Advanced raster editors, like GIMP and Adobe Photoshop, use vect",Technology & Computing 
"Rasterisation
In computer graphics, rasterisation (British English) or rasterization (American English) is the task of taking an image described in a vector graphics format (shapes) and converting it into a raster image (a series of pixels, dots or lines, which, when displayed together, create the image which was represented via shapes).[1][2] The rasterized image may then be displayed on a computer display, video display or printer, or stored in a bitmap file format. Rasterization may refer to the technique of drawing 3D models, or to the conversion of 2D rendering primitives, such as polygons and line segments, into a rasterized format.
Etymology
[edit]The term ""rasterisation"" comes from German Raster 'grid, pattern, schema' and Latin rāstrum 'scraper, rake'.[3][4]
2D images
[edit]Line primitives
[edit]Bresenham's line algorithm is an example of an algorithm used to rasterize lines.
Circle primitives
[edit]Algorithms such as the midpoint circle algorithm are used to render circles onto a pixelated canvas.
3D images
[edit]Rasterization is one of the typical techniques of rendering 3D models. Compared with other rendering techniques such as ray tracing, rasterization is extremely fast and therefore used in most realtime 3D engines. However, rasterization is simply the process of computing the mapping from scene geometry to pixels and does not prescribe a particular way to compute the color of those pixels. The specific color of each pixel is assigned by a pixel shader (which ",Technology & Computing 
"Resource-oriented architecture
In software engineering, a resource-oriented architecture (ROA) is a style of software architecture and programming paradigm for supportive designing and developing software in the form of Internetworking of resources with ""RESTful"" interfaces. These resources are software components (discrete pieces of code and/or data structures) which can be reused for different purposes. ROA design principles and guidelines are used during the phases of software development and system integration.
REST, or Representational State Transfer, describes a series of architectural constraints that exemplify how the web's design emerged.[1] Various concrete implementations of these ideas have been created throughout time, but it has been difficult to discuss the REST architectural style without blurring the lines between actual software and the architectural principles behind it.
In Chapter 5 of his thesis, Roy Fielding documents how the World Wide Web is designed to be constrained by the REST series of limitations. These are still fairly abstract and have been interpreted in various ways in designing new frameworks, systems, and websites. In the past, heated exchanges have been made about whether RPC-style REST architectures are RESTful.[1][2]
Guidelines for clarification
[edit]The Resource Oriented Architecture, as documented by Leonard Richardson and Sam Ruby in their 2007 book RESTful Web Services,[3] gives concrete advice on specific technical details. Naming t",Technology & Computing 
"Robot as a service
Robot as a service or robotics as a service (RaaS) is a cloud computing unit that facilitates the seamless integration of robot and embedded devices into Web and cloud computing environment. In terms of service-oriented architecture (SOA), a RaaS unit includes services for performing functionality, a service directory for discovery and publishing, and service clients for user's direct access.[1][2] The current RaaS implementation facilitates SOAP and RESTful communications between RaaS units and the other cloud computing units. Hardware support and standards are available to support RaaS implementation. Devices Profile for Web Services (DPWS) defines implementation constraints to enable secure Web Service messaging, discovery, description, and eventing on resource-constrained devices between Web services and devices.
RaaS can be considered a unit of the Internet of Things (IoT), Internet of Intelligent Things (IoIT) that deal with intelligent devices that have adequate computing capacity,[3] Cyber-physical system (CPS) that is a combination of a large computational and communication core and physical elements that can interact with the physical world,[4] and Autonomous decentralized system (ADS) whose components are designed to operate in a loosely coupled manner and data are shared through a content-oriented protocol.[5][6]
The more common usage of the term Robot as a Service (RaaS), is as a financial model for the purchase and use of a physical industrial",Technology & Computing 
"Second-language acquisition
Second-language acquisition (SLA), sometimes called second-language learning—otherwise referred to as L2 (language 2) acquisition, is the process of learning a language other than one's native language (L1). SLA research examines how learners develop their knowledge of second language, focusing on concepts like interlanguage, a transitional linguistic system with its own rules that evolves as learners acquire the target language.
SLA research spans cognitive, social, and linguistic perspectives. Cognitive approaches investigate memory and attention processes; sociocultural theories emphasize the role of social interaction and immersion; and linguistic studies examine the innate and learned aspects of language. Individual factors like age, motivation, and personality also influence SLA, as seen in discussions on the critical period hypothesis and learning strategies. In addition to acquisition, SLA explores language loss, or second-language attrition, and the impact of formal instruction on learning outcomes.
Definitions
[edit]Second language refers to any language learned in addition to a person's first language; although the concept is called second-language acquisition, it can also incorporate the learning of third, fourth, or subsequent languages.[1] Second-language acquisition refers to what learners do; it does not refer to practices in language teaching, although teaching can affect acquisition. The term acquisition was originally used to emp",Philosophy & Religion 
"Semantic Web
The Semantic Web, sometimes known as Web 3.0, is an extension of the World Wide Web through standards[1] set by the World Wide Web Consortium (W3C). The goal of the Semantic Web is to make Internet data machine-readable.
To enable the encoding of semantics with the data, technologies such as Resource Description Framework (RDF)[2] and Web Ontology Language (OWL)[3] are used. These technologies are used to formally represent metadata. For example, ontology can describe concepts, relationships between entities, and categories of things. These embedded semantics offer significant advantages such as reasoning over data and operating with heterogeneous data sources.[4] These standards promote common data formats and exchange protocols on the Web, fundamentally the RDF. According to the W3C, ""The Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries.""[5] The Semantic Web is therefore regarded as an integrator across different content and information applications and systems.
History
[edit]The term was coined by Tim Berners-Lee for a web of data (or data web)[6] that can be processed by machines[7]—that is, one in which much of the meaning is machine-readable. While its critics have questioned its feasibility, proponents argue that applications in library and information science, industry, biology and human sciences research have already proven the validity of the original concept.[8]
B",Technology & Computing 
"Semantics (computer science)
In programming language theory, semantics is the rigorous mathematical study of the meaning of programming languages.[1] Semantics assigns computational meaning to valid strings in a programming language syntax. It is closely related to, and often crosses over with, the semantics of mathematical proofs.
Semantics describes the processes a computer follows when executing a program in that specific language. This can be done by describing the relationship between the input and output of a program, or giving an explanation of how the program will be executed on a certain platform, thereby creating a model of computation.
History
[edit]In 1967, Robert W. Floyd published the paper Assigning meanings to programs; his chief aim was ""a rigorous standard for proofs about computer programs, including proofs of correctness, equivalence, and termination"".[2][3] Floyd further wrote:[2]
A semantic definition of a programming language, in our approach, is founded on a syntactic definition. It must specify which of the phrases in a syntactically correct program represent commands, and what conditions must be imposed on an interpretation in the neighborhood of each command.
In 1969, Tony Hoare published a paper on Hoare logic seeded by Floyd's ideas, now sometimes collectively called axiomatic semantics.[4][5]
In the 1970s, the terms operational semantics and denotational semantics emerged.[5]
Overview
[edit]The field of formal semantics encompasses all of the fol",Philosophy & Religion 
"Semantics of logic
In logic, the semantics of logic or formal semantics is the study of the meaning and interpretation of formal languages, formal systems, and (idealizations of) natural languages. This field seeks to provide precise mathematical models that capture the pre-theoretic notions of truth, validity, and logical consequence. While logical syntax concerns the formal rules for constructing well-formed expressions, logical semantics establishes frameworks for determining when these expressions are true and what follows from them.
The development of formal semantics has led to several influential approaches, including model-theoretic semantics (pioneered by Alfred Tarski), proof-theoretic semantics (associated with Gerhard Gentzen and Michael Dummett), possible worlds semantics (developed by Saul Kripke and others for modal logic and related systems), algebraic semantics (connecting logic to abstract algebra), and game semantics (interpreting logical validity through game-theoretic concepts). These diverse approaches reflect different philosophical perspectives on the nature of meaning and truth in logical systems.
Overview
[edit]The truth conditions of various sentences we may encounter in arguments will depend upon their meaning, and so logicians cannot completely avoid the need to provide some treatment of the meaning of these sentences. The semantics of logic refers to the approaches that logicians have introduced to understand and determine that part of meaning in",Philosophy & Religion 
"Servant leadership
Servant leadership is a leadership philosophy in which the goal of the leader is to serve. This is different from traditional leadership where the leader's main focus is the thriving of their company or organization. A servant leader shares power, puts the needs of the employees first and helps people develop and perform as highly as possible.[1] Instead of the people working to serve the leader, the leader exists to serve the people.[2] As stated by its founder, Robert K. Greenleaf, a servant leader should be focused on ""Do those served grow as persons? Do they, while being served, become healthier, wiser, freer, more autonomous, more likely themselves to become servants?""[3]
When leaders shift their mindset and serve first, they benefit as well as their employees in that their employees acquire personal growth, while the organization grows as well due to the employees' growing commitment and engagement. Since this leadership style came about, a number of different organizations including Starbucks and Marriott International have adopted this style as their way of leadership.[4]
According to a 2002 study by Sen Sendjaya and James C. Sarros, servant leadership is being practiced in some of the top-ranking companies, and these companies are highly ranked because of their leadership style and following.[1] Further research also confirms that servant leaders lead others to go beyond the call of duty.[5]
History
[edit]Before the modern popularity of the concept",Philosophy & Religion 
"Sociology of education
The sociology of education is the study of how public institutions and individual experiences affect education and its outcomes. It is mostly concerned with the public schooling systems of modern industrial societies, including the expansion of higher, further, adult, and continuing education.[1]
Education is seen as a fundamentally optimistic human endeavour characterised by aspirations for progress and betterment.[2] It is understood by many to be a means of overcoming handicaps, achieving greater equality, and acquiring wealth and social status.[3] Education is perceived as a place where children can develop according to their unique needs and potential.[2] Not only can children develop, but young and older adults too. Social interaction between people through education can always further development no matter what age they are. It is also perceived as one of the best means of achieving greater social equality.[3] Many would say that the purpose of education should be to develop every individual to their full potential, and give them a chance to achieve as much in life as their natural abilities allow (meritocracy). Few would argue that any education system accomplishes this goal perfectly. Some take a particularly critical view, arguing that the education system is designed with the intention of causing the social reproduction of inequality. Sociology is study of human relationship.
Foundations
[edit]Systematic sociology of education began with the ",Philosophy & Religion 
"Stop motion
Stop motion (also known as stop frame animation) is an animated filmmaking and special effects technique in which objects are physically manipulated in small increments between individually photographed frames so that they will appear to exhibit independent motion or change when the series of frames is played back. Any kind of object can thus be animated, but puppets with movable joints (puppet animation) or clay figures (claymation) are most commonly used. Puppets, models or clay figures built around an armature are used in model animation. Stop motion with live actors is often referred to as pixilation. Stop motion of flat materials such as paper, fabrics or photographs is usually called cutout animation.
Terminology
[edit]The term ""stop motion"", relating to the animation technique, is often spelled with a hyphen as ""stop-motion""—either standalone or as a compound modifier. Both orthographic variants, with and without the hyphen, are correct, but the hyphenated one has a second meaning that is unrelated to animation or cinema: ""a device for automatically stopping a machine or engine when something has gone wrong"".[2]
History
[edit]1849 to 1895: Before film
[edit]Before the advent of chronophotography in 1878, a small number of picture sequences were photographed with subjects in separate poses. These can now be regarded as a form of stop motion or pixilation, but very few results were meant to be animated. Until celluloid film base was established in 1888 and se",art_culture
"Theatre director
A theatre director or stage director is a professional in the theatre field who oversees and orchestrates the mounting of a theatre production such as a play, opera, dance, drama, musical theatre performance, etc. by unifying various endeavors and aspects of production. The director's function is to ensure the quality and completeness of theatre production and to lead the members of the creative team into realizing their artistic vision for it. The director thereby collaborates with a team of creative individuals and other staff to coordinate research and work on all the aspects of the production which includes the Technical and the Performance aspects. The technical aspects include: stagecraft, costume design, theatrical properties (props), lighting design, set design, and sound design for the production. The performance aspects include: acting, dance, orchestra, chants, and stage combat.
If the production is a new piece of writing or a (new) translation of a play, the director may also work with the playwright or a translator. In contemporary theatre, after the playwright, the director is generally the principle visionary, making decisions on the artistic conception and interpretation of the play and its staging. Different directors occupy different places of authority and responsibility, depending on the structure and philosophy of individual theatre companies. Directors use a wide variety of techniques, philosophies, and levels of collaboration.[1][2]
The",art_culture
"Time series database
A time series database is a software system that is optimized for storing and serving time series through associated pairs of time(s) and value(s).[1] In some fields, time series may be called profiles, curves, traces or trends.[2] Several early time series databases are associated with industrial applications which could efficiently store measured values from sensory equipment (also referred to as data historians), but now are used in support of a much wider range of applications. In many cases, the repositories of time-series data will utilize compression algorithms to manage the data efficiently.[3][4] Although it is possible to store time-series data in many different database types, the design of these systems with time as a key index is distinctly different from relational databases which reduce discrete relationships through referential models.[5]
Overview
[edit]Time series datasets are relatively large and uniform compared to other datasets―usually being composed of a timestamp and associated data.[6] Time series datasets can also have fewer relationships between data entries in different tables and don't require indefinite storage of entries.[6] The unique properties of time series datasets mean that time series databases can provide significant improvements in storage space and performance over general purpose databases.[6] For instance, due to the uniformity of time series data, specialized compression algorithms can provide improvements over r",Technology & Computing 
"Tracing garbage collection
In computer programming, tracing garbage collection is a form of automatic memory management that consists of determining which objects should be deallocated (""garbage collected"") by tracing which objects are reachable by a chain of references from certain ""root"" objects, and considering the rest as ""garbage"" and collecting them. Tracing is the most common type of garbage collection – so much so that ""garbage collection"" often refers to the tracing method, rather than others such as reference counting – and there are a large number of algorithms used in implementation.
Reachability of an object
[edit][1]Informally, an object is reachable if it is referenced by at least one variable in the program, either directly or through references from other reachable objects. More precisely, objects can be reachable in only two ways:
- A distinguished set of roots: objects that are assumed to be reachable. Typically, these include all the objects referenced from anywhere in the call stack (that is, all local variables and parameters in the functions currently being invoked), and any global variables.
- Anything referenced from a reachable object is itself reachable; more formally, reachability is a transitive closure.
The reachability definition of ""garbage"" is not optimal, insofar as the last time a program uses an object could be long before that object falls out of the environment scope. A distinction is sometimes drawn between syntactic garbage, those objec",Technology & Computing 
"United States corporate law
United States corporate law regulates the governance, finance and power of corporations in US law. Every state and territory has its own basic corporate code, while federal law creates minimum standards for trade in company shares and governance rights, found mostly in the Securities Act of 1933 and the Securities and Exchange Act of 1934, as amended by laws like the Sarbanes–Oxley Act of 2002 and the Dodd–Frank Wall Street Reform and Consumer Protection Act. The US Constitution was interpreted by the US Supreme Court to allow corporations to incorporate in the state of their choice, regardless of where their headquarters are. Over the 20th century, most major corporations incorporated under the Delaware General Corporation Law, which offered lower corporate taxes, fewer shareholder rights against directors, and developed a specialized court and legal profession. Nevada has attempted to do the same. Twenty-four states follow the Model Business Corporation Act,[1] while New York and California are important due to their size.
History
[edit]At the Declaration of Independence, corporations had been unlawful without explicit authorization in a royal charter or an Act of Parliament of the United Kingdom. Since the world's first stock market crash (the South Sea Bubble of 1720) corporations were perceived as dangerous. This was because, as the economist Adam Smith wrote in The Wealth of Nations (1776), directors managed ""other people's money"" and this co",economics_finance
"United States federal budget
The United States budget comprises the spending and revenues of the U.S. federal government. The budget is the financial representation of the priorities of the government, reflecting historical debates and competing economic philosophies. The government primarily spends on healthcare, retirement, and defense programs.
The non-partisan Congressional Budget Office provides extensive analysis of the budget and its economic effects.
The budget typically contains more spending than revenue, the difference adding to the federal debt each year. CBO estimated in February 2024 that federal debt held by the public is projected to rise from 99 percent of GDP in 2024 to 116 percent in 2034 and would continue to grow if current laws generally remained unchanged. Over that period, the growth of interest costs and mandatory spending outpaces the growth of revenues and the economy, driving up debt. Those factors persist beyond 2034, pushing federal debt higher still, to 172 percent of GDP in 2054.[1]
Overview
[edit]The budget document often begins with the President's proposal to Congress recommending funding levels for the next fiscal year, beginning October 1 and ending on September 30 of the year following. The fiscal year refers to the year in which it ends. However, Congress is the body required by law to pass appropriations annually and to submit funding bills passed by both houses to the President for signature. Congressional decisions are governed by rul",economics_finance
"User Datagram Protocol
In computer networking, the User Datagram Protocol (UDP) is one of the core communication protocols of the Internet protocol suite used to send messages (transported as datagrams in packets) to other hosts on an Internet Protocol (IP) network. Within an IP network, UDP does not require prior communication to set up communication channels or data paths.
UDP is a connectionless protocol, meaning that messages are sent without negotiating a connection and that UDP does not keep track of what it has sent.[1][2] UDP provides checksums for data integrity, and port numbers for addressing different functions at the source and destination of the datagram. It has no handshaking dialogues and thus exposes the user's program to any unreliability of the underlying network; there is no guarantee of delivery, ordering, or duplicate protection. If error-correction facilities are needed at the network interface level, an application may instead use Transmission Control Protocol (TCP) or Stream Control Transmission Protocol (SCTP) which are designed for this purpose.
UDP is suitable for purposes where error checking and correction are either not necessary or are performed in the application; UDP avoids the overhead of such processing in the protocol stack. Time-sensitive applications often use UDP because dropping packets is preferable to waiting for packets delayed due to retransmission, which may not be an option in a real-time system.[3]
The protocol was designed by D",Technology & Computing 
"User interface
In the industrial design field of human–computer interaction, a user interface (UI) is the space where interactions between humans and machines occur. The goal of this interaction is to allow effective operation and control of the machine from the human end, while the machine simultaneously feeds back information that aids the operators' decision-making process. Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls and process controls. The design considerations applicable when creating user interfaces are related to, or involve such disciplines as, ergonomics and psychology.
Generally, the goal of user interface design is to produce a user interface that makes it easy, efficient, and enjoyable (user-friendly) to operate a machine in the way which produces the desired result (i.e. maximum usability). This generally means that the operator needs to provide minimal input to achieve the desired output, and also that the machine minimizes undesired outputs to the user.
User interfaces are composed of one or more layers, including a human–machine interface (HMI) that typically interfaces machines with physical input hardware (such as keyboards, mice, or game pads) and output hardware (such as computer monitors, speakers, and printers). A device that implements an HMI is called a human interface device (HID). User interfaces that dispense with the physical movemen",Technology & Computing 
"Video game
A video game[a] or computer game[b] is an electronic game that involves interaction with a user interface or input device (such as a joystick, controller, keyboard, or motion sensing device) to generate visual feedback from a display device, most commonly shown in a video format on a television set, computer monitor, flat-panel display or touchscreen on handheld devices, or a virtual reality headset. Most modern video games are audiovisual, with audio complement delivered through speakers or headphones, and sometimes also with other types of sensory feedback (e.g., haptic technology that provides tactile sensations). Some video games also allow microphone and webcam inputs for in-game chatting and livestreaming.
Video games are typically categorized according to their hardware platform, which traditionally includes arcade video games, console games, and computer games (which includes LAN games, online games, and browser games). More recently, the video game industry has expanded onto mobile gaming through mobile devices (such as smartphones and tablet computers), virtual and augmented reality systems, and remote cloud gaming. Video games are also classified into a wide range of genres based on their style of gameplay and target audience.
The first video game prototypes in the 1950s and 1960s were simple extensions of electronic games using video-like output from large, room-sized mainframe computers. The first consumer video game was the arcade video game Computer ",Sports & Recreation 
"Videotelephony
Videotelephony (also known as videoconferencing or video calling) is the use of audio and video for simultaneous two-way communication.[1] Today, videotelephony is widespread. There are many terms to refer to videotelephony. Videophones are standalone devices for video calling (compare Telephone). In the present day, devices like smartphones and computers are capable of video calling, reducing the demand for separate videophones. Videoconferencing implies group communication.[2] Videoconferencing is used in telepresence, whose goal is to create the illusion that remote participants are in the same room.
The concept of videotelephony was conceived in the late 19th century, and versions were available to the public starting in the 1930s. Early demonstrations were installed at booths in post offices and shown at various world expositions. In 1970, AT&T launched the first commercial personal videotelephone system. In addition to videophones, there existed image phones which exchanged still images between units every few seconds over conventional telephone lines. The development of advanced video codecs, more powerful CPUs, and high-bandwidth Internet service in the late 1990s allowed digital videophones to provide high-quality low-cost color service between users almost any place in the world.
Applications of videotelephony include sign language transmission for deaf and speech-impaired people, distance education, telemedicine, and overcoming mobility issues. News ",Technology & Computing 
"Violin Concerto (Mendelssohn)
Felix Mendelssohn's Violin Concerto in E minor, Op. 64, MWV O 14, is his last concerto. It was well received at its premiere and has remained as one of the most prominent and highly-regarded violin concertos in history. It holds a central place in violin repertoire and has developed a reputation as an essential concerto for all aspiring concert violinists to master. A typical performance lasts just under half an hour.
Mendelssohn originally proposed the idea of the violin concerto to Ferdinand David, a close friend and concertmaster of the Leipzig Gewandhaus Orchestra. Although conceived in 1838, the work took another six years to complete and was not premiered until 1845. During this time, Mendelssohn maintained a regular correspondence with David as he gave him many suggestions throughout the creation process. The work itself was one of the foremost violin concertos of the Romantic era and was influential on many other composers.
Although the concerto consists of three movements in a standard fast–slow–fast structure that follow a traditional form, it was innovative and included many novel features for its time. Distinctive aspects include the almost immediate entrance of the violin at the beginning of the work and the through-composed form of the concerto as a whole, in which the three movements are melodically and harmonically connected and played attacca.
Many violinists have recorded this concerto and it is performed in concerts and classic",art_culture
"Windows Mixed Reality
Windows Mixed Reality (WMR) is a discontinued platform by Microsoft which provides augmented reality and virtual reality experiences with compatible head-mounted displays.
WMR supports a number of virtual and augmented reality headsets, including Microsoft HoloLens. In December 2023, Microsoft announced deprecation of WMR with complete removal in a future release of Windows 11 (version 24H2, which arrived in late 2024).[1]
History
[edit]Its flagship device, Microsoft HoloLens, was announced at the ""Windows 10: The Next Chapter"" press event on January 21, 2015.[2] The HoloLens provides an augmented reality experience where a live presentation of physical real-world elements is incorporated with that of virtual elements (referred to as ""holograms""[a] by Microsoft)[3][4][5] such that they are perceived to exist together in a shared environment. A variant of Windows for augmented reality computers[6] (which augment a real-world physical environment with virtual elements) Windows Mixed Reality features an augmented-reality operating environment in which any Universal Windows Platform app can run.[7]
The platform is also used for virtual reality headsets designed for use on the Windows 10 Fall Creators Update, which are built to specifications implemented as part of Windows Mixed Reality, but lack support for augmented-reality experiences. In January 2023, Microsoft laid off entire teams which were developing HoloLens, Virtual Reality, and Mixed Reality produc",Technology & Computing 
"Dogme95 certified movies, as reported in www.dogme.dk:
(shortened version from http://www.dogme95.dk/)
If you have made a film which fits into these rules, you can download a application form from their website and let it get a Dogma certificate.
Dogme95 is not a cop out for a film maker to make a cheap film. The Celebration had a budget over 1.3 million dollars, which is actually above the average of a Danish low budget film. Most low budget Danish films are around $750,000, and know this and I'm not Danish. Dogme95 was a reactionary statement made by film makers to help the film industry, and I feel it has. The story has been lost in Hollywood and in the Independent circuit. Most people go to the movies to tune out and not to think. The producers plague on this and produce cookie cutter type films where movie goers see the same film time and time again. Dogme95 places the film maker in an environment where they can't rely on the tricks and tools used by others. I would love to see Steven Spielberg do a film under the Vow of Chasity.
Log in or register to write something here or to contact authors.",art_culture
"Welcome to Faiss Documentation
Faiss
Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning.
Faiss is written in C++ with complete wrappers for Python. Some of the most useful algorithms are implemented on the GPU. It is developed primarily at FAIR, the fundamental AI research team of Meta.
What is similarity search?
Given a set of vectors \(x_i\) in dimension \(d\), Faiss builds a data structure in RAM from it. After the structure is constructed, when given a new vector \(x\) in dimension \(d\) it performs efficiently the operation:
where \(\lVert\cdot\rVert\) is the Euclidean distance (\(L^2\)).
In Faiss terms, the data structure is an index, an object that has an add method to add \(x_i\) vectors. Note that the \(x_i\)’s are assumed to be fixed.
Computing the argmin is the search operation on the index.
This is all what Faiss is about. It can also:
return not just the nearest neighbor, but also the 2nd nearest, 3rd, …, k-th nearest neighbor
search several vectors at a time rather than one (batch processing). For many index types, this is faster than searching one vector after another
trade precision for speed, ie. give an incorrect result 10% of the time with a method that’s 10x faster or uses 10x less memory
perform maximum inner product search \(argmax_i \langle x, ",Technology & Computing 
"A RANT
WHAT TRUE MODERN LITERATURE SHOULD LOOK LIKE
FUNNY: Modernist writers Gertrude Stein, Ezra Pound, Sherwood Anderson and their famous protege, Ernest Hemingway, saw the key to moving literary art forward in removing Victorian-era verbiage. They stressed “economy of language.” They saw modernism in the same terms as modernist painters, architects and designers: via simplicity and clarity. Eliminating the unnecessary to get to the core emotion beneath. Hemingway’s own prose, beginning with his earliest in our time vignettes, embodies this philosophy.
I ASK, then, how did we arrive at the piled-on unreadable verbiage of High Literary Modernism? A combination of Henry James sentence fetish, detail disease, and word clot? Run-on Joyce Faulkner Woolf paragraphs of stream-of-consciousness nonsense within endless Proustian narratives, through which the reader haplessly hopefully wades, as if digging through a garbage dump, until said reader, stupefyingly bored after hundreds or thousands of pages, at last cries out, “Enough!”
WHO PRAISED these High Modernist con artists? Who made them an essential inextricable part of the literary Canon– the art’s Pantheon– while more accessible and frankly more intelligent authors were expunged? High Modernists are held up to gullible students as role models, but in reality they’re giant OBSTACLES preventing the art from moving forward.
OUR STANCE at New Pop Lit is that Ernest Hemingway was not an end point of modernist writing, but a beginnin",art_culture
"The Feast Plugin completely replaces your theme setup with a rewritten modern standard, built not just around aesthetics, but also making giant leaps in:
- SEO
- pagespeed
- user experience
- accessibility
You can think of the plugin as a brand new theme (minus the styling) designed for 2024, but instead of falling behind on updates, your site is continually updated to meet modern best practices.
This lets you spend less time updating and maintaining your site, so that you can spend more time on creating content and giving your readers what they want.
Experienced bloggers will love...
Updates Without reinstalling
The Feast Plugin will make updating your site simpler, by providing theme-replacement functionality that can be kept up-to-date without having to reinstall your theme.
Save plugin customizations
Customizations made with the plugin settings are saved between theme changes and plugin updates.
Unlock next-gen features
We're building out next-generation features that are compatible with the block editor.
All new features will be built into the plugin moving forward, instead of the themes, so that we can update them as necessary over time.
Access all the themes
The Feast Plugin grants you access to our entire theme library so that you can refresh your site whenever you want, including:
- Foodie Pro 5
- Brunch Pro v.4.4.4
- Cook'd Pro v.4.4.4
- Seasoned Pro v.4.4.4
- Cravings Pro v.4.4.4
- Genesis 3.3.5
Here's what you should know
- The plugin lives alongside your current ",Technology & Computing 
"Waste Management, Inc. (WM)
- Previous Close
231.94 - Open
231.90 - Bid 230.55 x 100
- Ask 234.20 x 200
- Day's Range
231.73 - 234.84 - 52 Week Range
196.59 - 242.58 - Volume
1,605,538 - Avg. Volume
1,753,553 - Market Cap (intraday)
94.449B - Beta (5Y Monthly) 0.67
- PE Ratio (TTM)
35.40 - EPS (TTM)
6.63 - Earnings Date Jul 22, 2025 - Jul 28, 2025
- Forward Dividend & Yield 3.30 (1.42%)
- Ex-Dividend Date Jun 6, 2025
- 1y Target Est
248.23
Waste Management, Inc., through its subsidiaries, provides environmental solutions to residential, commercial, industrial, and municipal customers in the United States, Canada, Western Europe, and internationally. It offers collection services, including picking up and transporting waste and recyclable materials from where it was generated to a transfer station, recovery facility, or disposal site; owns and operates transfer stations; and owns, develops, and operates landfill gas-to-energy facilities that produce renewable electricity and renewable natural gas. It also operates materials processing and commodities recycling services, including cardboard, paper, glass, metals, plastics, construction and demolition materials, and other recycling commodities are recovered for resale or redirected for other purposes; recycling brokerage services, such as managing the marketing of recyclable materials for third parties; and other strategic business solutions. In addition, the company collects recyclable food and yard waste, as well as markets an",economics_finance
"Modular Data Acquisition
Distributed Measurement and Control
High-Performance Test
Automated Test System Development Software
Perspectives showcases how NI sees what’s next in the world of test and technology.
You can request repair, RMA, schedule calibration, or get technical support. A valid service agreement may be required.
Provides support for NI data acquisition and signal conditioning devices.
Provides support for Ethernet, GPIB, serial, USB, and other types of instruments.
Provides support for NI GPIB controllers and NI embedded controllers with GPIB ports.
Discuss developing automated research, validation, and production test systems in NI’s graphical programming environment.",Technology & Computing 
"Implementing Data Mesh: Design, Build, and Implement Data Contracts, Data Products, and Data Mesh
- Length: 268 pages
- Edition: 1
- Language: English
- Publisher: O'Reilly Media
- Publication Date: 2024-10-15
- ISBN-10: 1098156226
- ISBN-13: 9781098156220
As data continues to grow and become more complex, organizations seek innovative solutions to manage their data effectively. Data mesh is one solution that provides a new approach to managing data in complex organizations. This practical guide offers step-by-step guidance on how to implement data mesh in your organization.
In this book, Jean-Georges Perrin and Eric Broda focus on the key components of data mesh and provide practical advice supported by code. Data engineers, architects, and analysts will explore a simple and intuitive process for identifying key data mesh components and data products. You’ll learn a consistent set of interfaces and access methods that make data products easy to consume.
This approach ensures that your data products are easily accessible and the data mesh ecosystem is easy to navigate. This book helps you:
- Identify, define, and build data products that interoperate within an enterprise data mesh
- Build a data mesh fabric that binds data products together
- Build and deploy data products in a data mesh
- Establish the organizational structure to operate data products, data platforms, and data fabric
- Learn an innovative architecture that brings data products and data fabric together into t",Technology & Computing 
"The rise of Narrowband IoT (NB-IoT) technology has enabled a new level of connectivity in low-power, wide-area networks, designed to meet the unique demands of IoT applications requiring minimal data transmission over long ranges. By offering high energy efficiency, extended range, and robust connectivity, NB-IoT end devices are essential for applications in asset tracking, environmental monitoring, smart agriculture, and beyond. For organizations investing in IoT solutions, a comprehensive understanding of NB-IoT end devices is critical. Here, you’ll find an array of resources covering everything from the structure and components of NB-IoT devices to operational guidance, maintenance, support, and tailored FAQs on NB-IoT accessories and systems.
GAO Tek Inc. ranks as one of the leading global suppliers in advanced B2B technologies, including NB-IoT devices and accessories. With years of experience in the development, testing, and deployment of NB-IoT systems, GAO Tek has invested in R&D and rigorous quality assurance, ensuring the performance, durability, and reliability of its products. Through this extensive resources page, GAO Tek provides customers with a detailed guide to selecting, operating, and maintaining NB-IoT devices, helping clients make the most informed choices and maintain peak system performance.
80 GHz NB IoT Radar Level Sensor for Liquids and Solids – GAOTek
Digital Ultrasonic Water Meter for Smart Monitoring – GAOTek
NB IoT Wireless Remote Reading Device ",Technology & Computing 
"Welcome to gdpr-info.eu. Here you can find the official PDF of the Regulation (EU) 2016/679 (General Data Protection Regulation) in the current version of the OJ L 119, 04.05.2016; cor. OJ L 127, 23.5.2018 as a neatly arranged website. All Articles of the GDPR are linked with suitable recitals. The European Data Protection Regulation is applicable as of May 25th, 2018 in all member states to harmonize data privacy laws across Europe. If you find the page useful, feel free to support us by sharing the project.
Quick Access
Key Issues
- Consent
- Data Protection Officer
- Email Marketing
- Encryption
- Fines / Penalties
- Personal Data
- Privacy by Design
- Privacy Impact Assessment
- Processing
- Records of Processing Activities
- Right of Access
- Right to be Forgotten
- Right to be Informed
- Third Countries
Table of Contents
Chapter 1General provisions
Chapter 2Principles
Chapter 3Rights of the data subject
Section 1Transparency and modalities
Section 2Information and access to personal data
Section 3Rectification and erasure
Section 4Right to object and automated individual decision-making
Section 5Restrictions
Chapter 4Controller and processor
Section 1General obligations
Section 2Security of personal data
Section 3Data protection impact assessment and prior consultation
Section 4Data protection officer
Section 5Codes of conduct and certification
Chapter 5Transfers of personal data to third countries or international organisations
Chapter 6Independent supervisory authorit",Technology & Computing 
"- Processing shall be lawful only if and to the extent that at least one of the following applies:
- the data subject has given consent to the processing of his or her personal data for one or more specific purposes;
- processing is necessary for the performance of a contract to which the data subject is party or in order to take steps at the request of the data subject prior to entering into a contract;
- processing is necessary for compliance with a legal obligation to which the controller is subject;
- processing is necessary in order to protect the vital interests of the data subject or of another natural person;
- processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller;
- processing is necessary for the purposes of the legitimate interests pursued by the controller or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data, in particular where the data subject is a child.
Point (f) of the first subparagraph shall not apply to processing carried out by public authorities in the performance of their tasks.
- Member States may maintain or introduce more specific provisions to adapt the application of the rules of this Regulation with regard to processing for compliance with points (c) and (e) of paragraph 1 by determining more precisely specific requirements f",Technology & Computing 
"What is GDPR, the EU’s new data protection law?
What is the GDPR? Europe’s new data privacy and security law includes hundreds of pages’ worth of new requirements for organizations around the world. This GDPR overview will help you understand the law and determine what parts of it apply to you.
The General Data Protection Regulation (GDPR) is the toughest privacy and security law in the world. Though it was drafted and passed by the European Union (EU), it imposes obligations onto organizations anywhere, so long as they target or collect data related to people in the EU. The regulation was put into effect on May 25, 2018. The GDPR will levy harsh fines against those who violate its privacy and security standards, with penalties reaching into the tens of millions of euros.
With the GDPR, Europe is signaling its firm stance on data privacy and security at a time when more people are entrusting their personal data with cloud services and breaches are a daily occurrence. The regulation itself is large, far-reaching, and fairly light on specifics, making GDPR compliance a daunting prospect, particularly for small and medium-sized enterprises (SMEs).
We created this website to serve as a resource for SME owners and managers to address specific challenges they may face. While it is not a substitute for legal advice, it may help you to understand where to focus your GDPR compliance efforts. We also offer tips on privacy tools and how to mitigate risks. As the GDPR continues to be int",Technology & Computing 
"Image Classification Techniques in Remote Sensing [Infographic]
“Image classification is the process of assigning land cover classes to pixels. For example, classes include water, urban, forest, agriculture, and grassland.”
What is Image Classification in Remote Sensing?
The 4 main types of image classification techniques in remote sensing are:
- Unsupervised image classification
- Supervised image classification
- Object-based image analysis
- Deep learning object detection
Unsupervised and supervised image classification are the two most common approaches.
However, object-based classification and deep learning has gained more popularity because it’s useful for high-resolution data.
Jump To: Unsupervised classification | Supervised classification | Object-based image analysis | Deep learning object detection
1. Unsupervised Classification
In unsupervised classification, it first groups pixels into “clusters” based on their properties. Then, you classify each cluster with a land cover class.
Overall, unsupervised classification is the most basic technique. Because you don’t need samples for unsupervised classification, it’s an easy way to segment and understand an image.
The two basic steps for unsupervised classification are:
- Generate clusters
- Assign classes
Using remote sensing software, we first create “clusters”. Some of the common image clustering algorithms are:
- K-means
- ISODATA
After picking a clustering algorithm, you identify the number of groups you want to g",Technology & Computing 
"http://go.microsoft.com/fwlink/?LinkId=248929
Copyright (c) Microsoft Corporation.
This package contains the ""DirectX Tool Kit"", a collection of helper classes for writing Direct3D 11 C++ code for Win32 desktop applications for Windows 8.1 or later, Xbox One, and Universal Windows Platform (UWP) apps for Windows 10 and Windows 11.
This code is designed to build with Visual Studio 2019 (16.11), Visual Studio 2022, clang for Windows v12 or later, or MinGW 12.2. Use of the Windows 10 May 2020 Update SDK (19041) or later is required for Visual Studio.
These components are designed to work without requiring any content from the legacy DirectX SDK. For details, see Where is the DirectX SDK?.
-
Inc\
-
Public Header Files (in the DirectX C++ namespace):
- Audio.h - low-level audio API using XAudio2 (DirectXTK for Audio public header)
- BufferHelpers.h - C++ helpers for creating D3D resources from CPU data
- CommonStates.h - factory providing commonly used D3D state objects
- DDSTextureLoader.h - light-weight DDS file texture loader
- DirectXHelpers.h - misc C++ helpers for D3D programming
- Effects.h - set of built-in shaders for common rendering tasks
- GamePad.h - gamepad controller helper using XInput, Windows.Gaming.Input, or GameInput
- GeometricPrimitive.h - draws basic shapes such as cubes and spheres
- GraphicsMemory.h - helper for managing dynamic graphics memory allocation
- Keyboard.h - keyboard state tracking helper
- Model.h - draws meshes loaded from .CMO, .SDKMESH, or ",Technology & Computing 
"Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy. Some of the most useful algorithms are implemented on the GPU. It is developed primarily at Meta's Fundamental AI Research group.
See CHANGELOG.md for detailed information about latest features.
Faiss contains several methods for similarity search. It assumes that the instances are represented as vectors and are identified by an integer, and that the vectors can be compared with L2 (Euclidean) distances or dot products. Vectors that are similar to a query vector are those that have the lowest L2 distance or the highest dot product with the query vector. It also supports cosine similarity, since this is a dot product on normalized vectors.
Some of the methods, like those based on binary vectors and compact quantization codes, solely use a compressed representation of the vectors and do not require to keep the original vectors. This generally comes at the cost of a less precise search but these methods can scale to billions of vectors in main memory on a single server. Other methods, like HNSW and NSG add an indexing structure on top of the raw vectors to make searching more efficient.
The GPU implementation can accept input from either CPU or GPU memory",Technology & Computing 
"🐦 Milvus is a high-performance vector database built for scale. It powers AI applications by efficiently organizing and searching vast amounts of unstructured data, such as text, images, and multi-modal information.
🧑💻 Written in Go and C++, Milvus implements hardware accelaration for CPU/GPU to achieve best-in-class vector search performance. Thanks to its fully-distributed and K8s-native architecture, Milvus can scale horizontally, handle tens of thousands of search queries on billions of vectors, and keep data fresh with real-time streaming updates. Milvus also supports Standalone mode for single machine deployment. Milvus Lite is a lightweight version good for quickstart in python with pip install
.
Want to use Milvus with zero setup? Try out Zilliz Cloud ☁️ for free. Milvus is available as a fully managed service on Zilliz Cloud, with Serverless, Dedicated and BYOC options available.
For questions about how to use Milvus, join the community on Discord to get help. For reporting problems, file bugs and feature requests in GitHub Issues or ask in Discussions.
The Milvus open-source project is under LF AI & Data Foundation, distributed with Apache 2.0 License, with Zilliz as its major contributor.
$ pip install -U pymilvus
This installs pymilvus
, the Python SDK for Milvus. Use MilvusClient
to create a client:
from pymilvus import MilvusClient
-
pymilvus
also includes Milvus Lite for quickstart. To create a local vector database, simply instantiate a client with a local fil",Technology & Computing 
"PyTorch/Tensorflow solutions for Stanford's CS231n: ""CNNs for Visual Recognition""
-
Updated
Jan 27, 2021 - Jupyter Notebook
PyTorch/Tensorflow solutions for Stanford's CS231n: ""CNNs for Visual Recognition""
Code for IoT Journal paper 'ML-MCU: A Framework to Train ML Classifiers on MCU-based IoT Edge Devices'
Implementation of (overlap) local SGD in Pytorch
A compressed adaptive optimizer for training large-scale deep learning models using PyTorch
Communication-efficient decentralized SGD (Pytorch)
Lookahead optimizer (""Lookahead Optimizer: k steps forward, 1 step back"") for tensorflow
Computer Vision and Image Processing algorithms implemented using OpenCV, NumPy and MatPlotLib, for UOM's EN2550 Fundamentals of Image Processing and Machine Vision Module ❄
Implement a Neural Network trained with back propagation in Python
📈Implementing the ADAM optimizer from the ground up with PyTorch and comparing its performance on six 3-D objective functions (each progressively more difficult to optimize) against SGD, AdaGrad, and RMSProp.
Simple MATLAB toolbox for deep learning network: Version 1.0.3
Nadir: Cutting-edge PyTorch optimizers for simplicity & composability! 🔥🚀💻
MetaPerceptron: A Standardized Framework For Metaheuristic-Driven Multi-layer Perceptron Optimization
基于粒子群PSO+随机梯度下降SGD优化器的Pytorch训练框架
ND-Adam is a tailored version of Adam for training DNNs.
JAX compilation of RDDL description files, and a differentiable planner in JAX.
Object recognition AI using deep learning
Tensor",Technology & Computing 
"A
C
D
G
M
N
R
S
X
Self-attention is a mechanism used in machine learning, particularly in natural language processing (NLP) and computer vision tasks, to capture dependencies and relationships within input sequences. It allows the model to identify and weigh the importance of different parts of the input sequence by attending to itself.
Self-attention operates by transforming the input sequence into three vectors: query, key, and value. These vectors are obtained through linear transformations of the input. The attention mechanism calculates a weighted sum of the values based on the similarity between the query and key vectors. The resulting weighted sum, along with the original input, is then passed through a feed-forward neural network to produce the final output. This process allows the model to focus on relevant information and capture long-range dependencies.
Self-attention has several benefits that make it important in machine learning and artificial intelligence:
Long-range dependencies: Self-attention allows the model to capture relationships between distant elements in a sequence, enabling it to understand complex patterns and dependencies.
Contextual understanding: By attending to different parts of the input sequence, self-attention helps the model understand the context and assign appropriate weights to each element based on its relevance.
Parallel computation: Self-attention can be computed in parallel for each element in the sequence, making it computationally e",Technology & Computing 
"If you are looking for simulation software, you are probably thinking LTSpice or one of the open-source simulators like Ngspice (which drives Oregano and QUCs-S), or GNUCap. However, there is a new free option after the closing of Spectrum Software last year: Micro-Cap 12. You may be thinking: why use another closed-source simulator? Well, all the simulators have particular strengths, but Micro-Cap does have very nice features and used to retail for about $4,500.
The simulator boasts a multipage schematic editor, native robust digital simulation, Monte Carlo analysis, 33,000 parts in its library, worst-case and smoke analysis, Smith charts, and it can even incorporate spreadsheets. There’s a built-in designer for active and passive filters. Have a look at the brochure and you will see this is a pretty serious piece of software. And now it’s at least free as in beer.
Models
The number of models supported for active devices is impressive and includes some very recent MOSFET models, not just the old standard models. It can also read just about any regular Spice or IBIS model. It can also export Spice files if you want to use another engine or share designs with other Spice users. There are also quite a few examples provided. There are also over 2,000 standard digital parts including all the usual 7400 families, CD4000 CMOS, and even ECL.
As a bonus, we tried it under Wine and it worked well — at least the 32-bit version. The 64-bit one would probably work with a little effort. O",Technology & Computing 
"This document comprehensively describes all user-facing facets of the Hadoop MapReduce framework and serves as a tutorial.
Ensure that Hadoop is installed, configured and is running. More details:
Single Node Setup for first-time users.
Cluster Setup for large, distributed clusters.
Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner.
A MapReduce job usually splits the input data-set into independent chunks which are processed by the map tasks in a completely parallel manner. The framework sorts the outputs of the maps, which are then input to the reduce tasks. Typically both the input and the output of the job are stored in a file-system. The framework takes care of scheduling tasks, monitoring them and re-executes the failed tasks.
Typically the compute nodes and the storage nodes are the same, that is, the MapReduce framework and the Hadoop Distributed File System (see HDFS Architecture Guide) are running on the same set of nodes. This configuration allows the framework to effectively schedule tasks on the nodes where data is already present, resulting in very high aggregate bandwidth across the cluster.
The MapReduce framework consists of a single master ResourceManager
, one worker NodeManager
per cluster-node, and MRAppMaster
per application (see YARN Architecture Guide).
Minimall",Technology & Computing 
"MapReduce Tutorial
Purpose
This document comprehensively describes all user-facing facets of the Hadoop MapReduce framework and serves as a tutorial.
Prerequisites
Ensure that Hadoop is installed, configured and is running. More details:
- Single Node Setup for first-time users.
- Cluster Setup for large, distributed clusters.
Overview
Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner.
A MapReduce job usually splits the input data-set into independent chunks which are processed by the map tasks in a completely parallel manner. The framework sorts the outputs of the maps, which are then input to the reduce tasks. Typically both the input and the output of the job are stored in a file-system. The framework takes care of scheduling tasks, monitoring them and re-executes the failed tasks.
Typically the compute nodes and the storage nodes are the same, that is, the MapReduce framework and the Hadoop Distributed File System (see HDFS Architecture Guide) are running on the same set of nodes. This configuration allows the framework to effectively schedule tasks on the nodes where data is already present, resulting in very high aggregate bandwidth across the cluster.
The MapReduce framework consists of a single master JobTracker and one slave TaskTracker per cluster-node. The master is respons",Technology & Computing 
"Actor model
The actor model in computer science is a mathematical model of concurrent computation that treats an actor as the basic building block of concurrent computation. In response to a message it receives, an actor can: make local decisions, create more actors, send more messages, and determine how to respond to the next message received. Actors may modify their own private state, but can only affect each other indirectly through messaging (removing the need for lock-based synchronization).
The actor model originated in 1973.[1] It has been used both as a framework for a theoretical understanding of computation and as the theoretical basis for several practical implementations of concurrent systems. The relationship of the model to other work is discussed in actor model and process calculi.
History
According to Carl Hewitt, unlike previous models of computation, the actor model was inspired by physics, including general relativity and quantum mechanics.[citation needed] It was also influenced by the programming languages Lisp, Simula, early versions of Smalltalk, capability-based systems, and packet switching. Its development was ""motivated by the prospect of highly parallel computing machines consisting of dozens, hundreds, or even thousands of independent microprocessors, each with its own local memory and communications processor, communicating via a high-performance communications network.""[2] Since that time, the advent of massive concurrency through multi-core and",Technology & Computing 
"Service-oriented architecture
In software engineering, service-oriented architecture (SOA) is an architectural style that focuses on discrete services instead of a monolithic design.[1] By consequence, it is also applied in the field of software design where services are provided to the other components by application components, through a communication protocol over a network. A service is a discrete unit of functionality that can be accessed remotely and acted upon and updated independently, such as retrieving a credit card statement online. SOA is also intended to be independent of vendors, products and technologies.[2]
Service orientation is a way of thinking in terms of services and service-based development and the outcomes of services.[1]
A service has four properties according to one of many definitions of SOA:[3]
- It logically represents a repeatable business activity with a specified outcome.
- It is self-contained.
- It is a black box for its consumers, meaning the consumer does not have to be aware of the service's inner workings.
- It may be composed of other services.[4]
Different services can be used in conjunction as a service mesh to provide the functionality of a large software application,[5] a principle SOA shares with modular programming. Service-oriented architecture integrates distributed, separately maintained and deployed software components. It is enabled by technologies and standards that facilitate components' communication and cooperation over a ",Technology & Computing 
"I've been working with TPUs a lot recently and it's fun to see how they had such different design philosophies compared to GPUs.
The main strongpoint for TPUs is in their scalability. This is achieved through a co-design of both the hardware side (e.g. energy efficiency and modularity) and the software side (e.g. XLA compiler).
Background
To give a brief tldr on TPUs, it's Google's ASIC that focuses on two factors: extreme matmul throughput + energy efficiency.
Their origins go back to Google in 2006, when they were first evaluating whether they should implement either GPUs, FPGAs, or custom ASICs. Back then there were only a few applications that necessitated specialized hardware and they decided those needs could be met by bringing in excess CPU compute from their large datacenters. But this changed in 2013 when Google's voice search feature ran on neural networks and internal projections speculated that they would need much more compute if it took off.
Fast forward to today and TPUs power the majority of Google's AI services. Of course, that includes training and inference of Gemini or Veo, but also deploying their recommendation models (DLRMs).
Let's dive in and look at TPU internals from the bottom up.
TPU Single-Chip Level
I'll focus my diagrams to TPUv4, but this layout is more or less applicable to latest generation TPUs (e.g. TPUv6p ""Trillium""; TPUv7 ""Ironwood's details aren't released as of writing in June, 2025).
Here's the layout of a single TPUv4 chip:
In each ch",Technology & Computing 
"Philosophy of Law
Philosophy of law (or legal philosophy) is concerned with providing a general philosophical analysis of law and legal institutions. Issues in the field range from abstract conceptual questions about the nature of law and legal systems to normative questions about the relationship between law and morality and the justification for various legal institutions.
Topics in legal philosophy tend to be more abstract than related topics in political philosophy and applied ethics. For example, whereas the question of how properly to interpret the U.S. Constitution belongs to democratic theory (and hence falls under the heading of political philosophy), the analysis of legal interpretation falls under the heading of legal philosophy. Likewise, whereas the question of whether capital punishment is morally permissible falls under the heading of applied ethics, the question of whether the institution of punishment can be justified falls under the heading of legal philosophy.
There are roughly three categories into which the topics of legal philosophy fall: analytic jurisprudence, normative jurisprudence, and critical theories of law. Analytic jurisprudence involves providing an analysis of the essence of law so as to understand what differentiates it from other systems of norms, such as ethics. Normative jurisprudence involves the examination of normative, evaluative, and otherwise prescriptive issues about the law, such as restrictions on freedom, obligations to obey the",Philosophy & Religion 
"The International Organization for Standardization defines a “service robot” as a ""robot in personal use or professional use that performs useful tasks for humans or equipment"". (ISO 8373)
According to ISO 8373, robots require “a degree of autonomy”, which is the “ability to perform intended tasks based on current state and sensing, without human intervention”. For service robots this ranges from partial autonomy - including human robot interaction - to full autonomy - without active human robot intervention.
Service robots are categorized according to personal or professional use. They have many forms and structures as well as application areas.
The ""new"" ISO robotics vocabulary standard ISO 8373:2021 defines medical robots as a third category next to industrial and service robots. A medical robot is a robot intended to be used as medical electrical equipment or medical electrical systems.
The IFR statistics for service robots therefore include systems based on some degree of human robot interaction or even full tele-operation as well as fully autonomous systems, depending on the application.
If a mechanism developed with robotic technology is not fulfilling all characteristics of a robot (e.g. a teleoperated remote manipulator, haptic device, end-effector, unpowered exoskeleton), it is called a robotic device.
The IFR Statistical Department carries out annual statistical survey on service robotics sales. The data is evaluated and published in the World Robotics Service Robo",Technology & Computing 
"An in-memory database (IMDB) is a data management system that stores data primarily in the computer’s main memory.
In-memory databases rely on spinning disks for data storage. IMDBs allow mission-critical applications to benefit from faster response times than disk-based databases.
Apache Ignite works with memory, disk, and Intel Optane as active storage tiers.
This multi-tier architecture combines the advantages of in-memory computing with disk durability and strong consistency, all in one system.
Ignite becomes fully operational from disk upon a cluster startup or restarts without requiring a preload or a warm-up the memory tier.
Ignite treats disk as an active storage layer, allowing it to cache a subset of the data in memory and query both in-memory and disk-only records with SQL and all other available APIs.
Enable you to request, join, and group distributed datasets.
Execute logic close to the data, thus eliminating expensive data shuffling over the network.
Allow the seamless implementation of event-driven architectures.
with the help of Apache Ignite managed to design, build, and optimize a hybrid transactional-analytical processing (HTAP) solution. This enabled the bank to make key business decisions in real time.
faced an increasing need to apply transformations to large datasets in real time. To meet this need, their team selected Ignite to achieve persistence, caching and integrated compute.
Discover our quick start guide and build your first
application in 5-10 m",Technology & Computing 
"The Quick Version
The Data Mesh architecture provides a credible blueprint for managing data at scale. It oﬀers a solution for organisations that are simply too large or complex to be able to centralise all of their data within a single enterprise data warehouse. It enables self-service analytics, democratising access to data.
Data mesh does not depend on any particular product or service and can work well in heterogeneous environments where data is shared between diﬀerent tools and platforms produced by diﬀerent vendors.
A data strategy based around the principles of data mesh provides a strong foundation for enterprise scale data and analytics. Its inherent ﬂexibility means it’s well placed to accommodate a wide variety of data applications including traditional reporting and analytics, data science, machine learning and AI.
The Longer Version
There’s an apocryphal story about a Soviet oﬃcial visiting London in the 1980s. During his visit, he toured various parts of the city, including the stock exchange and the London School of Economics. While traveling through the city, he couldn’t help but notice many local bakeries piled high with breads and pastries of all kinds, and little sign of queuing. This was in stark contrast to the Soviet Union, where long queues for basic goods like bread were common. After a while, the Soviet oﬃcial turned to his hosts and asked if he could be introduced to “the person in charge of bread supply for London.”
Economists have long known about ",Technology & Computing 
"The Iowa State Wind Ensemble will host a sensory-friendly concert at 5:30 p.m. Friday in the Tye Recital Hall, located on the ground floor of the Simon Estes Music Hall.
The concert is the first of its kind for the university and the music and theater department, as the university has never before made a commitment to creating a sensory-friendly environment for neurodivergent individuals during a concert or performance.
“Audience members are welcome to express their delight and excitement at any moment during the concert without judgment,” according to the Inside Iowa State website.
The concert is slated to last 45 minutes, with attendees encouraged to explore the beauty of music in a non-judgmental environment.
Michael Golemo, director of bands and professor of music, commented on the concert.
“My grandson, who is five years old, is autistic and non-verbal,” Golemo stated in an email to the Daily. “Because of him, I’ve noticed ‘sensory friendly’ events that perhaps I might not have noticed before–be it a special day at the state fair or perhaps at the zoo. I thought this might be worth trying as an event with our Wind Ensemble. People with autism gravitate towards instrumental music, as the physical repetition is calming.”
Before the event, attendees are invited to explore musical instruments in room 102, starting at 5 p.m.
In the case that an attendee becomes overstimulated, the ISU Wind Ensemble will have a darkened room prepared on the other side of the lobby within the S",art_culture
"First and foremost, Jitsi is a community of developers that are pushing the envelope of video conferencing quality on the web. Come join us!
About Jitsi: Video Conferencing Software.
Jitsi is a set of open-source projects that allows you to easily build and deploy secure video conferencing solutions. At the heart of Jitsi are Jitsi Videobridge and Jitsi Meet, which let you have conferences on the internet, while other projects in the community enable other features such as audio, dial-in, recording, and simulcasting.
A vibrant developer community.
A foundation for amazing products.
Our community members have developed countless projects and products that started with Jitsi code.
Check ‘em out!
Completely free video conferencing.
Jitsi is the best, most secure video conferencing solution available for free to anyone. Try it out and download it for free
Features
- Jitsi Videobridge passes everyone’s video and audio to all participants, rather than mixing them first.
- Better quality, lower latency and if you are running your own service, a much more scalable and inexpensive solution.
- Jitsi is compatible with WebRTC, the open standard for Web communication.
- Advanced video routing support for simulcast, bandwidth estimations, scalable video coding and many others.
- Ubuntu and Debian packages for easy installation.",Technology & Computing 
"Author: fchollet
Date created: 2020/04/27
Last modified: 2023/11/09
Description: Training an image classifier from scratch on the Kaggle Cats vs Dogs dataset.
This example shows how to do image classification from scratch, starting from JPEG image files on disk, without leveraging pre-trained weights or a pre-made Keras Application model. We demonstrate the workflow on the Kaggle Cats vs Dogs binary classification dataset.
We use the image_dataset_from_directory
utility to generate the datasets, and
we use Keras image preprocessing layers for image standardization and data augmentation.
import os
import numpy as np
import keras
from keras import layers
from tensorflow import data as tf_data
import matplotlib.pyplot as plt
First, let's download the 786M ZIP archive of the raw data:
!curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip
!unzip -q kagglecatsanddogs_5340.zip
!ls
% Total % Received % Xferd Average Speed Time Time Time Current
Dload Upload Total Spent Left Speed
100 786M 100 786M 0 0 11.1M 0 0:01:10 0:01:10 --:--:-- 11.8M
CDLA-Permissive-2.0.pdf kagglecatsanddogs_5340.zip
PetImages 'readme[1].txt'
image_classification_from_scratch.ipynb
Now we have a PetImages
folder which contain two subfolders, Cat
and Dog
. Each
subfolder contains image files for each category.
!ls PetImages
Cat Dog
When working with lots of real-world image data, corrupted images are a common occurence. Let's filter out badly-encod",Technology & Computing 
"Configuration Best Practices
This document highlights and consolidates configuration best practices that are introduced throughout the user guide, Getting Started documentation, and examples.
This is a living document. If you think of something that is not on this list but might be useful to others, please don't hesitate to file an issue or submit a PR.
General Configuration Tips
When defining configurations, specify the latest stable API version.
Configuration files should be stored in version control before being pushed to the cluster. This allows you to quickly roll back a configuration change if necessary. It also aids cluster re-creation and restoration.
Write your configuration files using YAML rather than JSON. Though these formats can be used interchangeably in almost all scenarios, YAML tends to be more user-friendly.
Group related objects into a single file whenever it makes sense. One file is often easier to manage than several. See the guestbook-all-in-one.yaml file as an example of this syntax.
Note also that many
kubectl
commands can be called on a directory. For example, you can callkubectl apply
on a directory of config files.Don't specify default values unnecessarily: simple, minimal configuration will make errors less likely.
Put object descriptions in annotations, to allow better introspection.
Note:
There is a breaking change introduced in the YAML 1.2 boolean values specification with respect to YAML 1.1. This is a known issue in Kubernetes. YAML 1.2 only",Technology & Computing 
"Objects In Kubernetes
This page explains how Kubernetes objects are represented in the Kubernetes API, and how you can
express them in .yaml
format.
Understanding Kubernetes objects
Kubernetes objects are persistent entities in the Kubernetes system. Kubernetes uses these entities to represent the state of your cluster. Specifically, they can describe:
- What containerized applications are running (and on which nodes)
- The resources available to those applications
- The policies around how those applications behave, such as restart policies, upgrades, and fault-tolerance
A Kubernetes object is a ""record of intent""--once you create the object, the Kubernetes system will constantly work to ensure that the object exists. By creating an object, you're effectively telling the Kubernetes system what you want your cluster's workload to look like; this is your cluster's desired state.
To work with Kubernetes objects—whether to create, modify, or delete them—you'll need to use the
Kubernetes API. When you use the kubectl
command-line
interface, for example, the CLI makes the necessary Kubernetes API calls for you. You can also use
the Kubernetes API directly in your own programs using one of the
Client Libraries.
Object spec and status
Almost every Kubernetes object includes two nested object fields that govern
the object's configuration: the object spec
and the object status
.
For objects that have a spec
, you have to set this when you create the object,
providing a description of ",Technology & Computing 
"Managing Workloads
You've deployed your application and exposed it via a Service. Now what? Kubernetes provides a number of tools to help you manage your application deployment, including scaling and updating.
Organizing resource configurations
Many applications require multiple resources to be created, such as a Deployment along with a Service.
Management of multiple resources can be simplified by grouping them together in the same file
(separated by ---
in YAML). For example:
apiVersion: v1
kind: Service
metadata:
name: my-nginx-svc
labels:
app: nginx
spec:
type: LoadBalancer
ports:
- port: 80
selector:
app: nginx
---
apiVersion: apps/v1
kind: Deployment
metadata:
name: my-nginx
labels:
app: nginx
spec:
replicas: 3
selector:
matchLabels:
app: nginx
template:
metadata:
labels:
app: nginx
spec:
containers:
- name: nginx
image: nginx:1.14.2
ports:
- containerPort: 80
Multiple resources can be created the same way as a single resource:
kubectl apply -f https://k8s.io/examples/application/nginx-app.yaml
service/my-nginx-svc created
deployment.apps/my-nginx created
The resources will be created in the order they appear in the manifest. Therefore, it's best to specify the Service first, since that will ensure the scheduler can spread the pods associated with the Service as they are created by the controller(s), such as Deployment.
kubectl apply
also accepts multiple -f
arguments:
kubectl apply -f https://k8s.io/examples/application/nginx/nginx-svc.yaml \
-f https://k8s.io/examples",Technology & Computing 
"Time series databases are revolutionizing how we handle and analyze timestamped data. Whether working with IoT sensors, financial data, or monitoring system performance in real-time, a time series database provides the speed, scalability, and efficiency you need to maximize your data.
At KX, we offer unparalleled capabilities for managing vast amounts of time series data, ensuring rapid retrieval and insightful analysis to drive informed decision-making.
What is time series data?
Time series data is a collection of data points gathered or recorded at successive time intervals. It is used to observe and analyze changes over time, helping to identify trends, patterns, and variations.
Many modeling and analytics approaches require evenly spaced intervals between timestamped data points; however, real-world data often has irregular intervals, resulting in gaps or missing values, which necessitate imputation methods to address.
Each timestamped data point is associated with a corresponding data value.
These values can then be visualized in temporal (time-based) charts such as the line chart shown below.
Analytic models can be built from these raw time series data points and used for advanced decision-making. A simple example is a smoothing algorithm for “Exponential Moving Average” (EMA), as shown below.
What is a time series database?
A time series database is optimized to store, retrieve, and manage timestamped data points. These databases are designed to handle high ingestion a",Technology & Computing 
"Note
Access to this page requires authorization. You can try signing in or changing directories.
Access to this page requires authorization. You can try changing directories.
.NET's garbage collector manages the allocation and release of memory for your application. Each time you create a new object, the common language runtime allocates memory for the object from the managed heap. As long as address space is available in the managed heap, the runtime continues to allocate space for new objects. However, memory is not infinite. Eventually the garbage collector must perform a collection in order to free some memory. The garbage collector's optimizing engine determines the best time to perform a collection, based upon the allocations being made. When the garbage collector performs a collection, it checks for objects in the managed heap that are no longer being used by the application and performs the necessary operations to reclaim their memory.
In this section
Reference
- System.GC
- System.GCCollectionMode
- System.GCNotificationStatus
- System.Runtime.GCLatencyMode
- System.Runtime.GCSettings
- GCSettings.LargeObjectHeapCompactionMode
- Object.Finalize
- System.IDisposable",Technology & Computing 
"Note
Access to this page requires authorization. You can try signing in or changing directories.
Access to this page requires authorization. You can try changing directories.
In the common language runtime (CLR), the garbage collector (GC) serves as an automatic memory manager. The garbage collector manages the allocation and release of memory for an application. Therefore, developers working with managed code don't have to write code to perform memory management tasks. Automatic memory management can eliminate common problems such as forgetting to free an object and causing a memory leak or attempting to access freed memory for an object that's already been freed.
This article describes the core concepts of garbage collection.
Benefits
The garbage collector provides the following benefits:
Frees developers from having to manually release memory.
Allocates objects on the managed heap efficiently.
Reclaims objects that are no longer being used, clears their memory, and keeps the memory available for future allocations. Managed objects automatically get clean content to start with, so their constructors don't have to initialize every data field.
Provides memory safety by making sure that an object can't use for itself the memory allocated for another object.
Fundamentals of memory
The following list summarizes important CLR memory concepts:
Each process has its own, separate virtual address space. All processes on the same computer share the same physical memory and the page fi",Technology & Computing 
"Data Factory documentation in Microsoft Fabric
Data factory in Microsoft Fabric provides cloud-scale data movement and data transformation services that allow you to solve the most complex data factory and ETL scenarios. It's intended to make your data factory experience easy to use, powerful, and truly enterprise-grade.
What is Data Factory?
Overview
- What is Data Factory?
- Data Factory demo
- What's new in Data Factory?
- What can I connect to?
- Pricing in Data Factory
- Migrate to Data Factory in Fabric",Technology & Computing 
"Note
Access to this page requires authorization. You can try signing in or changing directories.
Access to this page requires authorization. You can try changing directories.
HLSL is the C-like high-level shader language that you use with programmable shaders in DirectX.
For example, you can use HLSL to write a vertex shader, or a pixel shader, and use those shaders in the implementation of the renderer in your Direct3D application.
Or you could use HLSL to write a compute shader, perhaps to implement a physics simulation. However, if for example you're inclined to write your own convolution operator (for image processing) as HLSL in a compute shader, then you'll get better performance in that scenario if you use Direct Machine Learning (DirectML) instead.
HLSL was created (starting with DirectX 9) to set up the programmable 3D pipeline. You can program the entire pipeline with HLSL instructions.
Where to go next
Programming guide for HLSL
For a conceptual introduction to HLSL, see the Programming guide for HLSL.
The programming guide discusses the different kinds of shader stages, and how to create, compile, optimize, bind, and link shaders.
There you'll also find overviews of, and release notes about, the successive generations of shader model version that have been released, going back as far as HLSL shader model 5.
Reference for HLSL
For HLSL reference documentation, see the Reference for HLSL.
The reference section has a complete listing of the language syntax and of the",Technology & Computing 
"Welcome back to my Beginner’s Guide: Making Your Own Training Videos series. This guide is for anyone interested in learning about making training videos, also known as learning videos.
The Beginner’s Guide to Making Training Videos will give you everything you need to start creating effective video for learning. It’s full of practical processes, guidance, and advice on how to execute learning videos of all sizes using a repeatable and customizable process. If you missed my first post, which covered the first step to making a learning video (set a goal), check it out here. This post focuses on step 2: write the script or the 8-step process.
Step 2: Write the Script
After you’ve set your goal, it’s time to write your script.
Writing for the small screen, especially a screen used to aid in the learning process, is like learning to drive a manual transmission after driving automatic cars for years. The basics are the same, but now there is a new set of steps to follow in order to keep the engine moving in the right direction. For example, you must have a mastery understanding of the writing process, a wide vocabulary, a consistent style, and knowledge of proper grammar and punctuation. To make your writing work on the small screen specifically for learning purposes, you also must master the instructional design process and adhere to its best practices.
And, you need a cursory understanding of screenwriting. When you are creating scripts for learning, you must become well versed ",Technology & Computing 
"Developing service oriented architectures.
After spending the last four years rolling out and maintaining service oriented architectures, it’s my hope that I’ve accumulated enough scars on the topic to approximate wisdom. This is an attempt to share some useful tidbits.
First I’ll briefly describe the two different SOAs I’ve been working on to provide some context, and then launch into the lessons I’ve learned and observations I’ve made.
Digg
At Digg our SOA consisted of many Python backend services communicating with each other as well as being used by our PHP frontend servers and Tornado API servers. They used Apache Thrift for defining the interfaces, clients and as the underlying protocol. We had three major services (user, story, comment), and a handful of smaller ones.
All backend services were hosted on one class of machine–frontend servers were a separate class–and all backend services were deployed in unison from a single Git repository.
SocialCode
Coming off the Digg SOA experience, we changed up a few things when it came to building the SOA at SocialCode. Backend services and APIs stayed in Python but rather than using Thrift we chose HTTP as the protocol, and we implemented the frontend products as JavaScript applications which communicated directly with the HTTP APIs, making the browser a native API client.
APIs are isolated to their own servers for decoupled debugging and scaling, have independent code bases, and are deployed individually.
With these two differe",Technology & Computing 
"Film Studies
Film Studies
The School of Writing, Literature, and Film offers courses in critical studies in film and screenwriting. The film portal serves as a clearinghouse and information resource for term by term of credit-bearing cinema courses and film events for OSU campus and community. If you wish to list a course or cinema event here, please contact Jon Lewis or the School of Writing, Literature, and Film Main Office .
Film in English at OSU has a distinguished history. From 2002 to 2007 OSU/English was home to the Cinema Journal, edited by School of Writing, Literature, and Film faculty member Jon Lewis, representing the Society for Cinema and Media Studies, a professional organization of film and television scholars with more than 3,000 members throughout the world.
Interdisciplinary in approach, film has evolved as a co-discipline of literary studies and as a focused field of study which lends itself to OSU’s aspiration to become a truly global university. In baccalaureate core courses in film, students learn to recognize the genres, traditions, and forms of cinematic expression and the cultural contexts in which they have evolved. Building on new literacies and technologies, they learn skills of critical thinking, writing, and research. Advanced film courses contribute to the Literature and Culture area of the MA in English and to interdisciplinary MAIS programs in CLA. Elective courses in critical film studies are popular elective choices for students majoring o",art_culture
"Zero-copy networking
Did you know...?In many performance-oriented settings, the number of times that data is copied puts an upper limit on how fast things can go. As a result, zero-copy algorithms have long been of interest, even though the benefits achieved in practice tend to be disappointing. Networking is often performance-sensitive and is definitely dominated by the copying of data, so an interest in zero-copy algorithms in networking comes naturally. A set of patches under review makes that capability available, in some settings at least.LWN.net is a subscriber-supported publication; we rely on subscribers to keep the entire operation going. Please help out by buying a subscription and keeping LWN on the net.
When a process transmits a buffer of data, the kernel must format that data into a packet with all of the necessary headers and checksums. Once upon a time, this formatting required copying the data into a single kernel-space buffer. Network hardware has long since gained the ability to do scatter/gather I/O and, with techniques like TCP segmentation offloading, the ability to generate packets from a buffer of data. So support for zero-copy operations has been available at the hardware level for some time.
On the software side, the contents of a file can be transmitted without copying them through user space using the sendfile() system call. That works well when transmitting static data that is in the page cache, but it cannot be used to transmit data that does not",Technology & Computing 
"This is part 2 of a three-part series on interesting abstractions for zero-copy deserialization I’ve been working on over the last year. This part is about making zero-copy deserialization work for more types. Part 1 is about making it more pleasant to work with and can be found here; while Part 3 is about eliminating the deserialization step entirely and can be found here. The posts can be read in any order, though only the first post contains an explanation of what zero-copy deserialization is.
Background
This section is the same as in the last article and can be skipped if you’ve read it
For the past year and a half I’ve been working full time on ICU4X, a new internationalization library in Rust being built under the Unicode Consortium as a collaboration between various companies.
There’s a lot I can say about ICU4X, but to focus on one core value proposition: we want it to be modular both in data and code. We want ICU4X to be usable on embedded platforms, where memory is at a premium. We want applications constrained by download size to be able to support all languages rather than pick a couple popular ones because they cannot afford to bundle in all that data. As a part of this, we want loading data to be fast and pluggable. Users should be able to design their own data loading strategies for their individual use cases.
See, a key part of performing correct internationalization is the data. Different locales1 do things differently, and all of the information on this need",Technology & Computing 
"DataOps (data operations) is a process-oriented methodology for data teams. It encompasses the best qualities of DevOps (development and operations) methodology, such as faster development and easier maintenance, and lets you apply them to big data.
DataOps platforms are used by data teams as centralized command centers that let you orchestrate data pipelines at various stages in one place.
If you’re looking for ways to improve your data practices and make development more efficient, you should consider adopting a DataOps platform. In this guide, you’ll learn about DataOps and the advantages of a DataOps platform as well as how to choose the right one for you.
What Is a DataOps Platform
Many developers are familiar with DevOps, which is a philosophy and a set of tools aimed at streamlining the end to end development cycle and encourages close interaction between developers and others within the organization. This includes things like version control, code reviews, automated testing, CICD, isolated testing environments, and more. The goal is clear: to reduce time to market, ensure flexibility and continuous delivery, improve service quality, and generally, make informed operational decisions.
DataOps has a lot in common with DevOps, but instead of talking about software development, DataOps pertains to data analytics. It’s designed to streamline workflows related to the extraction of valuable insights from data. It also enables productive collaboration both within data teams a",Technology & Computing 
"Special Event Highlight
MicroAI’s Security and Monitoring platform brings AI-enabled closed-loop cyber protection to telecom operators, service providers, and OEMs.
MicroAI’s enterprise grade platform consolidates all components needed for deploying AI-enabled solutions into IT and OT devices and machines.
Live data is leveraged from a variety of devices, machines, and networks. MicroAI’s technology is agnostic to sensor values and types, creating a multi-variant model that utilizes AI inference analysis to generate a wide range of analytics.
Learn MoreFully automatic tuning of the AI model(s) to be deployed. Multidimensional behavioral algorithms produce recursive analysis, training, and processing. This enables a continuous evolution of the AI model that takes place directly on the endpoint.
Learn MoreReal-time, on-demand, health scores provide continuous observability into the health, performance, and security of connected assets. Stakeholders and operators can fast-track health assessments and to identify recurring problems based on historical data and predictive insights.
Learn MoreEmbedded ML algorithms learn the normal operating behavior of an individual machine or a group of machines. Deep federated learning provides the accurate baselines required to rapidly detect performance anomalies of any size or duration.
Learn MoreThe embedding and training of intelligent workflows automate the process of performance alert notifications to ensure accurate dissemination of crit",Technology & Computing 
"Machine Intelligence – Making machines more transparent. An embedded AI platform that provides deep insights into machine and device performance. Full transparency, all the time.
Interested in how MicroAI can benefit you?
Smart Connectivity – A Telecom service orchestration platform that powers novel solutions, creates new revenue streams, optimizes NQoS, and improves sustainability.
The cyber-security landscape is changing….daily. Rapid detection and mitigation of a cyber-attack can mean the difference between a minor disruption or an operational catastrophe. Threat Detection in minutes instead of days.
Digital Factory – Factory performance revolutionized. An AI-enabled plug-and-play solution that delivers predictive manufacturing, predictive maintenance, and improved OEE for manufacturers.
MicroAI Launchpad™ – A complete AI-enablement ecosystem that provides advanced AI capabilities with reduced cost and less complexity.
AIStudio – AI model visualization and tuning. AIStudio provides the means to dynamically demonstrate the capabilities of MicroAI’s AI technologies on your asset data.
A Gen AI Knowledge Management Ecosystem Powered by generative AI, MicroAI’s Intelligent Knowledge Management System (KMS) leverages advanced AI algorithms to efficiently organize, analyze, and retrieve organizational knowledge, transforming vast data landscapes into accessible insights.
Learn more about the AI-enabled methodologies and measurements that MicroAI deploys to deliver next-generati",Technology & Computing 
"A (very) belated follow up to Getting Started with Microformats 2, covering the basics of consuming and using microformats 2 data. Originally posted on waterpigs.co.uk.
More and more people are using microformats 2 to mark up profiles, posts, events and other data on their personal sites, enabling developers to build applications which use this data in useful and interesting ways. Whether you want to add basic support for webmention comments to your personal site, or have ambitious plans for a structured-data-aware-social-graph-search-engine-super-feed-reader, you’re going to need a solid grasp of how to parse and handle microformats 2 data.
Choose a Parser
To turn a web page containing data marked up with microformats 2 (or classic microformats, if supported) into a canonical MF2 JSON data structure, you’ll need a parser.
At the time of writing, there are actively supported microformats 2 parsers available for the following programming languages:
Parsers for various other languages exist, but might not be actively supported or support recent changes to the parsing specification.
There are also various websites which you can use to experiment with microformats markup without having to download a library and write any code:
- My own live-updating php-mf2 sandbox
- The various parser comparison tools hosted on microformats.io
- Aaron Parecki’s pin13.net microformats parser for parsing either URLs or HTML fragments
If there’s not currently a parser available for your language of",Technology & Computing 
"About Microformats
Designed for humans first and machines second, microformats are a set of simple, open data formats built upon existing and widely adopted standards. Instead of throwing away what works today, microformats intend to solve simpler problems first by adapting to current behaviors and usage patterns (e.g. XHTML, blogging).
Microformats are:
- A way of thinking about data
- Design principles for formats
- Adapted to current behaviors and usage patterns (“Pave the cow paths.”)
- Highly correlated with semantic XHTML, AKA the real world semantics, AKA lowercase semantic web, AKA lossless XHTML
- A set of simple open data format standards that many are actively developing and implementing for more/better structured blogging and web microcontent publishing in general.
- “An evolutionary revolution”
- All the above.
Microformats are not:
- A new language
- Infinitely extensible and open-ended
- An attempt to get everyone to change their behavior and rewrite their tools
- A whole new approach that throws away what already works today
- A panacea for all taxonomies, ontologies, and other such abstractions
- Defining the whole world, or even just boiling the ocean
- Any of the above
The microformats principles
- Solve a specific problem
- Start as simple as possible
- Design for humans first, machines second
- Reuse building blocks from widely adopted standards
- Modularity / embeddability
- Enable and encourage decentralized development, content, services
See the wiki f",Technology & Computing 
"The High-Performance
Vector Database Built for Scale
Milvus is an open-source vector database built for GenAI applications. Install with pip, perform high-speed searches, and scale to tens of billions of vectors with minimal performance loss.
Start running Milvus in seconds
from pymilvus import MilvusClient
client = MilvusClient(""milvus_demo.db"")
client.create_collection(
collection_name=""demo_collection"",
dimension=5
)
Deployment Options to Match Your Unique Journey
Milvus Lite
Lightweight, easy to start
- VectorDB-as-a-library runs in notebooks/ laptops with a pip install
- Best for learning and prototyping
Milvus Standalone
Robust, single-machine deployment
- Complete vector database for production or testing
- Ideal for datasets with up to millions of vectors
Milvus Distributed
Scalable, enterprise-grade solution
- Highly reliable and distributed vector database with comprehensive toolkit
- Scale horizontally to handle billions of vectors
- Try Free
Zilliz Cloud (fully managed Milvus)
Hassle-free and 10x faster than Milvus
- Available in both serverless and dedicated cluster
- SaaS and BYOC options for different security and compliance requirements
Learn more about different Milvus deployment models
Plays nicely with all your favorite AI dev tools
Start Building Your GenAI App
Guided with notebooks developed by us and our community
Loved by GenAI developers
Based on our research, Milvus was selected as the vector database of choice (over Chroma and Pinecone). Milvus is an",Technology & Computing 
"Welcome to Milvus Docs!
Here you will learn about what Milvus is, and how to install, use, and deploy Milvus to build an application according to your business need.
Try Managed Milvus For Free!
Zilliz Cloud is hassle-free, powered by Milvus and 10x faster.
Get Started
Install Milvus
Learn how to install Milvus using either Docker Compose or on Kubernetes.
Quick Start
Learn how to quickly run Milvus with sample code.
Bootcamp
Learn how to build vector similarity search applications with Milvus.
Recommended articles
Use
Deploy
What’s new in docs
June 2025 - Milvus 2.6.0 release
- Added guidance on how to use embedding function.
- Added guidance on how to use decay ranker.
- Added guidance on how to add fields to an existing collection.
- Added guidance on how to perform phrase match.
- Added descriptions of IVF_RABITQ index.
Blog
Announcements
Announcing VDBBench 1.0: Open-Source Vector Database Benchmarking with Your Real-World Production Workloads
Discover VDBBench 1.0, an open-source tool for benchmarking vector databases with real-world data, streaming ingestion, and concurrent workloads.",Technology & Computing 
"What is Milvus?
Everything you need to know about Milvus in less than 10 minutes.
What are vector embeddings?
Vector embeddings are numerical representations derived from machine learning models, encapsulating the semantic meaning of unstructured data. These embeddings are generated through the analysis of complex correlations within data by neural networks or transformer architectures, creating a dense vector space where each point corresponds to the ""meaning"" of data objects, such as words in a document.
This process transforms textual or other unstructured data into vectors that reflect semantic similarities—words with related meanings are positioned closer together in this multi-dimensional space, facilitating a type of search known as ""dense vector search."" This contrasts with traditional keyword search, which relies on exact matches and uses sparse vectors. The development of vector embeddings, often stemming from foundational models trained extensively by major tech firms, allows for more nuanced searches that capture the essence of the data, moving beyond the limitations of lexical or sparse vector search methods.
What can I use vector embeddings for?
Vector embeddings can be utilized across various applications, enhancing efficiency and accuracy in various ways. Here are some of the most frequent use cases:
Finding Similar Images, Videos, or Audio Files
Vector embeddings enable searching for similar multimedia content by content rather than just keywords, using Convo",Technology & Computing 
"Welcome to your SEO learning journey!
You'll get the most out of this guide if your desire to learn search engine optimization (SEO) is exceeded only by your willingness to execute and test concepts.
This guide is designed to describe all major aspects of SEO, from finding the terms and phrases (keywords) that can generate qualified traffic to your website, to making your site friendly to search engines, to building links and marketing the unique value of your site.
The world of search engine optimization is complex and ever-changing, but you can easily understand the basics, and even a small amount of SEO knowledge can make a big difference. Free SEO education is also widely available on the web, including in guides like this! (Woohoo!)
Combine this information with some practice and you are well on your way to becoming a savvy SEO.
The basics of search engine optimization
Ever heard of Maslow's hierarchy of needs? It's a theory of psychology that prioritizes the most fundamental human needs (like air, water, and physical safety) over more advanced needs (like esteem and social belonging). The theory is that you can't achieve the needs at the top without ensuring the more fundamental needs are met first. Love doesn't matter if you don't have food.
Our founder, Rand Fishkin, made a similar pyramid to explain the way folks should go about SEO, and we've affectionately dubbed it ""Mozlow's hierarchy of SEO needs.""
Here's what it looks like:
Try Moz Pro, free!
As you can see, the",Technology & Computing 
"What Is SEO? Search Engine Optimization Best Practices
Updated by Chima Mmeje — April 14, 2025.
What is SEO and how does it work?
SEO stands for search engine optimization. It is the practice of improving your website's content, structure, and visibility to rank higher on search engines like Google.
SEO is essential for beginners and businesses. It helps small websites compete with larger ones, drives organic traffic without relying solely on ads, and builds credibility by appearing at the top of search results.
Organic searches drive most website traffic, making SEO one of the most powerful digital marketing strategies. Whether you're running a blog, an online store, or a local business site, understanding SEO can increase your reach and success.
How does SEO work?
SEO works by helping search engines understand your website content and ensuring it appears for relevant searches.
This process involves three key steps: crawling, indexing, and ranking.
Crawling: How search engines discover content
Search engines use automated bots called ""crawlers"" or ""spiders"" to scan websites. These bots follow links from page to page, discovering new and updated content across the web. If your site structure is clear and content is regularly refreshed, crawlers are more likely to find all your pages.
To ensure search bots can effectively crawl your site:
- Use an organized site structure with internal linking
- Create an XML sitemap to guide search engine crawlers
- Regularly update content t",Technology & Computing 
"Why MQTT?
Lightweight and Efficient
MQTT clients are very small, require minimal resources so can be used on small microcontrollers. MQTT message headers are small to optimize network bandwidth.
Bi-directional Communications
MQTT allows for messaging between device to cloud and cloud to device. This makes for easy broadcasting messages to groups of things.
Scale to Millions of Things
MQTT can scale to connect with millions of IoT devices.
Reliable Message Delivery
Reliability of message delivery is important for many IoT use cases. This is why MQTT has 3 defined quality of service levels: 0 - at most once, 1- at least once, 2 - exactly once
Support for Unreliable Networks
Many IoT devices connect over unreliable cellular networks. MQTT’s support for persistent sessions reduces the time to reconnect the client with the broker.
Security Enabled
MQTT makes it easy to encrypt messages using TLS and authenticate clients using modern authentication protocols, such as OAuth.
MQTT Publish / Subscribe Architecture
MQTT in Action
MQTT is used in a wide variety of industries",Technology & Computing 
"FAQ
MQTT is an OASIS standard for IoT connectivity. It is a publish/subscribe, extremely simple and lightweight messaging protocol, designed for constrained devices and low-bandwidth, high-latency or unreliable networks. The design principles are to minimise network bandwidth and device resource requirements whilst also attempting to ensure reliability and some degree of assurance of delivery. These principles also turn out to make the protocol ideal of the “Internet of Things” world of connected devices, and for mobile applications where bandwidth and battery power are at a premium.
MQTT was invented by Dr Andy Stanford-Clark of IBM, and Arlen Nipper of Arcom (now Eurotech), in 1999.
MQTT has been widely implemented across a variety of industries since 1999. A few of the more interesting examples are listed on the Use Case page.
v5.0 and v3.1.1 are now OASIS standards (v3.1.1 has also been ratified by ISO).
Yes. TCP/IP port 1883 is reserved with IANA for use with MQTT. TCP/IP port 8883 is also registered, for using MQTT over SSL.
You can pass a user name and password with an MQTT packet in V3.1 of the protocol. Encryption across the network can be handled with SSL, independently of the MQTT protocol itself (it is worth noting that SSL is not the lightest of protocols, and does add significant network overhead). Additional security can be added by an application encrypting data that it sends and receives, but this is not something built-in to the protocol, in order to keep it",Technology & Computing 
"Take Action for Arts Education
How to Support Arts Education
Now is a vital time to show our support for arts education and federal programs that increase its availability by encouraging legislators to make every effort to provide sustained funding to programs critical to arts education. We urge our members, parents, advocates, and all those who support the arts to reach out to their elected officials in Congress.
Featured Resources
Search for teacher’s guides, lesson plans, advocacy resources, research reports, and more.
EVENTS & PROFESSIONAL LEARNING
Music Industry and Music Education Working Together to Meet New Challenges
NAfME Collegiate Chapter Leadership Training 2025
2025 Collegiate Kickoff Week
About NAfME
NAfME is a collaborative community that supports music educators and advocates for equitable access to music education. With more than 57,000 members teaching millions of students, NAfME advances the music education profession and promotes lifelong experiences in music.
COMMUNITY & GROUPS
STUDENT OPPORTUNITIES
Music In Our Schools Month®
Promote music education during the annual celebration in March
Tri-M® Music Honor Society
The only national honor society for student musicians
Composition Competitions
Annual programs to encourage and recognize student composers
Careers in Music Education
Want to teach music? Advance your career in the classroom? Post a job?
Check out the NAfME Career Center resources.
NAfME Advocacy
NAfME supports music educators and students at ",art_culture
"Welcome to the Computer Vision & Learning research group (CompVis) at the Ludwig Maximilian University of Munich (formerly the Computer Vision Group, Heidelberg University). The group led by Prof. Dr. Björn Ommer conducts fundamental research in Computer Vision and Machine Learning and has been exploring their applications in areas as diverse as the Digital Humanities and the Life Sciences.
We are interested in all aspects of image and video understanding — machine learning approaches that teach machines to reason about and make sense of visual data. In particular, we investigate generative approaches for visual synthesis, invertible deep models for explainable AI, deep metric and representation learning, and self-supervised learning paradigms. These are then also laying the basis for applications such as visual analytics in the Digital Humanities or Neuroscience.
The CompVis group is affiliated with the",Technology & Computing 
"Cross Site Request Forgery (CSRF)
Contributor(s): Dave Wichers, Davisnw, Paul Petefish, Adar Weidman, Michael Brooks, Ahsan Mir, Dc, D0ubl3 h3lix, Jim Manico, Robert Gilbert, Tgondrom, Pawel Krawczyk, Brandt, A V Minhaz, Kevin Lorenzo, Andrew Smith, Christina Schelin, Ari Elias-Bachrach, Sarciszewski, kingthorin, Ben Spatafora, Krishna Madala
Overview
Cross-Site Request Forgery (CSRF) is an attack that forces an end user to execute unwanted actions on a web application in which they’re currently authenticated. With a little help of social engineering (such as sending a link via email or chat), an attacker may trick the users of a web application into executing actions of the attacker’s choosing. If the victim is a normal user, a successful CSRF attack can force the user to perform state changing requests like transferring funds, changing their email address, and so forth. If the victim is an administrative account, CSRF can compromise the entire web application.
Related Security Activities
How to Review Code for CSRF Vulnerabilities
See the OWASP Code Review Guide article on how to review code for CSRF vulnerabilities.
How to Test for CSRF Vulnerabilities
See the OWASP Testing Guide article on how to test for CSRF vulnerabilities.
How to Prevent CSRF Vulnerabilities
See the CSRF Prevention Cheat Sheet for prevention measures.
Listen to the OWASP Top Ten CSRF Podcast.
Most frameworks have built-in CSRF support such as Joomla, Spring, Struts, Ruby on Rails, .NET and others.
Use",Technology & Computing 
"Model Compression
436 papers with code • 2 benchmarks • 3 datasets
Model Compression is an actively pursued area of research over the last few years with the goal of deploying state-of-the-art deep networks in low-power and resource limited devices without significant drop in accuracy. Parameter pruning, low-rank factorization and weight quantization are some of the proposed methods to compress the size of deep networks.
Benchmarks
These leaderboards are used to track progress in Model Compression
Libraries
Use these libraries to find Model Compression models and implementationsMost implemented papers
SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size
(2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car.
Well-Read Students Learn Better: On the Importance of Pre-training Compact Models
Recent developments in natural language representations have been accompanied by large and expensive models that leverage vast amounts of general-domain text through self-supervised pre-training.
GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers
In this paper, we address this challenge, and propose GPTQ, a new one-shot weight quantization method based on approximate second-order information, that is both highly-accurate and highly-efficient.
AMC: AutoML for Model Compression and Acceleration on Mobile Devices
Model compression is a critical technique to efficiently deploy neural network m",Technology & Computing 
"Named Entity Recognition (NER)
954 papers with code • 76 benchmarks • 130 datasets
Named Entity Recognition (NER) is a task of Natural Language Processing (NLP) that involves identifying and classifying named entities in a text into predefined categories such as person names, organizations, locations, and others. The goal of NER is to extract structured information from unstructured text data and represent it in a machine-readable format. Approaches typically use BIO notation, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens.
Example:
( Image credit: Zalando )
Benchmarks
These leaderboards are used to track progress in Named Entity Recognition (NER)
Libraries
Use these libraries to find Named Entity Recognition (NER) models and implementationsSubtasks
- NER
- Nested Named Entity Recognition
- Few-shot NER
- Chinese Named Entity Recognition
- Chinese Named Entity Recognition
- Multilingual Named Entity Recognition
- Medical Named Entity Recognition
- Cross-Domain Named Entity Recognition
- Zero-shot Named Entity Recognition (NER)
- Multi-modal Named Entity Recognition
- Named Entity Recognition In Vietnamese
- Toponym Recognition
- Scientific Concept Extraction
- Multi-Grained Named Entity Recognition
Most implemented papers
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from",Technology & Computing 
"Share this: Google+
K Means Clustering: Partition
This tutorial will introduce you to the heart of Pattern Recognition, unsupervised learning of Neural network called k-means clutering. When User click picture box to input new data (X,Y), the program will make group/cluster the data by minimizing the sum of squares of distances between data and the corresponding cluster centroids. Different color code represent the clusters. This algorithm is a standard and popular algorithm for unsupervised learning of Neural network, Pattern recognitions, Classification analysis, clustering analysis etc.
Topics of this k means tutorials:
What is K-Mean Clustering ?
Numerical Example (hand calculation) ; Spanish translation available here
K Means Clustering Calculator
How the K-Mean Clustering algorithm works ?
Download Code in VB ( Screenshot )
Download code in Matlab
What is the mimimum number of attributes?
What are the applications of K-mean clustering ?
What are the weaknesses of K-Mean Clustering?
Are there any other resources for K-mean Clustering ?
Citation (other papers that has reference to this tutorial)",Technology & Computing 
"Theories of Criminal Law
Any theory of criminal law must explain why criminal law is distinctive—why it is a body of law worthy of separate attention. This entry begins by identifying features of criminal law that make this so (§1). It then asks what functions that body of law fulfills (§2), and what justifies its creation and continued existence (§3). If criminal law should be retained, we must consider its proper limits (§4). We must consider the conditions under which agents should be criminally responsible for whatever falls within those limits (§5). And we must ask which rules of procedure and evidence should govern efforts to establish criminal responsibility (§6). The focus of this entry is Anglo-American criminal law and scholarship thereon. Many of the questions raised, and many of the answers considered, are nonetheless of general application.
- 1. Features of Criminal Law
- 2. Functions of Criminal Law
- 3. Justifications of Criminal Law
- 4. The Limits of Criminal Law
- 5. Criminal Responsibility
- 6. Criminal Procedure and Evidence
- Bibliography
- Academic Tools
- Other Internet Resources
- Related Entries
1. Features of Criminal Law
The life of the criminal law begins with criminalization. To criminalize an act-type—call it \(\phi\)ing—is to make it a crime to commit tokens of that type. Many claim that if it is a crime to \(\phi\) then \(\phi\)ing is legally wrongful—it is something that, in the eyes of the law, ought not to be done (Hart 1994, 27; Gardner 200",Philosophy & Religion 
"Legal Positivism
Legal positivism is the thesis that the existence and content of law depends on social facts and not on its merits. The English jurist John Austin (1790–1859) formulated it thus:
The existence of law is one thing; its merit and demerit another. Whether it be or be not is one enquiry; whether it be or be not conformable to an assumed standard, is a different enquiry. (1832 [1995: 157])
The positivist thesis does not say that law’s merits are unintelligible, unimportant, or peripheral to the philosophy of law. It says that they do not determine whether laws or legal systems exist. Whether a society has a legal system depends on the presence of certain structures of governance, not on the extent to which it satisfies ideals of justice, democracy, or the rule of law. What laws are in force in that system depends on what social standards its officials recognize as authoritative; for example, legislative enactments, judicial decisions, or social customs. The fact that a policy would be just, wise, efficient, or prudent is never sufficient reason for thinking that it is actually the law, and the fact that it is unjust, unwise, inefficient or imprudent is never sufficient reason for doubting it. According to positivism, law is a matter of what has been posited (ordered, decided, practiced, tolerated, etc.). Austin thought the thesis “simple and glaring”. While it is probably the dominant view among analytically inclined philosophers of law, it is also the subject of ",Philosophy & Religion 
"Games
Apps
Books
Kids
google_logo Play
Games
Apps
Books
Kids
none
search
help_outline
Sign in with Google
play_apps
Library & devices
payment
Payments & subscriptions
reviews
My Play activity
redeem
Offers
Play Pass
Personalization in Play
settings
Settings
Privacy Policy
•
Terms of Service
Games
Apps
Books
Kids
Google Meet
Google LLC
4.4
star
11.5M reviews
info
10B+
Downloads
PEGI 3
info
Install
Share
Add to wishlist
About this app
arrow_forward
Google Meet is a high-quality video calling app designed to help you have meaningful and fun interactions with your friends, family, colleagues, and classmates, wherever they are.
Meet lets you connect in whatever way works for you: Call someone spontaneously, schedule time together, or send a video message that they can watch and respond to later.
Meet also helps you get things done. It integrates with other Google Workspace apps like Gmail, Docs, Slides, and Calendar, and offers a number of features to help you run smooth and engaging meetings, like noise cancellation, in-call chat, recordings, and more.*
Features to look forward to:
Make spontaneous calls or host video meetings with your friends and colleagues, all in one app.
Enjoy one-on-one video calls for up to 24 hours and host meetings for up to 60 minutes and 100 people at no cost.
Follow along in your preferred language with real-time translated captions in over 70 languages.
Use in-call chat to share ideas, ask questions, or provide feedback without interrupting the flow ",Technology & Computing 
"View Fiscal policies grouped by subject
FI0105 – General Statement on University Fiscal Policy
To provide University of Tennessee employees with a basic overview of the University’s fiscal policy and procedure development.
Full Policy >FI0110 – Budgets
To provide policies and procedures relating to budgets and budgetary control.
Full Policy >FI0112 – Budgeting Current Unrestricted Funds
To provide policies and procedures relating to budgets and budgetary control of current unrestricted funds.
Full Policy >FI0115 – Reconciling and Reviewing Departmental Ledgers
To establish fiscal responsibility for reconciling and reviewing University funds.
Full Policy >FI0120 – Records Management
To provide guidance for identifying, maintaining, preserving and destroying university records while complying with applicable laws and regulations.
Full Policy >FI0125 – Conflict of Interest [replaced by GE0002]
FI0130 – Fraud, Waste and Abuse
The purpose of this policy is to define fraud, waste, and abuse and the procedures and responsibilities for preventing, reporting, investigating, and resolving known or suspected instances of such behavior.
Full Policy >FI0131 – Cash Shortages and Property Losses
To provide reporting requirements for cash shortages and losses of equipment or other university property when employee involvement is not suspected.
Full Policy >FI0135 – Commercial Insurance
To provide information related to the university’s insurance coverages, restrictions on procuring insurance",economics_finance
"Cross-site request forgery (CSRF)
In this section, we'll explain what cross-site request forgery is, describe some examples of common CSRF vulnerabilities, and explain how to prevent CSRF attacks.
What is CSRF?
Cross-site request forgery (also known as CSRF) is a web security vulnerability that allows an attacker to induce users to perform actions that they do not intend to perform. It allows an attacker to partly circumvent the same origin policy, which is designed to prevent different websites from interfering with each other.
Labs
If you're already familiar with the basic concepts behind CSRF vulnerabilities and just want to practice exploiting them on some realistic, deliberately vulnerable targets, you can access all of the labs in this topic from the link below.
What is the impact of a CSRF attack?
In a successful CSRF attack, the attacker causes the victim user to carry out an action unintentionally. For example, this might be to change the email address on their account, to change their password, or to make a funds transfer. Depending on the nature of the action, the attacker might be able to gain full control over the user's account. If the compromised user has a privileged role within the application, then the attacker might be able to take full control of all the application's data and functionality.
How does CSRF work?
For a CSRF attack to be possible, three key conditions must be in place:
- A relevant action. There is an action within the application that the at",Technology & Computing 
"Machine learning is being used extensively in fields like computer vision, natural language processing, and data mining. In many modern applications that are being built, we usually derive a classifier or a model from an extremely large data set. The accuracy of the training algorithms is directly proportional to the amount of data we have. So most modern data sets often consist of a large number of examples, each of which is made up of many features. Having access to a lot of examples is very useful in extracting a good model from the data, but managing a large number of features is usually a burden to our algorithm. The thing is that some of these features may be irrelevant, so it’s important to make sure the final model doesn’t get affected by this. If the feature sets are complex, then our algorithm will be slowed down and it will be very difficult to find the global optimum. Given this situation, a good way to approach it would be to reduce the number of features we have. But if we do that in a careless manner, we might end up losing information. We want to reduce the number of features while retaining the maximum amount of information. Now what does it have to with manifold learning? Why do we care about reducing the dimensionality of our data?
First of all, what is “dimensionality”?
Dimensionality refers to the minimum number of coordinates needed to specify any point within a space or an object. So a line has a dimensionality of 1 because only one coordinate is needed",Technology & Computing 
"Named Entity Recognition
Tagging names, concepts or key phrases is a crucial task for natural language understanding pipelines. Prodigy lets you label NER training data or improve an existing model’s accuracy.
Quickstart
I want to train a new model with new categories from scratch.
If you’re starting from scratch, you can use the ner.manual
recipe with
raw text and one or more labels and start highlighting entity spans. See the
docs on fully manual annotation for an example. To make the process
faster and more efficient, you can also use patterns to
pre-highlight entities, so you only need to correct them. If you know that
“Barack Obama” is pretty much always a PERSON
, you can write a pattern for
that. If you have a spaCy pipeline that’s already
doing an okay job at predicting some of your entities, you can use
ner.correct
to pre-highlight them for you, so you only have to correct
the suggestions and add new categories.
Once you’ve collected a dataset of maybe a few hundred annotations, you can run
training experiments to see if you’re on the right track. The
train
recipe takes one or more Prodigy datasets, trains a model and
outputs statistics and results. You can also use data-to-spacy
to export
data in spaCy’s format to use with
spacy train
, or db-out
to export your
annotations to use in any other process or application.
I want to improve an existing spaCy NER model.
If you want to improve and correct an existing model on your data, you can use
the ner.correct
recipe to ",Technology & Computing 
"Installations
194 articles
Art installations are three-dimensional works of art that are meant to transform the viewer’s perception of space. They fall under an artistic genre of contemporary art and can be temporary or permanent, often designed to become an alternative reflection to more traditional art forms.
Art installations gained initial traction in the 1970s, with the ranks of Kurt Schwitters and Marcel Duchamp at the forefront of this contemporary art genre. With engineering elements incorporated into the art, these works transform into an immersive experience the viewer could enjoy in both physical and visual sense.",art_culture
"Epidemiology
The Johns Hopkins Bloomberg School of Public Health was ranked #1 in Epidemiology by peers in the 2025 U.S. News & World Report Rankings. We improve the public’s health by training epidemiologists and advancing knowledge concerning the causes and prevention of disease and the promotion of health.
Epidemiology Headlines
Tens of Thousands of Heart Attacks and Strokes Could Be Avoided Each Year if Cholesterol-Lowering Drugs Were Used According to Guidelines
New study details gaps between actual and recommended use of statins and other lipid-lowering drugs—and estimates public health benefits of closing those gaps
Is There an Autism Epidemic?
Autism diagnosis rates have risen over the past two decades—but why? An autism researcher explains what's behind the increase.
Frontline Research, Real Progress
From job sites to city streets, courtrooms to EHRs, five stories show public health’s reach and impact.
Research Saves Lives
Epidemiology plays an essential role to ensure the public's health through research and practice. Without research—at Johns Hopkins and at thousands of other universities, medical schools, and research institutions across the nation—scientific breakthroughs suffer, and the lifesaving treatments of tomorrow are at risk.
Finding the Best Recipe for Health
For the past 25 years, the DASH diet—developed by Johns Hopkins researcher Lawrence Appel—has helped patients lower their blood pressure and avoid heart disease.
Long-Running Surveys Help Researcher",Health & Medicine 
"How the Golang concurrent GC achieves low latencies in real-time systems: a visualization of the algorithm and an empirical comparison with other languages.
Each day, Pusher sends billions of messages in real-time: source to destination in less than 100ms. How do we achieve this? A key factor is Go’s low-latency garbage collector.
Garbage collectors are a bane of real-time systems because they pause the program. So when designing our new message bus, we chose the language carefully. Go emphasizes low latency, but we were wary: does Go really achieve this? If so, how?
In this blog post, we’ll look at Go’s garbage collector. We’ll see how it works (the tricolor algorithm), why it works (achieving such short GC pauses), and most importantly, whether it works (benchmarking these GC pauses, and comparing them with other languages).
The system we have been building is a pub/sub message bus with an in-memory store of published messages. This version in Go is a rewrite of our first implementation in Haskell. We stopped work on our Haskell version in May, after discovering fundamental latency problems with GHC’s garbage collector.
We published a detailed post-mortem of the Haskell implementation. The fundamental problem was that GHC’s pause times were proportional to the size of the working set (that is, the number of objects in memory). In our case, we have many objects in memory, which led to pause times of hundreds of milliseconds. This is a problem with any GC that blocks the prog",Technology & Computing 
"Evolutionary biology
Evolutionary biology is the study of the origin and evolution of species. Evolutionary biologists research the processes and causes of evolution and biodiversity, determine relationships between species, and document the history of evolution. Thus evolutionary biology includes the fields of cladistics, phylogenetics, and molecular evolution. Additionally population geneticists study the causes of genetic variation and ecolological geneticists consider the effects of the environment on species.
This scientific field is related to other areas of biology. To learn about past evolution paleontologists examine the fossil record, embryologists study developmental processes, and zoologists learn how various animals work. Evolutionary biologist Theodosius Dobzhansky wrote an essay titled ""Nothing in Biology Makes Sense Except in the Light of Evolution.""[1]
Evolutionary biology became a recognized field of study in the 1930's when it was realized that evolution could be explained by Mendelian genetics, in a model of evolution termed the modern synthesis. Many universities have evolutionary biology departments. Evolutionary biology has a practical application in species conservation.
Evolutionary Biology is the name of an influential textbook on the subject written by biologist Douglas Futuyma in 1942.
Significant evolutionary biologists[edit]
- Charles Darwin
- Richard Dawkins
- Theodosius Dobzhansky
- Niles Eldredge
- Douglas Futuyma
- Stephen Jay Gould
- Julian ",Science & Research 
"Welcome to Remix
Focused on web standards and modern web app UX, you’re simply going to build better websites
Remix is a full stack web framework that lets you focus on the user interface and work back through web standards to deliver a fast, slick, and resilient user experience. People are gonna love using your stuff.
export async function loader({ request }) {
return getProjects();
}
export async function action({ request }) {
const form = await request.formData();
return createProject({
title: form.get(""title""),
});
}
export default function Projects() {
const projects = useLoaderData();
const { state } = useNavigation();
const busy = state === ""submitting"";
return (
<div>
{projects.map((project) => (
<Link to={project.slug}>
{project.title}
</Link>
))}
<Form method=""post"">
<input name=""title"" />
<button type=""submit"" disabled={busy}>
{busy
? ""Creating...""
: ""Create New Project""}
</button>
</Form>
</div>
);
}
Testimonials
While you were waiting for your static site to build, distributed web infrastructure got really good. Break through the static.
Remix is a seamless server and browser runtime that provides snappy page loads and instant transitions by leveraging distributed systems and native browser features instead of clunky static builds. Built on the Web Fetch API (instead of Node) it can run anywhere. It already runs natively on Cloudflare Workers, and of course supports serverless and traditional Node.js environments, so you can come as you are.
Page speed is only on",Technology & Computing 
"MapReduce: Simplified Data Processing on Large Clusters Jeffrey Dean and Sanjay Ghemawat
Abstract
MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper.
Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system.
Our implementation of MapReduce runs on a large cluster of commodity machines and is highly scalable: a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google's clusters every day.
Appeared in: OSDI'04: Sixth Symposium on Operating System Design and Implementation, San Francisco, CA, December, 2004.
Download",Technology & Computing 
"MapReduce: Simplified Data Processing on Large Clusters
Abstract
MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper.
Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system.
Our implementation of MapReduce runs on a large cluster of commodity machines and is highly scalable: a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google's clusters every day.
HTML Slides",Technology & Computing 
"PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression
NeurIPS, 2024There has been significant interest in ""extreme"" compression of large language models (LLMs), i.e. to 1-2 bits per parameter, which allows such models to be executed efficiently on resource-constrained devices. Existing work focused on improved one-shot quantization techniques and weight representations; yet, purely post-training approaches are reaching diminishing returns in terms of the accuracy-vs-bit-width trade-off. State-of-the-art quantization methods such as QuIP# and AQLM include fine-tuning (part of) the compressed parameters over a limited amount of calibration data; however, such fine-tuning techniques over compressed weights often make exclusive use of straight-through estimators (STE), whose performance is not well-understood in this setting. In this work, we question the use of STE for extreme LLM compression, showing that it can be sub-optimal, and perform a systematic study of quantization-aware fine-tuning strategies for LLMs. We propose PV-Tuning - a representation-agnostic framework that generalizes and improves upon existing fine-tuning strategies, and provides convergence guarantees in restricted cases. On the practical side, when used for 1-2 bit vector quantization, PV-Tuning outperforms prior techniques for highly-performant models such as Llama and Mistral. Using PV-Tuning, we achieve the first Pareto-optimal quantization for Llama-2 family models at 2 bits per par",Technology & Computing 
"Note
Go to the end to download the full example code. or to run this example in your browser via JupyterLite or Binder
Comparison of Manifold Learning methods#
An illustration of dimensionality reduction on the S-curve dataset with various manifold learning methods.
For a discussion and comparison of these algorithms, see the manifold module page
For a similar example, where the methods are applied to a sphere dataset, see Manifold Learning methods on a severed sphere
Note that the purpose of the MDS is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space.
# Authors: The scikit-learn developers
# SPDX-License-Identifier: BSD-3-Clause
Dataset preparation#
We start by generating the S-curve dataset.
import matplotlib.pyplot as plt
# unused but required import for doing 3d projections with matplotlib < 3.2
import mpl_toolkits.mplot3d # noqa: F401
from matplotlib import ticker
from sklearn import datasets, manifold
n_samples = 1500
S_points, S_color = datasets.make_s_curve(n_samples, random_state=0)
Let’s look at the original data. Also define some helping functions, which we will use further on.
def plot_3d(points, points_color, title):
x, y, z = points.T
fig, ax = plt.subplots(
figsize=(6, 6),
facecolor=""white"",
tight_layout=True,
subplot_kw={""projecti",Technology & Computing 
"2.2. Manifold learning#
Manifold learning is an approach to non-linear dimensionality reduction. Algorithms for this task are based on the idea that the dimensionality of many data sets is only artificially high.
2.2.1. Introduction#
High-dimensional datasets can be very difficult to visualize. While data in two or three dimensions can be plotted to show the inherent structure of the data, equivalent high-dimensional plots are much less intuitive. To aid visualization of the structure of a dataset, the dimension must be reduced in some way.
The simplest way to accomplish this dimensionality reduction is by taking a random projection of the data. Though this allows some degree of visualization of the data structure, the randomness of the choice leaves much to be desired. In a random projection, it is likely that the more interesting structure within the data will be lost.
To address this concern, a number of supervised and unsupervised linear dimensionality reduction frameworks have been designed, such as Principal Component Analysis (PCA), Independent Component Analysis, Linear Discriminant Analysis, and others. These algorithms define specific rubrics to choose an “interesting” linear projection of the data. These methods can be powerful, but often miss important non-linear structure in the data.
Manifold Learning can be thought of as an attempt to generalize linear frameworks like PCA to be sensitive to non-linear structure in data. Though supervised variants exist, the typ",Technology & Computing 
"SE Radio is a weekly software engineering podcast for professional software developers. Our goal is to be a lasting educational resource, not a newscast. Since 2006, we've been talking to experts from throughout the software engineering universe about the range of topics that matter to professional developers. Brought to you by IEEE Computer Society and IEEE Software magazine.",Technology & Computing 
"NB-IoT Devices
NB-IoT Devices: Effortless Connectivity and Exceptional Coverage
Our NB-IoT devcies are designed for simplicity and efficiency, offering:
- Diverse Sensor Range: With a wide variety of sensors available, you can easily find the perfect match for any monitoring need, from environmental to movement detection.
- Expansive Network Coverage: Benefit from the massive NB-IoT network coverage, ensuring reliable data transmission even in remote areas or challenging environments.
- Gateway-Free Operation: Eliminate the need for additional hardware. These sensors connect directly to the NB-IoT network, simplifying your setup.
- Rapid Integration with Telemetry2U: Enjoy quick and straightforward integration with the Telemetry2U platform, streamlining your data collection and analysis process.
- Smartphone Configuration: Configure and manage your NB-IoT devices effortlessly using a smartphone, making setup and adjustments a breeze.
- Long Battery Life: With impressive battery life, these NB-IoT devicers are designed for long-term deployment, reducing maintenance and ensuring consistent performance.
Explore our NB-IoT devices and experience the future of effortless and robust IoT connectivity.",Technology & Computing 
"If you’re thinking of becoming a software engineer (or developer – they’re very similar, as we’ll talk about below) … this guide will teach you all about it.
You’ll get a complete step-by-step path for how you’ll achieve that goal.
Enjoy your 15-step software engineer roadmap!
Is this you?
You love to crack tough problems…
As a software engineer, you’ll use your intelligence and creative ability to tackle difficult problems and provide a ton of value by solving them for your employer or client.
You enjoy immersing yourself in the study of a topic…
To become a software engineer, you need to learn a number of complex skills. You’ll also never stop learning after that. If you’re all about expanding your knowledge and bettering your skills, this could be the perfect career path for you.
You want to work with others to achieve ambitious goals together…
The basement-dwelling developer working on coding problems all on his own is a myth. Most of the time you’ll have to lead others or collaborate with them on a solution. You’ll also actively take part in meetings and do presentations about your work.
And you’d like to make more money than most of your peers by doing that…
Then why not become a software developer or engineer?
What is a software engineer, exactly?
A software engineer is a computer expert who uses engineering principles to design, create, debug, test, deploy and maintain the systems and code of software applications.
Working in tandem with a team, software engineers cre",Technology & Computing 
"Advanced Full-Text Search Capabilities
Powered by Lucene™, Solr enables powerful matching capabilities including phrases, wildcards, joins, grouping and much more across any data type
Powered by Lucene™, Solr enables powerful matching capabilities including phrases, wildcards, joins, grouping and much more across any data type
Solr is proven at extremely large scales the world over
Solr uses the tools you use to make application building a snap
Solr ships with a built-in, responsive administrative user interface to make it easy to control your Solr instances
Need more insight into your instances? Solr publishes loads of metric data via JMX
Built on the battle-tested Apache Zookeeper, Solr makes it easy to scale up and down. Solr bakes in replication, distribution, rebalancing and fault tolerance out of the box.
Solr's is designed to adapt to your needs all while simplifying configuration
Want to see your updates now? Solr takes advantage of Lucene's Near Real-Time Indexing capabilities to make sure you see your content when you want to see it
Solr publishes many well-defined extension points that make it easy to plugin both index and query time plugins. Of course, since it is Apache-licensed open source, you can change any code you want!
Use Solr's data-driven schemaless mode when getting started and then lock it down when it's time for production.
Solr ships with optional plugins for indexing rich content (e.g. PDFs, Word), language detection, search results clustering and m",Technology & Computing 
"Users who have completed the tutorial are encouraged to review the other documentation available.
Solr generates JavaDocs for all included code in each release. Copies of this documentation for every release can be found online:
Additional documentation can be found on the Solr Community Wiki or the various books published about Solr.
If you want to run Solr on Kubernetes, the easiest way to get started is via installing the Helm charts below.
If you have a Solr book that you would like to see listed here, please edit this website and submit a Pull Request.
Doug Turnbull, John Berryman and Manning Publications are proud to announce Relevant Search.
This book demystifies relevance work and shows you that a search engine is a programmable relevance framework. You'll learn how to apply Elasticsearch or Solr to your business' unique ranking problems. The book demonstrates how to program relevance and how to incorporate secondary data sources, taxonomies, text analytics, and personalization. By the end, you’ll be able to achieve a virtuous cycle of provable, measurable relevance improvements over a search product’s lifetime.
Buy here (Use code relsepc for 40% discount)
David Smiley, Eric Pugh, Kranti Parisa, and Matt Mitchell are proud to finally announce the book “Apache Solr Enterprise Search Server, Third Edition” by Packt Publishing. You can find links to buy it at Packt’s site & Amazon from our book’s official website: solrenterprisesearchserver.com. You'll find a useful sear",Technology & Computing 
"Every CVE that is detected by a software scanner is by definition already public knowledge. That means the Solr PMC and the rest of the world probably already know about it.
To find a path forward in addressing a detected CVE we suggest the following process for fastest results:
Jira is for discussing specific development modifications. Any Jira that contains only scan report output, or references multiple dependencies at the same time is likely to be ignored/closed. The large number of folks sending us reports of things that are already known is a serious drag on our (volunteer) time so please search Jira before opening a new issue.
The Solr PMC greatly appreciates reports of new security vulnerabilities found in Solr itself or demonstrations of exploiting vulnerabilities via dependencies. It is important not to publish a previously unknown exploit, or exploit demonstration code on public mailing lists. Please disclose new exploits responsibly by following these ASF guidelines for reporting. The contact email for reporting newly discovered exploits in Solr is security@solr.apache.org.
Before reporting a new exploit ensure that you have tested it against an instance of Solr that is running a supported version and has been properly configured with:
Since the process of checking whether CVEs in dependencies of Solr affect your Solr deployment is tedious and error-prone, we are experimenting with sharing information about advisories that are known (not) to affect Solr in a machi",Technology & Computing 
"What is Cosine Annealing?
In the vast landscape of optimisation algorithms lies a hidden gem that has been gaining increasing attention in recent years: cosine annealing. Optimisation algorithms are the backbone of numerous machine learning and deep learning applications, ranging from image classification to natural language processing. However, the quest for more efficient and effective optimisation techniques continues, driving researchers to explore innovative approaches such as cosine annealing.
Table of Contents
It is often considered an enhancement to traditional optimisation methods like Stochastic Gradient Descent (SGD) and Adam. It offers a unique perspective on navigating the complex optimisation landscapes encountered in various machine learning tasks. By leveraging the principles of annealing borrowed from metallurgy, cosine annealing orchestrates a graceful descent through the optimisation space, gracefully adjusting learning rates to ensure optimal convergence.
This blog post aims to shed light on its inner workings, practical applications, implementation strategies, and prospects. Through this exploration, we strive to unravel the mysteries and provide readers with a comprehensive understanding of its potential to revolutionise optimisation in machine learning.
Understanding Cosine Annealing
Cosine annealing represents a sophisticated yet elegant approach to optimization, drawing inspiration from the principles of annealing in metallurgy and the cosine function",Technology & Computing 
"Use this tag for Azure Cognitive services questions including Vision, Speech, Language, Decision & Web Search APIs and SDKs.
Useful Resources:
Use this tag for Azure Cognitive services questions including Vision, Speech, Language, Decision & Web Search APIs and SDKs.
Useful Resources:",Technology & Computing 
"CUDA (Compute Unified Device Architecture) is a parallel computing platform and programming model for NVIDIA GPUs (Graphics Processing Units). CUDA provides an interface to NVIDIA GPUs through a variety of programming languages, libraries, and APIs.
CUDA is Nvidia's parallel computing platform and programming model for GPUs (Graphics Processing Units). CUDA provides an interface to Nvidia GPUs through a variety of programming languages, libraries, and APIs. Before posting CUDA questions, please read ""How to get useful answers to your CUDA questions"" below.
CUDA has an online documentation repository, updated with each release, including references for APIs and libraries; user guides for applications; and a detailed CUDA C/C++ Programming Guide.
The CUDA platform enables application development using several languages and associated APIs, including:
There also exist third-party bindings for using CUDA in other languages and programming environments, such as Managed CUDA for .NET languages (including C#).
You should ask questions about CUDA here on Stack Overflow, but if you have bugs to report you should discuss them on the CUDA forums or report them via the registered developer portal. You may want to cross-link to any discussion here on SO.
The CUDA execution model is not multithreading in the usual sense, so please do not tag CUDA questions with multithreading unless your question involves thread safety of the CUDA APIs, or the use of both normal CPU multithreading and CUDA",Technology & Computing 
"In machine learning, grid search refers to multiple runs to find the optimal value of parameter(s)/hyperparameter(s) of a model, e.g. mtry for random-forest or alpha, beta, lambda for glm, or C, kernel and gamma for SVM.
In machine learning, grid search refers to multiple runs to find the optimal value of parameter(s)/hyperparameter(s) of a model, e.g. mtry for random-forest or alpha, beta, lambda for glm, or C, kernel and gamma for SVM.",Technology & Computing 
"SystemVerilog is a unified hardware design, specification, and verification language based on extensions to Verilog.
SystemVerilog is a unified hardware description language (hdl) and verification language. Its two primary uses are to describe logical circuits targeted towards field-programmable gate arrays (FPGAs - fpga), programmable logic devices (PLD) and application-specific integrated circuits (ASICs - asic) and to develop tests and environments to validate these circuit descriptions.
It is defined by IEEE 1800-2023 and with the exception of keywords, is a backwards-compatible superset of verilog, IEEE 1364-2005.",Technology & Computing 
"Verilog is a hardware description language (HDL) used to model electronic systems. It is most commonly used in the design and verification of digital circuits at the register-transfer level of abstraction.
From Wikipedia:
Verilog, standardized as IEEE 1364, is a hardware description language (HDL) used to model electronic systems. It is most commonly used in the design and verification of digital circuits at the register-transfer level of abstraction.
Tag usage
- ALWAYS post your Verilog code as a full module we can copy and run.
- ALWAYS post your simulation results, clearly showing error messages and signal names in waveform images.
Logic synthesis
Automated tools are able to translate Verilog code meeting certain restrictions into a gate-level description of the circuit that can then be implemented in an FPGA or IC. The task is in some ways similar to the task of a compiler for conventional programming languages, but such tools for Verilog are known as ""synthesis tools"". Language constructs and coding styles that can be processed by synthesis tools are known as ""synthesizable"". Constructs that are not synthesizable may be used for testbenches, reference models, or debug instrumentation.
When asking a question, please specify whether you are looking for a synthesizable solution.
Sometimes referred to as Verilog HDL, not to be confused with VHDL.
Standardization
Verilog was initially a proprietary system developed by Gateway Design Automation (later acquired by Cadence Desig",Technology & Computing 
"Svelte
web development for the rest of us
get startedattractively thin, graceful and stylish
Svelte is a UI framework that uses a compiler to let you write breathtakingly concise components that do minimal work in the browser, using languages you already know — HTML, CSS and JavaScript. It’s a love letter to web development.
But don’t take our word for it. Developers consistently rank Svelte as the framework they’re most excited about using.
used by companies you’ve heard of
join our friendly community
Our sister organisation, Svelte Society, organises events around the globe. Find your chapter and join us in our Discord server.
Backed by Vercel and countless donors, developed by full-time and part-time maintainers, Svelte is here to stay.
Rich-HarrisConduitrydummdidummtrueadmtanhauhaubenmccannpaoloricciutiPuruVJbaseballyamagtm-nayanDreaminDaniSwatinemjacwrightlukeedmindronesmrkishiadigubapngwnngtr6788geoffrichekhaledignatiusmb7nikEmilTholinnavoriteantonyOcean-OStivaczxbodyabtk5hjchesPaulBGDdominikgpushkinehalfnelsonGarrettGeorgebtakitabrunnerhTehShrikeFWeinbcolincaseyjamesbirtlesevs-chrisfcrozatierjacobmischkabluwyarxpoeticawackbyte DripsDatawrapperVercelCohereDabbleMonogramFrontend MastersGitHub SponsorsHugging FaceThreema Open Source FundPinturaCodesmithRasterAvastJeff Moexyflow - React Flow | Svelte FlowINVISRMattSanityMetafyChangelogClancy DigitalKohei YoshinoKenoxa GmbHLevel Up TutorialsThe PuddingJason HetheringtonZev AverbachDonovan DikaiomultiEvidenceWonderTax Labsn8",Technology & Computing 
"Svelte 5 is alive
Our biggest release yet
After almost 18 months of development, comprising thousands of commits from dozens of contributors, Svelte 5 is finally stable.
It’s the most significant release in the project’s history. Svelte 5 is a ground-up rewrite: your apps will be faster, smaller and more reliable. You’ll be able to write more consistent and idiomatic code. For newcomers to the framework, there’s less stuff to learn.
Despite all that, Svelte is almost completely backwards-compatible with Svelte 4 — for the majority of users, the initial upgrade will be completely seamless:
{
""devDependencies"": {
""@sveltejs/vite-plugin-svelte"": ""^3.0.0"",
""svelte"": ""^4"",
""@sveltejs/vite-plugin-svelte"": ""^4.0.0"",
""svelte"": ""^5"",
// …
}
}
What is Svelte?
Svelte is a framework for building user interfaces on the web. It uses a compiler to convert declarative component code, based on HTML, CSS and JavaScript, into tightly optimised JavaScript.
Because the compiler shifts a lot of the work out of the browser and into npm run build
, Svelte apps are small and fast. But beyond that, Svelte is designed to be an enjoyable and intuitive way to build apps: it prioritises getting stuff done.
The team behind Svelte also maintains SvelteKit, an application framework that handles routing and data loading and server-side rendering and all the gory details that go into building modern websites and apps.
What changed, and why?
For one thing, we’ve overhauled our website. You can read more about t",Technology & Computing 
"High-Performance, Scalable Time-Series Database for Industrial IoT
From predictive maintenance and remote monitoring to AI and ML, the latest industrial applications all have one thing in common — a reliance on large, high quality datasets. And no database better helps you gain real-time insights than TDengine™, the only time-series database designed for Industrial IoT.
Instances worldwide
GitHub stars
Global customers
Trusted by 500+ Industrial Customers Worldwide
10x Higher Performance at Any Scale
With its distributed scalable architecture that grows together with your business, TDengine can store and process massive datasets up to 10.6x faster than other TSDBs — all while providing the split-second latency that your real-time visualization and reporting apps demand.
High Performance Distributed Design90% Reduction of Data Storage Costs
With its unique design and data model, TDengine provides the most cost-effective solution for storing your operations data, including tiered storage, S3, and 10:1 data compression, ensuring that you can get valuable business insights from your data without breaking the bank.
Tiered Storage High CompressionZero-Code Data Consolidation Across Sites
With built-in connectors for a wide variety of industrial sources — MQTT, Kafka, OPC, PI System, and more — TDengine delivers zero-code data ingestion and extract, transform, and load (ETL) in a centralized platform that acts as a single source of truth for your business.
Data Consolidation Data So",Technology & Computing 
"If you’ve worked with sklearn before, you’ve encountered learning rates in algorithms like GradientBoostingClassifier
or SGDClassifier
. These typically use fixed learning rates throughout training. This approach works reasonably well for simpler models because their optimization surfaces are generally less complex.
However, deep neural networks present more challenging optimization problems with multiple local minima and saddle points, different optimal learning rates at different training stages, and the need for fine-tuning as the model approaches convergence.
Fixed learning rates create several problems:
- Learning rate too high: The model oscillates around the optimal point, unable to settle into the minimum
- Learning rate too low: Training progresses extremely slowly, wasting computational resources and potentially getting trapped in poor local minima
- No adaptation: Cannot adjust to different phases of training
Learning rate schedulers address these issues by dynamically adjusting the learning rate based on training progress or performance metrics.
What Are Learning Rate Schedulers?
Learning rate schedulers are algorithms that automatically adjust your model’s learning rate during training. Instead of using the same learning rate from start to finish, these schedulers change it based on predefined rules or training performance.
The beauty of schedulers lies in their ability to optimize different phases of training. Early in training, when weights are far from optimal",Technology & Computing 
"Quantization and compression are two related but distinct concepts when it comes to large language models (LLMs) like GPT-3.5. Let’s explore the differences between quantization and compression in the context of LLMs:
- Quantization:
- Definition: Quantization is the process of reducing the precision or bit-width of numerical values in a model.
- Application: In the context of LLMs, quantization typically involves reducing the number of bits used to represent the weights and activations of the model. For example, instead of using 32-bit floating-point numbers, quantization may involve using 16-bit or 8-bit fixed-point numbers.
- Purpose: The primary goal of quantization is to reduce the memory footprint and computational requirements of the model, making it more efficient for deployment on devices with limited resources (such as mobile phones or edge devices).
- Trade-offs: While quantization reduces model size and speeds up inference, it may lead to a slight loss in model accuracy due to the reduced precision of numerical values.
- Compression:
- Definition: Compression is the process of reducing the size of the model by removing redundant or unnecessary information.
- Application: Compression techniques can be applied to various parts of the model, such as weights, embeddings, or even intermediate representations. Popular compression techniques include weight pruning (removing small or redundant weights), knowledge distillation (training a smaller model to mimic the behavio",Technology & Computing 
"Introduction
You are reading the documentation for Vue 3!
- Vue 2 support has ended on Dec 31, 2023. Learn more about Vue 2 EOL.
- Upgrading from Vue 2? Check out the Migration Guide.
What is Vue?
Vue (pronounced /vjuː/, like view) is a JavaScript framework for building user interfaces. It builds on top of standard HTML, CSS, and JavaScript and provides a declarative, component-based programming model that helps you efficiently develop user interfaces of any complexity.
Here is a minimal example:
js
import { createApp, ref } from 'vue'
createApp({
setup() {
return {
count: ref(0)
}
}
}).mount('#app')
template
<div id=""app"">
<button @click=""count++"">
Count is: {{ count }}
</button>
</div>
Result
The above example demonstrates the two core features of Vue:
Declarative Rendering: Vue extends standard HTML with a template syntax that allows us to declaratively describe HTML output based on JavaScript state.
Reactivity: Vue automatically tracks JavaScript state changes and efficiently updates the DOM when changes happen.
You may already have questions - don't worry. We will cover every little detail in the rest of the documentation. For now, please read along so you can have a high-level understanding of what Vue offers.
Prerequisites
The rest of the documentation assumes basic familiarity with HTML, CSS, and JavaScript. If you are totally new to frontend development, it might not be the best idea to jump right into a framework as your first step - grasp the basics and then come b",Technology & Computing 
"Classical mechanics is a physical theory describing the motion of objects such as projectiles, parts of machinery, spacecraft, planets, stars, and galaxies. The development of classical mechanics involved substantial change in the methods and philosophy of physics.[1] The qualifier classical distinguishes this type of mechanics from physics developed after the revolutions in physics of the early 20th century, all of which revealed limitations in classical mechanics.[2]
The earliest formulation of classical mechanics is often referred to as Newtonian mechanics. It consists of the physical concepts based on the 17th century foundational works of Sir Isaac Newton, and the mathematical methods invented by Newton, Gottfried Wilhelm Leibniz, Leonhard Euler and others to describe the motion of bodies under the influence of forces. Later, methods based on energy were developed by Euler, Joseph-Louis Lagrange, William Rowan Hamilton and others, leading to the development of analytical mechanics (which includes Lagrangian mechanics and Hamiltonian mechanics). These advances, made predominantly in the 18th and 19th centuries, extended beyond earlier works; they are, with some modification, used in all areas of modern physics.
If the present state of an object that obeys the laws of classical mechanics is known, it is possible to determine how it will move in the future, and how it has moved in the past. Chaos theory shows that the long term predictions of classical mechanics are not rel",Science & Research 
"Description
Prepare your website for cookie consent requirements related to GDPR, CCPA, DSGVO, EU cookie law and notice requirements with this incredibly powerful, easy-to-use, well supported and 100% free WordPress plugin.
Key Features
- Local Data Storage – all user data is stored locally on your website only – we do not collect or store any of your user data on our servers
- Simple to use — install & setup in seconds
- Give your users full control over cookies stored on their computer, including the ability for users to revoke their consent.
- Fully customisable – upload your own logo, colours, fonts
- Fully editable – change all text
- Direct integration of GTM, GA, Meta Pixel, GTM4WP and more
- Google Consent Mode v2 fully supported
- Set the position of the Cookie Consent Banner: at the top or bottom of your pages
- Flexible – decide which scripts will be loaded by default or only when the user gives consent
- ‘Accept’, ‘Reject’, ‘Close’ and ‘Settings’ buttons & you can also change their order
- Consent expiration settings
- Link to Privacy Policy page
- Simple, beautiful & intuitive user interface
- Choose from two unique layouts
- Sleek animations to enhance the user experience
- Mobile responsive design
- SEO friendly
- Optimized for WCAG & ADA accessibility guidelines
- WPML, QTranslate, WP Multilang, TranslatePress and Polylang compatible, .pot file for translations included
- CDN base URL supported
- Supports all major caching servers and plugins
- Available in 19",Technology & Computing 
"Take your business to next level
Become part of our growing family of +600,000 users and get the tools you need to make smart choices for your website. Simple, powerful insights are just a click away.
Measure and understand your visitors, track your content, authors, and categories—all with just a simple install. No consent needed.
Achieve GDPR, CCPA, and PECR-compliant analytics within WordPress with maximum privacy and control. Experience powerful, self-hosted insights and author performance metrics, all managed directly from your dashboard.
WP Statistics offers unparalleled privacy and control, setting the standard for GDPR, CCPA, and PECR compliant analytics within WordPress. Experience powerful, self-hosted insights and author performance metrics, all managed directly from your dashboard.
Measure and optimize the impact of your content from start to finish—no dedicated data analyst needed.
Use WP Statistics without consent banners, no cookies, and full compliance with GDPR, CCPA, and PECR by default—ensuring no personally identifiable information (PII) is tracked.
Get a complete view of your content and more, tracking every detail from clicked links to geographical data and device reports.
Discover why over 600,000 users choose WP Statistics for insightful, privacy-respecting analytics.
I’ve been using the WP Statistics plugin for a long time now and I am very satisfied with it. My website Daily Vegan has usually about 10,000 visitors per day, and WP Statistics is part o",Technology & Computing 
"Cross-site Request Forgery, also known as CSRF, Sea Surf, or XSRF, is an attack whereby an attacker tricks a victim into performing actions on their behalf. The impact of the attack depends on the level of permissions that the victim has. Such attacks take advantage of the fact that a website completely trusts a user once it can confirm that the user is indeed who they say they are.
Cross-site Request Forgery is considered a sleeping giant in the world of web application security. It is often not taken as seriously as it should even though it can prove to be a stealthy and powerful attack if executed properly. It is also a common attack, which is why it has secured a spot on the OWASP Top 10 list several times in a row. However, an exploited Cross-site Scripting vulnerability (XSS) is more of a risk than any CSRF vulnerability because CSRF attacks have a major limitation. CSRF only allows for state changes to occur and therefore the attacker cannot receive the contents of the HTTP response.
How Are CSRF Attacks Executed
There are two main parts to executing a Cross-site Request Forgery attack. The first one is tricking the victim into clicking a link or loading a page. This is normally done through social engineering and malicious links. The second part is sending a crafted, legitimate-looking request from the victim’s browser to the website. The request is sent with values chosen by the attacker including any cookies that the victim has associated with that website. This way",Technology & Computing 
"For Families, College Students, and Individuals Looking for Extra Learning Help
Using sophisticated artificial intelligence, ALEKS students are always learning at the boundaries of their knowledge.
ALEKS is an online learning program for Math, Chemistry, Statistics, and Accounting. Using personalized learning and adaptive assessments, ALEKS quickly and accurately determines exactly what a student is most ready to learn. ALEKS is a turnkey solution for college preparation, remediation, acceleration, enrichment, and homeschooling.",Technology & Computing 
"By Beishi
With the advent of large models, vector retrieval is facing unprecedented challenges. The dimensions and quantities of embeddings have seen an unprecedented increase, which poses significant engineering challenges. The Intelligent Engine Division is responsible for designing and constructing Alibaba's search, promotion, and AI-related engineering systems. During actual business iteration and development, we encountered many problems caused by the expansion of embedding dimensions and quantities, with the index creation time issue particularly prominent.
Figure 1 HNSW
Approximate graph algorithms, represented by the HNSW [1] algorithm, have become mainstream technology choices in vector recall due to their high cost-effectiveness and recall rate. Approximate graph algorithms play a crucial role and have a broad application scope, especially in the search recall scenarios of platforms such as Taobao Tmall, Pailitao, and Xianyu. However, a major criticism of approximate graph algorithms is the long index creation time, especially in high-dimensional scenarios with massive data, where this drawback is further magnified.
In a distributed scenario, based on the divide-and-conquer approach, the original data is divided into multiple orthogonal subsets. Each node is only responsible for one of these subsets. In this way, multiple independent compute (storage) nodes can solve the massive data problem that a single machine cannot address. The same applies in the vector recall",Technology & Computing 
"K-means clustering is a popular method for grouping data by assigning observations to clusters based on proximity to the cluster’s center. This article explores k-means clustering, its importance, applications, and workings, providing a clear understanding of its role in data analysis. In this article, you will explore k-means clustering, an unsupervised learning technique that groups data points into clusters based on similarity. A k means clustering example illustrates how this method assigns data points to the nearest centroid, refining the clusters iteratively. Understanding what is k-means clustering will enhance your grasp of data analysis and pattern recognition.
K-means clustering is a popular unsupervised machine learning algorithm used for partitioning a dataset into a pre-defined number of clusters. The goal is to group similar data points together and discover underlying patterns or structures within the data.
The main objective of the K-Means algorithm is to minimize the sum of distances between the points and their respective cluster centroid.
Optimization plays a crucial role in the k-means clustering algorithm. The goal of the optimization process is to find the best set of centroids that minimizes the sum of squared distances between each data point and its closest centroid.
To learn more about clustering and other machine learning algorithms (both supervised and unsupervised) check out our AI/ML Blackbelt Plus Program!
Here’s how it works:
The main objective",Technology & Computing 
"- Acanthamoeba
- Accommodative Dysfunction
- Amblyopia
- Anterior Uveitis
- Astigmatism
- Blepharitis
- Cataract
- Chalazion
- Color Vision Deficiency
- Concussions
- Conjunctivitis
- Convergence Insufficiency
- Corneal Abrasion
- Diabetic Retinopathy
- Dry Eye
- Eye Coordination
- Floaters & Spots
- Glaucoma
- Hordeolum
- Hyperopia
- Keratitis
- Keratoconus
- Macular Degeneration
- Migraine with Aura
- Myokymia
- Myopia
- Nystagmus
- Ocular Allergies
- Ocular Hypertension
- Ocular Migraine
- Pinguecula
- Presbyopia
- Pterygium
- Ptosis
- Retinal Detachment
- Retinoblastoma
- Retinitis Pigmentosa
- Strabismus
- Subconjunctival Hemorrhage
- Vision-Related Learning Problems
Computer vision syndrome
Many individuals experience eye discomfort and vision problems when viewing digital screens for extended periods. The level of discomfort appears to increase with the amount of digital screen use.
The average American worker spends seven hours a day on the computer either in the office or working from home. To help alleviate digital eyestrain, follow the 20-20-20 rule; take a 20-second break to view something 20 feet away every 20 minutes.
Causes & risk factors
Viewing a computer or digital screen often makes the eyes work harder. As a result, the unique characteristics and high visual demands of computer and digital screen viewing make many individuals susceptible to the development of vision-related symptoms. Uncorrected vision problems can increase the severity of computer vision ",Technology & Computing 
"What is Art Deco?
ADSNY has created materials to help you explore the 1920s and 30s, the origins and influences of the Art Deco style, a timeline, and more! One of the questions often asked is “What is Art Deco?” Experts offer a variety of definitions of the term. Here we offer you a variety of expert definitions of Art Deco, as well as a selection of engaging articles to help you better understand the unique architecture, design, and culture of the 1920s and 30s. Click on any image to learn more.
Defining Art Deco
Although the question seems simple, historians have not been able to agree upon a single, definitive answer. Since ADSNY's founding, we have asked historians to share their unique definition of Art Deco.
1920s & 30s Architecture
These articles by various architectural historians, architects, and preservationists give insight into the unique architectural style of the 1920s and 30s in New York City and in other Deco cities around the world.
Art Deco & Early Modern Design
The shift to modern design left no aspect of life untouched! Here we explore the many facets of Art Deco and early modern decorative arts and design including design of interiors, fashion, graphics, and more!
Interwar Culture
If you are interested in learning more about the Roaring 20s, Prohibition, the Jazz Age, the Great Depression, or the Machine Age, there are countless developments that fostered the unique culture of the1920s and 30s.
Art Deco Book List
This ever growing book list includes valu",art_culture
"Explore Art Deco Napier with the Art Deco Trust, the official and most experienced tourism operator in Hawke’s Bay. As a heritage focused not-for-profit charity, the Trust is your one stop shop for all things ‘Art Deco Napier’.
Visit the Art Deco Centre, 7 Tennyson Street, Napier to find out more about the devastating 1931 earthquake and the rebuild of the city in the Art Deco style of the times. We have daily guided walks from $31.00 per person and vintage car tours from $270 for 4 people. The Art Deco Centre has fabulous Art Deco-inspired gifts for sale.
Each year the Trust hosts two Art Deco events: coming next is our intimate and indulgent, Winter Deco, 18-20 July 2025; and our next, world-famous, Art Deco Festival Napier, 19-22 February 2026, when thousands of people, dressed in Deco attire visit Napier to celebrate our city’s art deco era heritage! Visit our Festival website for more details.
During the Winter months (1 April – 30 September), the 10am and 2pm walks begin with the short film, before the 1-hour guided walk ($31.00 per person).
Art Deco Centre is open Monday – Sunday, 9:30am – 2:30pm
Closed: Christmas Day, Good Friday and Anzac Day until 1pm
Walking Tours
Discover the fascinating story of Napier’s heritage on a guided walking tour.
Vintage Car Tours
Discover the fascinating story of Napier’s heritage on a guided vintage car tour.
The Art Deco Trust offers a fantastic and well-organized tour. It started with a fascinating short film about the 1931 earthquak",art_culture
"Build any course imaginable up to 9x faster with AI
Storyline is the top software for creating custom, interactive e‑learning. And it now integrates the magic of AI, so you can create immersive courses faster than ever before.
Powerhouse course authoring, supercharged with AI
Build any training you can imagine with the industry’s leading e‑learning authoring tool, now infused with AI that’s been specifically built for instructional design.
Dream it, build it
Design dynamic learning experiences with any interaction imaginable. Storyline makes it easy to turn static training content into engaging, interactive courses.
AI, the right way
Stay in the driver’s seat. AI Assistant accelerates online course creation, but doesn’t take it over. Our proprietary AI Assistant is built for instructional design, so you’ll get high‑quality help, every time.
Polish to perfection
Perfect your course with help from the integrated AI Assistant. Ask it to change your writing tone, check your grammar, improve readability, generate additional content, and more.
Engaging interactivity, without limits
Create virtually any interaction under the sun. Storyline is simple enough for beginners, yet powerful enough for experts.
Build any interaction
Create any interaction you can imagine with the slide layers, triggers, and states in Storyline. Learners can click, hover over, or drag any object to trigger any action.
Get instant interactivity
Drop buttons, dials, sliders, markers, and hotspots on your slide",Technology & Computing 
"A Graphic Design Tool Made for Everyone
Free yourself from complicated graphic design software. Create the way you want with BeFunky's Graphic Designer!
Completely Customizable Templates
The best graphic design templates empower you to create like never before. Free yourself from the constraints of complicated graphic design software and create beautiful online designs with drag-and-drop simplicity. Take advantage of a huge selection of pre-designed, professional templates for social media to create the perfect Twitter headers, Facebook Covers, Youtube thumbnails, or an on-brand Instagram post. You can also customize our user-friendly templates for marketing your business – whether that be via direct-marketing brochures, event flyers, or content creation for social media. Use our powerful features to take customizable to the next level, create templates from scratch. Simply drag-and-drop your logo, vector graphics, images, and even add that font you love!
Revolutionary Graphic Design Elements
Our free graphic design tool makes it simple to design however you want without any design skills. Whether you plan on underlining text for emphasis, adding vintage ribbons to create a classic look, or creating something totally unique with geometric shapes, we offer fun and functional vector design elements to bring those visual concepts to life. Use design elements to create brand logos, personalized cards, or customize blog graphics – and those are just a few examples of what you can ",Technology & Computing 
"I recently became curious about TPUs, a specialised hardware for training Machine- and Deep-Learning models, where TPU stands for Tensor Processing Unit. This fancy chip can provide very high gains for anyone aiming to perform really massive parallelisation of AI tasks such as training, fine-tuning, and inference.
In this blog post, I will touch on what a TPU is, why it could be useful for AI applications when compared to GPUs and briefly discuss associated opportunity costs.
What’s a TPU?
The simplest of putting is that a TPU is a circuit chip specially designed for neuronal network machine learning, optimised for tensor operations, and able to process a high volume of low-precision operations.
TPUs were originally designed and privately used by Google in their own data centres in 2015 and made only available for hiring through the Google Cloud Platform in 2018. At present, only a small chip version has become commercially available – Edge TPU. TPUs have underpinned well-known applications such as Translate, Map Street View and Google Photos. They have been used in the AlphaGo match against the Go World Champion Lee Sedol. And also made available through Kaggle and Colab.
GPUs vs TPUs
- Scope of applications
GPUs are general-purpose hardware units popular in the AI community, however, they can be used for several other applications beyond AI, such as scientific simulation, video encoding, graphics rendering (video games), and crypto-mining. TPUs are purpose-built processors ",Technology & Computing 
"Art Deco
- Originally called:
- style moderne
What is Art Deco?
When was the Art Deco era?
What are the main characteristics of the Art Deco style?
What was Art Deco influenced by?
What is the difference between Art Deco and Art Nouveau?
Art Deco, movement in the decorative arts and architecture that originated in the 1910s and 1920s in western Europe and developed into a major style in the United States during the 1930s. Its name was derived from the Exposition Internationale des Arts Décoratifs et Industriels Modernes, held in Paris in 1925, where the style was first exhibited. Art Deco design represented modernism turned into fashion. Its products included both individually crafted luxury items and mass-produced wares, but, in either case, the intention was to create a sleek and anti-traditional elegance that symbolized wealth and sophistication.
The distinguishing features of the style are simple, clean shapes, often with a “streamlined” look; ornament that is geometric or stylized from representational forms; and unusually varied, often expensive materials, which frequently include manufactured substances (plastics, especially Bakelite; vita-glass; and ferroconcrete) in addition to natural ones (jade, silver, ivory, obsidian, chrome, and rock crystal). The characteristic features of the style reflected admiration for the modernity of the machine and for the inherent design qualities of machine-made objects (e.g., relative simplicity, planarity, symmetry, and unvaried rep",art_culture
"New Wave
- French:
- Nouvelle Vague
- Key People:
- Jean-Paul Belmondo
- Related Topics:
- film
- auteur theory
- Left Bank school
New Wave, the style of a number of highly individualistic French film directors of the late 1950s. Preeminent among New Wave directors were Louis Malle, Claude Chabrol, François Truffaut, Alain Resnais, and Jean-Luc Godard, most of whom were associated with the film magazine Cahiers du cinéma, the publication that popularized the auteur theory in the 1950s. The theory held that certain directors so dominated their films that they were virtually the authors of the film.
Films by New Wave directors were often characterized by a fresh brilliance of technique that was thought to have overshadowed their subject matter. An example occurs in Godard’s Breathless (1960), in which scenes change in rapid sequence (“jump cuts”) to create a jerky and disconnected effect. Although it was never clearly defined as a movement, the New Wave stimulated discussion about the cinema and helped demonstrate that films could achieve both commercial and artistic success.",art_culture
"Renaissance art
What are the characteristics of Renaissance art, and how does it differ from the art of the Middle Ages?
When and where did Renaissance art start and end?
How did humanism and religion affect Renaissance art?
What made Renaissance art revolutionary?
What are some famous Renaissance artworks?
Renaissance art, painting, sculpture, architecture, music, and literature produced during the 14th, 15th, and 16th centuries in Europe under the combined influences of an increased awareness of nature, a revival of classical learning, and a more individualistic view of humans. Scholars no longer believe that the Renaissance marked an abrupt break with the values of the Middle Ages, as is suggested by the French word renaissance, literally “rebirth.” Rather, historical sources suggest that interest in nature, humanistic learning, and individualism were already present in the late medieval period and became dominant in 15th- and 16th-century Italy concurrently with social and economic changes such as the secularization of daily life, the rise of a rational money-credit economy, and greatly increased social mobility.
Proto-renaissance
In Italy the Renaissance proper was preceded by an important “proto-renaissance” in the late 13th and early 14th centuries, which drew inspiration from Franciscan radicalism. St. Francis had rejected the formal Scholasticism of the prevailing Christian theology and gone out among the poor praising the beauties and spiritual value of nature. His ",art_culture
"Modernist literature
- Related Topics:
- literature
What are the characteristics of Modernist literature?
What role did little magazines play in Modernism?
What was the Harlem Renaissance?
Modernist literature, the body of written works produced during Modernism, a period of experimentation in the arts from the late 19th to the mid-20th century, particularly in the years following World War I (1914–18). Modernist literature developed throughout Europe, the United States, and Latin America. This article discusses the principal characteristics of Modernist literature as well as some leading Modernist writers and developments within the larger movement. For further discussion about the movement itself, including Modernist visual art, music, dance, and architecture, see Modernism.
What was Modernism?
Modernism was a break with the past and the concurrent search for new forms of expression. In an era characterized by industrialization, the nearly global adoption of capitalism, rapid social change, and advances in science and the social sciences (for example, Freudian theory), Modernist artists felt a growing alienation incompatible with Victorian morality, optimism, and convention. New ideas in psychology, philosophy, and political theory kindled a search for new modes of expression. Prominent Modernist artists in fields outside literature include Édouard Manet, Pablo Picasso, and Salvador Dalí in the visual arts; Ludwig Mies van der Rohe and Le Corbusier in architecture; Martha G",art_culture
"Business News Daily provides resources, advice and product reviews to drive business growth. Our mission is to equip business owners with the knowledge and confidence to make informed decisions. As part of that, we recommend products and services for their success.
We collaborate with business-to-business vendors, connecting them with potential buyers. In some cases, we earn commissions when sales are made through our referrals. These financial relationships support our content but do not dictate our recommendations. Our editorial team independently evaluates products based on thousands of hours of research. We are committed to providing trustworthy advice for businesses. Learn more about our full process and see who our partners are here.
Businesses that practice corporate social responsibility aim to improve their communities, the economy or the environment.
Corporate social responsibility (CSR) is a management concept that describes how a company contributes to the well-being of communities and society through environmental and social measures. CSR plays a crucial role in how brands are perceived by customers and their target audience. It may also help attract employees and investors who prioritize the CSR goals a company has identified.
Learn about the importance of CSR and how it can impact the success of your business below.
There are many reasons for a company to embrace CSR practices.
It’s increasingly important for companies to have a socially conscious image. Consum",economics_finance
"A module
is a block of Verilog code that implements a certain functionality. Modules can be embedded within other modules and a higher level module can communicate with its lower level modules using their input and output ports.
Syntax
A module should be enclosed within module
and endmodule
keywords. Name of the module should be given right after the module
keyword and an optional list of ports may be declared as well. Note that ports declared in the list of port declarations cannot be redeclared within the body of the module.
module <name> ([port_list]);
// Contents of the module
endmodule
// A module can have an empty portlist
module name;
// Contents of the module
endmodule
All variable declarations, dataflow statements, functions or tasks and lower module instances if any, must be defined within the module
and endmodule
keywords. There can be multiple modules with different names in the same file and can be defined in any order.
Example
The module dff represents a D flip flop which has three input ports d , clk , rstn and one output port q . Contents of the module describe how a D flip flop should behave for different combinations of inputs. Here, input d is always assigned to output q at positive edge of clock if rstn is high because it is an active low reset.
// Module called ""dff"" has 3 inputs and 1 output port
module dff ( input d,
input clk,
input rstn,
output reg q);
// Contents of the module
always @ (posedge clk) begin
if (!rstn)
q <= 0;
else
q <= d;
end
endmodule",Technology & Computing 
"Data Analytics Company
Data Analytics Services for Data Analytics Companies and Data Companies
Request Free Consultation
Data Analytics
Big Data Analysis, Analytics & Visualization Solutions
We at CIS offer data visualization solutions which include precise reports, as well as interactive dashboards that meet the needs of your company's needs. Our customized solutions will meet all your requirements for service and will provide you with the necessary KPIs to analyze your company's growth. We also provide automated reporting, which eliminates the need for manual data feeds.
Big Data Analytics
Big Data Analysis Solutions
Big data analytics is the process of analyzing large and complex datasets to uncover patterns, trends, and other insights. It is a powerful tool that can provide organizations with valuable information about their customers, products, services, and operations. Big data analytics can help businesses make more informed decisions about how to best serve their customers and optimize their operations.
Big data is the term used for the large amount of unstructured or semi-structured data that organizations need to manage in order to gain insights from it. This includes web logs from websites, customer databases from online stores, financial records from banks and healthcare records from hospitals. The challenge with big data is that it's often too large or complex to be processed by traditional analytic tools such as spreadsheets or SQL databases. That's where big da",Technology & Computing 
"Automate your payments and say goodbye to your spreadsheets. Track and handle transactions with Cobot's extensive billing and invoicing features.
Consent to the use of cookies
We value your privacy.
We use cookies and similar technologies on our website and process personal data. We also share this data with third parties. Data processing may be done with your consent or because of a legitimate interest.
Some services process personal data in the USA. By consenting to the use of these services, you also consent to the processing of your data in the USA. See further details in our Privacy Policy.",Technology & Computing 
"Automate your payments and say goodbye to your spreadsheets. Track and handle transactions with Cobot's extensive billing and invoicing features.
Consent to the use of cookies
We value your privacy.
We use cookies and similar technologies on our website and process personal data. We also share this data with third parties. Data processing may be done with your consent or because of a legitimate interest.
Some services process personal data in the USA. By consenting to the use of these services, you also consent to the processing of your data in the USA. See further details in our Privacy Policy.",Technology & Computing 
"Cognex creates reliable, easy to use machine vision solutions built on decades of expertise in factory and warehouse automation projects big and small. With over 4.5 million systems installed worldwide, we focus on making technology that helps optimize real-world applications.
We offer a wide range of machine vision products including image sensors, 2D vision systems, and 3D vision systems, as well as powerful, easy-to-use software. Whether your needs are simple or complex, we have the solutions to help.
Image-based vision sensors are easy to use and simple to set up. Great for simpler tasks in automation, such as detecting defects, assembly verification and more.
2D machine vision systems are useful for inspecting, identifying, and guiding parts through a production process – all with high-speed image processing. Ideal for solving a wide range of common applications. Ideal for solving a wide range of common applications.
3D machine vision systems are ideal for inspection, process control, measurement, and robot guidance applications that require high precision.
Cognex machine vision software solves challenges with power and precision. Machine vision software gives access to a robust set of AI and rule-based tools.
> Looking for barcode readers? Start here
Machine vision is a technology that helps computers and systems analyze information in a way that mimics human vision. It uses cameras, sensors, and algorithms to capture and process images. Machine vision products are wide",Technology & Computing 
"COLORADO WIND ENSEMBLE
A Symphony Of Woodwinds, Brass and Percussion
Celebrating Season 42
Season 2025 – 2026 At A Glance
Gloriosa with Dr. John R. Locke, guest conductor
Saturday, Sept 13, at 7:30 PM @ King Center
Resplendent Glory – Rossano Galante
Petrichor – Charlie Johnson – Inclusive Repertoire Award Winner
Sunrise at Angel’s Gate – Philip Sparke
Wild Nights – Frank Ticheli
Glory of the Yankee Navy – John Philip Sousa
Deciduous – Viet Cuong
Gloriosa – Yasuhide Ito
Dance Mix
Saturday, Oct 11, 2:00 PM @ St. Andrew UMC, (Highlands Ranch)
Overture for Band – John Heins
Danceries (Set I) – Kenneth Hesketh
Grainger Set: Children’s March – Percy Grainger
Gumsucker’s March – Percy Grainger
Masquerade – Anne Clyne / Llinas
Tahiti Trot – Shostakovich / Brubaker
Samba Magic – Basement Jaxx / Sadler
People & Places
Saturday, Nov 15, 7:30 PM @ King Center
The Great Academy – Joshua Idio – Inclusive Repertoire Award Honorable Mention
A Somerset Rhapsody – Holst / Grundman
Three Washington Statues – Philip Sparke
Bamboo Shoots & City Streets – Benjamin Barker
La Chancla – Dennis Llinas
Avelynn’s Lullaby – Joel Puckett
Acts of Congress – Ryan George
Storyteller
Saturday, Feb 7, at 7:30 PM @ King Center
Overture to Light Cavalry – von Suppe / Godfrey
Incantation and Dance – John Barnes Chance
Give Us This Day – David Maslanka
The Light Within – Alan Stein
Wayfaring Stranger – Christopher Nelson
J’ai été au bal – Donald Grantham
Myths & Legends with Neil Guy, trombone
Saturday, Feb 28, a",art_culture
"Elevate your career in information security with these in-demand credentials.
Cybersecurity jobs are expected to grow by 32 percent between 2022 and 2032, making it an excellent time to transition into the field [1]. Whether you have experience or you're entering the field for the first time, certificate programs and certification exams can help strengthen your resume, expertise, and competitiveness as a job candidate. You can use the following article to compare eight popular cybersecurity certifications and two certificates in 2025.
In as little as six months, you can learn to identify risks, protect people, devices, and networks from threats, and gain hands-on experience with Python programming and Security Information and Event Management (SIEM) tools through the Google Cybersecurity Certificate program. Upon completion, you'll earn credentials for your resume from a tech industry leader.
If you already have some cybersecurity experience and need credentials to reflect that knowledge, you'll likely benefit from studying for and taking a certification exam. If you want to sharpen your skills through an educational program and earn credentials upon completion, a certificate may be the best fit for you. Those who intend to strengthen their resume and their skill set may consider both, as certificate programs are often used to prepare for certification exams.
While many cybersecurity professionals hold a bachelor’s degree in computer science, information technology, or a rela",Technology & Computing 
"CSP ePortfolio
The ePortfolio enables you to create and manage a digital portfolio of your work, reflections and achievements online.
You can also share elements of your portfolio and interact with others online. However, apart from your wall and your profile, nothing is viewable unless you want it to be.
If you need some help getting started, please watch our video guidance about uploading content.
The CSP also provides CPD templates to help you plan, record and evaluate your learning from different situations and experiences. To access these, log in to the ePortfolio, scroll and click the orange ‘CPD resources’ button. At top of the next page, click the link for “MSWord format versions of the CPD templates' to download the templates or upload them to your portfolio.
CSP Learning Hub
The Learning Hub is a virtual learning environment for members. You can access learning activities, such as courses, modules and eBites directly from CSP.
Courses include videos, interactive courses, learning assignments and PDF downloads. You can also access more familiar CSP career tools on the hub and details about education awards.
Need help?
Help and guidance is now available on the ePortfolio and Learning Hub homepages. However, please email the Learning and Development team should you need additional help using either system.",Technology & Computing 
"The term data mesh was coined by Zhamak Dehghani in 2019 and is based on four fundamental principles that bundle well-known concepts:
The domain ownership principle mandates the domain teams to take responsibility for their data. According to this principle, analytical data should be composed around domains, similar to the team boundaries aligning with the system’s bounded context. Following the domain-driven distributed architecture, analytical and operational data ownership is moved to the domain teams, away from the central data team.
The data as a product principle projects a product thinking philosophy onto analytical data. This principle means that there are consumers for the data beyond the domain. The domain team is responsible for satisfying the needs of other domains by providing high-quality data. Basically, domain data should be treated as any other public API.
The idea behind the self-serve data infrastructure platform is to adopt platform thinking to data infrastructure. A dedicated data platform team provides domain-agnostic functionality, tools, and systems to build, execute, and maintain interoperable data products for all domains. With its platform, the data platform team enables domain teams to seamlessly consume and create data products.
The federated governance principle achieves interoperability of all data products through standardization, which is promoted through the whole data mesh by the governance group. The main goal of federated governance is to ",Technology & Computing 
"Introduced in a 2016 paper, Hierarchical Navigable Small World (HNSW) is the algorithm that underpins many vector databases. What sets HNSW apart from other vector indexing techniques is its approach to a common challenge in data science and artificial intelligence: efficiently finding the closest data points in large multi-dimensional datasets.
In a nutshell, HNSW creates a multi-layered graph structure where each layer is a simplified, navigable network. Think of it as a digital map of a road network. Zoomed out, you see the major roads that connect cities and towns. Zoom in to the city level, and you can see how different neighborhoods are connected. At the finest level of zoom, you can see the connections between individual buildings in a neighborhood.
Similarly, HNSW constructs layers of connections with varying degrees of reachability. This structure allows quick and accurate search, even in vast, high-dimensional data spaces. This post will explore HSNW’s inner workings, its strengths, and its weaknesses.
Why are Hierarchical Navigable Small Worlds important?
Hierarchical Navigable Small Worlds are important because they provide an efficient way to navigate and search through complex, high-dimensional data. This efficiency allows for faster and more accurate nearest-neighbor searches, which is essential in applications like recommendation systems, image recognition, and natural language processing.
By organizing data hierarchically and enabling navigable shortcuts, HNS",Technology & Computing 
"Fiscal Policy
By David N. Weil
Fiscal policy is the use of government spending and taxation to influence the economy. When the government decides on the goods and services it purchases, the transfer payments it distributes, or the taxes it collects, it is engaging in fiscal policy. The primary economic impact of any change in the government budget is felt by particular groups—a tax cut for families with children, for example, raises their disposable income. Discussions of fiscal policy, however, generally focus on the effect of changes in the government budget on the overall economy. Although changes in taxes or spending that are “revenue neutral” may be construed as fiscal policy—and may affect the aggregate level of output by changing the incentives that firms or individuals face—the term “fiscal policy” is usually used to describe the effect on the aggregate economy of the overall levels of spending and taxation, and more particularly, the gap between them.
Fiscal policy is said to be tight or contractionary when revenue is higher than spending (i.e., the government budget is in surplus) and loose or expansionary when spending is higher than revenue (i.e., the budget is in deficit). Often, the focus is not on the level of the deficit, but on the change in the deficit. Thus, a reduction of the deficit from $200 billion to $100 billion is said to be contractionary fiscal policy, even though the budget is still in deficit.
Figure 1 shows the federal budget surplus over the pe",economics_finance
"Vector search powers the next generation of search experiences
Vector search provides the foundation for implementing semantic search for text or similarity search for images, videos, or audio. Retrieve relevant context of your data by relying on machine learning to encode your data, and apply generative AI to create more human-like experiences.
AI Playground
Prototype away
Experiment with cutting-edge AI search features using your own data. Test and swap models easily. Discover how to build RAG systems on the platform of your choice, using LLMs from OpenAI, Amazon Bedrock, and Anthropic.
Multimodal search
Perform similarity search
Find visually similar images, video clips, and audio that match specific styles or samples. Similarity search enables applications such as reverse image search, image recommendation, and video and audio matching.
Personalization
Personalize search
Model user behaviors and profiles, and find items similar to the ones a user has shown interest in. This lets you personalize recommendations for consumer products, movies, music, and more, and dynamically adapt any user experience to individual or cohort of users.
Natural language processing
Use NLP effortlessly
Modern natural language processing (NLP) lets you enrich search experiences. Use vector search to retrieve a configurable subset of relevant documents. In a second step, identify the paragraph answering a specific question using a question-answer transformer, extract named entities (NER), or dete",Technology & Computing 
"Elasticsearch is packed with new features to help you build the best search solutions for your use case. Dive into our sample notebooks to learn more, start a free cloud trial, or try Elastic on your local machine now.
TLDR: Elasticsearch is up to 12x faster - We at Elastic have received numerous requests from our community to clarify the performance differences between Elasticsearch and OpenSearch, particularly in the realm of Semantic Search / Vector Search, so we have undertaken this performance testing to provide a clear, data-driven comparison — no ambiguity, just straightforward facts to inform our users. The results show that Elasticsearch is up to 12x faster than OpenSearch for vector search and therefore requires fewer computational resources. This reflects Elastic's focus on consolidating Lucene as the best vector database for search and retrieval use cases.
Vector search is revolutionizing the way we conduct similarity searches, particularly in fields like AI and machine learning. With the increasing adoption of vector embedding models, the ability to efficiently search through millions of high-dimension vectors becomes critical.
When it comes to powering vector databases, Elastic and OpenSearch have taken notably different approaches. Elastic has invested heavily in optimizing Apache Lucene together with Elasticsearch to elevate them as the top-tier choice for vector search applications. In contrast, OpenSearch has broadened its focus, integrating other vector sea",Technology & Computing 
"Elasticsearch is packed with new features to help you build the best search solutions for your use case. Dive into our sample notebooks to learn more, start a free cloud trial, or try Elastic on your local machine now.
The challenge of finding nearest neighbors efficiently in high-dimensional spaces, particularly as datasets grow in size, is one of the most important ones in the context of vector search. As discussed in our previous blog post, brute force nearest neighbor search might be the best choice, when dataset size is limited. On the other hand, as vector dataset size increases, switching to approximate nearest neighbor search can be useful to retain query speed without sacrificing accuracy.
Elasticsearch implements approximate nearest neighbor search via the Hierarchical Navigable Small World algorithm. HNSW offers an efficient way to navigate the vector space, reducing the computational cost while still maintaining high search accuracy. In particular its hierarchical layered structure makes it possible to visit candidate neighbors and decide whether to include them in the final result set with fewer vector distance computations.
However, despite its strengths, the HNSW algorithm can be further optimized for large-scale vector searches. One effective way to enhance HNSW's performance is by finding ways to stop visiting the graph under specific circumstances, called early termination. This blog post explores early termination concepts for HNSW and how they can optimize",Technology & Computing 
"Elasticsearch is packed with new features to help you build the best search solutions for your use case. Dive into our sample notebooks to learn more, start a free cloud trial, or try Elastic on your local machine now.
Are you interested to learn about the characteristics of Elasticsearch for vector search and what the design looks like? As always, design decisions come with pros and cons. This blog aims to break down how we chose to build vector search in Elasticsearch.
Vector search is integrated in Elasticsearch through Apache Lucene
Some background about Lucene first: Lucene organizes data into immutable segments that are merged periodically. Adding more documents requires adding more segments. Modifying existing documents requires atomically adding more segments and marking previous versions of these documents as deleted. Every document within a segment is identified by a doc ID, which is the index of this document within the segment, similar to indices of an array. The motivation for this approach is managing inverted indices, which aren't good at in-place modifications but can be merged efficiently.
In addition to inverted indices, Lucene also supports stored fields (a document store), doc values (columnar storage), term vectors (per-document inverted indices), and multi-dimensional points in its segments. Vectors have been integrated the same way:
- New vectors get buffered into memory at index time.
- These in-memory buffers get serialized as part of segments when th",Technology & Computing 
"Try out vector search for yourself using this self-paced hands-on learning for Search AI. You can start a free cloud trial or try Elastic on your local machine now.
This article is the second in a series of three that dives into the intricacies of vector search also known as semantic search and how it is implemented in Elasticsearch.
The first part was focused on providing a general introduction to the basics of embeddings (aka vectors) and how vector search works under the hood.
Armed with all the vector search knowledge learned in the first article, this second part will guide you through the meanders of how to set up vector search and execute k-NN searches in Elasticsearch.
In the third part, we will leverage what we learned in the first two parts and build upon that knowledge by delving into how to craft powerful hybrid search queries in Elasticsearch.
Background on vector search in Elasticsearch
Even though Elasticsearch did not support vector search up until version 8.0 with the technical preview of the _knn_search
API endpoint, it has been possible to store vectors using the dense_vector
field type since the 7.0 release. At that point, vectors were simply stored as binary doc values but not indexed using any of the algorithms that we presented in our first article. Those dense vectors constituted the premises of the upcoming vector search features in Elasticsearch.
If you’re interested in diving more into the discussions that led to the current implementation of vector",Technology & Computing 
"Philosophy of Law, Problems of
PHILOSOPHY OF LAW, PROBLEMS OF
The existence of legal systems, even the most rudimentary, has afforded the opportunity for a variety of academic disciplines. Of these some are, or purport to be, empirical: They include the historical study of particular legal systems or specific legal doctrines and rules, and sociological studies of the ways in which the content and the efficacy of law and the forms and procedures of law-making and law-applying both influence and are influenced by their economic and social setting, and serve social needs or specific social functions. But since law in most societies soon reaches a very high degree of complexity, its administration requires the special training of judges and professional lawyers. This in turn has created the need for a specific form of legal science concerned with the systematic or dogmatic exposition of the law and its specific methods and procedures. For this purpose the law is divided into distinct branches (such as crime, tort, and contract), and general classifications and organizing concepts are introduced to collect common elements in the situations and relationships created by the law (such as rights, duties, obligations, legal personality, ownership, and possession) or elements common to many separate legal rules (such as act and intention).
No very firm boundaries divide the problems confronting these various disciplines from the problems of the philosophy of law. This is especially true",Philosophy & Religion 
"Close
Latest News
Artificial Intelligence
Video
Big Data and Analytics
Cloud
Networking
Cybersecurity
Applications
IT Management
Storage
Sponsored
Mobile
Small Business
Development
Database
Servers
Android
Apple
Innovation
Blogs
PC Hardware
Reviews
Search Engines
Virtualization
Read Down
Sign in
Close
Welcome!
Log into your account
your username
your password
Forgot your password?
Read Down
Password recovery
Recover your password
your email
Close
Search
Subscribe
Latest News
Artificial Intelligence
Video
Big Data and Analytics
Cloud
Networking
Cybersecurity
Applications
IT Management
Storage
Sponsored
Mobile
Small Business
Development
Database
Servers
Android
Apple
Innovation
Blogs
PC Hardware
Reviews
Search Engines
Virtualization
More
Subscribe
Search
Home
Big Data and Analytics
Big Data and Analytics
6 Best AI-Powered BI Tools for Smarter Analytics 2025
Kezia Jungco
-
June 4, 2025
Azure ML vs Databricks: Which is Better for Your Data Needs?
Sam Rinko
-
November 25, 2024
eWeek TweetChat, October 22: How to Get the Most From Your Data
James Maguire
-
September 30, 2024
Databricks vs. Snowflake (2024): Battle of the Best – Who Wins?
Shelby Hiter
-
June 27, 2024
Databricks vs. Redshift: Data Platform Comparison
Aminu Abdullahi
-
May 22, 2024
Databricks and Redshift are two powerful data management solutions that offer unique features and capabilities for organizations looking to analyze and process large volumes...
Azure Synapse vs. Databricks: Data Platform Comparison 2024
Col",Technology & Computing 
"Previous
Next
Welcome to Circuit Engineering
Company Limited!
Outsourcing your Extract IC, Read MCU, or any other Copy Microcontroller needs is a critical decision for your company. We understand that you have many companies to choose from, but if you are looking for a company that can provide customer satisfaction, you have chosen the right one, Circuit Engineering Co.,Ltd offers a full range of IC extract, MCU Read and Microcontroller Copy technology designed for quick set-up. If your disassembly or assembly requires extensive hand labor, our skilled workforce can provide detailed hand assembly according to IPC-A-610 Class II. At Circuit Engineering Co.,Ltd, we are well equipped to IC extract, MCU Read, or any other Microcontroller Copy and Printed Circuit Board Reverse Engineering, including customized packaging. Our goal at Circuit Engineering Co.,Ltd is to achieve customer satisfaction with superior service and products.
Our Services
Customer Feedback
Everything we build starts with design engineering. CECL manufactured boards for one of our products. It went perfectly – a real success.It is really an high quality service they have provided to us!
Nile Smith fromSinotech Inc.
We had several very old device with obsolete boards need to be replaced –through CECL professional service.We got what we needed, and we’ve been using the results of the work without any problem till now.
Richard AndersonTWP system Inc.
Guys from CECL manufacture PCBs we use in one of our products, ",Technology & Computing 
"Java Tutorial Last Updated : 21 Jun, 2025 Summarize Comments Improve Suggest changes Share Like Article Like Report Java is a high-level, object-oriented programming language used to build web apps, mobile applications, and enterprise software systems. It is known for its Write Once, Run Anywhere capability, which means code written in Java can run on any device that supports the Java Virtual Machine (JVM).Java syntax and structure is similar to C-based languages like C++ and C#. Its robustness, platform-independent compatibility, and strong memory management have made it a go-to language for developers worldwide.This Java tutorial is designed for both beginners and experienced professionals and it covers basic to advanced Java topics.Why Learn Java?Java is used to build Android apps, desktop and web apps, enterprise backend systems, and cloud-based software.Java is in high demand with many job opportunities in software development.Java has popular frameworks like Spring and Hibernate which makes Java powerful for enterprise applications.Java supports object-oriented programming for clean and reusable code.It runs on all platforms Windows, Mac, and Linux using the JVM.Top companies like Amazon, Netflix, and LinkedIn use Java.Java Hello World ProgramHere is a simple Java program that prints ""Hello World"". Java // A Java program to print ""Hello World"" public class Geeks { public static void main(String args[]) { System.out.println(""Hello World""); } } OutputHello World Java Basi",Technology & Computing 
"Genomics and Medicine
Genomic medicine is an emerging medical discipline that involves using genomic information about an individual as part of their clinical care (e.g. for diagnostic or therapeutic decision-making) and the health outcomes and policy implications of that clinical use. Already, genomic medicine is making an impact in the fields of oncology, pharmacology, rare and undiagnosed diseases, and infectious disease.
Notable Accomplishments in Genomic Medicine
Genomic medicine is advancing at a rapid pace. View this list of interesting developments in clinical implementation, pharmacogenomics, oncology, and more.
Learn MoreLast updated: September 11, 2024",Health & Medicine 
"Discover the best strategies for investing to maximize returns and achieve your financial goals effectively and efficiently.
Managing your personal finances can be tricky if you don’t have the strategies and guidance you need. Organization, research, planning and funding are all necessary to achieve your financial goals. On GOBankingRates, you can learn about different investment strategies and how to make your money work for you.
If you’re interested in stocks, CD accounts, real estate, investment funds, collecting valuables or any other investment, GOBankingRates has the information you need. You’ll find articles that explain the difference between different types of investments, breakdowns of investment methods, advice on what types of investments are most likely to be successful and even entertaining news stories about investing.
So whether you’re planning on making a big investment by purchasing property or you’re preparing to make a smaller investment, GOBankingRates can help.
Here are the answers to some of the most frequently askedInvesting Strategy questions.
Please disable your adblocker to enjoy the optimal web experience and access the quality content you appreciate from GOBankingRates.",economics_finance
"In-Memory Database
What is an In-Memory Database?
An in-memory database (IMDB) is a data management system that stores data primarily in the computer’s main memory. This is unlike traditional relational databases that rely on solid-state drives (SSDs) or spinning disks for data storage. IMDBs allow mission-critical applications to benefit from faster response times than disk-based databases. People occasionally refer to an IMDB as an in-memory database management system (IMDBMS).
Traditional relational databases are ubiquitous, but their disk-based technology is an obstacle to reaching real-time responses. Some in-memory computing approaches such as data grids achieve notable speed but lack full SQL support. Their implementation requires changes in existing applications designed for relational databases. IMDBs excel in providing the best of data grids and relational databases, combining RAM speeds with full ANSI SQL support.
ANSI-99 SQL and ACID Transactions
SQL is a standard introduced in 1986 by the American National Standards Institute (ANSI). It was last updated in 2016. The standard ANSI-99 consolidated many of the specifications that form the core of most relational databases used today. These specifications include commands for a data definition language (DDL), a data modification language (DML), a query syntax, and transactional commands.
IMDBs are also ACID compliant, meaning they enforce strong data consistency through the four critical properties of a transaction: ",Technology & Computing 
"Build the right data foundation for generative AI
Design a data architecture that accelerates data readiness for generative AI and unlock unparalleled productivity for data teams.
Fragmented data stacks, productivity pressures and the lack of data preparedness for generative AI are driving enterprises to evaluate new data strategies. Data fabric is designed to bring the power of generative AI to streamline the integration, curation, governance and delivery of high-quality data for analytics and artificial intelligence (AI).
The next-generation data fabric is hybrid by design and can run anywhere, on-premises or in any cloud environment. It also integrates across hybrid data planes, supporting any style of data integration.
Data fabric introduces new data intelligence and integration tools to prepare data for generative AI, helping to ensure readiness for both structured and unstructured data in AI initiatives. By streamlining data preparation and integration, organizations can unlock productivity for their data teams and drive business innovation.
Connect data from disparate sources in multicloud environments with a range of integration styles including batch, real-time and change data capture.
Secure critical enterprise data from both current and emerging risks, wherever it lives.
Use large language models (LLMs) to scale contextual understanding of data, empowering data consumers to trust and use reliable information.
An abstraction layer that provides a common business und",Technology & Computing 
"Computer vision is a field of artificial intelligence (AI) that uses machine learning and neural networks to teach computers and systems to derive meaningful information from digital images, videos and other visual inputs—and to make recommendations or take actions when they see defects or issues.
If AI enables computers to think, computer vision enables them to see, observe and understand.
Computer vision works much the same as human vision, except humans have a head start. Human sight has the advantage of lifetimes of context to train how to tell objects apart, how far away they are, whether they are moving or something is wrong with an image.
Computer vision trains machines to perform these functions, but it must do it in much less time by using cameras, data and algorithms in place of retinas, optic nerves and a visual cortex. Because a system trained to inspect products or watch a production asset can analyze thousands of products or processes a minute, noticing imperceptible defects or issues, it can quickly surpass human capabilities.
Computer vision is used in industries that range from energy and utilities to manufacturing and automotive—and the market is continuing to grow. According to industry analyst Gartner, the global market for computer vision software, hardware and services will generate USD 386 billion by 2031, up from USD 126 billion in 2022.1
Computer vision needs lots of data. It runs analyses of data over and over until it discerns distinctions and ultim",Technology & Computing 
"Data fabric is an architecture that facilitates the end-to-end integration of various data pipelines and cloud environments through the use of intelligent and automated systems.
Over the last decade, developments within hybrid cloud, artificial intelligence, the Internet of Things (IoT), and edge computing have led to the exponential growth of big data, creating even more complexity for enterprises to manage. This complex system has made the unification and governance of data environments an increasing priority as this growth has created significant challenges, such as data silos, security risks and general bottlenecks to decision making.
Data management teams are addressing these challenges head on with data fabric solutions. They are using them to unify their disparate data systems, embed governance, strengthen security and privacy measures, and provide more data accessibility to workers, particularly their business users.
These data integration efforts through data fabrics allow for more holistic, data-centric decision-making. Historically, an enterprise may have had different data platforms aligned to specific lines of business. For example, you might have a HR data platform, a supply chain data platform and a customer data platform, which house data in different and separate environments despite potential overlaps. However, a data fabric can allow decision-makers to view this data more cohesively to better understand the customer lifecycle, making connections between dat",Technology & Computing 
"Hot Products
-
Bypassing 2FA Network Authentication Service
-
The Service for Brute Force Attack Over Network Authentication: A Growing Threat
-
Password Cracking Service for Network Authentication: A Growing Threat
-
Cracking Network Authentication Services: Risks and Protections
-
Recovering Microcomputer GD32F101D6T6 embedded firmware
-
Secured Microprocessor GD32F101D4T6 Flash Program Decryption
-
Unlocking a secured MCU GD32F101C8T6 embedded firmware
-
Unlock encrypted microcontroller GD32F101C6 flash content
-
Cracking protective microprocessor GD32F101C4T6 flash memory
-
Decrypt secured MCU GD32F101C4T6 program
-
Decrypt secured microprocessor STM32F407ZG Flash Memory
-
Attack Locked MCU STM32F405ZG Memory
-
Hack encrypted STM32F407IG microprocessor Source code
-
Break Secured STM32F405VG microcontroller memory
-
Unlock Protective Microprocessor STM32F407VG Firmware
About us
Contact Us
1. For quote and order,payment, lead time, please email us at:
INFO@ic-cracker.com
2. If you have any suggestions, please email us at:
INFO@ic-cracker.com
Other Infomation",Technology & Computing 
"Automate and scale ML and generative AI application lifecycles. Get from PoC to production faster to make true business impact.
Consume MLRun, Iguazio’s open source framework, to automate data preparation, model tuning, customization, validation and optimization of ML models and LLMs over elastic resources. With MLRun you can rapidly deploy scalable real-time serving and application pipelines, with built-in observability and flexible deployment options: multi-cloud, hybrid and on-prem environments.
Learn how you can automate, scale and orchestrate AI pipelines end to end with the Iguazio AI Platform",Technology & Computing 
"Topic: Educational Data Mining (EDM) and Learning Analytics (LA)
Educational data mining (EDM) and learning analytics (LA) are used to represent the application of data mining in higher education and other educational settings. They are fundamentally based on computational data analysis and can consecutively collect, process, report, and work on digital data to improve the educational process. EDM and LA are used to offer more personalized, adaptive, and interactive educational environments to enhance learning outcomes, teaching and learning effectiveness, and optimize institutional proficiency, contributing to both learning sciences and educational theory more broadly.
The topic seeks to connect learning analytics researchers, developers, and practitioners who share a common interest in computational approaches to educational data mining, to better understand and improve learning through the creation and implementation of new tools and techniques.
Specifically, it welcomes high-quality original work including but not limited to:
►Student modeling
►Social Network Analysis
►Analysis and Visualization of Data
►Prediction, Clustering, and Relationship Mining
►Developing concept maps
►Discovering or improving domain models
►Predicting students’ future learning behavior
…
Make a new submission to the Topic: Educational Data Mining (EDM) and Learning Analytics (LA) section.
List of Publications
2025
Alma E. Abylkassymova, Akmaral B. Duisebayeva, Yessenkeldy A. Tuyakov, Almagul K. A",Technology & Computing 
"7 Careers in Exercise Physiology To Consider (With Salaries)
Written by
Updated June 6, 2025
What is exercise physiology?
Exercise physiology is a field that focuses on how the human body responds to exercise and other types of physical movement, such as intense workouts or injuries. This field is within the larger discipline of kinesiology, which is the study of human movement under a variety of different conditions. With exercise physiology, you analyze how the human body adapts to movement over time. Exercise physiology involves studying the effect of exercise as it relates to neurohumoral systems, muscular systems and cardiovascular systems to identify issues and solutions for more comfortable and sustainable movement.You can work in a variety of different jobs in exercise physiology, including those in sports, science, medicine and other areas of healthcare. Typically, you earn a degree in exercise physiology, kinesiology, biology, anatomy or nutrition to work within the field and spend time participating in internships, apprenticeships or entry-level jobs.Related: 12 of the Highest Paid Kinesiology CareersShowcase your skills with help from a resume expert
7 careers in exercise physiology
There are a variety of jobs that you may pursue within exercise physiology. Here are seven different careers in this field to consider. For the most up-to-date salary information from Indeed, visit indeed.com/salaries:1. Personal trainer
National average salary: $49,966 per yearPrimary",Health & Medicine 
"Time series database explained
In this technical paper, InfluxData CTO, Paul Dix, will walk you through what time series is (and isn’t), what makes it different from stream processing, full-text search and other solutions.
By reading this tech paper, you will:
- Learn how time series data is all around us,
- See why a purpose built TSDB is important.
- Read about how a Time Series database is optimized for time-stamped data.
- Understand the differences between metrics, events, & traces and some of the key characteristics of time series data.
What is a time series database?
A time series database (TSDB) is a database optimized for time-stamped or time series data. Time series data are simply measurements or events that are tracked, monitored, downsampled, and aggregated over time. This could be server metrics, application performance monitoring, network data, sensor data, events, clicks, trades in a market, and many other types of analytics data.
A time series database is built specifically for handling metrics and events or measurements that are time-stamped. A TSDB is optimized for measuring change over time. Properties that make time series data very different than other data workloads are data lifecycle management, summarization, and large range scans of many records.
Why is a time series database important now?
Time series databases are not new, but the first-generation time series databases were primarily focused on looking at financial data, the volatility of stock tra",Technology & Computing 
"An investment strategy is a set of principles that guides your portfolio decisions. With seemingly countless theories and approaches on offer, from simplistic learn-this-one-trick TikToks to dense tomes seemingly only for financial doctorates, it's easy to feel overwhelmed and uncertain about where to start.
But don't worry: successful investing doesn't require a finance degree, complicated math skills, or a TikTok account. By focusing on a few key investment strategies, even beginning traders can lay a solid foundation for long-term success in the market. The truth is many successful investors use straightforward strategies that anyone can learn. These time-tested approaches help you make smarter choices about where to put your money and how to manage risk—kind of like having guardrails on a set of stairs.
Key Takeaways
- Before choosing a stock market strategy, thoroughly assess your financial situation, risk tolerance, and investment goals. This self-review should be the basis of any approach you take.
- Passive index investing involves putting your money into index-tracking mutual or exchange-traded funds (ETFs), offering built-in diversification and a hands-off approach.
- Investors who follow growth strategies should review the executive teams of the firms they're investing in and news about the economy and relevant sectors.
- Momentum investors buy stocks trending upward and short-sell them since they view them as likely to come back down to earth.
- Dollar-cost averag",economics_finance
"What Is CSR?
Corporate social responsibility (CSR) is a self-regulating business model that helps a company be socially accountable to itself, its stakeholders, and the public.
By practicing corporate social responsibility, also called corporate citizenship, companies are aware of how they impact aspects of society, including economic, social, and environmental. Engaging in CSR means a company operates in ways that enhance society and the environment instead of contributing negatively to them.
Key Takeaways
- Corporate social responsibility is a business model by which companies make a concerted effort to operate in ways that enhance rather than degrade society and the environment.
- CSR can help improve society and promote a positive brand image for companies.
- CSR includes four categories: environmental impacts, ethical responsibility, philanthropic endeavors, and financial responsibilities.
Understanding Corporate Social Responsibility (CSR)
Through corporate social responsibility programs, philanthropy, and volunteer efforts, businesses can benefit society while boosting their brands. A socially responsible company is accountable to itself and its shareholders. CSR is commonly a strategy employed by large corporations. The more visible and successful a corporation is, the more responsibility it has to set standards of ethical behavior for its peers, competition, and industry.
Fast Fact
Small and midsize businesses also create social responsibility programs, although thei",economics_finance
"Latest News
Cloudwalkers cast highlight: Steve Crago
“Genuine curiosity pays off in a deeply technical environment”
ISI at ICWSM 2025
Misinformation, Bots, and Algorithms: Dr. Emilio Ferrara on technology’s impact on democracy
Smart Enough to Know Better? How AI Handles Legal Questions
SABRES: A Cutting-Edge Solution for Secure 5G
Startup raises $8M to try to make AI forget bad data; cites ISI research
Self-learning neural network cracks iconic black holes
Delivering the future
ISI's mission is to advance society through pioneering research and technological innovation. We cultivate an intellectually vibrant environment where researchers are empowered to imagine bold solutions to complex problems and to develop into world-class leaders. Guided by integrity, inclusion, and a commitment to excellence, we create unprecedented capabilities that harness information to transform lives.
Research & Development
Part of the University of Southern California’s Viterbi School of Engineering, ISI is a pioneer in research and development across an exceptionally wide range of advanced information processing, computer, and communications technologies.
Our broad expertise spans artificial intelligence, computational systems and technology, space engineering, informatics systems research, and networking and cybersecurity. Bridging multiple technology disciplines through both academic and industry expertise, ISI continues to shape the technologies of tomorrow.
Centers
ISI Centers are internatio",Technology & Computing 
"Businesses have always been data-driven. The ability to gather data, analyze it, and make decisions based on it has always been a key part of success. As such, the ability to effectively manage data has become critical.
In the past few years, data has exploded in size and complexity. For example, the amount of data created, captured, copied, and consumed worldwide will hit 181 zettabytes by 2025, up from only two zettabytes in 2010.
This fact has made it difficult for businesses to promptly gather, analyze, and act on data. However, DataOps (data operations) is a software framework that was created to address this very problem.
Table of Contents
What is DataOps?
Introduced by IBM’s Lenny Liebmann in June 2014, DataOps is a collection of best practices, techniques, processes, and solutions that applies integrated, process-oriented, and agile software engineering methods to automate, enhance quality, speed, and collaboration while encouraging a culture of continuous improvement in the field of data analytics.
DataOps began as a collection of best practices but has since grown into a novel and autonomous data analytics method. It considers the interrelatedness of the data analytics team and IT operations throughout the data lifecycle, from preparation to reporting.
Also read: 6 Ways Your Business Can Benefit from DataOps
What is the Purpose of DataOps?
DataOps aims to enable data analysts and engineers to work together more effectively to achieve better data-driven decision-maki",Technology & Computing 
"What is big data analytics?
We explain what big data analytics is, and how the methods of looking at data differ at scale
""Big data"" seems like a simple term for the way we power modern life, but it is far more complex than that suggests. Essentially, it's a mass collection of information that we use to make decisions, train models, enhance public-facing technology and much, much more.
The methods used to collect the raw data used in big data analytics range widely; the rise of the internet of things (IoT), cloud computing, and increased smartphone use all enable the harvesting of information. For some, such as bad actors, this is used for ill-intent such as identity theft. For businesses, however, data harvesting forms a cornerstone in their quest for increased profit.
Analytics are used to identify the insights, patterns and strategies present within datasets. Specialist software or systems tailored to the task are often used to process high volumes of data quicker than any team of people could. These are then used to inform business decision-making.
What is big data?
To appreciate big data analytics, you first need to comprehend what's being examined.
Big data is defined by three 'Vs' - volume, velocity, and variety. Huge tracts of information are produced every second of the day, and depending on one’s focus may be represented in any number of formats.
When it comes to big data analytics, what is most important is this last component. More diverse sources of data are now ",Technology & Computing 
"Named Entity Recognition: A Practitioner’s Guide to NLP
Named entity recognition (NER) , also known as entity chunking/extraction , is a popular technique used in information extraction to identify and segment the named entities and classify or categorize them under various predefined classes.
In any text document, there are particular terms that represent specific entities that are more informative and have a unique context. These entities are known as named entities , which more specifically refer to terms that represent real-world objects like people, places, organizations, and so on, which are often denoted by proper names. A naive approach could be to find these by looking at the noun phrases in text documents. Named entity recognition (NER) , also known as entity chunking/extraction , is a popular technique used in information extraction to identify and segment the named entities and classify or categorize them under various predefined classes.
SpaCy has some excellent capabilities for named entity recognition. Let’s try and use it on one of our sample news articles.
[(US, 'GPE'), (China, 'GPE'), (US, 'GPE'), (China, 'GPE'), (Sunway, 'ORG'), (TaihuLight, 'ORG'), (200,000, 'CARDINAL'), (second, 'ORDINAL'), (Sunway, 'ORG'), (TaihuLight, 'ORG'), (93,000, 'CARDINAL'), (4,608, 'CARDINAL'), (two, 'CARDINAL')]
Visualizing named entities in a news article with spaCy
We can clearly see that the major named entities have been identified by spacy
. To understand more in detail abo",Technology & Computing 
"What is Kubeflow?
Kubeflow is the foundation of tools for AI Platforms on Kubernetes. AI platform teams can build on top of Kubeflow, deploy the entire reference platform, or use each project independently to meet their specific needs. The Kubeflow reference platform is composable, modular, portable, and scalable, backed by an
ecosystem of Kubernetes-native
open source projects for each stage of
the AI/ML Lifecycle.
Deploy Kubeflow anywhere you run Kubernetes.
Kubeflow Components
Kubeflow Pipelines (KFP) is a platform for building then deploying portable and scalable machine learning workflows using Kubernetes.
Kubeflow Notebooks lets you run web-based development environments on your Kubernetes cluster by running them inside Pods.
Kubeflow Central Dashboard is our hub which connects the authenticated web interfaces of Kubeflow and other ecosystem components.
Kubeflow Trainer is a Kubernetes-native project for fine-tuning LLMs and model training. It enables scalable and distributed training with various frameworks including PyTorch, JAX, TensorFlow, and more.
Katib is a Kubernetes-native project for automated machine learning (AutoML) with support for hyperparameter tuning, early stopping and neural architecture search.
KServe (previously KFServing) solves production model serving on Kubernetes. It delivers high-abstraction and performant interfaces for frameworks like Tensorflow, XGBoost, ScikitLearn, PyTorch, and ONNX.
Kubeflow Model Registry is a cloud-native component tha",Technology & Computing 
"Overview
Kubeflow Pipelines (KFP) is a platform for building and deploying portable and scalable machine learning (ML) workflows using containers on Kubernetes-based systems.
With KFP you can author components and pipelines using the KFP Python SDK, compile pipelines to an intermediate representation YAML, and submit the pipeline to run on a KFP-conformant backend such as the open source KFP backend or Google Cloud Vertex AI Pipelines.
The open source KFP backend is available as a core component of Kubeflow or as a standalone installation. To use KFP as part of the Kubeflow platform, follow the instructions for installing Kubeflow. To use KFP as a standalone application, follow the standalone installation instructions. To get started with your first pipeline, follow the Getting Started instructions.
Why Kubeflow Pipelines?
KFP enables data scientists and machine learning engineers to:
- Author end-to-end ML workflows natively in Python
- Create fully custom ML components or leverage an ecosystem of existing components
- Easily pass parameters and ML artifacts between pipeline components
- Easily manage, track, and visualize pipeline definitions, runs, experiments, and ML artifacts
- Efficiently use compute resources through parallel task execution and through caching to eliminating redundant executions
- Keep experimentation and iteration light and Python-centric, minimizing the need to (re)build and maintain containers
- Maintain cross-platform pipeline portability through a",Technology & Computing 
"Introduction
What is Kubeflow
Kubeflow is a community and ecosystem of open-source projects to address each stage in the machine learning (ML) lifecycle with support for best-in-class open source tools and frameworks. Kubeflow makes AI/ML on Kubernetes simple, portable, and scalable.
Whether you’re a researcher, data scientist, ML engineer, or a team of developers, Kubeflow offers modular and scalable tools that cater to all aspects of the ML lifecycle: from building ML models to deploying them to production for AI applications.
What are Standalone Kubeflow Components
The Kubeflow ecosystem is composed of multiple open-source projects that address different aspects of the ML lifecycle. Many of these projects are designed to be usable both within the Kubeflow Platform and independently. These Kubeflow components can be installed standalone on a Kubernetes cluster. It provides flexibility to users who may not require the full Kubeflow Platform capabilities but wish to leverage specific ML functionalities such as model training or model serving.
What is Kubeflow Platform
The Kubeflow Platform refers to the full suite of Kubeflow components bundled together with additional integration and management tools. Using Kubeflow as a platform means deploying a comprehensive ML toolkit for the entire ML lifecycle.
In addition to the standalone Kubeflow components, the Kubeflow Platform includes
- Kubeflow Notebooks for interactive data exploration and model development.
- Central Dashboar",Technology & Computing 
"What Is Classical Mechanics?
Using just a few equations, scientists can describe the motion of a ball flying through the air and the pull of a magnet, and forecast eclipses of the moon. The mathematical study of the motion of everyday objects and the forces that affect them is called classical mechanics. Classical mechanics is often called Newtonian mechanics because nearly the entire study builds on the work of Isaac Newton. Some mathematical laws and principles at the core of classical mechanics include the following:
- Newton's First Law of Motion: A body at rest will remain at rest, and a body in motion will remain in motion unless it is acted upon by an external force.
- Newton's Second Law of Motion: The net force acting on an object is equal to the mass of that object times its acceleration.
- Newton's Third Law of Motion: For every action, there is an equal and opposite reaction.
- Newton's Law of Universal Gravitation: The pull of gravity between two objects will be proportional to the masses of the objects and inversely proportional to the square of the distance between their centers of mass.
- Law of Conservation of Energy: Energy cannot be created nor destroyed, and instead changes from one form to another; for example, mechanical energy turning into heat energy.
- Law of Conservation of Momentum: In the absence of external forces such as friction, when objects collide, the total momentum before the collision is the same as the total momentum after the collision.
",Science & Research 
"Project:Language policy
This page describes the current multi-lingual policy on MediaWiki.org.
Help: namespace
The Help:
namespace contains a set of public domain help pages. The aim is to provide a basic set of help pages that may be imported into new wikis covering the basic editing and usage instructions. These should be translated into as many languages as possible.
- English is the main reference language, and all root pages should be named and written in English.
- Sub-pages should only be used for translations into other languages, not for English content (e.g. you shouldn't use
Table editing/example
- useTable editing example
orExample of table editing
instead). - If an international version of a page exists but an English version does not, then please create a stub article for the English version as this aids navigation.
This system will be compatible with the planned automated import/export of Help pages, but may need a bit of working around to export/import non-English pages in the interim.
Translate extension
We use the Translate extension for hundreds of pages. These use the subpage convention, with {{#translation:}} for categories.
The system is recommended at least for most visited pages and all new help, manual and (main) extension pages, but no policy has been established on this yet.
- To translate: just go to Special:LanguageStats and start translating.
- To administer translations: Special:PageTranslation, Special:AggregateGroups.
You can request a page to",Technology & Computing 
"What is MongoDB?
MongoDB is a document database designed for ease of application development and scaling.
You can run MongoDB in the following environments:
MongoDB Atlas : The fully managed service for MongoDB deployments in the cloud
MongoDB Enterprise : The subscription-based, self-managed version of MongoDB
MongoDB Community : The source-available, free-to-use, and self-managed version of MongoDB
Work with your data in MongoDB
Deploy MongoDB
Create a cluster in the MongoDB Atlas UI or the Atlas CLI quickly and easily. To learn more, see Create a Cluster in the MongoDB Atlas documentation and Get Started with Atlas in the Atlas CLI documentation.
For self-hosted deployments, see Replication in the MongoDB manual to create a replica set.
Connect to your deployment
Access deployments in the MongoDB Atlas UI or connect with drivers or the MongoDB Shell (mongosh) in the MongoDB manual.
To learn more, see Find Your Connection String in the MongoDB manual.
Insert, query, update, or delete documents
Perform CRUD operations in the MongoDB Atlas UI or by using the MongoDB Query API - with or without transactions.
To learn more, see Create, View, Update, and Delete Documents in the MongoDB Atlas documentation and MongoDB CRUD Operations in the MongoDB manual.
Model your data
Design your data schema to support frequent access patterns. You can update or enforce your schema at any point.
To learn more, see Data Modeling Introduction in the MongoDB manual.
Import your data
Import data ",Technology & Computing 
"Document databases offer a variety of advantages, including:
Because of these advantages, document databases are general-purpose databases that can be used in a variety of use cases and industries.
Document databases are considered to be non-relational (or NoSQL) databases. Instead of storing data in fixed rows and columns, document databases use flexible documents. Document databases are the most popular alternative to tabular, relational databases. Learn more about NoSQL databases.
In this article, we'll explore answers to the following questions:
A document is a record in a document database. A document typically stores information about one object and any of its related metadata.
Documents store data in field-value pairs. The values can be a variety of types and structures, including strings, numbers, dates, arrays, or objects. Documents can be stored in formats like JSON, BSON, and XML.
Below is a JSON document that stores information about a user named Tom.
{
""_id"": 1,
""first_name"": ""Tom"",
""email"": ""tom@example.com"",
""cell"": ""765-555-5555"",
""likes"": [
""fashion"",
""spas"",
""shopping""
],
""businesses"": [
{
""name"": ""Entertainment 1080"",
""partner"": ""Jean"",
""status"": ""Bankrupt"",
""date_founded"": {
""$date"": ""2012-05-19T04:00:00Z""
}
},
{
""name"": ""Swag for Tweens"",
""date_founded"": {
""$date"": ""2012-11-01T04:00:00Z""
}
}
]
}
A collection is a group of documents. Collections typically store documents that have similar contents.
Not all documents in a collection are required to have the",Technology & Computing 
"On March 13, 1995, a Parisian conference was held to celebrate 100 years of film. Appropriately named Le cinéma vers son deuxième siècle, the event was specifically focused on cinema’s second century and had invited Danish director Lars von Trier to speak. Prior to his speech, audience members (which included many of the film industry’s most respected names) were handed red pamphlets that would formally announce Dogme 95.
How Dogme 95 began: Vow of Chastity
Together with Thomas Vinterberg, Trier had created a manifesto that deliberately mimicked Truffaut’s Une certaine tendance du cinema, the Cahiers du cinéma article that kickstarted the French New Wave in 1954. Within their manifesto, Trier and Vinterberg compiled a “Vow of Chastity”, in which they laid out the strict terms that would determine whether or not a film could be considered part of the Dogme 95 movement.
Shooting must be performed on location, without providing props or sets that don't logically exist within that setting
Diegetic sound only. Sounds must never be produced, such as music that does not exist within the scene
All shots must be handheld. Movement, immobility and stability must be attained by hand
The film must be in colour, with no special lighting. If there's not enough exposure, a single lamp may be attached to the camera
There can be no optical work or lens filters
No 'superficial' action (such as staged murders, elaborate stunts etc.)
Geographical alienation is strictly forbidden, meaning the fil",art_culture
"Search
Type
All
Articles
Music
People
Search for music pros and content
Language
English
Français
*Your language will be set using a browser cookie.
Login
Log in to Music in Africa
Login with Facebook
Login with Google
E-mail
*
Password
*
Leave this field blank
Menu
Artists & Industry
Close
All Artists & Industry
(52 488)
Artists
(38 492)
Bands /groups
DJs
Producers
Composers, arrangers & songwriters
Choirs, orchestras & ensembles
Session artists
Solo artists
Sound artists
Spoken word
Other
Artist Service Providers
(7 729)
Video Producers
Legal Experts
Audio Engineers
Collecting Societies
Distributors
Marketing Experts
Recording Studios
Record Labels
Publishers
Retailers
Managers
Events & Venues
(3 840)
Event Suppliers
Events
Venues
Archives & Media
(3 148)
Archives
TV channels
Publications
Radio Stations
Music Education
(2 838)
Primary & secondary schools
Academies
Colleges
University departments
Community music centres
Libraries
Online educators
Private tutors
Other
Organizations, Networks & Associations
(4 107)
Culture development
Legal/copyrights
Networks
Funding
Education
Media
Production & Technical
Research
Events
Marketing
Associations
Other
Create a profile
Magazine
Close
Magazine
News
Roskilde Festival deepens commitment to Africa-focused cultural collaboration
Nigeria: BNXN shares sophomore album Captain
Angola: Agatchu announces sophomore EP Vibe
Reviews
Review: M. Rumbi’s Goodbye Goldfish
Angola: DJs Satélite and Gálio reclaim roots with Afro-house album Raízes
A",art_culture
"How to Budget Money in 5 Steps
Divide your income among needs, wants, savings and debt repayment.
Many, or all, of the products featured on this page are from our advertising partners who compensate us when you take certain actions on our website or click to take an action on their website. However, this does not influence our evaluations. Our opinions are our own. Here is a list of our partners and here's how we make money.
A budget is a plan for how you use your money. No matter how much you earn or how often you get paid, a budget helps you stay on top of your bills, savings and other money goals. It can give you more control and less stress.
How to create a budget: step-by-step
To budget money, follow the five steps below.
Step 1. Figure out your after-tax income
If you get a regular paycheck, the amount you bring home is your after-tax income. This is also called your net income or take-home pay.
If money is taken out of your paycheck for things like a 401(k) or insurance, add that back in when making your budget. That way, you'll see your full income.
If you have other types of money coming in — such as from side gigs — subtract anything that reduces that income, such as taxes and business expenses.
Step 2. Choose a budgeting system
A budgeting system is a plan for how to use your money. Everyone has different habits, personality types and approaches to managing money, and there are systems that can fit your lifestyle.
Every budget should cover your needs, some wants an",economics_finance
"9 Investment Strategies for New Investors
The best investing strategies increase returns, minimize risk and meet your goals. Find the strategy that's right for you.
Many, or all, of the products featured on this page are from our advertising partners who compensate us when you take certain actions on our website or click to take an action on their website. However, this does not influence our evaluations. Our opinions are our own. Here is a list of our partners and here's how we make money.
The investing information provided on this page is for educational purposes only. NerdWallet, Inc. does not offer advisory or brokerage services, nor does it recommend or advise investors to buy or sell particular stocks, securities or other investments.
If you're ready to start investing, a good rule of thumb is to ask yourself some basic questions: What are your goals? How much time until you want to reach them? How comfortable are you with risk? Do you know how much you want to invest?
This is where investment strategies come into play.
What are investment strategies?
An investment strategy is a way of thinking that shapes how you select the investments in your portfolio. The best strategies should help you meet your financial goals and grow your wealth while maintaining a level of risk that lets you sleep at night. The strategy you choose may influence everything from the types of assets you invest in to how you approach buying and selling those assets.
9 popular investment strategies
",economics_finance
"Population and Epidemiology Studies
Research Making a Difference
Research Making a Difference
WHY IT'S IMPORTANT
Researchers know that populations vary in their susceptibility to and resilience against heart, lung, blood, and sleep disorders, as well as in disease course and outcomes. These differences sometimes are caused by age, sex, race, ancestry or genetic factors that cannot be changed. In other cases, these differences are due to factors that can be changed or modified, such as lifestyle choices or environment, and some biological factors. Future research will help to better understand the causes of population health differences and to identify strategies that effectively address these differences before they become health disparities. Health disparities are differences in the risk, burden of diseases, and adverse health conditions that exist among specific population groups.
KEY ACCOMPLISHMENTS
- The multi-generational Framingham Heart Study helped discover risk factors and interventions to prevent heart disease, and continues to drive discovery.
- The landmark Women’s Health Initiative (WHI) found that hormone replacement therapy did not prevent heart disease as thought in post-menopausal women.
- The long-term Jackson Heart Study revealed that African Americans who took certain health measures had a lower risk for heart disease.
- The Trans-Omics for Precision Medicine (TOPMed) program is leveraging data from participants in NHLBI’s population and epidemiology studi",Health & Medicine 
"LabVIEW has what you need to build automated test systems, fast. Outpace the competition with LabVIEW. Unlike other solutions:
LabVIEW can connect to any instrument, regardless of vendor
LabVIEW has a native user interface for monitoring and controlling test
LabVIEW has thousands of engineering analysis functions
LabVIEW works with popular programming languages, such as Python, C, and .NET",Technology & Computing 
"Reading Time: 6 minutes
Tin Can has been getting lots of people in a twist lately. Early adopters are tweeting and blogging about it and anyone who’s anyone seems to be dropping it into conversations to prove they’re at the cutting edge of learning technologies. It is certainly doing the rounds as the Next Big Thing. But ask anyone, “What is Tin Can? Explain it to me” and more often than not you’ll just get a shrug of the shoulders and a quizzical look.
This is because Tin Can API is pretty confusing to the newcomer. I can vouch for that because I am a newcomer to it myself. This blog post is my collected notes and thoughts from one day spent learning about Tin Can API. It’s become pretty clear over recent weeks to me that most people understand that Tin Can API is the next version of the SCORM standard, but few people realise that it is still only at the DRAFT stage. There is a high level of vendor ‘early adopter’ activity with technology companies implementing the draft standard but there is also a high level of vendor hype with people like Articulate touting Articulate Online as a “Tin Can API-supported learning management system”. The level of hype makes it sound more real than it is, and the race to innovate seems to have taken the standards definition squad by surprise. While these people are still working on the final revisions to the draft specification, the hype in the vendor market is leading e-learning practitioners to eagerly search out press releases and marketin",Technology & Computing 
"For many reasons—legal, business, and ethical—Oracle recognizes the need for our applications, and our customers' and partners' products built with our tools, to be usable by the disabled community. The Oracle Accessibility Program Office is responsible for defining the corporate standards for accessibility, and developing materials to train all employees so that they can successfully create products that meet those standards.
“Oracle is committed to creating accessible technologies and products that enhance the overall workplace environment and contribute to the productivity of our employees, our customers, and our customers' customers.”
Oracle has many technical papers and demos to help you learn how to configure and operate certain Oracle products if you have a disability, and in the case of a tool, how to configure and operate the product to produce accessible output. We recommend that you refer to the complete documentation set of the respective product for more information.
The ultimate success of a user with a disability interacting with Oracle products depends on many factors besides just our software. To gain a better understanding of the elements that may contribute to a successful experience using the accessibility features of our products, read The Accessibility Puzzle.
In honor of NDEAM and World Standards Day on Saturday, October 14, Oracle supports and celebrates the continuous progression of global accessibility standards. These standards empower all web users",Technology & Computing 
"Pennington Biomedical Research Center publicly introduced its Greaux Healthy initiative, a public service initiative designed to help improve Louisiana kids’ health at every age, during the weekly Red Stick Farmers Market on Thursday. Developed in partnership with the State of Louisiana, Greaux Healthy implements 35 years of Pennington Biomedical research and discoveries to inform tools, resources and programing for children, parents, healthcare providers and educators throughout the state.
Pennington Biomedical Research Center, a campus of Louisiana State University, is a world-renowned leader at the forefront of medical discoveries related to obesity, diabetes, cardiovascular disease, cancer and dementia. Our scientists conduct basic, clinical and population health research with the vision of leading the world in promoting metabolic health and eliminating metabolic disease through scientific discoveries that create solutions from cells to society.",Health & Medicine 
